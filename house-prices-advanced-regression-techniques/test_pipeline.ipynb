{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Configuration ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas\n",
      "1.3.5\n",
      "sklearn\n",
      "1.0.2\n",
      "xgboost\n",
      "1.6.2\n",
      "category_encoders\n",
      "2.6.0\n",
      "seaborn\n",
      "0.11.2\n",
      "matplotlib\n",
      "3.5.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpt\n",
    "import category_encoders as ce\n",
    "import xgboost as xgb\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from pandas.core.frame import DataFrame\n",
    "from category_encoders import MEstimateEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print('pandas')\n",
    "print(pd.__version__)\n",
    "print('sklearn')\n",
    "print(skl.__version__)\n",
    "print('xgboost')\n",
    "print(xgb.__version__)\n",
    "print('category_encoders')\n",
    "print(ce.__version__)\n",
    "print('seaborn')\n",
    "print(sns.__version__)\n",
    "print('matplotlib')\n",
    "print(mpt.__version__)\n",
    "\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "# Mute warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../input/house-prices-advanced-regression-techniques/\")\n",
    "df_train = pd.read_csv(data_dir / \"train.csv\", index_col=\"Id\")\n",
    "df_test = pd.read_csv(data_dir / \"test.csv\", index_col=\"Id\")\n",
    "# Merge the splits so we can process them together\n",
    "df_in = pd.concat([df_train, df_test])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X, y, model=XGBRegressor()):\n",
    "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
    "    log_y = np.log(y)\n",
    "    score = cross_val_score(\n",
    "        model, X, log_y, cv=5, scoring=\"neg_mean_squared_error\",\n",
    "    )\n",
    "    score = -1 * score.mean()\n",
    "    score = np.sqrt(score)\n",
    "    return score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "def clean(df: DataFrame):\n",
    "    df[\"Exterior2nd\"] = df[\"Exterior2nd\"].replace({\"Brk Cmn\": \"BrkComm\"})\n",
    "    # Some values of GarageYrBlt are corrupt, so we'll replace them\n",
    "    # with the year the house was built\n",
    "    df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"].where(\n",
    "        df.GarageYrBlt <= 2010, df.YearBuilt)\n",
    "    # Names beginning with numbers are awkward to work with\n",
    "    df.rename(columns={\n",
    "        \"1stFlrSF\": \"FirstFlrSF\",\n",
    "        \"2ndFlrSF\": \"SecondFlrSF\",\n",
    "        \"3SsnPorch\": \"Threeseasonporch\",\n",
    "    }, inplace=True,\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df_in = clean(df_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "features_nom = [\n",
    "    \"MSSubClass\", \"MSZoning\",\n",
    "    \"Street\", \"Alley\",\n",
    "    \"LandContour\", \"LotConfig\",\n",
    "    \"Neighborhood\", \"Condition1\",\n",
    "    \"Condition2\", \"BldgType\",\n",
    "    \"HouseStyle\", \"RoofStyle\",\n",
    "    \"RoofMatl\", \"Exterior1st\",\n",
    "    \"Exterior2nd\", \"MasVnrType\",\n",
    "    \"Foundation\", \"Heating\",\n",
    "    \"CentralAir\", \"GarageType\",\n",
    "    \"MiscFeature\", \"SaleType\",\n",
    "    \"SaleCondition\"\n",
    "]\n",
    "\n",
    "for name in features_nom:\n",
    "    df_in[name] = df_in[name].astype(\"category\")\n",
    "\n",
    "features_num = list(df_in.select_dtypes(include=np.number).columns)\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='error'))\n",
    "])\n",
    "\n",
    "categorical_column_transformer = ColumnTransformer(\n",
    "    verbose_feature_names_out=False,\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', features_num),\n",
    "        ('cat', categorical_transformer, features_nom)\n",
    "    ])\n",
    "\n",
    "\n",
    "class RestoreColumnTransformer(BaseEstimator):\n",
    "\n",
    "    def __init__(self, transformer:ColumnTransformer):\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.transformer.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_out = self.transformer.transform(X)\n",
    "        df_out = pd.DataFrame(\n",
    "            X_out, columns=self.transformer.get_feature_names_out(), index=X.index)\n",
    "        return df_out\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup pipeline ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (2919, 59), indices imply (2919, 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m\n\u001b[0;32m      9\u001b[0m imputer_transformer \u001b[39m=\u001b[39m FunctionTransformer(imput)\n\u001b[0;32m     11\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline(steps\u001b[39m=\u001b[39m[\n\u001b[0;32m     12\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mrestore\u001b[39m\u001b[39m'\u001b[39m, RestoreColumnTransformer(categorical_column_transformer)),\n\u001b[0;32m     13\u001b[0m     \u001b[39m# ('imputer', imputer_transformer),\u001b[39;00m\n\u001b[0;32m     14\u001b[0m ], verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 16\u001b[0m transformed_df: DataFrame \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mfit_transform(df_in)\n\u001b[0;32m     18\u001b[0m df_train \u001b[39m=\u001b[39m transformed_df\u001b[39m.\u001b[39mloc[df_train\u001b[39m.\u001b[39mindex, :]\n\u001b[0;32m     19\u001b[0m df_test \u001b[39m=\u001b[39m transformed_df\u001b[39m.\u001b[39mloc[df_test\u001b[39m.\u001b[39mindex, :]\n",
      "File \u001b[1;32md:\\projects\\ai\\house-prices-advanced-regression-techniques\\.venv\\lib\\site-packages\\sklearn\\pipeline.py:436\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39mfit_transform(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    435\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 436\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\u001b[39m.\u001b[39;49mtransform(Xt)\n",
      "Cell \u001b[1;32mIn[8], line 50\u001b[0m, in \u001b[0;36mRestoreColumnTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m     49\u001b[0m     X_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m---> 50\u001b[0m     df_out \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(\n\u001b[0;32m     51\u001b[0m         X_out, columns\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer\u001b[39m.\u001b[39;49mfeature_names_in_, index\u001b[39m=\u001b[39;49mX\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m df_out\n",
      "File \u001b[1;32md:\\projects\\ai\\house-prices-advanced-regression-techniques\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:672\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    662\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    663\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    664\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    669\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    670\u001b[0m         )\n\u001b[0;32m    671\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 672\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    673\u001b[0m             data,\n\u001b[0;32m    674\u001b[0m             index,\n\u001b[0;32m    675\u001b[0m             columns,\n\u001b[0;32m    676\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    677\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    678\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[0;32m    679\u001b[0m         )\n\u001b[0;32m    681\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32md:\\projects\\ai\\house-prices-advanced-regression-techniques\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:324\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[39m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    320\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[0;32m    321\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[0;32m    322\u001b[0m )\n\u001b[1;32m--> 324\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[0;32m    326\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    328\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32md:\\projects\\ai\\house-prices-advanced-regression-techniques\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:393\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    391\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[0;32m    392\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[1;32m--> 393\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (2919, 59), indices imply (2919, 80)"
     ]
    }
   ],
   "source": [
    "def imput(X: DataFrame):\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_out = imputer.fit_transform(X)\n",
    "    X_out = pd.DataFrame(\n",
    "        X_out, columns=X.columns, index=X.index)\n",
    "    return X_out\n",
    "\n",
    "\n",
    "imputer_transformer = FunctionTransformer(imput)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('restore', RestoreColumnTransformer(categorical_column_transformer)),\n",
    "    ('imputer', imputer_transformer),\n",
    "], verbose=False)\n",
    "\n",
    "transformed_df: DataFrame = pipeline.fit_transform(df_in)\n",
    "\n",
    "df_train = transformed_df.loc[df_train.index, :]\n",
    "df_test = transformed_df.loc[df_test.index, :]\n",
    "\n",
    "y = df_train.pop('SalePrice')\n",
    "X = df_train\n",
    "\n",
    "df_test.pop('SalePrice')\n",
    "X_test = df_test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor params ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    xgb_params = dict(\n",
    "        predictor='cpu_predictor',\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 2, 20),\n",
    "        num_parallel_tree=5,\n",
    "        learning_rate=trial.suggest_float(\n",
    "            \"learning_rate\", 1e-4, 1e-1, log=True),\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 1000, 12000),\n",
    "        min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 15),\n",
    "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n",
    "        reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n",
    "    )\n",
    "    xgb = XGBRegressor(random_state=0, **xgb_params)\n",
    "    return score_dataset(X, y, xgb)\n",
    "\n",
    "\n",
    "# study = optuna.create_study(direction=\"minimize\")\n",
    "# study.optimize(objective, n_trials=320)\n",
    "# xgb_params = study.best_params\n",
    "# print('Best params:')\n",
    "# print(xgb_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'num_parallel_tree': 5,\n",
    "    # 'predictor': 'cpu_predictor',\n",
    "    'max_depth': 3, \n",
    "    'learning_rate': 0.021417776537357703, \n",
    "    'n_estimators': 3197, \n",
    "    'min_child_weight': 1, \n",
    "    'colsample_bytree': 0.2019378980891107, \n",
    "    'subsample': 0.7824234012865849, \n",
    "    'reg_alpha': 0.002657877890767917, \n",
    "    'reg_lambda': 0.0008794544069627564\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.4s\n",
      "Scores:\n",
      " 0.11882136204052456\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(random_state=0, **xgb_params)\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('model', model)\n",
    "], verbose=True)\n",
    "\n",
    "scores = score_dataset(X, y, model=pipeline)\n",
    "\n",
    "print(\"Scores:\\n\", scores)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prev: 0.11926628354817692\n",
    "\n",
    "new:  0.11882136204052456"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model and Create Submissions #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(random_state=0,**xgb_params)\n",
    "xgb.fit(X, np.log(y))\n",
    "predictions = np.exp(xgb.predict(X_test))\n",
    "\n",
    "output = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac50c5aa4e15216d19d3b7167f93d59ed672a4f5fd2eb8af64e7f0aefedf61f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
