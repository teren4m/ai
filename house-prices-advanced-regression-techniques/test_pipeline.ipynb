{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Configuration ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import optuna\n",
    "import matplotlib as mpt\n",
    "import category_encoders as ce\n",
    "import xgboost as xgb\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from pandas.core.frame import DataFrame\n",
    "from category_encoders import MEstimateEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print('pandas')\n",
    "print(pd.__version__)\n",
    "print('sklearn')\n",
    "print(skl.__version__)\n",
    "print('xgboost')\n",
    "print(xgb.__version__)\n",
    "print('category_encoders')\n",
    "print(ce.__version__)\n",
    "print('seaborn')\n",
    "print(sns.__version__)\n",
    "print('matplotlib')\n",
    "print(mpt.__version__)\n",
    "\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "# Mute warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../input/house-prices-advanced-regression-techniques/\")\n",
    "df_train = pd.read_csv(data_dir / \"train.csv\", index_col=\"Id\")\n",
    "df_test = pd.read_csv(data_dir / \"test.csv\", index_col=\"Id\")\n",
    "# Merge the splits so we can process them together\n",
    "df_in = pd.concat([df_train, df_test])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X, y, model=XGBRegressor()):\n",
    "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
    "    log_y = np.log(y)\n",
    "    score = cross_val_score(\n",
    "        model, X, log_y, cv=5, scoring=\"neg_mean_squared_error\",\n",
    "    )\n",
    "    score = -1 * score.mean()\n",
    "    score = np.sqrt(score)\n",
    "    return score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "def clean(df: DataFrame):\n",
    "    df[\"Exterior2nd\"] = df[\"Exterior2nd\"].replace({\"Brk Cmn\": \"BrkComm\"})\n",
    "    # Some values of GarageYrBlt are corrupt, so we'll replace them\n",
    "    # with the year the house was built\n",
    "    df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"].where(\n",
    "        df.GarageYrBlt <= 2010, df.YearBuilt)\n",
    "    # Names beginning with numbers are awkward to work with\n",
    "    df.rename(columns={\n",
    "        \"1stFlrSF\": \"FirstFlrSF\",\n",
    "        \"2ndFlrSF\": \"SecondFlrSF\",\n",
    "        \"3SsnPorch\": \"Threeseasonporch\",\n",
    "    }, inplace=True,\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df_in = clean(df_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "def to_dataframe(index, columns):\n",
    "    return FunctionTransformer(lambda X: pd.DataFrame(X, index=index, columns=columns))\n",
    "\n",
    "\n",
    "features_nom = [\n",
    "    \"MSSubClass\", \"MSZoning\",\n",
    "    \"Street\", \"Alley\",\n",
    "    \"LandContour\", \"LotConfig\",\n",
    "    \"Neighborhood\", \"Condition1\",\n",
    "    \"Condition2\", \"BldgType\",\n",
    "    \"HouseStyle\", \"RoofStyle\",\n",
    "    \"RoofMatl\", \"Exterior1st\",\n",
    "    \"Exterior2nd\", \"MasVnrType\",\n",
    "    \"Foundation\", \"Heating\",\n",
    "    \"CentralAir\", \"GarageType\",\n",
    "    \"MiscFeature\", \"SaleType\",\n",
    "    \"SaleCondition\"\n",
    "]\n",
    "\n",
    "for name in features_nom:\n",
    "    df_in[name] = df_in[name].astype(\"category\")\n",
    "\n",
    "features_num = list(df_in.select_dtypes(include=np.number).columns)\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant',\n",
    "     missing_values=np.nan, fill_value='None')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)),\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup pipeline ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = ['SalePrice']\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    verbose_feature_names_out=False,\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, features_nom),\n",
    "        ('price', 'passthrough', y_column),\n",
    "    ])\n",
    "\n",
    "\n",
    "transform_pipeline = Pipeline(steps=[\n",
    "    ('encode', column_transformer),\n",
    "    ('dataframe', to_dataframe(df_in.index, features_nom + y_column)),\n",
    "], verbose=False)\n",
    "\n",
    "transformed_df = transform_pipeline.fit_transform(df_in)\n",
    "\n",
    "\n",
    "df_train = transformed_df.loc[df_train.index, :]\n",
    "df_test = transformed_df.loc[df_test.index, :]\n",
    "\n",
    "y = df_train.pop('SalePrice')\n",
    "X = df_train\n",
    "\n",
    "df_test.pop('SalePrice')\n",
    "X_test = df_test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor params ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    xgb_params = dict(\n",
    "        predictor='cpu_predictor',\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 2, 20),\n",
    "        num_parallel_tree=5,\n",
    "        learning_rate=trial.suggest_float(\n",
    "            \"learning_rate\", 1e-4, 1e-1, log=True),\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 1000, 12000),\n",
    "        min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 15),\n",
    "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n",
    "        reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n",
    "    )\n",
    "    xgb = XGBRegressor(random_state=0, **xgb_params)\n",
    "    return score_dataset(X, y, xgb)\n",
    "\n",
    "\n",
    "# study = optuna.create_study(direction=\"minimize\")\n",
    "# study.optimize(objective, n_trials=320)\n",
    "# xgb_params = study.best_params\n",
    "# print('Best params:')\n",
    "# print(xgb_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'num_parallel_tree': 5,\n",
    "    'predictor': 'cpu_predictor',\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.021417776537357703,\n",
    "    'n_estimators': 3197,\n",
    "    'min_child_weight': 1,\n",
    "    'colsample_bytree': 0.2019378980891107,\n",
    "    'subsample': 0.7824234012865849,\n",
    "    'reg_alpha': 0.002657877890767917,\n",
    "    'reg_lambda': 0.0008794544069627564\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.4s\n",
      "Scores:\n",
      " 0.20151813675487693\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(random_state=0, **xgb_params)\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('model', model)\n",
    "], verbose=True)\n",
    "\n",
    "scores = score_dataset(X, y, model=pipeline)\n",
    "\n",
    "print(\"Scores:\\n\", scores)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prev: 0.11926628354817692\n",
    "\n",
    "new:  0.11882136204052456"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model and Create Submissions #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(random_state=0, **xgb_params)\n",
    "xgb.fit(X, np.log(y))\n",
    "predictions = np.exp(xgb.predict(X_test))\n",
    "\n",
    "output = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac50c5aa4e15216d19d3b7167f93d59ed672a4f5fd2eb8af64e7f0aefedf61f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
