{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vars ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path('./project_vars.py')\n",
    "is_file_exist = path.is_file()\n",
    "\n",
    "if is_file_exist:\n",
    "    import project_vars\n",
    "\n",
    "is_write_to_results = False if not is_file_exist else project_vars.is_write_to_results\n",
    "save_itermidiate_results = False if not is_file_exist else project_vars.save_itermidiate_results\n",
    "\n",
    "if is_write_to_results:\n",
    "    import results as r\n",
    "\n",
    "def write_to_results(scores: float):\n",
    "    if is_write_to_results:\n",
    "        print(r.result(scores, 'data/results.json'))\n",
    "    else:\n",
    "        print(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Configuration ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib as mpt\n",
    "import category_encoders as ce\n",
    "import xgboost as xgb\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from pandas.core.frame import DataFrame\n",
    "from category_encoders import MEstimateEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer,OrdinalEncoder,OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "print(\"Version info.\")\n",
    "print (sys.version_info)\n",
    "\n",
    "print('pandas')\n",
    "print(pd.__version__)\n",
    "print('sklearn')\n",
    "print(skl.__version__)\n",
    "print('xgboost')\n",
    "print(xgb.__version__)\n",
    "print('category_encoders')\n",
    "print(ce.__version__)\n",
    "print('seaborn')\n",
    "print(sns.__version__)\n",
    "print('matplotlib')\n",
    "print(mpt.__version__)\n",
    "\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "# Mute warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "y_column_name = 'SalePrice'\n",
    "\n",
    "def to_dataframe(index, columns):\n",
    "    return FunctionTransformer(lambda X: pd.DataFrame(X, index=index, columns=columns))\n",
    "\n",
    "path = Path('./vars.py')\n",
    "\n",
    "print(path.is_file())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../input/house-prices-advanced-regression-techniques/\")\n",
    "df_train = pd.read_csv(data_dir / \"train.csv\", index_col=\"Id\")\n",
    "df_test = pd.read_csv(data_dir / \"test.csv\", index_col=\"Id\")\n",
    "# Merge the splits so we can process them together\n",
    "df_in_raw = pd.concat([df_train, df_test])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X, y, model=XGBRegressor(), n_jobs=None, fit_params=None):\n",
    "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
    "    log_y = np.log(y)\n",
    "    score = cross_val_score(\n",
    "        model, X, log_y, cv=5,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        n_jobs=n_jobs,\n",
    "        fit_params=fit_params,\n",
    "    )\n",
    "    score = -1 * score.mean()\n",
    "    score = np.sqrt(score)\n",
    "    return score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliners ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = df_in_raw[df_in_raw.LotArea < 100000]\n",
    "df_train = df_train[df_train.LotArea < 100000]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform PoolQC ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PoolQC = df_in[['PoolQC']]\n",
    "df_in['IsPoolExist'] = PoolQC.notna().astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforme Alley ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alley = df_in[['Alley']]\n",
    "df_in['IsAlleyExist'] = Alley.notna().astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforme Fence ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fence = df_in[['Fence']]\n",
    "df_in['IsFenceExist'] = Fence.notna().astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove useless ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_columns = [\n",
    "    'YrSold',\n",
    "    'MoSold',\n",
    "    'Utilities',\n",
    "    'RoofMatl',\n",
    "    '3SsnPorch',\n",
    "    'MiscFeature',\n",
    "    'BsmtFinSF2',\n",
    "    'Condition2',\n",
    "    \n",
    "    'PoolQC',\n",
    "    'PoolArea',\n",
    "    'Alley',\n",
    "]\n",
    "df_in = df_in.drop(removed_columns, axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df: DataFrame) -> DataFrame:\n",
    "    df[\"Exterior2nd\"] = df[\"Exterior2nd\"].replace({\"Brk Cmn\": \"BrkComm\"})\n",
    "    # Some values of GarageYrBlt are corrupt, so we'll replace them\n",
    "    # with the year the house was built\n",
    "    df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"].where(\n",
    "        df.GarageYrBlt <= 2010, df.YearBuilt)\n",
    "    # Names beginning with numbers are awkward to work with\n",
    "    df.rename(columns={\n",
    "        \"1stFlrSF\": \"FirstFlrSF\",\n",
    "        \"2ndFlrSF\": \"SecondFlrSF\",\n",
    "        # \"3SsnPorch\": \"Threeseasonporch\",\n",
    "    }, inplace=True,\n",
    "    )\n",
    "    # df[\"MiscFeature\"] = df[\"MiscFeature\"].replace({\"Othr\": np.nan}).replace({\"TenC\": np.nan}).replace({\"Gar2\": np.nan})\n",
    "    return df\n",
    "\n",
    "df_in = clean(df_in)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode nominative (unordered) categorical features ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nominative = [\n",
    "    \"MSSubClass\", \n",
    "    \"MSZoning\",\n",
    "    \"Street\", \n",
    "    # \"Alley\",\n",
    "    \"LandContour\", \n",
    "    \"LotConfig\",\n",
    "    \"Neighborhood\", \n",
    "    \"Condition1\",\n",
    "    \"Condition2\", \n",
    "    \"BldgType\",\n",
    "    \"HouseStyle\", \n",
    "    \"RoofStyle\",\n",
    "    \"RoofMatl\", \n",
    "    \"Exterior1st\",\n",
    "    \"Exterior2nd\", \n",
    "    \"MasVnrType\",\n",
    "    \"Foundation\", \n",
    "    \"Heating\",\n",
    "    \"GarageType\",\n",
    "    # \"MiscFeature\", \n",
    "    \"SaleType\",\n",
    "    \"SaleCondition\",\n",
    "    # \"MiscFeature\",\n",
    "]\n",
    "\n",
    "features_nominative = [item for item in features_nominative if item not in removed_columns]\n",
    "\n",
    "one_hot_count = sum([len(df_in[column].unique())\n",
    "                    for column in features_nominative]) - 1\n",
    "\n",
    "one_hote_names = ['OH{}'.format(name) for name in range(one_hot_count)]\n",
    "\n",
    "for name in features_nominative:\n",
    "    df_in[name] = df_in[name].astype(\"category\")\n",
    "\n",
    "categorical_nominative_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(\n",
    "        strategy='constant',\n",
    "        missing_values=np.nan,\n",
    "        fill_value='None')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "    # ('encoder', OrdinalEncoder(\n",
    "    #     handle_unknown='use_encoded_value',\n",
    "    #     unknown_value=np.nan\n",
    "    # )),\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the ordinal (ordered) categorical features ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas calls the categories \"levels\"\n",
    "five_levels = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
    "ten_levels = list(range(1,11))\n",
    "\n",
    "ordered_levels_int = {\n",
    "    \"OverallQual\": ten_levels,\n",
    "    \"OverallCond\": ten_levels,\n",
    "}\n",
    "\n",
    "ordered_levels_int = {key: ordered_levels_int[key] for key in ordered_levels_int.keys() if key not in removed_columns}\n",
    "\n",
    "ordered_levels = {\n",
    "    \"ExterQual\": five_levels,\n",
    "    \"ExterCond\": five_levels,\n",
    "    \"BsmtQual\": five_levels,\n",
    "    \"BsmtCond\": five_levels,\n",
    "    \"HeatingQC\": five_levels,\n",
    "    \"KitchenQual\": five_levels,\n",
    "    \"FireplaceQu\": five_levels,\n",
    "    \"GarageQual\": five_levels,\n",
    "    \"GarageCond\": five_levels,\n",
    "    \"PoolQC\": five_levels,\n",
    "    \"LotShape\": [\"Reg\", \"IR1\", \"IR2\", \"IR3\"],\n",
    "    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n",
    "    \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n",
    "    \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n",
    "    \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n",
    "    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n",
    "    \"Utilities\": [\"NoSeWa\", \"NoSewr\", \"AllPub\"],\n",
    "    \"CentralAir\": [\"N\", \"Y\"],\n",
    "    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n",
    "    \"Fence\": [\"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n",
    "}\n",
    "\n",
    "ordered_levels = {key: ordered_levels[key] for key in ordered_levels.keys() if key not in removed_columns}\n",
    "\n",
    "features_ordered = list(ordered_levels.keys())\n",
    "features_ordered_int = list(ordered_levels_int.keys())\n",
    "\n",
    "for name, levels in ordered_levels.items():\n",
    "    df_in[name] = df_in[name].astype(CategoricalDtype(levels, ordered=True))\n",
    "\n",
    "for name, levels in ordered_levels_int.items():\n",
    "    df_in[name] = df_in[name].astype(CategoricalDtype(levels, ordered=True))\n",
    "\n",
    "categorical_ordinal_int_transformer = Pipeline(\n",
    "    steps=[\n",
    "         ('imputer', SimpleImputer(\n",
    "            strategy='constant',\n",
    "            missing_values=np.nan,\n",
    "            fill_value=0)),\n",
    "        ('encoder', OrdinalEncoder(\n",
    "            handle_unknown='use_encoded_value', unknown_value=np.nan)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_ordinal_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(\n",
    "            strategy='constant',\n",
    "            missing_values=np.nan,\n",
    "            fill_value='None')),\n",
    "        ('encoder', OrdinalEncoder(\n",
    "            handle_unknown='use_encoded_value', unknown_value=np.nan)),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical data transform ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_num = list(\n",
    "    df_in.select_dtypes(include=np.number)\n",
    "    .columns\n",
    "    .difference([y_column_name])\n",
    "    )\n",
    "\n",
    "print(list(features_num))\n",
    "\n",
    "numerical_constant_transformer = Pipeline(steps=[\n",
    "    ('imputer_constant', SimpleImputer(strategy='constant', fill_value=0,\n",
    "     missing_values=np.nan)),\n",
    "])\n",
    "\n",
    "len(features_num)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup pipeline ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    verbose_feature_names_out=False,\n",
    "    transformers=[\n",
    "        ('num_constant', numerical_constant_transformer, features_num),\n",
    "        ('cat_nominative', categorical_nominative_transformer, features_nominative),\n",
    "        ('cat_ordered', categorical_ordinal_transformer, features_ordered),\n",
    "        ('cat_ordered_int', categorical_ordinal_int_transformer, features_ordered_int),\n",
    "        ('price', 'passthrough', [y_column_name]),\n",
    "    ], verbose=True)\n",
    "\n",
    "\n",
    "transform_pipeline = Pipeline(steps=[\n",
    "    ('encode', column_transformer),\n",
    "    ('dataframe', to_dataframe(df_in.index,\n",
    "                               features_num +\n",
    "                               one_hote_names +\n",
    "                            #    features_nominative +\n",
    "                               features_ordered +\n",
    "                               features_ordered_int +\n",
    "                               [y_column_name]\n",
    "                               )),\n",
    "], verbose=True)\n",
    "\n",
    "transformed_df = transform_pipeline.fit_transform(df_in)\n",
    "\n",
    "\n",
    "df_train = transformed_df.loc[df_train.index, :]\n",
    "df_test = transformed_df.loc[df_test.index, :]\n",
    "\n",
    "y: DataFrame = df_train.pop('SalePrice')\n",
    "X: DataFrame = df_train\n",
    "\n",
    "if save_itermidiate_results:\n",
    "    y.to_csv('data/y.csv')\n",
    "    X.to_csv('data/X.csv')\n",
    "\n",
    "df_test.pop('SalePrice')\n",
    "X_test = df_test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor params ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_estimators = 20000\n",
    "xgb_params = {\n",
    "    # \"colsample_bylevel\": 0.3874941751507784,\n",
    "    # \"colsample_bynode\": 0.5619050645629974,\n",
    "    # \"colsample_bytree\": 0.7664751627840607,\n",
    "    # \"eta\": 0.8923067850311843,\n",
    "    \n",
    "    # \"max_depth\": 4,\n",
    "    # \"min_child_weight\": 3,\n",
    "    # \"reg_alpha\": 0.0077501013720934625,\n",
    "    # \"reg_lambda\": 0.9819773887231251,\n",
    "    # \"subsample\": 0.5597482197496666,\n",
    "    # \"gamma\": 0,\n",
    "    \"learning_rate\": 0.006,\n",
    "    \"predictor\": \"cpu_predictor\",\n",
    "    \"num_parallel_tree\": 1,\n",
    "    \"n_estimators\": max_n_estimators\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stop ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X, y, test_size=0.25)\n",
    "\n",
    "model = XGBRegressor(random_state=0, nthread=9, **xgb_params)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_validation, y_validation)],\n",
    "    eval_metric='rmsle',\n",
    "    early_stopping_rounds=max_n_estimators*0.1,\n",
    ")\n",
    "\n",
    "results = model.evals_result()\n",
    "training_loss: list[float] = results['validation_0']['rmsle']\n",
    "validation_loss: list[float] = results['validation_1']['rmsle']\n",
    "min_validation_index = validation_loss.index(min(validation_loss))\n",
    "training_loss[min_validation_index]\n",
    "validation_loss[min_validation_index]\n",
    "\n",
    "xgb_params['n_estimators'] = min_validation_index\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(results[\"validation_0\"][\"rmsle\"], label=\"Training loss\")\n",
    "plt.plot(results[\"validation_1\"][\"rmsle\"], label=\"Validation loss\")\n",
    "plt.axvline(min_validation_index, color=\"gray\", label=\"Optimal tree number\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = score_dataset(\n",
    "    X, y,\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "write_to_results(scores)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model and Create Submissions #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(random_state=0, nthread=9,**xgb_params)\n",
    "xgb.fit(X, np.log(y))\n",
    "predictions = np.exp(xgb.predict(X_test))\n",
    "\n",
    "output = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "\n",
    "print(\"Your submission was successfully saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac50c5aa4e15216d19d3b7167f93d59ed672a4f5fd2eb8af64e7f0aefedf61f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
