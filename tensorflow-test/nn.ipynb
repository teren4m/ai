{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from model_profiler import model_profiler\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import cv2 as cv\n",
    "import json\n",
    "import pandas as pd\n",
    "import nvidia_smi\n",
    "from numba import cuda\n",
    "\n",
    "batch_size = 50\n",
    "epoch_size = 3000\n",
    "test_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape\n",
      "(29, 20)\n",
      "\n",
      "output shape\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "def get_txt_data(path: Path) -> np.ndarray:\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        result: list = json.loads(f.readline())\n",
    "        return np.array(flatten(result))\n",
    "\n",
    "\n",
    "# p = pathlib.Path('../../openCV_python/data/out/resized_frames/resized')\n",
    "# txt_files = list(p.glob('*.txt'))\n",
    "# img_files = [item.parent.resolve() / item.stem for item in txt_files]\n",
    "# txt_files[0].stem\n",
    "# image = txt_files[0].parent.resolve() / txt_files[0].stem\n",
    "\n",
    "# img_count = len(txt_files)\n",
    "# img_shape = cv.imread(str(image)).shape\n",
    "\n",
    "# txt_shape = get_txt_data(txt_files[0]).shape\n",
    "\n",
    "# input_shape = (img_count, *img_shape)\n",
    "# output_shape = (img_count, *txt_shape)\n",
    "input_data: np.ndarray = np.load('data/train_input.npy')\n",
    "output_data: np.ndarray = np.load('data/train_output.npy')\n",
    "input_shape = input_data.shape[1:]\n",
    "output_shape = output_data.shape[1:]\n",
    "# data = []\n",
    "\n",
    "# for i in range(len(img_files)):\n",
    "#     input_data[i] = cv.imread(str(img_files[i]))\n",
    "#     output_data[i] = get_txt_data(txt_files[i])\n",
    "\n",
    "print('input shape')\n",
    "print(input_shape)\n",
    "print()\n",
    "print('output shape')\n",
    "print(output_shape)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    l = len(input_data)\n",
    "    last = l - 1\n",
    "    first = int(l-l/test_len)\n",
    "    train_images = input_data[0:first]\n",
    "    train_labels = output_data[0:first]\n",
    "\n",
    "    test_images = input_data[first:last]\n",
    "    test_labels = output_data[first:last]\n",
    "    print('Train shape: {}'.format(train_images.shape))\n",
    "    print('Test shape: {}'.format(test_images.shape))\n",
    "\n",
    "    return (train_images, train_labels), (test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5404, 29, 20)\n",
      "Test shape: (771, 29, 20)\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_data()\n",
    "input_shape = train_images.shape[1:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x00000155D8C0BAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x00000155D8C0BAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_5 (Normalizat  (None, 29, 20)           3         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 27, 32)            1952      \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 25, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 12, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 122880)            47308800  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1024)              125830144 \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173,152,203\n",
      "Trainable params: 173,152,200\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "activation_fun = 'gelu'\n",
    "print(np.prod(input_shape))\n",
    "\n",
    "normalization = tf.keras.layers.Normalization(axis=None)\n",
    "normalization.adapt([0,255.0])\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Input(input_shape))\n",
    "model.add(normalization)\n",
    "model.add(tf.keras.layers.Conv1D(32, 3, activation=activation_fun))\n",
    "model.add(tf.keras.layers.Conv1D(32, 3, activation=activation_fun))\n",
    "model.add(tf.keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(1024 * 120, activation_fun))\n",
    "# model.add(tf.keras.layers.Dropout(0.6))\n",
    "model.add(tf.keras.layers.Dense(1024, activation_fun))\n",
    "model.add(tf.keras.layers.Dense(8))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = model_profiler(model, batch_size)\n",
    "\n",
    "# print(profile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 158.8749 - val_loss: 102.1942\n",
      "Epoch 2/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 92.2337 - val_loss: 146.0277\n",
      "Epoch 3/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 82.9538 - val_loss: 76.9187\n",
      "Epoch 4/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 66.6021 - val_loss: 66.3920\n",
      "Epoch 5/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 60.3189 - val_loss: 60.0926\n",
      "Epoch 6/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 54.5770 - val_loss: 61.7322\n",
      "Epoch 7/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 53.0181 - val_loss: 54.2667\n",
      "Epoch 8/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 47.5472 - val_loss: 54.6726\n",
      "Epoch 9/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 44.6838 - val_loss: 49.4141\n",
      "Epoch 10/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 43.7782 - val_loss: 41.0352\n",
      "Epoch 11/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 38.2210 - val_loss: 55.0952\n",
      "Epoch 12/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 38.2679 - val_loss: 44.6197\n",
      "Epoch 13/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 35.4806 - val_loss: 45.2260\n",
      "Epoch 14/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 34.7806 - val_loss: 40.0281\n",
      "Epoch 15/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 33.0194 - val_loss: 38.2987\n",
      "Epoch 16/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 31.9074 - val_loss: 38.4675\n",
      "Epoch 17/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 29.4067 - val_loss: 31.6783\n",
      "Epoch 18/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 27.4532 - val_loss: 31.1882\n",
      "Epoch 19/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 25.6049 - val_loss: 30.1300\n",
      "Epoch 20/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 24.5042 - val_loss: 30.6012\n",
      "Epoch 21/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 25.8935 - val_loss: 28.7749\n",
      "Epoch 22/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 23.7838 - val_loss: 29.8612\n",
      "Epoch 23/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 22.4836 - val_loss: 26.3707\n",
      "Epoch 24/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 22.2125 - val_loss: 24.5955\n",
      "Epoch 25/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 21.1436 - val_loss: 27.0266\n",
      "Epoch 26/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 21.3554 - val_loss: 24.7254\n",
      "Epoch 27/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 19.7217 - val_loss: 27.1782\n",
      "Epoch 28/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 20.8319 - val_loss: 25.2686\n",
      "Epoch 29/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 20.3942 - val_loss: 25.1331\n",
      "Epoch 30/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 18.9194 - val_loss: 26.8050\n",
      "Epoch 31/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 21.1223 - val_loss: 29.5553\n",
      "Epoch 32/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 21.3982 - val_loss: 22.5264\n",
      "Epoch 33/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 18.7436 - val_loss: 23.5914\n",
      "Epoch 34/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 18.3325 - val_loss: 21.7363\n",
      "Epoch 35/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 16.4522 - val_loss: 21.9087\n",
      "Epoch 36/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 17.1673 - val_loss: 21.1872\n",
      "Epoch 37/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 17.1243 - val_loss: 24.0994\n",
      "Epoch 38/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 16.2378 - val_loss: 23.5736\n",
      "Epoch 39/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 16.3512 - val_loss: 21.6404\n",
      "Epoch 40/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 15.9895 - val_loss: 19.2867\n",
      "Epoch 41/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 15.0099 - val_loss: 19.1156\n",
      "Epoch 42/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 14.8248 - val_loss: 21.1680\n",
      "Epoch 43/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 15.1719 - val_loss: 19.6810\n",
      "Epoch 44/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 14.5957 - val_loss: 18.7140\n",
      "Epoch 45/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 14.4619 - val_loss: 19.2371\n",
      "Epoch 46/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 13.8694 - val_loss: 17.6953\n",
      "Epoch 47/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 13.5492 - val_loss: 20.9030\n",
      "Epoch 48/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 14.1931 - val_loss: 17.8878\n",
      "Epoch 49/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 14.0898 - val_loss: 16.7025\n",
      "Epoch 50/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 13.3074 - val_loss: 17.9746\n",
      "Epoch 51/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 13.3838 - val_loss: 17.5660\n",
      "Epoch 52/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 13.2631 - val_loss: 16.4522\n",
      "Epoch 53/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 15.1937 - val_loss: 17.4424\n",
      "Epoch 54/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 13.7908 - val_loss: 19.1724\n",
      "Epoch 55/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 12.8464 - val_loss: 17.3162\n",
      "Epoch 56/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 12.5325 - val_loss: 17.8456\n",
      "Epoch 57/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 13.6693 - val_loss: 17.2574\n",
      "Epoch 58/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 12.6848 - val_loss: 16.5988\n",
      "Epoch 59/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 12.6301 - val_loss: 16.9201\n",
      "Epoch 60/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 12.5467 - val_loss: 17.6425\n",
      "Epoch 61/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 12.4647 - val_loss: 21.2509\n",
      "Epoch 62/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 13.6301 - val_loss: 17.3571\n",
      "Epoch 63/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 13.3724 - val_loss: 15.4936\n",
      "Epoch 64/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 12.1393 - val_loss: 17.9884\n",
      "Epoch 65/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 11.8234 - val_loss: 18.7762\n",
      "Epoch 66/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 13.1311 - val_loss: 15.9890\n",
      "Epoch 67/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 11.5885 - val_loss: 15.4296\n",
      "Epoch 68/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 11.1973 - val_loss: 17.5794\n",
      "Epoch 69/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 13.8765 - val_loss: 16.8550\n",
      "Epoch 70/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 12.3911 - val_loss: 15.1849\n",
      "Epoch 71/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 11.6656 - val_loss: 17.1721\n",
      "Epoch 72/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 11.4949 - val_loss: 15.0863\n",
      "Epoch 73/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 10.8759 - val_loss: 15.0493\n",
      "Epoch 74/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 10.6954 - val_loss: 20.1683\n",
      "Epoch 75/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 15.3883 - val_loss: 16.1840\n",
      "Epoch 76/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 10.9442 - val_loss: 15.9977\n",
      "Epoch 77/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 11.6660 - val_loss: 16.3838\n",
      "Epoch 78/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 10.5683 - val_loss: 14.3693\n",
      "Epoch 79/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 11.0585 - val_loss: 15.8648\n",
      "Epoch 80/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 13.8149 - val_loss: 14.2429\n",
      "Epoch 81/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 11.0924 - val_loss: 15.1029\n",
      "Epoch 82/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 10.4895 - val_loss: 16.1170\n",
      "Epoch 83/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.9105 - val_loss: 15.4181\n",
      "Epoch 84/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 11.2415 - val_loss: 16.8793\n",
      "Epoch 85/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 11.0996 - val_loss: 14.5030\n",
      "Epoch 86/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 10.2043 - val_loss: 19.0411\n",
      "Epoch 87/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 10.6454 - val_loss: 17.4703\n",
      "Epoch 88/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 10.5018 - val_loss: 17.1448\n",
      "Epoch 89/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 10.4907 - val_loss: 15.6888\n",
      "Epoch 90/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 10.0472 - val_loss: 13.3148\n",
      "Epoch 91/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.2464 - val_loss: 13.0413\n",
      "Epoch 92/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.2225 - val_loss: 14.3766\n",
      "Epoch 93/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.3137 - val_loss: 15.1851\n",
      "Epoch 94/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 10.5505 - val_loss: 16.4614\n",
      "Epoch 95/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 11.4749 - val_loss: 13.8551\n",
      "Epoch 96/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.9734 - val_loss: 16.3652\n",
      "Epoch 97/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.8551 - val_loss: 16.0100\n",
      "Epoch 98/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.7918 - val_loss: 15.9905\n",
      "Epoch 99/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.6585 - val_loss: 14.0668\n",
      "Epoch 100/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.2874 - val_loss: 15.2083\n",
      "Epoch 101/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.5739 - val_loss: 14.5261\n",
      "Epoch 102/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.8558 - val_loss: 12.3164\n",
      "Epoch 103/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.5009 - val_loss: 13.8069\n",
      "Epoch 104/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.0132 - val_loss: 11.8146\n",
      "Epoch 105/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.7671 - val_loss: 13.3979\n",
      "Epoch 106/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.2811 - val_loss: 15.0818\n",
      "Epoch 107/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.0516 - val_loss: 14.5556\n",
      "Epoch 108/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.8405 - val_loss: 11.6617\n",
      "Epoch 109/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.2783 - val_loss: 12.9094\n",
      "Epoch 110/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.5367 - val_loss: 13.0126\n",
      "Epoch 111/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.1834 - val_loss: 13.3700\n",
      "Epoch 112/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.3520 - val_loss: 12.4854\n",
      "Epoch 113/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.4049 - val_loss: 13.8809\n",
      "Epoch 114/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.9651 - val_loss: 12.5378\n",
      "Epoch 115/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.0146 - val_loss: 14.2733\n",
      "Epoch 116/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.8195 - val_loss: 15.3815\n",
      "Epoch 117/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 10.7409 - val_loss: 11.9289\n",
      "Epoch 118/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.9367 - val_loss: 17.1525\n",
      "Epoch 119/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 10.8100 - val_loss: 12.3820\n",
      "Epoch 120/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.4907 - val_loss: 12.5391\n",
      "Epoch 121/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.1541 - val_loss: 13.1592\n",
      "Epoch 122/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.9071 - val_loss: 13.1866\n",
      "Epoch 123/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.6207 - val_loss: 12.8564\n",
      "Epoch 124/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.9734 - val_loss: 13.2975\n",
      "Epoch 125/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.8682 - val_loss: 12.6525\n",
      "Epoch 126/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.2644 - val_loss: 16.7464\n",
      "Epoch 127/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.9815 - val_loss: 13.7390\n",
      "Epoch 128/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.6112 - val_loss: 13.5773\n",
      "Epoch 129/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.9477 - val_loss: 12.8615\n",
      "Epoch 130/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.5391 - val_loss: 13.4666\n",
      "Epoch 131/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.7238 - val_loss: 12.6682\n",
      "Epoch 132/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.4728 - val_loss: 13.6054\n",
      "Epoch 133/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.5853 - val_loss: 14.2431\n",
      "Epoch 134/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.1251 - val_loss: 13.7081\n",
      "Epoch 135/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.4167 - val_loss: 13.0113\n",
      "Epoch 136/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.8282 - val_loss: 14.2702\n",
      "Epoch 137/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.1926 - val_loss: 16.4642\n",
      "Epoch 138/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.8618 - val_loss: 12.4214\n",
      "Epoch 139/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.4200 - val_loss: 11.4719\n",
      "Epoch 140/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.7524 - val_loss: 13.3111\n",
      "Epoch 141/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.4205 - val_loss: 15.0105\n",
      "Epoch 142/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.4755 - val_loss: 15.8817\n",
      "Epoch 143/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.3818 - val_loss: 13.3529\n",
      "Epoch 144/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.4635 - val_loss: 16.5826\n",
      "Epoch 145/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.0377 - val_loss: 13.2711\n",
      "Epoch 146/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.5299 - val_loss: 11.4820\n",
      "Epoch 147/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.6151 - val_loss: 13.0143\n",
      "Epoch 148/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.0574 - val_loss: 12.3880\n",
      "Epoch 149/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.3107 - val_loss: 13.1389\n",
      "Epoch 150/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 9.5351 - val_loss: 11.5727\n",
      "Epoch 151/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.5326 - val_loss: 12.6051\n",
      "Epoch 152/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.0610 - val_loss: 11.2833\n",
      "Epoch 153/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.4240 - val_loss: 12.5672\n",
      "Epoch 154/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 7.4229 - val_loss: 11.4720\n",
      "Epoch 155/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 7.4179 - val_loss: 12.8090\n",
      "Epoch 156/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 7.8461 - val_loss: 11.5252\n",
      "Epoch 157/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 7.3818 - val_loss: 12.3926\n",
      "Epoch 158/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.6506 - val_loss: 11.4218\n",
      "Epoch 159/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.4176 - val_loss: 14.0327\n",
      "Epoch 160/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.1909 - val_loss: 11.3690\n",
      "Epoch 161/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.0189 - val_loss: 12.1598\n",
      "Epoch 162/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.2440 - val_loss: 11.2205\n",
      "Epoch 163/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.9735 - val_loss: 10.4642\n",
      "Epoch 164/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.2574 - val_loss: 11.4918\n",
      "Epoch 165/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.3047 - val_loss: 11.9729\n",
      "Epoch 166/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.7743 - val_loss: 11.5582\n",
      "Epoch 167/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.7269 - val_loss: 11.4326\n",
      "Epoch 168/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.5088 - val_loss: 12.7219\n",
      "Epoch 169/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.6547 - val_loss: 11.5586\n",
      "Epoch 170/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.1894 - val_loss: 11.6212\n",
      "Epoch 171/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.0266 - val_loss: 10.8892\n",
      "Epoch 172/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.2486 - val_loss: 15.2266\n",
      "Epoch 173/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.7677 - val_loss: 12.4821\n",
      "Epoch 174/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.5642 - val_loss: 14.6431\n",
      "Epoch 175/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 8.1937 - val_loss: 11.4026\n",
      "Epoch 176/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.2444 - val_loss: 10.8099\n",
      "Epoch 177/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.8778 - val_loss: 10.9799\n",
      "Epoch 178/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.9918 - val_loss: 11.1618\n",
      "Epoch 179/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.0650 - val_loss: 11.3868\n",
      "Epoch 180/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.6777 - val_loss: 11.8464\n",
      "Epoch 181/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.8692 - val_loss: 10.7204\n",
      "Epoch 182/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.0729 - val_loss: 11.5334\n",
      "Epoch 183/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.4147 - val_loss: 12.6767\n",
      "Epoch 184/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.8298 - val_loss: 11.4369\n",
      "Epoch 185/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.8477 - val_loss: 11.4813\n",
      "Epoch 186/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.7681 - val_loss: 12.1922\n",
      "Epoch 187/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.0458 - val_loss: 11.6717\n",
      "Epoch 188/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.3509 - val_loss: 12.1830\n",
      "Epoch 189/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.9209 - val_loss: 10.7211\n",
      "Epoch 190/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.9962 - val_loss: 11.0405\n",
      "Epoch 191/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.8971 - val_loss: 11.4465\n",
      "Epoch 192/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.9343 - val_loss: 11.1854\n",
      "Epoch 193/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.0047 - val_loss: 12.6550\n",
      "Epoch 194/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.0106 - val_loss: 11.3858\n",
      "Epoch 195/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.1812 - val_loss: 12.1393\n",
      "Epoch 196/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.6605 - val_loss: 13.3521\n",
      "Epoch 197/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.2282 - val_loss: 11.6259\n",
      "Epoch 198/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.4008 - val_loss: 11.1304\n",
      "Epoch 199/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.1892 - val_loss: 10.9248\n",
      "Epoch 200/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.9928 - val_loss: 10.0733\n",
      "Epoch 201/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.3918 - val_loss: 9.6216\n",
      "Epoch 202/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.3272 - val_loss: 11.1213\n",
      "Epoch 203/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.9974 - val_loss: 10.0519\n",
      "Epoch 204/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.5570 - val_loss: 10.6764\n",
      "Epoch 205/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.7194 - val_loss: 10.6948\n",
      "Epoch 206/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.6295 - val_loss: 10.5494\n",
      "Epoch 207/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 6.9516 - val_loss: 14.2022\n",
      "Epoch 208/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 8.0820 - val_loss: 10.4478\n",
      "Epoch 209/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.7906 - val_loss: 11.3337\n",
      "Epoch 210/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 7.1921 - val_loss: 12.7288\n",
      "Epoch 211/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 7.0838 - val_loss: 10.4929\n",
      "Epoch 212/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.6901 - val_loss: 10.4195\n",
      "Epoch 213/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.9039 - val_loss: 13.4021\n",
      "Epoch 214/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.8112 - val_loss: 12.3591\n",
      "Epoch 215/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 7.3122 - val_loss: 10.4805\n",
      "Epoch 216/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.9293 - val_loss: 10.5239\n",
      "Epoch 217/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.7597 - val_loss: 10.9721\n",
      "Epoch 218/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.9176 - val_loss: 10.1817\n",
      "Epoch 219/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.1854 - val_loss: 9.5717\n",
      "Epoch 220/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.8528 - val_loss: 9.8286\n",
      "Epoch 221/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.0436 - val_loss: 9.8270\n",
      "Epoch 222/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.2427 - val_loss: 9.1520\n",
      "Epoch 223/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.9813 - val_loss: 9.7089\n",
      "Epoch 224/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.1066 - val_loss: 10.0254\n",
      "Epoch 225/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.4795 - val_loss: 10.1804\n",
      "Epoch 226/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.3706 - val_loss: 10.3572\n",
      "Epoch 227/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.2866 - val_loss: 12.0164\n",
      "Epoch 228/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 7.6403 - val_loss: 12.8124\n",
      "Epoch 229/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 7.0819 - val_loss: 10.6265\n",
      "Epoch 230/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.1972 - val_loss: 10.0799\n",
      "Epoch 231/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.0062 - val_loss: 12.2205\n",
      "Epoch 232/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.5111 - val_loss: 10.4979\n",
      "Epoch 233/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.1576 - val_loss: 10.5471\n",
      "Epoch 234/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.9345 - val_loss: 9.4806\n",
      "Epoch 235/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.3452 - val_loss: 13.3463\n",
      "Epoch 236/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.6050 - val_loss: 10.4184\n",
      "Epoch 237/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.5094 - val_loss: 10.4391\n",
      "Epoch 238/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.1357 - val_loss: 9.9761\n",
      "Epoch 239/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.0880 - val_loss: 9.5396\n",
      "Epoch 240/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.6696 - val_loss: 10.4569\n",
      "Epoch 241/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.0324 - val_loss: 9.9665\n",
      "Epoch 242/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.3310 - val_loss: 10.2532\n",
      "Epoch 243/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.1503 - val_loss: 11.0595\n",
      "Epoch 244/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.2846 - val_loss: 10.3165\n",
      "Epoch 245/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.5738 - val_loss: 10.7436\n",
      "Epoch 246/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.2666 - val_loss: 10.6333\n",
      "Epoch 247/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.2977 - val_loss: 10.1696\n",
      "Epoch 248/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.0836 - val_loss: 10.6460\n",
      "Epoch 249/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.5668 - val_loss: 9.8373\n",
      "Epoch 250/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 5.8294 - val_loss: 10.5824\n",
      "Epoch 251/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.1793 - val_loss: 9.8473\n",
      "Epoch 252/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.7724 - val_loss: 10.7911\n",
      "Epoch 253/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.8676 - val_loss: 10.9816\n",
      "Epoch 254/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.0715 - val_loss: 10.6024\n",
      "Epoch 255/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.0441 - val_loss: 11.4432\n",
      "Epoch 256/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.6802 - val_loss: 11.6716\n",
      "Epoch 257/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.9228 - val_loss: 10.1377\n",
      "Epoch 258/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.7990 - val_loss: 10.8837\n",
      "Epoch 259/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.1161 - val_loss: 9.6069\n",
      "Epoch 260/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.3247 - val_loss: 11.2086\n",
      "Epoch 261/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 7.3400 - val_loss: 10.7362\n",
      "Epoch 262/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.1285 - val_loss: 10.5560\n",
      "Epoch 263/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.5053 - val_loss: 12.3255\n",
      "Epoch 264/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.9535 - val_loss: 9.9093\n",
      "Epoch 265/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.8445 - val_loss: 10.4823\n",
      "Epoch 266/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.5193 - val_loss: 11.0813\n",
      "Epoch 267/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.5839 - val_loss: 9.4261\n",
      "Epoch 268/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.9590 - val_loss: 9.6243\n",
      "Epoch 269/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.8488 - val_loss: 10.3234\n",
      "Epoch 270/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 6.7814 - val_loss: 9.6407\n",
      "Epoch 271/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.6665 - val_loss: 9.8213\n",
      "Epoch 272/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 6.6572 - val_loss: 9.1562\n",
      "Epoch 273/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.9371 - val_loss: 10.1516\n",
      "Epoch 274/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 5.9264 - val_loss: 11.6819\n",
      "Epoch 275/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 6.7740 - val_loss: 10.2416\n",
      "Epoch 276/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 6.0143 - val_loss: 9.5584\n",
      "Epoch 277/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 6.5061 - val_loss: 11.4827\n",
      "Epoch 278/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.5775 - val_loss: 10.9477\n",
      "Epoch 279/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.5688 - val_loss: 10.4703\n",
      "Epoch 280/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.0025 - val_loss: 10.5308\n",
      "Epoch 281/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.0727 - val_loss: 11.8585\n",
      "Epoch 282/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 6.1027 - val_loss: 9.7356\n",
      "Epoch 283/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.7055 - val_loss: 9.6600\n",
      "Epoch 284/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.2632 - val_loss: 9.6653\n",
      "Epoch 285/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 7.5986 - val_loss: 12.7910\n",
      "Epoch 286/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 8.8843 - val_loss: 12.8591\n",
      "Epoch 287/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.6375 - val_loss: 10.7886\n",
      "Epoch 288/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.3527 - val_loss: 10.1175\n",
      "Epoch 289/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.7896 - val_loss: 10.8985\n",
      "Epoch 290/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.8821 - val_loss: 9.1052\n",
      "Epoch 291/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.4392 - val_loss: 9.6254\n",
      "Epoch 292/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.7385 - val_loss: 9.1844\n",
      "Epoch 293/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.6407 - val_loss: 9.7440\n",
      "Epoch 294/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.2040 - val_loss: 10.0086\n",
      "Epoch 295/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.2862 - val_loss: 9.2116\n",
      "Epoch 296/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.2608 - val_loss: 10.0820\n",
      "Epoch 297/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.9503 - val_loss: 9.4851\n",
      "Epoch 298/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.9676 - val_loss: 13.4802\n",
      "Epoch 299/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.2367 - val_loss: 9.8225\n",
      "Epoch 300/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.3326 - val_loss: 10.5907\n",
      "Epoch 301/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.5700 - val_loss: 10.2741\n",
      "Epoch 302/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.4691 - val_loss: 11.6653\n",
      "Epoch 303/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.3622 - val_loss: 9.8021\n",
      "Epoch 304/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.2552 - val_loss: 9.8447\n",
      "Epoch 305/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.4104 - val_loss: 9.6873\n",
      "Epoch 306/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.0340 - val_loss: 9.4983\n",
      "Epoch 307/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.5034 - val_loss: 10.5338\n",
      "Epoch 308/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.5225 - val_loss: 9.2194\n",
      "Epoch 309/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.9819 - val_loss: 10.1811\n",
      "Epoch 310/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.5196 - val_loss: 9.3882\n",
      "Epoch 311/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.1344 - val_loss: 9.9406\n",
      "Epoch 312/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.2680 - val_loss: 10.2618\n",
      "Epoch 313/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.3576 - val_loss: 10.6009\n",
      "Epoch 314/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.3400 - val_loss: 9.4415\n",
      "Epoch 315/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.2459 - val_loss: 9.0496\n",
      "Epoch 316/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.2105 - val_loss: 9.3652\n",
      "Epoch 317/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.1363 - val_loss: 9.0889\n",
      "Epoch 318/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.9231 - val_loss: 8.9701\n",
      "Epoch 319/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.4160 - val_loss: 9.5953\n",
      "Epoch 320/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.4055 - val_loss: 9.9834\n",
      "Epoch 321/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.3612 - val_loss: 10.4220\n",
      "Epoch 322/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.4421 - val_loss: 9.9253\n",
      "Epoch 323/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.2365 - val_loss: 9.1965\n",
      "Epoch 324/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.8187 - val_loss: 10.0267\n",
      "Epoch 325/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.3554 - val_loss: 10.3592\n",
      "Epoch 326/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.4398 - val_loss: 9.7821\n",
      "Epoch 327/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.6039 - val_loss: 10.6504\n",
      "Epoch 328/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.8587 - val_loss: 9.1612\n",
      "Epoch 329/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 4.9917 - val_loss: 9.3064\n",
      "Epoch 330/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 5.4639 - val_loss: 9.3517\n",
      "Epoch 331/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.1076 - val_loss: 10.1808\n",
      "Epoch 332/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.2670 - val_loss: 10.6038\n",
      "Epoch 333/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 6.7702 - val_loss: 9.1519\n",
      "Epoch 334/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.0116 - val_loss: 9.6847\n",
      "Epoch 335/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.3591 - val_loss: 8.9262\n",
      "Epoch 336/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.3174 - val_loss: 12.1009\n",
      "Epoch 337/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.8908 - val_loss: 9.8153\n",
      "Epoch 338/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.4159 - val_loss: 10.4794\n",
      "Epoch 339/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.5104 - val_loss: 9.7598\n",
      "Epoch 340/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.2988 - val_loss: 10.7951\n",
      "Epoch 341/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.3739 - val_loss: 11.3891\n",
      "Epoch 342/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.1004 - val_loss: 10.8365\n",
      "Epoch 343/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.5022 - val_loss: 10.7111\n",
      "Epoch 344/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.4572 - val_loss: 9.2115\n",
      "Epoch 345/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.3059 - val_loss: 10.4634\n",
      "Epoch 346/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.7270 - val_loss: 9.6386\n",
      "Epoch 347/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.3848 - val_loss: 9.9482\n",
      "Epoch 348/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.7621 - val_loss: 9.2782\n",
      "Epoch 349/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.1321 - val_loss: 9.3098\n",
      "Epoch 350/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.9728 - val_loss: 9.1490\n",
      "Epoch 351/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.2199 - val_loss: 11.2149\n",
      "Epoch 352/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.6198 - val_loss: 8.8611\n",
      "Epoch 353/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.0084 - val_loss: 9.2296\n",
      "Epoch 354/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.0422 - val_loss: 9.1002\n",
      "Epoch 355/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 4.9679 - val_loss: 9.9657\n",
      "Epoch 356/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.3078 - val_loss: 8.6602\n",
      "Epoch 357/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 4.8662 - val_loss: 9.7643\n",
      "Epoch 358/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.2846 - val_loss: 9.0503\n",
      "Epoch 359/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.1306 - val_loss: 8.8340\n",
      "Epoch 360/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 4.9631 - val_loss: 9.5478\n",
      "Epoch 361/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.2649 - val_loss: 12.0351\n",
      "Epoch 362/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 9.9759 - val_loss: 10.2931\n",
      "Epoch 363/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.8845 - val_loss: 10.1887\n",
      "Epoch 364/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 5.7539 - val_loss: 9.2103\n",
      "Epoch 365/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.3179 - val_loss: 9.8252\n",
      "Epoch 366/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 5.1985 - val_loss: 10.3879\n",
      "Epoch 367/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.0978 - val_loss: 8.9048\n",
      "Epoch 368/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.7544 - val_loss: 10.3534\n",
      "Epoch 369/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.2496 - val_loss: 10.8855\n",
      "Epoch 370/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.4533 - val_loss: 10.8980\n",
      "Epoch 371/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.2200 - val_loss: 9.1927\n",
      "Epoch 372/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.2036 - val_loss: 9.5332\n",
      "Epoch 373/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.0772 - val_loss: 9.4285\n",
      "Epoch 374/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.0092 - val_loss: 10.0836\n",
      "Epoch 375/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.9122 - val_loss: 9.3685\n",
      "Epoch 376/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.1535 - val_loss: 9.3442\n",
      "Epoch 377/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.9398 - val_loss: 10.2696\n",
      "Epoch 378/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.7051 - val_loss: 9.5591\n",
      "Epoch 379/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.9854 - val_loss: 9.4054\n",
      "Epoch 380/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.8966 - val_loss: 9.0559\n",
      "Epoch 381/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.8938 - val_loss: 9.3937\n",
      "Epoch 382/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.7805 - val_loss: 9.7470\n",
      "Epoch 383/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.1051 - val_loss: 9.4924\n",
      "Epoch 384/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.0567 - val_loss: 8.5280\n",
      "Epoch 385/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.0075 - val_loss: 11.3890\n",
      "Epoch 386/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.7595 - val_loss: 9.3061\n",
      "Epoch 387/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.0815 - val_loss: 10.3893\n",
      "Epoch 388/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.2449 - val_loss: 9.2639\n",
      "Epoch 389/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.6478 - val_loss: 9.7269\n",
      "Epoch 390/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.1979 - val_loss: 10.1301\n",
      "Epoch 391/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.8205 - val_loss: 9.5839\n",
      "Epoch 392/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.1397 - val_loss: 9.8746\n",
      "Epoch 393/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.2860 - val_loss: 9.4552\n",
      "Epoch 394/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.5695 - val_loss: 9.0497\n",
      "Epoch 395/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.0368 - val_loss: 8.7967\n",
      "Epoch 396/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.8578 - val_loss: 8.5587\n",
      "Epoch 397/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.8522 - val_loss: 9.5164\n",
      "Epoch 398/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.0433 - val_loss: 8.8045\n",
      "Epoch 399/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.9228 - val_loss: 9.3687\n",
      "Epoch 400/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.7851 - val_loss: 9.5322\n",
      "Epoch 401/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.2669 - val_loss: 8.7681\n",
      "Epoch 402/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.9723 - val_loss: 8.7830\n",
      "Epoch 403/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.5845 - val_loss: 8.6226\n",
      "Epoch 404/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.6861 - val_loss: 9.3083\n",
      "Epoch 405/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.9144 - val_loss: 8.9916\n",
      "Epoch 406/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.9260 - val_loss: 8.7897\n",
      "Epoch 407/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.6329 - val_loss: 9.9929\n",
      "Epoch 408/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.0628 - val_loss: 8.4688\n",
      "Epoch 409/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.9188 - val_loss: 9.3720\n",
      "Epoch 410/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.7268 - val_loss: 8.7992\n",
      "Epoch 411/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.5985 - val_loss: 10.6746\n",
      "Epoch 412/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.1970 - val_loss: 9.1506\n",
      "Epoch 413/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.9505 - val_loss: 9.1889\n",
      "Epoch 414/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.6575 - val_loss: 9.0582\n",
      "Epoch 415/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.5902 - val_loss: 9.4954\n",
      "Epoch 416/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.6178 - val_loss: 8.8345\n",
      "Epoch 417/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.5434 - val_loss: 8.4081\n",
      "Epoch 418/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.1273 - val_loss: 9.3502\n",
      "Epoch 419/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.1050 - val_loss: 8.8883\n",
      "Epoch 420/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.8966 - val_loss: 10.6041\n",
      "Epoch 421/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.9582 - val_loss: 9.0762\n",
      "Epoch 422/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.5721 - val_loss: 8.7203\n",
      "Epoch 423/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.4359 - val_loss: 8.4253\n",
      "Epoch 424/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.2936 - val_loss: 8.9652\n",
      "Epoch 425/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.6586 - val_loss: 9.6904\n",
      "Epoch 426/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.1077 - val_loss: 10.0930\n",
      "Epoch 427/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.8241 - val_loss: 9.5790\n",
      "Epoch 428/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.6855 - val_loss: 8.9911\n",
      "Epoch 429/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.9177 - val_loss: 8.4641\n",
      "Epoch 430/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.7078 - val_loss: 9.4551\n",
      "Epoch 431/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.6486 - val_loss: 8.6561\n",
      "Epoch 432/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.6152 - val_loss: 9.6360\n",
      "Epoch 433/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 5.1236 - val_loss: 9.5105\n",
      "Epoch 434/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.4909 - val_loss: 8.9456\n",
      "Epoch 435/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.7057 - val_loss: 9.2391\n",
      "Epoch 436/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.3742 - val_loss: 8.3964\n",
      "Epoch 437/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.9251 - val_loss: 8.7236\n",
      "Epoch 438/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.3835 - val_loss: 9.9127\n",
      "Epoch 439/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.1226 - val_loss: 8.5931\n",
      "Epoch 440/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.5347 - val_loss: 9.6239\n",
      "Epoch 441/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 5.0973 - val_loss: 9.2316\n",
      "Epoch 442/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 5.5379 - val_loss: 9.2027\n",
      "Epoch 443/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.9913 - val_loss: 9.0590\n",
      "Epoch 444/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.4986 - val_loss: 8.7293\n",
      "Epoch 445/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.4775 - val_loss: 8.5054\n",
      "Epoch 446/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.5792 - val_loss: 10.5540\n",
      "Epoch 447/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.7769 - val_loss: 9.5337\n",
      "Epoch 448/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.6747 - val_loss: 9.5046\n",
      "Epoch 449/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.7632 - val_loss: 9.0547\n",
      "Epoch 450/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.2788 - val_loss: 9.8779\n",
      "Epoch 451/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.4030 - val_loss: 9.6699\n",
      "Epoch 452/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.7570 - val_loss: 8.7602\n",
      "Epoch 453/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.3551 - val_loss: 9.6844\n",
      "Epoch 454/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 4.6380 - val_loss: 8.9396\n",
      "Epoch 455/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.4971 - val_loss: 8.9433\n",
      "Epoch 456/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.8474 - val_loss: 8.2425\n",
      "Epoch 457/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0249 - val_loss: 8.8195\n",
      "Epoch 458/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.7856 - val_loss: 9.6408\n",
      "Epoch 459/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.3526 - val_loss: 8.4387\n",
      "Epoch 460/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 4.8263 - val_loss: 9.3571\n",
      "Epoch 461/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.4344 - val_loss: 9.8248\n",
      "Epoch 462/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.7662 - val_loss: 8.5921\n",
      "Epoch 463/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.4860 - val_loss: 8.4468\n",
      "Epoch 464/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.7597 - val_loss: 8.7187\n",
      "Epoch 465/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.7653 - val_loss: 8.9709\n",
      "Epoch 466/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.7812 - val_loss: 10.7462\n",
      "Epoch 467/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 5.1266 - val_loss: 9.1947\n",
      "Epoch 468/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.3776 - val_loss: 9.1473\n",
      "Epoch 469/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.4093 - val_loss: 8.5358\n",
      "Epoch 470/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.6547 - val_loss: 8.2051\n",
      "Epoch 471/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.1389 - val_loss: 9.0205\n",
      "Epoch 472/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.5460 - val_loss: 10.6190\n",
      "Epoch 473/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.4590 - val_loss: 8.8105\n",
      "Epoch 474/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.3651 - val_loss: 8.3878\n",
      "Epoch 475/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.6199 - val_loss: 8.4980\n",
      "Epoch 476/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.3943 - val_loss: 9.5833\n",
      "Epoch 477/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.6546 - val_loss: 9.7131\n",
      "Epoch 478/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 5.4229 - val_loss: 9.3981\n",
      "Epoch 479/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.7666 - val_loss: 8.3478\n",
      "Epoch 480/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.1510 - val_loss: 9.0653\n",
      "Epoch 481/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.4405 - val_loss: 9.1152\n",
      "Epoch 482/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 5.0132 - val_loss: 8.8075\n",
      "Epoch 483/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.4021 - val_loss: 8.6948\n",
      "Epoch 484/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.4033 - val_loss: 8.4979\n",
      "Epoch 485/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.3644 - val_loss: 9.9303\n",
      "Epoch 486/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.3942 - val_loss: 8.7280\n",
      "Epoch 487/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.8513 - val_loss: 10.5082\n",
      "Epoch 488/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.5646 - val_loss: 8.8891\n",
      "Epoch 489/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.3483 - val_loss: 9.0275\n",
      "Epoch 490/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.3584 - val_loss: 8.2092\n",
      "Epoch 491/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.2010 - val_loss: 9.3402\n",
      "Epoch 492/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.5240 - val_loss: 9.2349\n",
      "Epoch 493/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.6032 - val_loss: 8.4242\n",
      "Epoch 494/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.2476 - val_loss: 8.0991\n",
      "Epoch 495/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.3131 - val_loss: 8.6452\n",
      "Epoch 496/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.3048 - val_loss: 8.0717\n",
      "Epoch 497/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.2343 - val_loss: 9.4839\n",
      "Epoch 498/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.4663 - val_loss: 9.1669\n",
      "Epoch 499/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.0661 - val_loss: 9.3494\n",
      "Epoch 500/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.1408 - val_loss: 9.5472\n",
      "Epoch 501/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.8443 - val_loss: 8.4122\n",
      "Epoch 502/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.1502 - val_loss: 9.2483\n",
      "Epoch 503/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.3637 - val_loss: 9.4482\n",
      "Epoch 504/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.5657 - val_loss: 8.4820\n",
      "Epoch 505/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.5128 - val_loss: 9.1915\n",
      "Epoch 506/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.8078 - val_loss: 9.5277\n",
      "Epoch 507/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.7862 - val_loss: 8.0147\n",
      "Epoch 508/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.2598 - val_loss: 8.5589\n",
      "Epoch 509/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.1873 - val_loss: 8.3353\n",
      "Epoch 510/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 3.9694 - val_loss: 9.7644\n",
      "Epoch 511/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.6667 - val_loss: 8.3431\n",
      "Epoch 512/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.2198 - val_loss: 8.9042\n",
      "Epoch 513/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.9272 - val_loss: 9.0113\n",
      "Epoch 514/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.3145 - val_loss: 9.4830\n",
      "Epoch 515/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.5311 - val_loss: 9.7804\n",
      "Epoch 516/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.1220 - val_loss: 8.4508\n",
      "Epoch 517/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 4.6476 - val_loss: 8.2796\n",
      "Epoch 518/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.2902 - val_loss: 8.5127\n",
      "Epoch 519/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.8618 - val_loss: 9.6633\n",
      "Epoch 520/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.2331 - val_loss: 10.5191\n",
      "Epoch 521/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.6338 - val_loss: 8.8693\n",
      "Epoch 522/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.4909 - val_loss: 9.8805\n",
      "Epoch 523/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 4.6139 - val_loss: 10.3549\n",
      "Epoch 524/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 5.0139 - val_loss: 9.3918\n",
      "Epoch 525/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.3939 - val_loss: 8.9164\n",
      "Epoch 526/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.1479 - val_loss: 9.9851\n",
      "Epoch 527/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 4.7770 - val_loss: 8.7612\n",
      "Epoch 528/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.2657 - val_loss: 8.3942\n",
      "Epoch 529/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0872 - val_loss: 8.6779\n",
      "Epoch 530/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.2263 - val_loss: 8.0374\n",
      "Epoch 531/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.1658 - val_loss: 8.9199\n",
      "Epoch 532/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.3129 - val_loss: 9.8531\n",
      "Epoch 533/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.1627 - val_loss: 8.0304\n",
      "Epoch 534/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9211 - val_loss: 8.3589\n",
      "Epoch 535/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0167 - val_loss: 8.2198\n",
      "Epoch 536/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.1871 - val_loss: 9.9992\n",
      "Epoch 537/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.9532 - val_loss: 10.1652\n",
      "Epoch 538/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.0918 - val_loss: 8.5266\n",
      "Epoch 539/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.2784 - val_loss: 8.9799\n",
      "Epoch 540/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.2349 - val_loss: 10.4296\n",
      "Epoch 541/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.7396 - val_loss: 8.8601\n",
      "Epoch 542/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9989 - val_loss: 9.9724\n",
      "Epoch 543/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.4104 - val_loss: 10.1534\n",
      "Epoch 544/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 4.4833 - val_loss: 8.4404\n",
      "Epoch 545/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.0028 - val_loss: 9.9468\n",
      "Epoch 546/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.7717 - val_loss: 8.7641\n",
      "Epoch 547/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.4622 - val_loss: 9.0308\n",
      "Epoch 548/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.3166 - val_loss: 9.0442\n",
      "Epoch 549/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.1040 - val_loss: 8.9812\n",
      "Epoch 550/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.1323 - val_loss: 9.7912\n",
      "Epoch 551/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.1726 - val_loss: 8.3545\n",
      "Epoch 552/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.9295 - val_loss: 8.3280\n",
      "Epoch 553/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.8423 - val_loss: 8.6607\n",
      "Epoch 554/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.2820 - val_loss: 8.4364\n",
      "Epoch 555/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.2146 - val_loss: 9.0276\n",
      "Epoch 556/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.3589 - val_loss: 8.6484\n",
      "Epoch 557/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.8888 - val_loss: 7.9476\n",
      "Epoch 558/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.6403 - val_loss: 9.1178\n",
      "Epoch 559/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.5128 - val_loss: 8.7355\n",
      "Epoch 560/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.1152 - val_loss: 8.5016\n",
      "Epoch 561/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.0139 - val_loss: 9.1925\n",
      "Epoch 562/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.3117 - val_loss: 8.6634\n",
      "Epoch 563/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 4.0787 - val_loss: 8.6723\n",
      "Epoch 564/3000\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 4.0430 - val_loss: 8.3558\n",
      "Epoch 565/3000\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 4.2309 - val_loss: 8.7836\n",
      "Epoch 566/3000\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 4.3243 - val_loss: 9.8258\n",
      "Epoch 567/3000\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 4.2612 - val_loss: 8.8662\n",
      "Epoch 568/3000\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 4.2897 - val_loss: 8.6779\n",
      "Epoch 569/3000\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 4.3054 - val_loss: 8.9014\n",
      "Epoch 570/3000\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 4.2667 - val_loss: 8.7821\n",
      "Epoch 571/3000\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 4.3588 - val_loss: 9.1910\n",
      "Epoch 572/3000\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 4.2136 - val_loss: 8.6560\n",
      "Epoch 573/3000\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 4.4656 - val_loss: 8.5467\n",
      "Epoch 574/3000\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 4.0542 - val_loss: 8.4161\n",
      "Epoch 575/3000\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 4.0108 - val_loss: 8.8305\n",
      "Epoch 576/3000\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 4.0925 - val_loss: 8.8316\n",
      "Epoch 577/3000\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 3.9266 - val_loss: 8.5920\n",
      "Epoch 578/3000\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 4.2896 - val_loss: 9.2075\n",
      "Epoch 579/3000\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 4.3519 - val_loss: 9.4729\n",
      "Epoch 580/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 4.2009 - val_loss: 8.4574\n",
      "Epoch 581/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.0449 - val_loss: 8.8089\n",
      "Epoch 582/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.0311 - val_loss: 10.0241\n",
      "Epoch 583/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 5.5278 - val_loss: 10.6772\n",
      "Epoch 584/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 5.4928 - val_loss: 9.8961\n",
      "Epoch 585/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 4.5566 - val_loss: 8.9604\n",
      "Epoch 586/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 4.1611 - val_loss: 9.0881\n",
      "Epoch 587/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.2195 - val_loss: 9.4474\n",
      "Epoch 588/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.3779 - val_loss: 8.3957\n",
      "Epoch 589/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0316 - val_loss: 8.6227\n",
      "Epoch 590/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7780 - val_loss: 9.7868\n",
      "Epoch 591/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.3322 - val_loss: 8.5106\n",
      "Epoch 592/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8158 - val_loss: 8.3827\n",
      "Epoch 593/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0744 - val_loss: 8.5809\n",
      "Epoch 594/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.2465 - val_loss: 9.1296\n",
      "Epoch 595/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9776 - val_loss: 8.4913\n",
      "Epoch 596/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8889 - val_loss: 8.4380\n",
      "Epoch 597/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8284 - val_loss: 8.7073\n",
      "Epoch 598/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0430 - val_loss: 8.1196\n",
      "Epoch 599/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8325 - val_loss: 9.1402\n",
      "Epoch 600/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8113 - val_loss: 10.1718\n",
      "Epoch 601/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 4.5832 - val_loss: 9.8426\n",
      "Epoch 602/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0862 - val_loss: 8.4635\n",
      "Epoch 603/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.2003 - val_loss: 9.6660\n",
      "Epoch 604/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.1214 - val_loss: 9.4898\n",
      "Epoch 605/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.3644 - val_loss: 8.8196\n",
      "Epoch 606/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.1277 - val_loss: 8.4453\n",
      "Epoch 607/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9557 - val_loss: 8.2306\n",
      "Epoch 608/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9616 - val_loss: 8.5095\n",
      "Epoch 609/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0152 - val_loss: 8.9480\n",
      "Epoch 610/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.5221 - val_loss: 8.9893\n",
      "Epoch 611/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.4357 - val_loss: 9.1253\n",
      "Epoch 612/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.2620 - val_loss: 8.0716\n",
      "Epoch 613/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.6224 - val_loss: 8.5349\n",
      "Epoch 614/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.9501 - val_loss: 8.2309\n",
      "Epoch 615/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8602 - val_loss: 8.9020\n",
      "Epoch 616/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0349 - val_loss: 8.6420\n",
      "Epoch 617/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0657 - val_loss: 8.6665\n",
      "Epoch 618/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.2061 - val_loss: 8.4695\n",
      "Epoch 619/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6307 - val_loss: 8.7000\n",
      "Epoch 620/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7596 - val_loss: 8.1819\n",
      "Epoch 621/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8687 - val_loss: 8.4652\n",
      "Epoch 622/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0814 - val_loss: 8.8871\n",
      "Epoch 623/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8451 - val_loss: 7.8883\n",
      "Epoch 624/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8156 - val_loss: 8.2137\n",
      "Epoch 625/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8078 - val_loss: 8.3471\n",
      "Epoch 626/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7605 - val_loss: 7.9502\n",
      "Epoch 627/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6076 - val_loss: 8.8804\n",
      "Epoch 628/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.1251 - val_loss: 8.6586\n",
      "Epoch 629/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0909 - val_loss: 8.4627\n",
      "Epoch 630/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8290 - val_loss: 8.8833\n",
      "Epoch 631/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7728 - val_loss: 8.3824\n",
      "Epoch 632/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7240 - val_loss: 8.9458\n",
      "Epoch 633/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.3614 - val_loss: 8.5968\n",
      "Epoch 634/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.2220 - val_loss: 8.4216\n",
      "Epoch 635/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7319 - val_loss: 9.0899\n",
      "Epoch 636/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0531 - val_loss: 9.0406\n",
      "Epoch 637/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.1109 - val_loss: 8.5804\n",
      "Epoch 638/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9920 - val_loss: 8.3587\n",
      "Epoch 639/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9250 - val_loss: 9.3543\n",
      "Epoch 640/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.5918 - val_loss: 8.4617\n",
      "Epoch 641/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.2596 - val_loss: 9.9427\n",
      "Epoch 642/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0560 - val_loss: 8.8733\n",
      "Epoch 643/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9094 - val_loss: 10.0127\n",
      "Epoch 644/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9571 - val_loss: 8.3836\n",
      "Epoch 645/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7409 - val_loss: 8.0517\n",
      "Epoch 646/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6673 - val_loss: 9.3475\n",
      "Epoch 647/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.5983 - val_loss: 8.3345\n",
      "Epoch 648/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.1527 - val_loss: 8.9787\n",
      "Epoch 649/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.2833 - val_loss: 8.7033\n",
      "Epoch 650/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8132 - val_loss: 8.7382\n",
      "Epoch 651/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8496 - val_loss: 8.8073\n",
      "Epoch 652/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.2691 - val_loss: 8.3169\n",
      "Epoch 653/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8579 - val_loss: 8.4885\n",
      "Epoch 654/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.2287 - val_loss: 7.8813\n",
      "Epoch 655/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6205 - val_loss: 8.7389\n",
      "Epoch 656/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7936 - val_loss: 9.1830\n",
      "Epoch 657/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7813 - val_loss: 10.6144\n",
      "Epoch 658/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.3953 - val_loss: 9.1643\n",
      "Epoch 659/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0263 - val_loss: 8.1886\n",
      "Epoch 660/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0599 - val_loss: 8.4086\n",
      "Epoch 661/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8222 - val_loss: 8.6112\n",
      "Epoch 662/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0734 - val_loss: 8.4873\n",
      "Epoch 663/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9855 - val_loss: 8.5147\n",
      "Epoch 664/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7735 - val_loss: 8.4847\n",
      "Epoch 665/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5861 - val_loss: 7.7772\n",
      "Epoch 666/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6880 - val_loss: 9.1565\n",
      "Epoch 667/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 3.5412 - val_loss: 8.7385\n",
      "Epoch 668/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.6197 - val_loss: 8.3929\n",
      "Epoch 669/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.8416 - val_loss: 9.3901\n",
      "Epoch 670/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 4.3499 - val_loss: 8.4871\n",
      "Epoch 671/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9486 - val_loss: 8.4988\n",
      "Epoch 672/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.6352 - val_loss: 8.1466\n",
      "Epoch 673/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.3726 - val_loss: 8.7277\n",
      "Epoch 674/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6769 - val_loss: 8.2899\n",
      "Epoch 675/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.7236 - val_loss: 8.9226\n",
      "Epoch 676/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 3.9819 - val_loss: 8.9895\n",
      "Epoch 677/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 3.8821 - val_loss: 8.9764\n",
      "Epoch 678/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.9920 - val_loss: 8.9183\n",
      "Epoch 679/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.6902 - val_loss: 8.5157\n",
      "Epoch 680/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.6868 - val_loss: 8.9609\n",
      "Epoch 681/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6027 - val_loss: 8.2505\n",
      "Epoch 682/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7095 - val_loss: 8.8488\n",
      "Epoch 683/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6453 - val_loss: 8.0765\n",
      "Epoch 684/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4424 - val_loss: 9.5901\n",
      "Epoch 685/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9760 - val_loss: 8.2170\n",
      "Epoch 686/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5718 - val_loss: 8.7088\n",
      "Epoch 687/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.1143 - val_loss: 7.9916\n",
      "Epoch 688/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9030 - val_loss: 8.8527\n",
      "Epoch 689/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8119 - val_loss: 8.6173\n",
      "Epoch 690/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.8483 - val_loss: 8.3643\n",
      "Epoch 691/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.8260 - val_loss: 8.5136\n",
      "Epoch 692/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.6638 - val_loss: 7.9836\n",
      "Epoch 693/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.3893 - val_loss: 7.9780\n",
      "Epoch 694/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.5230 - val_loss: 8.2328\n",
      "Epoch 695/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.6229 - val_loss: 8.7050\n",
      "Epoch 696/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0356 - val_loss: 8.5943\n",
      "Epoch 697/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9871 - val_loss: 8.6617\n",
      "Epoch 698/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8132 - val_loss: 8.9860\n",
      "Epoch 699/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8735 - val_loss: 8.5060\n",
      "Epoch 700/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.8580 - val_loss: 8.1770\n",
      "Epoch 701/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.6255 - val_loss: 9.9093\n",
      "Epoch 702/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.3909 - val_loss: 8.9171\n",
      "Epoch 703/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.2469 - val_loss: 8.1395\n",
      "Epoch 704/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.7496 - val_loss: 9.0720\n",
      "Epoch 705/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.8817 - val_loss: 8.2308\n",
      "Epoch 706/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.8510 - val_loss: 8.7871\n",
      "Epoch 707/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 4.1368 - val_loss: 8.9394\n",
      "Epoch 708/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7601 - val_loss: 8.3161\n",
      "Epoch 709/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.8225 - val_loss: 9.2514\n",
      "Epoch 710/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.9034 - val_loss: 8.6676\n",
      "Epoch 711/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.0665 - val_loss: 8.0940\n",
      "Epoch 712/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.5128 - val_loss: 8.9664\n",
      "Epoch 713/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.8784 - val_loss: 8.1118\n",
      "Epoch 714/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.6658 - val_loss: 9.1453\n",
      "Epoch 715/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.0132 - val_loss: 8.1765\n",
      "Epoch 716/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.5594 - val_loss: 9.1113\n",
      "Epoch 717/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.0245 - val_loss: 8.1941\n",
      "Epoch 718/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 4.0884 - val_loss: 8.0751\n",
      "Epoch 719/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.5229 - val_loss: 7.9836\n",
      "Epoch 720/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.4070 - val_loss: 8.8389\n",
      "Epoch 721/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.8923 - val_loss: 8.3247\n",
      "Epoch 722/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6498 - val_loss: 9.0765\n",
      "Epoch 723/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6676 - val_loss: 7.8080\n",
      "Epoch 724/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4580 - val_loss: 9.2686\n",
      "Epoch 725/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.3050 - val_loss: 8.7401\n",
      "Epoch 726/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9437 - val_loss: 8.2616\n",
      "Epoch 727/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7270 - val_loss: 7.9888\n",
      "Epoch 728/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4252 - val_loss: 8.0649\n",
      "Epoch 729/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8314 - val_loss: 8.4070\n",
      "Epoch 730/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5413 - val_loss: 7.9947\n",
      "Epoch 731/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.4116 - val_loss: 8.7843\n",
      "Epoch 732/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5757 - val_loss: 8.2323\n",
      "Epoch 733/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7000 - val_loss: 7.8218\n",
      "Epoch 734/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4124 - val_loss: 8.9028\n",
      "Epoch 735/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0707 - val_loss: 8.0944\n",
      "Epoch 736/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7295 - val_loss: 8.1604\n",
      "Epoch 737/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5703 - val_loss: 8.3269\n",
      "Epoch 738/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7811 - val_loss: 8.4777\n",
      "Epoch 739/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7150 - val_loss: 8.6974\n",
      "Epoch 740/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5100 - val_loss: 8.2537\n",
      "Epoch 741/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7805 - val_loss: 7.7651\n",
      "Epoch 742/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3977 - val_loss: 9.7490\n",
      "Epoch 743/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8061 - val_loss: 8.4867\n",
      "Epoch 744/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4264 - val_loss: 8.2287\n",
      "Epoch 745/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.5028 - val_loss: 8.6435\n",
      "Epoch 746/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.5802 - val_loss: 7.9868\n",
      "Epoch 747/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3401 - val_loss: 7.6464\n",
      "Epoch 748/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2835 - val_loss: 8.1036\n",
      "Epoch 749/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5225 - val_loss: 7.7625\n",
      "Epoch 750/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.2885 - val_loss: 8.5161\n",
      "Epoch 751/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3973 - val_loss: 7.9660\n",
      "Epoch 752/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3323 - val_loss: 7.9135\n",
      "Epoch 753/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6958 - val_loss: 8.0382\n",
      "Epoch 754/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7500 - val_loss: 10.2426\n",
      "Epoch 755/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.1582 - val_loss: 7.9899\n",
      "Epoch 756/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6058 - val_loss: 8.0456\n",
      "Epoch 757/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2710 - val_loss: 8.2808\n",
      "Epoch 758/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4174 - val_loss: 7.9165\n",
      "Epoch 759/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8585 - val_loss: 7.9040\n",
      "Epoch 760/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3706 - val_loss: 8.3118\n",
      "Epoch 761/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5557 - val_loss: 8.2597\n",
      "Epoch 762/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3378 - val_loss: 7.8535\n",
      "Epoch 763/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6260 - val_loss: 8.2746\n",
      "Epoch 764/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4873 - val_loss: 8.0634\n",
      "Epoch 765/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5475 - val_loss: 8.0709\n",
      "Epoch 766/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3722 - val_loss: 8.2433\n",
      "Epoch 767/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5996 - val_loss: 8.8030\n",
      "Epoch 768/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6100 - val_loss: 8.2730\n",
      "Epoch 769/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3636 - val_loss: 9.0101\n",
      "Epoch 770/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6948 - val_loss: 8.6841\n",
      "Epoch 771/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5001 - val_loss: 9.0891\n",
      "Epoch 772/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5079 - val_loss: 7.6938\n",
      "Epoch 773/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4738 - val_loss: 7.8586\n",
      "Epoch 774/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5178 - val_loss: 8.1513\n",
      "Epoch 775/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0084 - val_loss: 8.4187\n",
      "Epoch 776/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4512 - val_loss: 8.1328\n",
      "Epoch 777/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3054 - val_loss: 9.8468\n",
      "Epoch 778/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7836 - val_loss: 8.2338\n",
      "Epoch 779/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5932 - val_loss: 8.8622\n",
      "Epoch 780/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5216 - val_loss: 8.6248\n",
      "Epoch 781/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5292 - val_loss: 7.9688\n",
      "Epoch 782/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2447 - val_loss: 7.9857\n",
      "Epoch 783/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.4128 - val_loss: 8.5133\n",
      "Epoch 784/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4204 - val_loss: 8.1402\n",
      "Epoch 785/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.4420 - val_loss: 8.2666\n",
      "Epoch 786/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7646 - val_loss: 8.2313\n",
      "Epoch 787/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5714 - val_loss: 8.0217\n",
      "Epoch 788/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1859 - val_loss: 8.2882\n",
      "Epoch 789/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5885 - val_loss: 8.3505\n",
      "Epoch 790/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7834 - val_loss: 8.4447\n",
      "Epoch 791/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3978 - val_loss: 8.2176\n",
      "Epoch 792/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4453 - val_loss: 8.0442\n",
      "Epoch 793/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3548 - val_loss: 7.9357\n",
      "Epoch 794/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2285 - val_loss: 8.1471\n",
      "Epoch 795/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5100 - val_loss: 7.9136\n",
      "Epoch 796/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2418 - val_loss: 7.9676\n",
      "Epoch 797/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2657 - val_loss: 10.2951\n",
      "Epoch 798/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.9718 - val_loss: 9.9652\n",
      "Epoch 799/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.9172 - val_loss: 8.0811\n",
      "Epoch 800/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5059 - val_loss: 8.2061\n",
      "Epoch 801/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5574 - val_loss: 7.8224\n",
      "Epoch 802/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4159 - val_loss: 8.0717\n",
      "Epoch 803/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4381 - val_loss: 8.9196\n",
      "Epoch 804/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5252 - val_loss: 7.4438\n",
      "Epoch 805/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2364 - val_loss: 8.5484\n",
      "Epoch 806/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3885 - val_loss: 7.8035\n",
      "Epoch 807/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5011 - val_loss: 7.8960\n",
      "Epoch 808/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2251 - val_loss: 7.9569\n",
      "Epoch 809/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6459 - val_loss: 8.4325\n",
      "Epoch 810/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2197 - val_loss: 7.5982\n",
      "Epoch 811/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0970 - val_loss: 7.6677\n",
      "Epoch 812/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1954 - val_loss: 8.0219\n",
      "Epoch 813/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3178 - val_loss: 8.0757\n",
      "Epoch 814/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3142 - val_loss: 7.7819\n",
      "Epoch 815/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6704 - val_loss: 8.5389\n",
      "Epoch 816/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3694 - val_loss: 8.1585\n",
      "Epoch 817/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6436 - val_loss: 8.6197\n",
      "Epoch 818/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5226 - val_loss: 7.8003\n",
      "Epoch 819/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2384 - val_loss: 8.8310\n",
      "Epoch 820/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 5.4273 - val_loss: 9.3221\n",
      "Epoch 821/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.1045 - val_loss: 8.3458\n",
      "Epoch 822/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5196 - val_loss: 8.1827\n",
      "Epoch 823/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4537 - val_loss: 7.8244\n",
      "Epoch 824/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4993 - val_loss: 8.2560\n",
      "Epoch 825/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5285 - val_loss: 8.7821\n",
      "Epoch 826/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4713 - val_loss: 7.8068\n",
      "Epoch 827/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3263 - val_loss: 7.9518\n",
      "Epoch 828/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2700 - val_loss: 8.1114\n",
      "Epoch 829/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5944 - val_loss: 8.1417\n",
      "Epoch 830/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4198 - val_loss: 8.6736\n",
      "Epoch 831/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4686 - val_loss: 9.1966\n",
      "Epoch 832/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5730 - val_loss: 9.2251\n",
      "Epoch 833/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.3819 - val_loss: 8.2712\n",
      "Epoch 834/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4022 - val_loss: 8.5183\n",
      "Epoch 835/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3915 - val_loss: 8.3205\n",
      "Epoch 836/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1729 - val_loss: 7.6573\n",
      "Epoch 837/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3383 - val_loss: 7.7195\n",
      "Epoch 838/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4534 - val_loss: 7.9708\n",
      "Epoch 839/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2412 - val_loss: 7.7934\n",
      "Epoch 840/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4706 - val_loss: 7.7851\n",
      "Epoch 841/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4066 - val_loss: 8.4058\n",
      "Epoch 842/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4459 - val_loss: 8.9757\n",
      "Epoch 843/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7699 - val_loss: 7.8079\n",
      "Epoch 844/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2107 - val_loss: 7.8823\n",
      "Epoch 845/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1254 - val_loss: 7.8682\n",
      "Epoch 846/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1731 - val_loss: 8.0778\n",
      "Epoch 847/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1592 - val_loss: 7.8345\n",
      "Epoch 848/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3580 - val_loss: 7.9684\n",
      "Epoch 849/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1128 - val_loss: 7.3595\n",
      "Epoch 850/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0545 - val_loss: 8.4502\n",
      "Epoch 851/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5644 - val_loss: 8.0234\n",
      "Epoch 852/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2290 - val_loss: 8.6915\n",
      "Epoch 853/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5344 - val_loss: 7.7298\n",
      "Epoch 854/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2148 - val_loss: 7.8123\n",
      "Epoch 855/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1329 - val_loss: 7.8564\n",
      "Epoch 856/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3211 - val_loss: 9.1514\n",
      "Epoch 857/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4959 - val_loss: 8.1466\n",
      "Epoch 858/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1605 - val_loss: 7.9837\n",
      "Epoch 859/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2974 - val_loss: 8.9585\n",
      "Epoch 860/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4197 - val_loss: 7.9999\n",
      "Epoch 861/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4888 - val_loss: 8.0240\n",
      "Epoch 862/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1654 - val_loss: 8.3914\n",
      "Epoch 863/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2200 - val_loss: 8.4835\n",
      "Epoch 864/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4144 - val_loss: 8.0318\n",
      "Epoch 865/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3182 - val_loss: 8.1007\n",
      "Epoch 866/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5558 - val_loss: 8.5407\n",
      "Epoch 867/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4052 - val_loss: 7.9649\n",
      "Epoch 868/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2467 - val_loss: 8.5538\n",
      "Epoch 869/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.3676 - val_loss: 8.4328\n",
      "Epoch 870/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6465 - val_loss: 7.7918\n",
      "Epoch 871/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.3230 - val_loss: 8.2235\n",
      "Epoch 872/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.3513 - val_loss: 8.0978\n",
      "Epoch 873/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4335 - val_loss: 8.0728\n",
      "Epoch 874/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2947 - val_loss: 8.7149\n",
      "Epoch 875/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8951 - val_loss: 10.4223\n",
      "Epoch 876/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 6.2189 - val_loss: 8.3704\n",
      "Epoch 877/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.6220 - val_loss: 8.5808\n",
      "Epoch 878/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.4300 - val_loss: 8.4730\n",
      "Epoch 879/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3031 - val_loss: 8.4882\n",
      "Epoch 880/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4472 - val_loss: 7.9439\n",
      "Epoch 881/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2668 - val_loss: 8.0349\n",
      "Epoch 882/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0501 - val_loss: 7.8328\n",
      "Epoch 883/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.9998 - val_loss: 8.4461\n",
      "Epoch 884/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.3893 - val_loss: 8.1837\n",
      "Epoch 885/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4710 - val_loss: 8.5049\n",
      "Epoch 886/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.4771 - val_loss: 7.9722\n",
      "Epoch 887/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3405 - val_loss: 8.0685\n",
      "Epoch 888/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.1060 - val_loss: 7.5796\n",
      "Epoch 889/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.2564 - val_loss: 8.0172\n",
      "Epoch 890/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1710 - val_loss: 8.0570\n",
      "Epoch 891/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4411 - val_loss: 9.7472\n",
      "Epoch 892/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.8209 - val_loss: 8.5189\n",
      "Epoch 893/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.6033 - val_loss: 7.8281\n",
      "Epoch 894/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.3359 - val_loss: 8.0173\n",
      "Epoch 895/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.5897 - val_loss: 8.1324\n",
      "Epoch 896/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5794 - val_loss: 8.2521\n",
      "Epoch 897/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.4887 - val_loss: 8.3479\n",
      "Epoch 898/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2638 - val_loss: 7.8038\n",
      "Epoch 899/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3393 - val_loss: 7.8356\n",
      "Epoch 900/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.2583 - val_loss: 8.7172\n",
      "Epoch 901/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6475 - val_loss: 8.0259\n",
      "Epoch 902/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1491 - val_loss: 7.8941\n",
      "Epoch 903/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3564 - val_loss: 8.2376\n",
      "Epoch 904/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4441 - val_loss: 8.0206\n",
      "Epoch 905/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3633 - val_loss: 8.0748\n",
      "Epoch 906/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1511 - val_loss: 8.1149\n",
      "Epoch 907/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1098 - val_loss: 8.0935\n",
      "Epoch 908/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0738 - val_loss: 8.4764\n",
      "Epoch 909/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4506 - val_loss: 8.0906\n",
      "Epoch 910/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1534 - val_loss: 7.8167\n",
      "Epoch 911/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.1242 - val_loss: 7.9254\n",
      "Epoch 912/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.0822 - val_loss: 7.7113\n",
      "Epoch 913/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0281 - val_loss: 8.0717\n",
      "Epoch 914/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3238 - val_loss: 8.0839\n",
      "Epoch 915/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2499 - val_loss: 8.1212\n",
      "Epoch 916/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3577 - val_loss: 8.9191\n",
      "Epoch 917/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6223 - val_loss: 8.9527\n",
      "Epoch 918/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4181 - val_loss: 8.0119\n",
      "Epoch 919/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2639 - val_loss: 7.4555\n",
      "Epoch 920/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1617 - val_loss: 7.8058\n",
      "Epoch 921/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3547 - val_loss: 7.9680\n",
      "Epoch 922/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1197 - val_loss: 7.7479\n",
      "Epoch 923/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0568 - val_loss: 8.1304\n",
      "Epoch 924/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2640 - val_loss: 7.4568\n",
      "Epoch 925/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0459 - val_loss: 8.5633\n",
      "Epoch 926/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0927 - val_loss: 7.7289\n",
      "Epoch 927/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0411 - val_loss: 7.8428\n",
      "Epoch 928/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2434 - val_loss: 7.6581\n",
      "Epoch 929/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8944 - val_loss: 7.6663\n",
      "Epoch 930/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1886 - val_loss: 7.7352\n",
      "Epoch 931/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0641 - val_loss: 7.7971\n",
      "Epoch 932/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0766 - val_loss: 7.8844\n",
      "Epoch 933/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0750 - val_loss: 8.5905\n",
      "Epoch 934/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.0684 - val_loss: 8.4993\n",
      "Epoch 935/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3567 - val_loss: 7.7024\n",
      "Epoch 936/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2292 - val_loss: 7.7132\n",
      "Epoch 937/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2960 - val_loss: 9.1165\n",
      "Epoch 938/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7808 - val_loss: 8.0172\n",
      "Epoch 939/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2884 - val_loss: 8.2337\n",
      "Epoch 940/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1044 - val_loss: 7.3768\n",
      "Epoch 941/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0461 - val_loss: 8.0910\n",
      "Epoch 942/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1255 - val_loss: 7.7488\n",
      "Epoch 943/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4884 - val_loss: 8.0253\n",
      "Epoch 944/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1051 - val_loss: 8.2053\n",
      "Epoch 945/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2900 - val_loss: 7.5330\n",
      "Epoch 946/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1142 - val_loss: 8.4149\n",
      "Epoch 947/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4291 - val_loss: 7.6246\n",
      "Epoch 948/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1772 - val_loss: 8.3706\n",
      "Epoch 949/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6561 - val_loss: 8.2628\n",
      "Epoch 950/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2412 - val_loss: 7.8300\n",
      "Epoch 951/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2735 - val_loss: 8.4809\n",
      "Epoch 952/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6043 - val_loss: 7.7743\n",
      "Epoch 953/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1310 - val_loss: 9.6319\n",
      "Epoch 954/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7252 - val_loss: 7.9188\n",
      "Epoch 955/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2278 - val_loss: 7.6222\n",
      "Epoch 956/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1778 - val_loss: 8.9026\n",
      "Epoch 957/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.7454 - val_loss: 8.2116\n",
      "Epoch 958/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2406 - val_loss: 8.2192\n",
      "Epoch 959/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6769 - val_loss: 8.5036\n",
      "Epoch 960/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1888 - val_loss: 8.0554\n",
      "Epoch 961/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1081 - val_loss: 8.0411\n",
      "Epoch 962/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3821 - val_loss: 8.0798\n",
      "Epoch 963/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0618 - val_loss: 8.5302\n",
      "Epoch 964/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1852 - val_loss: 8.5730\n",
      "Epoch 965/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0773 - val_loss: 9.0629\n",
      "Epoch 966/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2650 - val_loss: 7.7329\n",
      "Epoch 967/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8969 - val_loss: 8.3409\n",
      "Epoch 968/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2499 - val_loss: 7.6124\n",
      "Epoch 969/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8485 - val_loss: 8.0887\n",
      "Epoch 970/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9247 - val_loss: 8.0299\n",
      "Epoch 971/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9217 - val_loss: 7.8216\n",
      "Epoch 972/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1455 - val_loss: 7.6797\n",
      "Epoch 973/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.9978 - val_loss: 8.8348\n",
      "Epoch 974/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2132 - val_loss: 7.4522\n",
      "Epoch 975/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6323 - val_loss: 8.2515\n",
      "Epoch 976/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1548 - val_loss: 8.0820\n",
      "Epoch 977/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9391 - val_loss: 8.2756\n",
      "Epoch 978/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1850 - val_loss: 8.1103\n",
      "Epoch 979/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0145 - val_loss: 7.9270\n",
      "Epoch 980/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9607 - val_loss: 8.1045\n",
      "Epoch 981/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9491 - val_loss: 7.7738\n",
      "Epoch 982/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3870 - val_loss: 8.3921\n",
      "Epoch 983/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2064 - val_loss: 7.9579\n",
      "Epoch 984/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.1089 - val_loss: 8.4699\n",
      "Epoch 985/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.1469 - val_loss: 7.6965\n",
      "Epoch 986/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.0757 - val_loss: 7.4655\n",
      "Epoch 987/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.0138 - val_loss: 7.8019\n",
      "Epoch 988/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9171 - val_loss: 8.2881\n",
      "Epoch 989/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.6176 - val_loss: 8.6294\n",
      "Epoch 990/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3899 - val_loss: 7.9940\n",
      "Epoch 991/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1293 - val_loss: 7.9061\n",
      "Epoch 992/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.1176 - val_loss: 7.5505\n",
      "Epoch 993/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9431 - val_loss: 7.7255\n",
      "Epoch 994/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1738 - val_loss: 7.9696\n",
      "Epoch 995/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.0374 - val_loss: 8.0704\n",
      "Epoch 996/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9184 - val_loss: 8.1517\n",
      "Epoch 997/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9989 - val_loss: 8.1623\n",
      "Epoch 998/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1295 - val_loss: 7.7196\n",
      "Epoch 999/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9172 - val_loss: 7.7603\n",
      "Epoch 1000/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6602 - val_loss: 7.7243\n",
      "Epoch 1001/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9000 - val_loss: 8.1001\n",
      "Epoch 1002/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0564 - val_loss: 8.1012\n",
      "Epoch 1003/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2008 - val_loss: 8.6016\n",
      "Epoch 1004/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0605 - val_loss: 7.6488\n",
      "Epoch 1005/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8239 - val_loss: 7.7055\n",
      "Epoch 1006/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6866 - val_loss: 7.6014\n",
      "Epoch 1007/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9460 - val_loss: 7.7994\n",
      "Epoch 1008/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8956 - val_loss: 7.4074\n",
      "Epoch 1009/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5189 - val_loss: 9.0832\n",
      "Epoch 1010/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.6532 - val_loss: 7.7238\n",
      "Epoch 1011/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3576 - val_loss: 7.7636\n",
      "Epoch 1012/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0327 - val_loss: 8.8877\n",
      "Epoch 1013/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5949 - val_loss: 8.1072\n",
      "Epoch 1014/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2931 - val_loss: 7.7790\n",
      "Epoch 1015/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0245 - val_loss: 7.4508\n",
      "Epoch 1016/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0188 - val_loss: 7.4037\n",
      "Epoch 1017/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1692 - val_loss: 8.2599\n",
      "Epoch 1018/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2356 - val_loss: 7.8000\n",
      "Epoch 1019/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0057 - val_loss: 7.5000\n",
      "Epoch 1020/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9212 - val_loss: 8.0548\n",
      "Epoch 1021/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1831 - val_loss: 7.8957\n",
      "Epoch 1022/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3119 - val_loss: 8.3425\n",
      "Epoch 1023/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2511 - val_loss: 8.2478\n",
      "Epoch 1024/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2732 - val_loss: 8.2058\n",
      "Epoch 1025/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0947 - val_loss: 7.8797\n",
      "Epoch 1026/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0738 - val_loss: 8.3434\n",
      "Epoch 1027/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9643 - val_loss: 7.7531\n",
      "Epoch 1028/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0600 - val_loss: 7.5829\n",
      "Epoch 1029/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0272 - val_loss: 7.8778\n",
      "Epoch 1030/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2677 - val_loss: 9.3771\n",
      "Epoch 1031/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.5680 - val_loss: 7.5150\n",
      "Epoch 1032/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9385 - val_loss: 7.4444\n",
      "Epoch 1033/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8070 - val_loss: 8.2369\n",
      "Epoch 1034/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1921 - val_loss: 7.4655\n",
      "Epoch 1035/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8319 - val_loss: 8.2156\n",
      "Epoch 1036/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9414 - val_loss: 8.1565\n",
      "Epoch 1037/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.1064 - val_loss: 8.2293\n",
      "Epoch 1038/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1572 - val_loss: 7.5136\n",
      "Epoch 1039/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0079 - val_loss: 7.9297\n",
      "Epoch 1040/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9464 - val_loss: 8.1841\n",
      "Epoch 1041/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9012 - val_loss: 7.6139\n",
      "Epoch 1042/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9579 - val_loss: 8.8588\n",
      "Epoch 1043/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1776 - val_loss: 7.8746\n",
      "Epoch 1044/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.0093 - val_loss: 9.0191\n",
      "Epoch 1045/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.5018 - val_loss: 8.0741\n",
      "Epoch 1046/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9649 - val_loss: 7.7117\n",
      "Epoch 1047/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0842 - val_loss: 7.9450\n",
      "Epoch 1048/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7787 - val_loss: 7.7151\n",
      "Epoch 1049/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7661 - val_loss: 8.0193\n",
      "Epoch 1050/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1176 - val_loss: 8.5054\n",
      "Epoch 1051/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2404 - val_loss: 7.7720\n",
      "Epoch 1052/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8245 - val_loss: 7.9296\n",
      "Epoch 1053/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.9246 - val_loss: 8.0524\n",
      "Epoch 1054/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9409 - val_loss: 7.7760\n",
      "Epoch 1055/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8376 - val_loss: 8.0841\n",
      "Epoch 1056/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1150 - val_loss: 8.8725\n",
      "Epoch 1057/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1796 - val_loss: 7.4508\n",
      "Epoch 1058/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7890 - val_loss: 8.0677\n",
      "Epoch 1059/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7419 - val_loss: 8.1397\n",
      "Epoch 1060/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1502 - val_loss: 8.1549\n",
      "Epoch 1061/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.8493 - val_loss: 8.3777\n",
      "Epoch 1062/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1335 - val_loss: 7.5992\n",
      "Epoch 1063/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9493 - val_loss: 7.7501\n",
      "Epoch 1064/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0125 - val_loss: 7.7728\n",
      "Epoch 1065/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2135 - val_loss: 8.3018\n",
      "Epoch 1066/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1290 - val_loss: 7.9618\n",
      "Epoch 1067/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0438 - val_loss: 7.5798\n",
      "Epoch 1068/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7772 - val_loss: 7.5414\n",
      "Epoch 1069/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9432 - val_loss: 7.4946\n",
      "Epoch 1070/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7999 - val_loss: 7.4495\n",
      "Epoch 1071/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9780 - val_loss: 8.3809\n",
      "Epoch 1072/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4855 - val_loss: 8.1416\n",
      "Epoch 1073/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.3276 - val_loss: 7.4314\n",
      "Epoch 1074/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8236 - val_loss: 8.7537\n",
      "Epoch 1075/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.3693 - val_loss: 7.9168\n",
      "Epoch 1076/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8343 - val_loss: 7.7338\n",
      "Epoch 1077/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6593 - val_loss: 7.4438\n",
      "Epoch 1078/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7148 - val_loss: 7.5733\n",
      "Epoch 1079/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7027 - val_loss: 7.8175\n",
      "Epoch 1080/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9552 - val_loss: 7.6283\n",
      "Epoch 1081/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8462 - val_loss: 7.9939\n",
      "Epoch 1082/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0573 - val_loss: 7.7000\n",
      "Epoch 1083/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8679 - val_loss: 8.1033\n",
      "Epoch 1084/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2320 - val_loss: 7.6114\n",
      "Epoch 1085/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8383 - val_loss: 8.2368\n",
      "Epoch 1086/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2722 - val_loss: 8.2451\n",
      "Epoch 1087/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2666 - val_loss: 7.7957\n",
      "Epoch 1088/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8033 - val_loss: 7.5717\n",
      "Epoch 1089/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8443 - val_loss: 8.0765\n",
      "Epoch 1090/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1684 - val_loss: 8.7205\n",
      "Epoch 1091/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.3037 - val_loss: 7.8777\n",
      "Epoch 1092/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0158 - val_loss: 7.8995\n",
      "Epoch 1093/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.8784 - val_loss: 7.6335\n",
      "Epoch 1094/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9102 - val_loss: 7.6647\n",
      "Epoch 1095/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7785 - val_loss: 8.0653\n",
      "Epoch 1096/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8973 - val_loss: 7.8426\n",
      "Epoch 1097/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7952 - val_loss: 7.9383\n",
      "Epoch 1098/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2018 - val_loss: 8.1178\n",
      "Epoch 1099/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7733 - val_loss: 8.0359\n",
      "Epoch 1100/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.0028 - val_loss: 7.7499\n",
      "Epoch 1101/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7396 - val_loss: 7.5418\n",
      "Epoch 1102/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7921 - val_loss: 8.0570\n",
      "Epoch 1103/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9664 - val_loss: 7.5944\n",
      "Epoch 1104/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.8442 - val_loss: 7.9418\n",
      "Epoch 1105/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.1923 - val_loss: 8.0191\n",
      "Epoch 1106/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.1137 - val_loss: 7.7701\n",
      "Epoch 1107/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.0720 - val_loss: 8.2465\n",
      "Epoch 1108/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.1501 - val_loss: 7.5961\n",
      "Epoch 1109/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9210 - val_loss: 7.4654\n",
      "Epoch 1110/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7030 - val_loss: 7.4894\n",
      "Epoch 1111/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8154 - val_loss: 7.4705\n",
      "Epoch 1112/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8559 - val_loss: 7.6830\n",
      "Epoch 1113/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9636 - val_loss: 7.5120\n",
      "Epoch 1114/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8621 - val_loss: 8.1022\n",
      "Epoch 1115/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8845 - val_loss: 8.4387\n",
      "Epoch 1116/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.2610 - val_loss: 7.5017\n",
      "Epoch 1117/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8162 - val_loss: 7.3715\n",
      "Epoch 1118/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7167 - val_loss: 7.3189\n",
      "Epoch 1119/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.6742 - val_loss: 7.6633\n",
      "Epoch 1120/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.0078 - val_loss: 7.5283\n",
      "Epoch 1121/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8684 - val_loss: 8.0250\n",
      "Epoch 1122/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8745 - val_loss: 7.3768\n",
      "Epoch 1123/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.6695 - val_loss: 7.4414\n",
      "Epoch 1124/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8203 - val_loss: 7.9372\n",
      "Epoch 1125/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9577 - val_loss: 8.0564\n",
      "Epoch 1126/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7978 - val_loss: 8.0664\n",
      "Epoch 1127/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9455 - val_loss: 7.8903\n",
      "Epoch 1128/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7513 - val_loss: 9.3342\n",
      "Epoch 1129/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 4.1557 - val_loss: 8.1076\n",
      "Epoch 1130/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9962 - val_loss: 7.6057\n",
      "Epoch 1131/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9833 - val_loss: 7.8469\n",
      "Epoch 1132/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9108 - val_loss: 7.9775\n",
      "Epoch 1133/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.2360 - val_loss: 7.9304\n",
      "Epoch 1134/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.1669 - val_loss: 7.7690\n",
      "Epoch 1135/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8654 - val_loss: 7.6985\n",
      "Epoch 1136/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9501 - val_loss: 7.9964\n",
      "Epoch 1137/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8701 - val_loss: 7.9034\n",
      "Epoch 1138/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7688 - val_loss: 7.5235\n",
      "Epoch 1139/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9400 - val_loss: 7.6208\n",
      "Epoch 1140/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9019 - val_loss: 7.7981\n",
      "Epoch 1141/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7458 - val_loss: 7.2520\n",
      "Epoch 1142/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.6054 - val_loss: 7.8940\n",
      "Epoch 1143/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8460 - val_loss: 7.9941\n",
      "Epoch 1144/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8948 - val_loss: 7.5977\n",
      "Epoch 1145/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.6726 - val_loss: 7.8272\n",
      "Epoch 1146/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.1115 - val_loss: 8.6696\n",
      "Epoch 1147/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.0069 - val_loss: 8.1842\n",
      "Epoch 1148/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.0411 - val_loss: 8.1554\n",
      "Epoch 1149/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.0504 - val_loss: 8.3482\n",
      "Epoch 1150/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.1287 - val_loss: 8.4151\n",
      "Epoch 1151/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.0742 - val_loss: 7.6785\n",
      "Epoch 1152/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.6854 - val_loss: 7.9815\n",
      "Epoch 1153/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.0297 - val_loss: 8.2338\n",
      "Epoch 1154/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8698 - val_loss: 8.2124\n",
      "Epoch 1155/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8993 - val_loss: 7.5641\n",
      "Epoch 1156/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.6737 - val_loss: 8.1870\n",
      "Epoch 1157/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8353 - val_loss: 7.8970\n",
      "Epoch 1158/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.6834 - val_loss: 7.8216\n",
      "Epoch 1159/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.0034 - val_loss: 8.0791\n",
      "Epoch 1160/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9724 - val_loss: 7.7190\n",
      "Epoch 1161/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8974 - val_loss: 8.0236\n",
      "Epoch 1162/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7468 - val_loss: 8.4211\n",
      "Epoch 1163/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8037 - val_loss: 7.6835\n",
      "Epoch 1164/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7493 - val_loss: 7.8416\n",
      "Epoch 1165/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7592 - val_loss: 7.6425\n",
      "Epoch 1166/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7771 - val_loss: 8.3147\n",
      "Epoch 1167/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 3.2726 - val_loss: 7.7257\n",
      "Epoch 1168/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9385 - val_loss: 7.7012\n",
      "Epoch 1169/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6992 - val_loss: 7.4460\n",
      "Epoch 1170/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7088 - val_loss: 7.3245\n",
      "Epoch 1171/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6855 - val_loss: 7.5537\n",
      "Epoch 1172/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7368 - val_loss: 7.8162\n",
      "Epoch 1173/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9522 - val_loss: 8.0196\n",
      "Epoch 1174/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7832 - val_loss: 7.7095\n",
      "Epoch 1175/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1779 - val_loss: 7.6317\n",
      "Epoch 1176/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7305 - val_loss: 7.5014\n",
      "Epoch 1177/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8101 - val_loss: 7.8754\n",
      "Epoch 1178/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.8067 - val_loss: 8.0563\n",
      "Epoch 1179/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.9839 - val_loss: 7.7787\n",
      "Epoch 1180/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.8177 - val_loss: 8.8393\n",
      "Epoch 1181/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9801 - val_loss: 8.0852\n",
      "Epoch 1182/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0875 - val_loss: 7.5661\n",
      "Epoch 1183/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.8313 - val_loss: 8.7017\n",
      "Epoch 1184/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.1774 - val_loss: 7.9748\n",
      "Epoch 1185/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.9345 - val_loss: 7.4140\n",
      "Epoch 1186/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7971 - val_loss: 7.7438\n",
      "Epoch 1187/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7448 - val_loss: 7.3972\n",
      "Epoch 1188/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6844 - val_loss: 7.5367\n",
      "Epoch 1189/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7549 - val_loss: 7.7347\n",
      "Epoch 1190/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7087 - val_loss: 7.7455\n",
      "Epoch 1191/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5427 - val_loss: 7.6650\n",
      "Epoch 1192/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7140 - val_loss: 8.2505\n",
      "Epoch 1193/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7209 - val_loss: 7.9531\n",
      "Epoch 1194/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6513 - val_loss: 7.8188\n",
      "Epoch 1195/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.8189 - val_loss: 7.7698\n",
      "Epoch 1196/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7370 - val_loss: 8.1144\n",
      "Epoch 1197/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7025 - val_loss: 7.9559\n",
      "Epoch 1198/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7359 - val_loss: 7.4992\n",
      "Epoch 1199/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7109 - val_loss: 8.3076\n",
      "Epoch 1200/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8149 - val_loss: 8.2083\n",
      "Epoch 1201/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8949 - val_loss: 7.9376\n",
      "Epoch 1202/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8416 - val_loss: 7.3234\n",
      "Epoch 1203/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7153 - val_loss: 7.9401\n",
      "Epoch 1204/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7209 - val_loss: 7.5191\n",
      "Epoch 1205/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7533 - val_loss: 7.5898\n",
      "Epoch 1206/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6794 - val_loss: 9.0562\n",
      "Epoch 1207/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.0371 - val_loss: 7.6987\n",
      "Epoch 1208/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6818 - val_loss: 8.0494\n",
      "Epoch 1209/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.9340 - val_loss: 7.9847\n",
      "Epoch 1210/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7621 - val_loss: 7.8087\n",
      "Epoch 1211/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.8192 - val_loss: 8.2672\n",
      "Epoch 1212/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2314 - val_loss: 7.7699\n",
      "Epoch 1213/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6952 - val_loss: 7.9631\n",
      "Epoch 1214/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9397 - val_loss: 7.8314\n",
      "Epoch 1215/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.9679 - val_loss: 7.6117\n",
      "Epoch 1216/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8800 - val_loss: 8.6912\n",
      "Epoch 1217/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0158 - val_loss: 7.6330\n",
      "Epoch 1218/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6449 - val_loss: 7.6647\n",
      "Epoch 1219/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7329 - val_loss: 7.9946\n",
      "Epoch 1220/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8733 - val_loss: 7.6334\n",
      "Epoch 1221/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6063 - val_loss: 7.8425\n",
      "Epoch 1222/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8184 - val_loss: 7.7169\n",
      "Epoch 1223/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6853 - val_loss: 7.9052\n",
      "Epoch 1224/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.8673 - val_loss: 7.8753\n",
      "Epoch 1225/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7802 - val_loss: 7.8698\n",
      "Epoch 1226/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.9256 - val_loss: 7.9136\n",
      "Epoch 1227/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6284 - val_loss: 7.6795\n",
      "Epoch 1228/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8336 - val_loss: 7.8193\n",
      "Epoch 1229/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9098 - val_loss: 7.5556\n",
      "Epoch 1230/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7998 - val_loss: 7.3105\n",
      "Epoch 1231/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5836 - val_loss: 7.6728\n",
      "Epoch 1232/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8666 - val_loss: 7.8527\n",
      "Epoch 1233/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6228 - val_loss: 8.1733\n",
      "Epoch 1234/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.0166 - val_loss: 7.8585\n",
      "Epoch 1235/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7150 - val_loss: 8.5358\n",
      "Epoch 1236/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7942 - val_loss: 7.7541\n",
      "Epoch 1237/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6503 - val_loss: 7.7779\n",
      "Epoch 1238/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.6809 - val_loss: 7.8137\n",
      "Epoch 1239/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0393 - val_loss: 7.9312\n",
      "Epoch 1240/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8101 - val_loss: 7.4027\n",
      "Epoch 1241/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8841 - val_loss: 9.3328\n",
      "Epoch 1242/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1451 - val_loss: 7.8962\n",
      "Epoch 1243/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6824 - val_loss: 8.0794\n",
      "Epoch 1244/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7961 - val_loss: 7.4797\n",
      "Epoch 1245/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6738 - val_loss: 8.1160\n",
      "Epoch 1246/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9712 - val_loss: 8.1968\n",
      "Epoch 1247/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7644 - val_loss: 7.5709\n",
      "Epoch 1248/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7877 - val_loss: 7.6787\n",
      "Epoch 1249/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6197 - val_loss: 7.2866\n",
      "Epoch 1250/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4954 - val_loss: 7.5763\n",
      "Epoch 1251/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6402 - val_loss: 7.7271\n",
      "Epoch 1252/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5999 - val_loss: 7.8295\n",
      "Epoch 1253/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6136 - val_loss: 7.5518\n",
      "Epoch 1254/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5976 - val_loss: 8.0301\n",
      "Epoch 1255/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7659 - val_loss: 7.4337\n",
      "Epoch 1256/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7412 - val_loss: 7.8279\n",
      "Epoch 1257/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8784 - val_loss: 7.8206\n",
      "Epoch 1258/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8305 - val_loss: 7.3380\n",
      "Epoch 1259/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8055 - val_loss: 7.8986\n",
      "Epoch 1260/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7174 - val_loss: 8.0939\n",
      "Epoch 1261/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.1615 - val_loss: 7.5052\n",
      "Epoch 1262/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6774 - val_loss: 7.6235\n",
      "Epoch 1263/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7136 - val_loss: 7.6795\n",
      "Epoch 1264/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7045 - val_loss: 7.3074\n",
      "Epoch 1265/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4177 - val_loss: 7.3690\n",
      "Epoch 1266/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6515 - val_loss: 7.5621\n",
      "Epoch 1267/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6928 - val_loss: 7.6578\n",
      "Epoch 1268/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4963 - val_loss: 8.1942\n",
      "Epoch 1269/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9118 - val_loss: 7.4853\n",
      "Epoch 1270/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6906 - val_loss: 7.4257\n",
      "Epoch 1271/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5811 - val_loss: 8.0483\n",
      "Epoch 1272/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5698 - val_loss: 7.7787\n",
      "Epoch 1273/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6368 - val_loss: 7.5944\n",
      "Epoch 1274/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7405 - val_loss: 7.8022\n",
      "Epoch 1275/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5612 - val_loss: 7.6046\n",
      "Epoch 1276/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6028 - val_loss: 7.8335\n",
      "Epoch 1277/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7573 - val_loss: 8.8897\n",
      "Epoch 1278/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.9543 - val_loss: 7.5276\n",
      "Epoch 1279/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5612 - val_loss: 7.4021\n",
      "Epoch 1280/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6666 - val_loss: 7.7507\n",
      "Epoch 1281/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8013 - val_loss: 7.8354\n",
      "Epoch 1282/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.1945 - val_loss: 7.7376\n",
      "Epoch 1283/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6048 - val_loss: 7.8643\n",
      "Epoch 1284/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7746 - val_loss: 7.6724\n",
      "Epoch 1285/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.6340 - val_loss: 7.6512\n",
      "Epoch 1286/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7294 - val_loss: 7.7984\n",
      "Epoch 1287/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7580 - val_loss: 7.4379\n",
      "Epoch 1288/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7365 - val_loss: 7.6932\n",
      "Epoch 1289/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7310 - val_loss: 7.3161\n",
      "Epoch 1290/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3578 - val_loss: 7.8311\n",
      "Epoch 1291/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7131 - val_loss: 7.4977\n",
      "Epoch 1292/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5530 - val_loss: 7.5597\n",
      "Epoch 1293/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5510 - val_loss: 7.5622\n",
      "Epoch 1294/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6171 - val_loss: 7.5709\n",
      "Epoch 1295/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5373 - val_loss: 8.4616\n",
      "Epoch 1296/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8531 - val_loss: 7.2782\n",
      "Epoch 1297/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5356 - val_loss: 7.8429\n",
      "Epoch 1298/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8017 - val_loss: 7.5940\n",
      "Epoch 1299/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6378 - val_loss: 7.8177\n",
      "Epoch 1300/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6509 - val_loss: 8.4326\n",
      "Epoch 1301/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8049 - val_loss: 7.7336\n",
      "Epoch 1302/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6259 - val_loss: 7.6415\n",
      "Epoch 1303/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5216 - val_loss: 7.4372\n",
      "Epoch 1304/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6299 - val_loss: 7.4975\n",
      "Epoch 1305/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9223 - val_loss: 7.6698\n",
      "Epoch 1306/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7590 - val_loss: 8.1892\n",
      "Epoch 1307/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7366 - val_loss: 7.8076\n",
      "Epoch 1308/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7131 - val_loss: 7.3614\n",
      "Epoch 1309/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5535 - val_loss: 7.3253\n",
      "Epoch 1310/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3728 - val_loss: 7.8870\n",
      "Epoch 1311/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5187 - val_loss: 7.4400\n",
      "Epoch 1312/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5872 - val_loss: 8.6157\n",
      "Epoch 1313/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8207 - val_loss: 7.4675\n",
      "Epoch 1314/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7594 - val_loss: 7.8515\n",
      "Epoch 1315/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6826 - val_loss: 7.5966\n",
      "Epoch 1316/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5466 - val_loss: 7.9340\n",
      "Epoch 1317/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5693 - val_loss: 7.1996\n",
      "Epoch 1318/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4913 - val_loss: 7.4025\n",
      "Epoch 1319/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4494 - val_loss: 7.5734\n",
      "Epoch 1320/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4097 - val_loss: 7.1883\n",
      "Epoch 1321/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4317 - val_loss: 7.2461\n",
      "Epoch 1322/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3266 - val_loss: 7.6099\n",
      "Epoch 1323/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6331 - val_loss: 8.0460\n",
      "Epoch 1324/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8368 - val_loss: 7.8321\n",
      "Epoch 1325/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6823 - val_loss: 8.2071\n",
      "Epoch 1326/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6091 - val_loss: 7.6026\n",
      "Epoch 1327/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6527 - val_loss: 7.1763\n",
      "Epoch 1328/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4808 - val_loss: 7.7686\n",
      "Epoch 1329/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8327 - val_loss: 7.9859\n",
      "Epoch 1330/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9198 - val_loss: 8.7444\n",
      "Epoch 1331/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9789 - val_loss: 7.5251\n",
      "Epoch 1332/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7081 - val_loss: 7.6027\n",
      "Epoch 1333/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6899 - val_loss: 7.6871\n",
      "Epoch 1334/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7070 - val_loss: 7.6532\n",
      "Epoch 1335/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7468 - val_loss: 8.2267\n",
      "Epoch 1336/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9405 - val_loss: 7.7718\n",
      "Epoch 1337/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7261 - val_loss: 7.8848\n",
      "Epoch 1338/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0145 - val_loss: 7.8160\n",
      "Epoch 1339/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8699 - val_loss: 7.8394\n",
      "Epoch 1340/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7065 - val_loss: 7.6710\n",
      "Epoch 1341/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6817 - val_loss: 7.7211\n",
      "Epoch 1342/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6982 - val_loss: 7.4317\n",
      "Epoch 1343/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4940 - val_loss: 7.4853\n",
      "Epoch 1344/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7866 - val_loss: 7.8355\n",
      "Epoch 1345/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7107 - val_loss: 7.5248\n",
      "Epoch 1346/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6713 - val_loss: 7.9949\n",
      "Epoch 1347/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7432 - val_loss: 7.7121\n",
      "Epoch 1348/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0178 - val_loss: 7.8207\n",
      "Epoch 1349/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7742 - val_loss: 7.7389\n",
      "Epoch 1350/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6684 - val_loss: 7.5078\n",
      "Epoch 1351/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7818 - val_loss: 7.9917\n",
      "Epoch 1352/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.9692 - val_loss: 7.4213\n",
      "Epoch 1353/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4965 - val_loss: 7.8365\n",
      "Epoch 1354/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6924 - val_loss: 8.0105\n",
      "Epoch 1355/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7924 - val_loss: 7.4547\n",
      "Epoch 1356/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7002 - val_loss: 7.6414\n",
      "Epoch 1357/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4726 - val_loss: 7.6027\n",
      "Epoch 1358/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5843 - val_loss: 7.3702\n",
      "Epoch 1359/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5542 - val_loss: 7.7449\n",
      "Epoch 1360/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 3.1701 - val_loss: 7.9044\n",
      "Epoch 1361/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8254 - val_loss: 7.6940\n",
      "Epoch 1362/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7297 - val_loss: 7.5645\n",
      "Epoch 1363/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4221 - val_loss: 7.2349\n",
      "Epoch 1364/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.3829 - val_loss: 7.6084\n",
      "Epoch 1365/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5409 - val_loss: 7.4466\n",
      "Epoch 1366/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.5642 - val_loss: 7.7994\n",
      "Epoch 1367/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6084 - val_loss: 7.8215\n",
      "Epoch 1368/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5487 - val_loss: 7.3630\n",
      "Epoch 1369/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4847 - val_loss: 7.6165\n",
      "Epoch 1370/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6060 - val_loss: 7.2798\n",
      "Epoch 1371/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7251 - val_loss: 7.8966\n",
      "Epoch 1372/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.9442 - val_loss: 7.5804\n",
      "Epoch 1373/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.6158 - val_loss: 7.6002\n",
      "Epoch 1374/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7247 - val_loss: 7.4794\n",
      "Epoch 1375/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.8596 - val_loss: 7.8691\n",
      "Epoch 1376/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.2551 - val_loss: 7.6369\n",
      "Epoch 1377/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.8157 - val_loss: 8.0028\n",
      "Epoch 1378/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.8137 - val_loss: 8.3163\n",
      "Epoch 1379/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.9627 - val_loss: 7.5293\n",
      "Epoch 1380/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6217 - val_loss: 7.9167\n",
      "Epoch 1381/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7782 - val_loss: 7.7390\n",
      "Epoch 1382/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6685 - val_loss: 7.5567\n",
      "Epoch 1383/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.6286 - val_loss: 7.7250\n",
      "Epoch 1384/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.8952 - val_loss: 7.6592\n",
      "Epoch 1385/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5302 - val_loss: 7.7368\n",
      "Epoch 1386/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5454 - val_loss: 7.4686\n",
      "Epoch 1387/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5871 - val_loss: 7.8870\n",
      "Epoch 1388/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6298 - val_loss: 7.5375\n",
      "Epoch 1389/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.5688 - val_loss: 7.6439\n",
      "Epoch 1390/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5648 - val_loss: 7.4894\n",
      "Epoch 1391/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4534 - val_loss: 8.2573\n",
      "Epoch 1392/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5959 - val_loss: 8.6274\n",
      "Epoch 1393/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6914 - val_loss: 8.0016\n",
      "Epoch 1394/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5851 - val_loss: 8.1728\n",
      "Epoch 1395/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7391 - val_loss: 7.6786\n",
      "Epoch 1396/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5687 - val_loss: 7.8313\n",
      "Epoch 1397/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7197 - val_loss: 7.7993\n",
      "Epoch 1398/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7245 - val_loss: 7.6148\n",
      "Epoch 1399/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4340 - val_loss: 7.5700\n",
      "Epoch 1400/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5255 - val_loss: 8.1327\n",
      "Epoch 1401/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6112 - val_loss: 7.7778\n",
      "Epoch 1402/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5704 - val_loss: 8.0039\n",
      "Epoch 1403/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6349 - val_loss: 7.4967\n",
      "Epoch 1404/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5861 - val_loss: 7.5231\n",
      "Epoch 1405/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5233 - val_loss: 7.5396\n",
      "Epoch 1406/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4761 - val_loss: 7.7191\n",
      "Epoch 1407/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6326 - val_loss: 7.5757\n",
      "Epoch 1408/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4969 - val_loss: 7.9670\n",
      "Epoch 1409/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4932 - val_loss: 8.2075\n",
      "Epoch 1410/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6452 - val_loss: 8.7674\n",
      "Epoch 1411/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9318 - val_loss: 7.6280\n",
      "Epoch 1412/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5638 - val_loss: 7.7422\n",
      "Epoch 1413/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8221 - val_loss: 7.7504\n",
      "Epoch 1414/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7471 - val_loss: 7.2283\n",
      "Epoch 1415/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6033 - val_loss: 7.6663\n",
      "Epoch 1416/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4599 - val_loss: 7.7534\n",
      "Epoch 1417/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6172 - val_loss: 7.3488\n",
      "Epoch 1418/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.4869 - val_loss: 7.6327\n",
      "Epoch 1419/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5261 - val_loss: 7.7842\n",
      "Epoch 1420/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4983 - val_loss: 7.6956\n",
      "Epoch 1421/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4169 - val_loss: 7.5608\n",
      "Epoch 1422/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5251 - val_loss: 8.0103\n",
      "Epoch 1423/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9963 - val_loss: 7.8171\n",
      "Epoch 1424/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5680 - val_loss: 7.4160\n",
      "Epoch 1425/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3418 - val_loss: 8.2454\n",
      "Epoch 1426/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8247 - val_loss: 7.2614\n",
      "Epoch 1427/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3516 - val_loss: 7.3801\n",
      "Epoch 1428/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6499 - val_loss: 7.8759\n",
      "Epoch 1429/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4735 - val_loss: 7.3456\n",
      "Epoch 1430/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6062 - val_loss: 8.3532\n",
      "Epoch 1431/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6998 - val_loss: 7.5614\n",
      "Epoch 1432/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5326 - val_loss: 7.6161\n",
      "Epoch 1433/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7244 - val_loss: 8.0612\n",
      "Epoch 1434/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8553 - val_loss: 7.7726\n",
      "Epoch 1435/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5940 - val_loss: 7.2882\n",
      "Epoch 1436/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4232 - val_loss: 7.7589\n",
      "Epoch 1437/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6336 - val_loss: 7.3876\n",
      "Epoch 1438/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3570 - val_loss: 7.7873\n",
      "Epoch 1439/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6773 - val_loss: 7.5248\n",
      "Epoch 1440/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4899 - val_loss: 7.5411\n",
      "Epoch 1441/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4755 - val_loss: 7.4119\n",
      "Epoch 1442/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4861 - val_loss: 7.5624\n",
      "Epoch 1443/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4252 - val_loss: 7.5751\n",
      "Epoch 1444/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5059 - val_loss: 7.5496\n",
      "Epoch 1445/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5181 - val_loss: 7.6028\n",
      "Epoch 1446/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4860 - val_loss: 7.3523\n",
      "Epoch 1447/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.3278 - val_loss: 7.7740\n",
      "Epoch 1448/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7841 - val_loss: 7.7752\n",
      "Epoch 1449/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4976 - val_loss: 7.7021\n",
      "Epoch 1450/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7219 - val_loss: 7.9195\n",
      "Epoch 1451/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5409 - val_loss: 7.5487\n",
      "Epoch 1452/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5667 - val_loss: 7.6356\n",
      "Epoch 1453/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4817 - val_loss: 7.4372\n",
      "Epoch 1454/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.4750 - val_loss: 7.5674\n",
      "Epoch 1455/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3329 - val_loss: 7.7029\n",
      "Epoch 1456/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3463 - val_loss: 7.4876\n",
      "Epoch 1457/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3774 - val_loss: 8.0358\n",
      "Epoch 1458/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5931 - val_loss: 7.3521\n",
      "Epoch 1459/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4576 - val_loss: 7.4951\n",
      "Epoch 1460/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4861 - val_loss: 7.4382\n",
      "Epoch 1461/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.6573 - val_loss: 7.5380\n",
      "Epoch 1462/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4680 - val_loss: 7.5876\n",
      "Epoch 1463/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5511 - val_loss: 7.4790\n",
      "Epoch 1464/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4872 - val_loss: 7.6279\n",
      "Epoch 1465/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7044 - val_loss: 7.7906\n",
      "Epoch 1466/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4171 - val_loss: 7.7414\n",
      "Epoch 1467/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6916 - val_loss: 7.7462\n",
      "Epoch 1468/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 3.0479 - val_loss: 7.6926\n",
      "Epoch 1469/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.8439 - val_loss: 7.6076\n",
      "Epoch 1470/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5725 - val_loss: 7.9289\n",
      "Epoch 1471/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6383 - val_loss: 7.7094\n",
      "Epoch 1472/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0223 - val_loss: 7.7652\n",
      "Epoch 1473/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7757 - val_loss: 8.4242\n",
      "Epoch 1474/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6415 - val_loss: 7.9123\n",
      "Epoch 1475/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7059 - val_loss: 7.9379\n",
      "Epoch 1476/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6009 - val_loss: 7.6431\n",
      "Epoch 1477/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3240 - val_loss: 7.5577\n",
      "Epoch 1478/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5058 - val_loss: 7.8194\n",
      "Epoch 1479/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4552 - val_loss: 7.7291\n",
      "Epoch 1480/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6747 - val_loss: 7.6277\n",
      "Epoch 1481/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8671 - val_loss: 8.3752\n",
      "Epoch 1482/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9481 - val_loss: 8.0888\n",
      "Epoch 1483/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5733 - val_loss: 7.5191\n",
      "Epoch 1484/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5026 - val_loss: 7.4403\n",
      "Epoch 1485/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2862 - val_loss: 7.6619\n",
      "Epoch 1486/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6664 - val_loss: 7.3933\n",
      "Epoch 1487/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2659 - val_loss: 7.2032\n",
      "Epoch 1488/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4488 - val_loss: 7.2370\n",
      "Epoch 1489/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3269 - val_loss: 7.5988\n",
      "Epoch 1490/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.4291 - val_loss: 7.9146\n",
      "Epoch 1491/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4026 - val_loss: 7.9640\n",
      "Epoch 1492/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5894 - val_loss: 7.5720\n",
      "Epoch 1493/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.2469 - val_loss: 7.7418\n",
      "Epoch 1494/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7010 - val_loss: 7.6754\n",
      "Epoch 1495/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7356 - val_loss: 7.7166\n",
      "Epoch 1496/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4471 - val_loss: 7.6574\n",
      "Epoch 1497/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7253 - val_loss: 7.3642\n",
      "Epoch 1498/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.4622 - val_loss: 7.3043\n",
      "Epoch 1499/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.5666 - val_loss: 7.4658\n",
      "Epoch 1500/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6030 - val_loss: 7.1150\n",
      "Epoch 1501/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3877 - val_loss: 7.5723\n",
      "Epoch 1502/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3372 - val_loss: 7.4012\n",
      "Epoch 1503/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3443 - val_loss: 7.5626\n",
      "Epoch 1504/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6407 - val_loss: 8.4216\n",
      "Epoch 1505/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9832 - val_loss: 7.8614\n",
      "Epoch 1506/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6213 - val_loss: 7.5218\n",
      "Epoch 1507/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5718 - val_loss: 7.5282\n",
      "Epoch 1508/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4889 - val_loss: 7.8296\n",
      "Epoch 1509/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5647 - val_loss: 8.0361\n",
      "Epoch 1510/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5310 - val_loss: 7.5226\n",
      "Epoch 1511/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5638 - val_loss: 7.6088\n",
      "Epoch 1512/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6789 - val_loss: 8.3843\n",
      "Epoch 1513/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5700 - val_loss: 7.3252\n",
      "Epoch 1514/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3659 - val_loss: 7.4513\n",
      "Epoch 1515/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4631 - val_loss: 8.8415\n",
      "Epoch 1516/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 4.9377 - val_loss: 7.8674\n",
      "Epoch 1517/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.8786 - val_loss: 7.5241\n",
      "Epoch 1518/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6227 - val_loss: 7.7066\n",
      "Epoch 1519/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5382 - val_loss: 7.4994\n",
      "Epoch 1520/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3645 - val_loss: 7.8476\n",
      "Epoch 1521/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7257 - val_loss: 8.6967\n",
      "Epoch 1522/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0543 - val_loss: 8.6059\n",
      "Epoch 1523/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8326 - val_loss: 7.4744\n",
      "Epoch 1524/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6664 - val_loss: 8.8474\n",
      "Epoch 1525/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7769 - val_loss: 7.9679\n",
      "Epoch 1526/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6416 - val_loss: 7.8606\n",
      "Epoch 1527/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5004 - val_loss: 7.5271\n",
      "Epoch 1528/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4986 - val_loss: 7.7476\n",
      "Epoch 1529/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4358 - val_loss: 7.4375\n",
      "Epoch 1530/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4656 - val_loss: 8.0254\n",
      "Epoch 1531/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7528 - val_loss: 7.9941\n",
      "Epoch 1532/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7950 - val_loss: 7.5261\n",
      "Epoch 1533/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3459 - val_loss: 7.5106\n",
      "Epoch 1534/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4948 - val_loss: 7.4918\n",
      "Epoch 1535/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5505 - val_loss: 7.5844\n",
      "Epoch 1536/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3708 - val_loss: 7.3394\n",
      "Epoch 1537/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4942 - val_loss: 7.5018\n",
      "Epoch 1538/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2768 - val_loss: 7.2434\n",
      "Epoch 1539/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4558 - val_loss: 7.9255\n",
      "Epoch 1540/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5485 - val_loss: 7.3461\n",
      "Epoch 1541/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4382 - val_loss: 7.6919\n",
      "Epoch 1542/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4810 - val_loss: 7.5158\n",
      "Epoch 1543/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3645 - val_loss: 7.4364\n",
      "Epoch 1544/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3752 - val_loss: 7.4340\n",
      "Epoch 1545/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4592 - val_loss: 7.3144\n",
      "Epoch 1546/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3163 - val_loss: 7.2914\n",
      "Epoch 1547/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4258 - val_loss: 7.4793\n",
      "Epoch 1548/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3708 - val_loss: 7.6732\n",
      "Epoch 1549/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6548 - val_loss: 7.2237\n",
      "Epoch 1550/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2630 - val_loss: 7.3556\n",
      "Epoch 1551/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4024 - val_loss: 7.4413\n",
      "Epoch 1552/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5560 - val_loss: 7.3878\n",
      "Epoch 1553/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5961 - val_loss: 7.5034\n",
      "Epoch 1554/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5308 - val_loss: 7.3728\n",
      "Epoch 1555/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4245 - val_loss: 7.8234\n",
      "Epoch 1556/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5965 - val_loss: 7.1746\n",
      "Epoch 1557/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3275 - val_loss: 7.9226\n",
      "Epoch 1558/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6329 - val_loss: 7.9559\n",
      "Epoch 1559/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6126 - val_loss: 7.3057\n",
      "Epoch 1560/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3963 - val_loss: 7.3898\n",
      "Epoch 1561/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3256 - val_loss: 7.5116\n",
      "Epoch 1562/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4611 - val_loss: 7.4734\n",
      "Epoch 1563/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5607 - val_loss: 7.7108\n",
      "Epoch 1564/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9165 - val_loss: 7.6849\n",
      "Epoch 1565/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5145 - val_loss: 7.5396\n",
      "Epoch 1566/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6651 - val_loss: 8.3137\n",
      "Epoch 1567/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.0086 - val_loss: 7.6131\n",
      "Epoch 1568/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4171 - val_loss: 7.3003\n",
      "Epoch 1569/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6252 - val_loss: 7.6335\n",
      "Epoch 1570/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6683 - val_loss: 7.7212\n",
      "Epoch 1571/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4316 - val_loss: 7.6018\n",
      "Epoch 1572/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6198 - val_loss: 7.8017\n",
      "Epoch 1573/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6391 - val_loss: 7.5874\n",
      "Epoch 1574/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4257 - val_loss: 8.1987\n",
      "Epoch 1575/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7924 - val_loss: 7.8957\n",
      "Epoch 1576/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6010 - val_loss: 7.5662\n",
      "Epoch 1577/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3519 - val_loss: 7.2665\n",
      "Epoch 1578/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6216 - val_loss: 7.3749\n",
      "Epoch 1579/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4403 - val_loss: 7.4695\n",
      "Epoch 1580/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3506 - val_loss: 7.5749\n",
      "Epoch 1581/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2984 - val_loss: 7.2934\n",
      "Epoch 1582/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3409 - val_loss: 7.4484\n",
      "Epoch 1583/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2908 - val_loss: 7.3768\n",
      "Epoch 1584/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4411 - val_loss: 7.5669\n",
      "Epoch 1585/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3882 - val_loss: 7.6669\n",
      "Epoch 1586/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5908 - val_loss: 7.6213\n",
      "Epoch 1587/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4027 - val_loss: 7.8750\n",
      "Epoch 1588/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4521 - val_loss: 7.8372\n",
      "Epoch 1589/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4605 - val_loss: 7.2906\n",
      "Epoch 1590/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2539 - val_loss: 7.5834\n",
      "Epoch 1591/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4380 - val_loss: 7.6393\n",
      "Epoch 1592/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4826 - val_loss: 7.4164\n",
      "Epoch 1593/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3655 - val_loss: 7.3818\n",
      "Epoch 1594/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6411 - val_loss: 7.3142\n",
      "Epoch 1595/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4378 - val_loss: 7.5282\n",
      "Epoch 1596/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3497 - val_loss: 7.6826\n",
      "Epoch 1597/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8504 - val_loss: 7.3798\n",
      "Epoch 1598/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4952 - val_loss: 7.8140\n",
      "Epoch 1599/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5792 - val_loss: 7.4770\n",
      "Epoch 1600/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3633 - val_loss: 7.2839\n",
      "Epoch 1601/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3836 - val_loss: 7.5652\n",
      "Epoch 1602/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4271 - val_loss: 7.3612\n",
      "Epoch 1603/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4917 - val_loss: 7.8453\n",
      "Epoch 1604/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3467 - val_loss: 7.3262\n",
      "Epoch 1605/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3262 - val_loss: 8.8797\n",
      "Epoch 1606/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8955 - val_loss: 7.4687\n",
      "Epoch 1607/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4180 - val_loss: 7.5015\n",
      "Epoch 1608/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4949 - val_loss: 7.5660\n",
      "Epoch 1609/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4527 - val_loss: 7.9865\n",
      "Epoch 1610/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5459 - val_loss: 7.5777\n",
      "Epoch 1611/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2824 - val_loss: 7.9412\n",
      "Epoch 1612/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3522 - val_loss: 7.5013\n",
      "Epoch 1613/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2995 - val_loss: 7.4763\n",
      "Epoch 1614/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3888 - val_loss: 7.5523\n",
      "Epoch 1615/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3857 - val_loss: 7.9267\n",
      "Epoch 1616/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7440 - val_loss: 7.1523\n",
      "Epoch 1617/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2945 - val_loss: 7.7070\n",
      "Epoch 1618/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2884 - val_loss: 7.3014\n",
      "Epoch 1619/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3773 - val_loss: 7.3944\n",
      "Epoch 1620/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2354 - val_loss: 7.2254\n",
      "Epoch 1621/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2802 - val_loss: 7.4400\n",
      "Epoch 1622/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3111 - val_loss: 7.4516\n",
      "Epoch 1623/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4551 - val_loss: 7.5375\n",
      "Epoch 1624/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3617 - val_loss: 7.4847\n",
      "Epoch 1625/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7922 - val_loss: 7.8639\n",
      "Epoch 1626/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6595 - val_loss: 7.1986\n",
      "Epoch 1627/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2882 - val_loss: 7.4254\n",
      "Epoch 1628/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3996 - val_loss: 7.5946\n",
      "Epoch 1629/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3690 - val_loss: 7.8001\n",
      "Epoch 1630/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3801 - val_loss: 7.5093\n",
      "Epoch 1631/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3905 - val_loss: 7.8122\n",
      "Epoch 1632/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4419 - val_loss: 7.2841\n",
      "Epoch 1633/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1535 - val_loss: 8.0648\n",
      "Epoch 1634/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5702 - val_loss: 7.5238\n",
      "Epoch 1635/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3452 - val_loss: 7.3153\n",
      "Epoch 1636/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3183 - val_loss: 7.9255\n",
      "Epoch 1637/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4748 - val_loss: 7.5256\n",
      "Epoch 1638/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3967 - val_loss: 8.1829\n",
      "Epoch 1639/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4636 - val_loss: 7.4790\n",
      "Epoch 1640/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3061 - val_loss: 7.1652\n",
      "Epoch 1641/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2525 - val_loss: 7.4597\n",
      "Epoch 1642/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.9842 - val_loss: 7.5029\n",
      "Epoch 1643/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6114 - val_loss: 7.9183\n",
      "Epoch 1644/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3554 - val_loss: 7.5706\n",
      "Epoch 1645/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3891 - val_loss: 7.4251\n",
      "Epoch 1646/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3308 - val_loss: 7.1511\n",
      "Epoch 1647/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2546 - val_loss: 7.2807\n",
      "Epoch 1648/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3029 - val_loss: 7.3986\n",
      "Epoch 1649/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2439 - val_loss: 7.2456\n",
      "Epoch 1650/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2189 - val_loss: 7.2258\n",
      "Epoch 1651/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1534 - val_loss: 7.6354\n",
      "Epoch 1652/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3488 - val_loss: 7.3112\n",
      "Epoch 1653/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4121 - val_loss: 7.6171\n",
      "Epoch 1654/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3633 - val_loss: 8.1504\n",
      "Epoch 1655/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5293 - val_loss: 7.3237\n",
      "Epoch 1656/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3872 - val_loss: 8.0088\n",
      "Epoch 1657/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5848 - val_loss: 7.2481\n",
      "Epoch 1658/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1908 - val_loss: 7.5115\n",
      "Epoch 1659/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3811 - val_loss: 8.0963\n",
      "Epoch 1660/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5865 - val_loss: 7.1847\n",
      "Epoch 1661/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3009 - val_loss: 7.3202\n",
      "Epoch 1662/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4251 - val_loss: 7.8219\n",
      "Epoch 1663/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6697 - val_loss: 7.9528\n",
      "Epoch 1664/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8459 - val_loss: 7.7711\n",
      "Epoch 1665/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5462 - val_loss: 7.7649\n",
      "Epoch 1666/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9084 - val_loss: 7.4604\n",
      "Epoch 1667/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4793 - val_loss: 7.3086\n",
      "Epoch 1668/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3751 - val_loss: 7.8838\n",
      "Epoch 1669/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5171 - val_loss: 7.3131\n",
      "Epoch 1670/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3570 - val_loss: 7.3715\n",
      "Epoch 1671/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3283 - val_loss: 7.5342\n",
      "Epoch 1672/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4294 - val_loss: 7.2974\n",
      "Epoch 1673/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4140 - val_loss: 7.6055\n",
      "Epoch 1674/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8408 - val_loss: 7.2744\n",
      "Epoch 1675/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5196 - val_loss: 7.4070\n",
      "Epoch 1676/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2590 - val_loss: 7.4053\n",
      "Epoch 1677/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1617 - val_loss: 7.5443\n",
      "Epoch 1678/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3563 - val_loss: 7.6226\n",
      "Epoch 1679/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3929 - val_loss: 7.4497\n",
      "Epoch 1680/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4180 - val_loss: 7.2523\n",
      "Epoch 1681/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1797 - val_loss: 7.4670\n",
      "Epoch 1682/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6624 - val_loss: 7.5573\n",
      "Epoch 1683/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4725 - val_loss: 7.2911\n",
      "Epoch 1684/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2234 - val_loss: 7.4122\n",
      "Epoch 1685/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2194 - val_loss: 7.7715\n",
      "Epoch 1686/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5609 - val_loss: 7.4451\n",
      "Epoch 1687/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3037 - val_loss: 7.6893\n",
      "Epoch 1688/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3031 - val_loss: 7.7009\n",
      "Epoch 1689/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2501 - val_loss: 7.2662\n",
      "Epoch 1690/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1793 - val_loss: 7.3753\n",
      "Epoch 1691/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1931 - val_loss: 7.4665\n",
      "Epoch 1692/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1915 - val_loss: 7.6544\n",
      "Epoch 1693/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4971 - val_loss: 7.6922\n",
      "Epoch 1694/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2849 - val_loss: 7.3033\n",
      "Epoch 1695/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3227 - val_loss: 7.4724\n",
      "Epoch 1696/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5006 - val_loss: 7.4978\n",
      "Epoch 1697/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3187 - val_loss: 7.5249\n",
      "Epoch 1698/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2603 - val_loss: 7.4772\n",
      "Epoch 1699/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2265 - val_loss: 7.6753\n",
      "Epoch 1700/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2800 - val_loss: 7.3186\n",
      "Epoch 1701/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3688 - val_loss: 7.4058\n",
      "Epoch 1702/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1592 - val_loss: 7.6437\n",
      "Epoch 1703/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5072 - val_loss: 7.4914\n",
      "Epoch 1704/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6334 - val_loss: 7.6656\n",
      "Epoch 1705/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3350 - val_loss: 7.4207\n",
      "Epoch 1706/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4798 - val_loss: 7.3767\n",
      "Epoch 1707/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2491 - val_loss: 7.3728\n",
      "Epoch 1708/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2353 - val_loss: 7.4892\n",
      "Epoch 1709/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2456 - val_loss: 8.2794\n",
      "Epoch 1710/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5961 - val_loss: 7.4437\n",
      "Epoch 1711/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2082 - val_loss: 7.3475\n",
      "Epoch 1712/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2512 - val_loss: 7.2062\n",
      "Epoch 1713/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1816 - val_loss: 7.3284\n",
      "Epoch 1714/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2073 - val_loss: 7.2351\n",
      "Epoch 1715/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2853 - val_loss: 7.4673\n",
      "Epoch 1716/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2094 - val_loss: 7.6159\n",
      "Epoch 1717/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.9329 - val_loss: 7.8006\n",
      "Epoch 1718/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3839 - val_loss: 7.4478\n",
      "Epoch 1719/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3235 - val_loss: 8.1789\n",
      "Epoch 1720/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5291 - val_loss: 7.5265\n",
      "Epoch 1721/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2704 - val_loss: 7.5240\n",
      "Epoch 1722/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3036 - val_loss: 7.3726\n",
      "Epoch 1723/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5455 - val_loss: 7.8018\n",
      "Epoch 1724/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3822 - val_loss: 7.9049\n",
      "Epoch 1725/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3616 - val_loss: 7.2034\n",
      "Epoch 1726/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2556 - val_loss: 7.2363\n",
      "Epoch 1727/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3030 - val_loss: 7.4901\n",
      "Epoch 1728/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3390 - val_loss: 7.2487\n",
      "Epoch 1729/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3002 - val_loss: 7.7482\n",
      "Epoch 1730/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3698 - val_loss: 7.4502\n",
      "Epoch 1731/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1628 - val_loss: 7.5351\n",
      "Epoch 1732/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3517 - val_loss: 7.1763\n",
      "Epoch 1733/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2150 - val_loss: 7.3748\n",
      "Epoch 1734/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2042 - val_loss: 7.4930\n",
      "Epoch 1735/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3193 - val_loss: 7.4051\n",
      "Epoch 1736/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1569 - val_loss: 8.1353\n",
      "Epoch 1737/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3743 - val_loss: 7.2690\n",
      "Epoch 1738/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2442 - val_loss: 7.5612\n",
      "Epoch 1739/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3525 - val_loss: 7.7356\n",
      "Epoch 1740/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3867 - val_loss: 7.3278\n",
      "Epoch 1741/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2679 - val_loss: 8.0082\n",
      "Epoch 1742/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3110 - val_loss: 7.2791\n",
      "Epoch 1743/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1830 - val_loss: 7.3593\n",
      "Epoch 1744/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2713 - val_loss: 7.4464\n",
      "Epoch 1745/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1859 - val_loss: 7.3843\n",
      "Epoch 1746/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5102 - val_loss: 7.6160\n",
      "Epoch 1747/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3658 - val_loss: 7.9250\n",
      "Epoch 1748/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5636 - val_loss: 7.2770\n",
      "Epoch 1749/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2220 - val_loss: 7.7047\n",
      "Epoch 1750/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3697 - val_loss: 7.3764\n",
      "Epoch 1751/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3437 - val_loss: 7.5810\n",
      "Epoch 1752/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3977 - val_loss: 7.3125\n",
      "Epoch 1753/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2216 - val_loss: 7.3839\n",
      "Epoch 1754/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3999 - val_loss: 7.7263\n",
      "Epoch 1755/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4533 - val_loss: 7.5761\n",
      "Epoch 1756/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4116 - val_loss: 7.3646\n",
      "Epoch 1757/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1147 - val_loss: 7.2216\n",
      "Epoch 1758/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1882 - val_loss: 7.9013\n",
      "Epoch 1759/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3230 - val_loss: 7.7200\n",
      "Epoch 1760/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8687 - val_loss: 7.5205\n",
      "Epoch 1761/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2284 - val_loss: 7.8718\n",
      "Epoch 1762/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3800 - val_loss: 7.5643\n",
      "Epoch 1763/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3001 - val_loss: 8.2665\n",
      "Epoch 1764/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3624 - val_loss: 7.6400\n",
      "Epoch 1765/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2674 - val_loss: 7.8222\n",
      "Epoch 1766/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3069 - val_loss: 7.6962\n",
      "Epoch 1767/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3199 - val_loss: 7.3245\n",
      "Epoch 1768/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1692 - val_loss: 7.5489\n",
      "Epoch 1769/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2390 - val_loss: 7.1808\n",
      "Epoch 1770/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9847 - val_loss: 7.6054\n",
      "Epoch 1771/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1758 - val_loss: 7.4961\n",
      "Epoch 1772/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3421 - val_loss: 7.2921\n",
      "Epoch 1773/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3152 - val_loss: 7.5897\n",
      "Epoch 1774/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2107 - val_loss: 7.5412\n",
      "Epoch 1775/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3054 - val_loss: 7.3363\n",
      "Epoch 1776/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1194 - val_loss: 8.0392\n",
      "Epoch 1777/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4285 - val_loss: 7.4536\n",
      "Epoch 1778/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3258 - val_loss: 7.8262\n",
      "Epoch 1779/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.2456 - val_loss: 7.5244\n",
      "Epoch 1780/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2431 - val_loss: 7.2884\n",
      "Epoch 1781/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3206 - val_loss: 7.6935\n",
      "Epoch 1782/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2513 - val_loss: 7.3158\n",
      "Epoch 1783/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1090 - val_loss: 7.2835\n",
      "Epoch 1784/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1245 - val_loss: 7.2871\n",
      "Epoch 1785/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1369 - val_loss: 7.3397\n",
      "Epoch 1786/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0605 - val_loss: 7.5117\n",
      "Epoch 1787/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0831 - val_loss: 7.9015\n",
      "Epoch 1788/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4799 - val_loss: 7.4618\n",
      "Epoch 1789/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3104 - val_loss: 7.5921\n",
      "Epoch 1790/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2275 - val_loss: 7.2743\n",
      "Epoch 1791/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1354 - val_loss: 7.3973\n",
      "Epoch 1792/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1708 - val_loss: 7.0431\n",
      "Epoch 1793/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1468 - val_loss: 7.4357\n",
      "Epoch 1794/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2490 - val_loss: 7.4039\n",
      "Epoch 1795/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1620 - val_loss: 7.3816\n",
      "Epoch 1796/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4727 - val_loss: 7.5127\n",
      "Epoch 1797/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4905 - val_loss: 7.5212\n",
      "Epoch 1798/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2097 - val_loss: 7.3209\n",
      "Epoch 1799/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2598 - val_loss: 8.1504\n",
      "Epoch 1800/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3655 - val_loss: 7.5202\n",
      "Epoch 1801/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4026 - val_loss: 7.9186\n",
      "Epoch 1802/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2700 - val_loss: 7.8350\n",
      "Epoch 1803/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2562 - val_loss: 7.8199\n",
      "Epoch 1804/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2544 - val_loss: 7.3006\n",
      "Epoch 1805/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1266 - val_loss: 7.4471\n",
      "Epoch 1806/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0715 - val_loss: 7.2207\n",
      "Epoch 1807/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2344 - val_loss: 7.6306\n",
      "Epoch 1808/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2516 - val_loss: 7.6702\n",
      "Epoch 1809/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1961 - val_loss: 7.5833\n",
      "Epoch 1810/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1513 - val_loss: 7.2221\n",
      "Epoch 1811/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2561 - val_loss: 7.5191\n",
      "Epoch 1812/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2185 - val_loss: 7.3832\n",
      "Epoch 1813/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3747 - val_loss: 7.3214\n",
      "Epoch 1814/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1571 - val_loss: 7.7662\n",
      "Epoch 1815/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2763 - val_loss: 7.5093\n",
      "Epoch 1816/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1437 - val_loss: 7.5720\n",
      "Epoch 1817/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2319 - val_loss: 7.9129\n",
      "Epoch 1818/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3382 - val_loss: 7.5099\n",
      "Epoch 1819/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2597 - val_loss: 7.7978\n",
      "Epoch 1820/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4256 - val_loss: 7.6174\n",
      "Epoch 1821/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5001 - val_loss: 7.2469\n",
      "Epoch 1822/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3300 - val_loss: 7.4065\n",
      "Epoch 1823/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2479 - val_loss: 7.5622\n",
      "Epoch 1824/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2412 - val_loss: 7.4186\n",
      "Epoch 1825/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2352 - val_loss: 7.6580\n",
      "Epoch 1826/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3024 - val_loss: 7.7535\n",
      "Epoch 1827/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3842 - val_loss: 7.2553\n",
      "Epoch 1828/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1562 - val_loss: 7.9921\n",
      "Epoch 1829/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3654 - val_loss: 7.6186\n",
      "Epoch 1830/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3748 - val_loss: 7.3168\n",
      "Epoch 1831/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0495 - val_loss: 7.9000\n",
      "Epoch 1832/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3029 - val_loss: 7.5467\n",
      "Epoch 1833/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2680 - val_loss: 7.9238\n",
      "Epoch 1834/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.7158 - val_loss: 7.7853\n",
      "Epoch 1835/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3029 - val_loss: 7.5832\n",
      "Epoch 1836/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2318 - val_loss: 7.4274\n",
      "Epoch 1837/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2560 - val_loss: 7.6808\n",
      "Epoch 1838/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3025 - val_loss: 7.2228\n",
      "Epoch 1839/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2660 - val_loss: 7.9148\n",
      "Epoch 1840/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4203 - val_loss: 7.5407\n",
      "Epoch 1841/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2985 - val_loss: 7.3680\n",
      "Epoch 1842/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3525 - val_loss: 7.7202\n",
      "Epoch 1843/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2599 - val_loss: 7.3494\n",
      "Epoch 1844/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3006 - val_loss: 7.3711\n",
      "Epoch 1845/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2973 - val_loss: 7.7837\n",
      "Epoch 1846/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1406 - val_loss: 7.6480\n",
      "Epoch 1847/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3281 - val_loss: 7.7913\n",
      "Epoch 1848/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3360 - val_loss: 7.8969\n",
      "Epoch 1849/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2572 - val_loss: 7.3688\n",
      "Epoch 1850/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1133 - val_loss: 7.3062\n",
      "Epoch 1851/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1745 - val_loss: 7.6152\n",
      "Epoch 1852/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0836 - val_loss: 7.2401\n",
      "Epoch 1853/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2413 - val_loss: 7.4485\n",
      "Epoch 1854/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2659 - val_loss: 7.9389\n",
      "Epoch 1855/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2723 - val_loss: 7.3408\n",
      "Epoch 1856/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2698 - val_loss: 7.4936\n",
      "Epoch 1857/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1256 - val_loss: 7.6359\n",
      "Epoch 1858/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.3236 - val_loss: 7.3180\n",
      "Epoch 1859/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2074 - val_loss: 7.5701\n",
      "Epoch 1860/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1121 - val_loss: 7.4090\n",
      "Epoch 1861/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.5922 - val_loss: 7.5835\n",
      "Epoch 1862/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.4148 - val_loss: 7.7882\n",
      "Epoch 1863/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.4259 - val_loss: 7.8570\n",
      "Epoch 1864/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.4286 - val_loss: 8.4599\n",
      "Epoch 1865/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.7302 - val_loss: 7.7547\n",
      "Epoch 1866/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.4535 - val_loss: 7.3218\n",
      "Epoch 1867/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2010 - val_loss: 7.8236\n",
      "Epoch 1868/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.4346 - val_loss: 7.5215\n",
      "Epoch 1869/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.2175 - val_loss: 7.4760\n",
      "Epoch 1870/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 2.2499 - val_loss: 7.9678\n",
      "Epoch 1871/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.4111 - val_loss: 7.5173\n",
      "Epoch 1872/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2856 - val_loss: 7.1345\n",
      "Epoch 1873/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1084 - val_loss: 7.2044\n",
      "Epoch 1874/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0894 - val_loss: 7.4817\n",
      "Epoch 1875/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1549 - val_loss: 7.5755\n",
      "Epoch 1876/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.8732 - val_loss: 7.4778\n",
      "Epoch 1877/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2947 - val_loss: 7.5385\n",
      "Epoch 1878/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2119 - val_loss: 7.5218\n",
      "Epoch 1879/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3525 - val_loss: 7.5374\n",
      "Epoch 1880/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1998 - val_loss: 7.3467\n",
      "Epoch 1881/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2735 - val_loss: 7.7834\n",
      "Epoch 1882/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3611 - val_loss: 7.9101\n",
      "Epoch 1883/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6364 - val_loss: 7.6877\n",
      "Epoch 1884/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4528 - val_loss: 7.7228\n",
      "Epoch 1885/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.6826 - val_loss: 7.7415\n",
      "Epoch 1886/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4336 - val_loss: 7.4405\n",
      "Epoch 1887/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2853 - val_loss: 7.3486\n",
      "Epoch 1888/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2495 - val_loss: 7.2896\n",
      "Epoch 1889/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1963 - val_loss: 7.7317\n",
      "Epoch 1890/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2965 - val_loss: 7.4400\n",
      "Epoch 1891/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2071 - val_loss: 7.4842\n",
      "Epoch 1892/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2752 - val_loss: 7.6395\n",
      "Epoch 1893/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3718 - val_loss: 7.3266\n",
      "Epoch 1894/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1291 - val_loss: 7.5100\n",
      "Epoch 1895/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3601 - val_loss: 7.4684\n",
      "Epoch 1896/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4341 - val_loss: 7.2114\n",
      "Epoch 1897/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2971 - val_loss: 7.6345\n",
      "Epoch 1898/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1641 - val_loss: 7.3047\n",
      "Epoch 1899/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5332 - val_loss: 7.7557\n",
      "Epoch 1900/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3041 - val_loss: 7.2572\n",
      "Epoch 1901/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3102 - val_loss: 8.2096\n",
      "Epoch 1902/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.5125 - val_loss: 7.3600\n",
      "Epoch 1903/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4325 - val_loss: 7.3988\n",
      "Epoch 1904/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3020 - val_loss: 7.4564\n",
      "Epoch 1905/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1788 - val_loss: 8.1253\n",
      "Epoch 1906/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.5105 - val_loss: 7.4606\n",
      "Epoch 1907/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1844 - val_loss: 7.4832\n",
      "Epoch 1908/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1166 - val_loss: 7.5899\n",
      "Epoch 1909/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2520 - val_loss: 8.0896\n",
      "Epoch 1910/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.6450 - val_loss: 8.9004\n",
      "Epoch 1911/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.8215 - val_loss: 7.7760\n",
      "Epoch 1912/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2951 - val_loss: 7.3591\n",
      "Epoch 1913/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2103 - val_loss: 7.2604\n",
      "Epoch 1914/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1281 - val_loss: 7.4354\n",
      "Epoch 1915/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0136 - val_loss: 7.1827\n",
      "Epoch 1916/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0057 - val_loss: 7.2140\n",
      "Epoch 1917/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1405 - val_loss: 8.3840\n",
      "Epoch 1918/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4217 - val_loss: 7.2772\n",
      "Epoch 1919/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3279 - val_loss: 7.3081\n",
      "Epoch 1920/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1848 - val_loss: 7.7061\n",
      "Epoch 1921/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2556 - val_loss: 7.3561\n",
      "Epoch 1922/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0827 - val_loss: 7.3527\n",
      "Epoch 1923/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2580 - val_loss: 7.3270\n",
      "Epoch 1924/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3289 - val_loss: 7.5186\n",
      "Epoch 1925/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.5457 - val_loss: 8.6667\n",
      "Epoch 1926/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7381 - val_loss: 8.3000\n",
      "Epoch 1927/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5938 - val_loss: 7.6120\n",
      "Epoch 1928/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4305 - val_loss: 7.2909\n",
      "Epoch 1929/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1376 - val_loss: 7.4961\n",
      "Epoch 1930/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1338 - val_loss: 7.4093\n",
      "Epoch 1931/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0978 - val_loss: 7.4678\n",
      "Epoch 1932/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1615 - val_loss: 7.4634\n",
      "Epoch 1933/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2821 - val_loss: 7.4680\n",
      "Epoch 1934/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3769 - val_loss: 8.4256\n",
      "Epoch 1935/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.7298 - val_loss: 7.7637\n",
      "Epoch 1936/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2608 - val_loss: 8.7255\n",
      "Epoch 1937/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4467 - val_loss: 7.4331\n",
      "Epoch 1938/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1615 - val_loss: 8.0132\n",
      "Epoch 1939/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2276 - val_loss: 7.4908\n",
      "Epoch 1940/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0668 - val_loss: 7.5894\n",
      "Epoch 1941/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1090 - val_loss: 7.3480\n",
      "Epoch 1942/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1889 - val_loss: 7.6874\n",
      "Epoch 1943/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2116 - val_loss: 7.2396\n",
      "Epoch 1944/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1706 - val_loss: 7.5333\n",
      "Epoch 1945/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3400 - val_loss: 7.2207\n",
      "Epoch 1946/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2960 - val_loss: 7.6219\n",
      "Epoch 1947/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1975 - val_loss: 7.3665\n",
      "Epoch 1948/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1414 - val_loss: 7.6608\n",
      "Epoch 1949/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4559 - val_loss: 7.4945\n",
      "Epoch 1950/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3482 - val_loss: 7.4346\n",
      "Epoch 1951/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1081 - val_loss: 7.9900\n",
      "Epoch 1952/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3932 - val_loss: 7.4616\n",
      "Epoch 1953/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.3959 - val_loss: 7.7007\n",
      "Epoch 1954/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4834 - val_loss: 7.5229\n",
      "Epoch 1955/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2886 - val_loss: 7.2367\n",
      "Epoch 1956/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0773 - val_loss: 7.6679\n",
      "Epoch 1957/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2624 - val_loss: 7.2983\n",
      "Epoch 1958/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0845 - val_loss: 7.4498\n",
      "Epoch 1959/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3190 - val_loss: 7.7445\n",
      "Epoch 1960/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2172 - val_loss: 8.0118\n",
      "Epoch 1961/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4267 - val_loss: 7.3434\n",
      "Epoch 1962/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1150 - val_loss: 7.1815\n",
      "Epoch 1963/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0440 - val_loss: 7.3212\n",
      "Epoch 1964/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.6033 - val_loss: 8.0731\n",
      "Epoch 1965/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 2.3673 - val_loss: 7.6781\n",
      "Epoch 1966/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.2040 - val_loss: 7.3183\n",
      "Epoch 1967/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1751 - val_loss: 7.4430\n",
      "Epoch 1968/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0156 - val_loss: 7.6644\n",
      "Epoch 1969/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.3401 - val_loss: 7.5618\n",
      "Epoch 1970/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1405 - val_loss: 7.4848\n",
      "Epoch 1971/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1048 - val_loss: 7.1781\n",
      "Epoch 1972/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1051 - val_loss: 7.8286\n",
      "Epoch 1973/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1791 - val_loss: 7.5392\n",
      "Epoch 1974/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.3843 - val_loss: 7.3011\n",
      "Epoch 1975/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1492 - val_loss: 7.3925\n",
      "Epoch 1976/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1148 - val_loss: 7.3596\n",
      "Epoch 1977/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1352 - val_loss: 7.7376\n",
      "Epoch 1978/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2205 - val_loss: 7.5446\n",
      "Epoch 1979/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2616 - val_loss: 8.0207\n",
      "Epoch 1980/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.2894 - val_loss: 7.2264\n",
      "Epoch 1981/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0474 - val_loss: 7.1059\n",
      "Epoch 1982/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0615 - val_loss: 7.3227\n",
      "Epoch 1983/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0555 - val_loss: 7.3959\n",
      "Epoch 1984/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0323 - val_loss: 7.3122\n",
      "Epoch 1985/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1119 - val_loss: 7.4525\n",
      "Epoch 1986/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0901 - val_loss: 7.2131\n",
      "Epoch 1987/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0409 - val_loss: 7.6252\n",
      "Epoch 1988/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.3533 - val_loss: 7.3250\n",
      "Epoch 1989/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0648 - val_loss: 7.3799\n",
      "Epoch 1990/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1388 - val_loss: 7.3791\n",
      "Epoch 1991/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0753 - val_loss: 7.1555\n",
      "Epoch 1992/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9495 - val_loss: 7.2762\n",
      "Epoch 1993/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9682 - val_loss: 7.2243\n",
      "Epoch 1994/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0048 - val_loss: 7.4626\n",
      "Epoch 1995/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0615 - val_loss: 7.6741\n",
      "Epoch 1996/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.4282 - val_loss: 7.5118\n",
      "Epoch 1997/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1337 - val_loss: 7.3882\n",
      "Epoch 1998/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1861 - val_loss: 8.0669\n",
      "Epoch 1999/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.4721 - val_loss: 7.4772\n",
      "Epoch 2000/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1749 - val_loss: 7.6410\n",
      "Epoch 2001/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0285 - val_loss: 7.7515\n",
      "Epoch 2002/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0125 - val_loss: 7.6843\n",
      "Epoch 2003/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0984 - val_loss: 7.3169\n",
      "Epoch 2004/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2248 - val_loss: 7.6718\n",
      "Epoch 2005/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.4061 - val_loss: 7.6359\n",
      "Epoch 2006/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2765 - val_loss: 7.4265\n",
      "Epoch 2007/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1648 - val_loss: 7.4165\n",
      "Epoch 2008/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1378 - val_loss: 7.5140\n",
      "Epoch 2009/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1536 - val_loss: 7.3939\n",
      "Epoch 2010/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0200 - val_loss: 7.3692\n",
      "Epoch 2011/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1546 - val_loss: 7.3839\n",
      "Epoch 2012/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0957 - val_loss: 7.4845\n",
      "Epoch 2013/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.3057 - val_loss: 7.3187\n",
      "Epoch 2014/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1967 - val_loss: 7.3910\n",
      "Epoch 2015/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0770 - val_loss: 7.5826\n",
      "Epoch 2016/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0651 - val_loss: 7.6363\n",
      "Epoch 2017/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2334 - val_loss: 8.1055\n",
      "Epoch 2018/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2871 - val_loss: 7.4100\n",
      "Epoch 2019/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1035 - val_loss: 7.6563\n",
      "Epoch 2020/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2077 - val_loss: 7.4880\n",
      "Epoch 2021/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0492 - val_loss: 7.4744\n",
      "Epoch 2022/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0505 - val_loss: 7.2586\n",
      "Epoch 2023/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0443 - val_loss: 7.6826\n",
      "Epoch 2024/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2531 - val_loss: 7.4506\n",
      "Epoch 2025/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1209 - val_loss: 7.4723\n",
      "Epoch 2026/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2128 - val_loss: 7.1977\n",
      "Epoch 2027/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9044 - val_loss: 7.3054\n",
      "Epoch 2028/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9906 - val_loss: 7.5344\n",
      "Epoch 2029/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9664 - val_loss: 7.3586\n",
      "Epoch 2030/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9863 - val_loss: 7.3947\n",
      "Epoch 2031/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1541 - val_loss: 7.3256\n",
      "Epoch 2032/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2835 - val_loss: 7.5060\n",
      "Epoch 2033/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2728 - val_loss: 8.1772\n",
      "Epoch 2034/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.5999 - val_loss: 8.4037\n",
      "Epoch 2035/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.5747 - val_loss: 7.7606\n",
      "Epoch 2036/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1724 - val_loss: 7.8630\n",
      "Epoch 2037/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2877 - val_loss: 7.3635\n",
      "Epoch 2038/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1449 - val_loss: 7.3268\n",
      "Epoch 2039/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0344 - val_loss: 8.0169\n",
      "Epoch 2040/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2364 - val_loss: 7.3972\n",
      "Epoch 2041/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9768 - val_loss: 7.3760\n",
      "Epoch 2042/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0097 - val_loss: 7.3222\n",
      "Epoch 2043/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1637 - val_loss: 7.5215\n",
      "Epoch 2044/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.3415 - val_loss: 7.5063\n",
      "Epoch 2045/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1187 - val_loss: 7.4781\n",
      "Epoch 2046/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.5002 - val_loss: 7.4698\n",
      "Epoch 2047/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0972 - val_loss: 7.4928\n",
      "Epoch 2048/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0595 - val_loss: 7.3460\n",
      "Epoch 2049/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0006 - val_loss: 7.2224\n",
      "Epoch 2050/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2494 - val_loss: 7.6565\n",
      "Epoch 2051/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2938 - val_loss: 7.4237\n",
      "Epoch 2052/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1026 - val_loss: 7.5304\n",
      "Epoch 2053/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1594 - val_loss: 7.2651\n",
      "Epoch 2054/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1278 - val_loss: 7.1876\n",
      "Epoch 2055/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9952 - val_loss: 7.1743\n",
      "Epoch 2056/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0423 - val_loss: 7.6297\n",
      "Epoch 2057/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1099 - val_loss: 7.7315\n",
      "Epoch 2058/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1172 - val_loss: 7.4801\n",
      "Epoch 2059/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0646 - val_loss: 7.2142\n",
      "Epoch 2060/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0002 - val_loss: 7.1318\n",
      "Epoch 2061/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0118 - val_loss: 7.2315\n",
      "Epoch 2062/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0654 - val_loss: 7.9073\n",
      "Epoch 2063/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1460 - val_loss: 7.9465\n",
      "Epoch 2064/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0049 - val_loss: 7.4283\n",
      "Epoch 2065/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2047 - val_loss: 7.3143\n",
      "Epoch 2066/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1363 - val_loss: 7.6806\n",
      "Epoch 2067/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1848 - val_loss: 7.5415\n",
      "Epoch 2068/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0842 - val_loss: 7.5088\n",
      "Epoch 2069/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2091 - val_loss: 7.4071\n",
      "Epoch 2070/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0251 - val_loss: 7.5694\n",
      "Epoch 2071/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0620 - val_loss: 7.4805\n",
      "Epoch 2072/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1324 - val_loss: 7.5544\n",
      "Epoch 2073/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1280 - val_loss: 7.3392\n",
      "Epoch 2074/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0036 - val_loss: 7.5276\n",
      "Epoch 2075/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0530 - val_loss: 7.1763\n",
      "Epoch 2076/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9871 - val_loss: 7.3081\n",
      "Epoch 2077/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9918 - val_loss: 7.7031\n",
      "Epoch 2078/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1547 - val_loss: 7.5074\n",
      "Epoch 2079/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1161 - val_loss: 7.8113\n",
      "Epoch 2080/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2413 - val_loss: 7.4681\n",
      "Epoch 2081/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2440 - val_loss: 7.2631\n",
      "Epoch 2082/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9347 - val_loss: 7.4844\n",
      "Epoch 2083/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0608 - val_loss: 7.3922\n",
      "Epoch 2084/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2042 - val_loss: 7.4506\n",
      "Epoch 2085/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1250 - val_loss: 8.1343\n",
      "Epoch 2086/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2380 - val_loss: 7.6245\n",
      "Epoch 2087/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0529 - val_loss: 8.2208\n",
      "Epoch 2088/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2347 - val_loss: 7.5997\n",
      "Epoch 2089/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2922 - val_loss: 7.9988\n",
      "Epoch 2090/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.3047 - val_loss: 7.3388\n",
      "Epoch 2091/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9642 - val_loss: 7.6747\n",
      "Epoch 2092/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1595 - val_loss: 7.4088\n",
      "Epoch 2093/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0555 - val_loss: 7.7436\n",
      "Epoch 2094/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1068 - val_loss: 7.7380\n",
      "Epoch 2095/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9171 - val_loss: 7.3964\n",
      "Epoch 2096/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0583 - val_loss: 7.3595\n",
      "Epoch 2097/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9866 - val_loss: 7.4015\n",
      "Epoch 2098/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0835 - val_loss: 7.4165\n",
      "Epoch 2099/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2983 - val_loss: 8.0161\n",
      "Epoch 2100/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.3050 - val_loss: 7.7447\n",
      "Epoch 2101/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0129 - val_loss: 7.3119\n",
      "Epoch 2102/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0024 - val_loss: 7.3018\n",
      "Epoch 2103/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9773 - val_loss: 8.4988\n",
      "Epoch 2104/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2623 - val_loss: 7.5495\n",
      "Epoch 2105/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0981 - val_loss: 7.7247\n",
      "Epoch 2106/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1958 - val_loss: 7.3678\n",
      "Epoch 2107/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0012 - val_loss: 7.9481\n",
      "Epoch 2108/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0830 - val_loss: 7.4896\n",
      "Epoch 2109/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0858 - val_loss: 7.6644\n",
      "Epoch 2110/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1816 - val_loss: 7.3567\n",
      "Epoch 2111/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0554 - val_loss: 7.9443\n",
      "Epoch 2112/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.9526 - val_loss: 7.5986\n",
      "Epoch 2113/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.3134 - val_loss: 8.6181\n",
      "Epoch 2114/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2597 - val_loss: 7.9345\n",
      "Epoch 2115/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1607 - val_loss: 7.5260\n",
      "Epoch 2116/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0961 - val_loss: 7.5383\n",
      "Epoch 2117/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9644 - val_loss: 8.0900\n",
      "Epoch 2118/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1321 - val_loss: 7.2519\n",
      "Epoch 2119/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8878 - val_loss: 7.3501\n",
      "Epoch 2120/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8662 - val_loss: 7.8077\n",
      "Epoch 2121/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0963 - val_loss: 7.4788\n",
      "Epoch 2122/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0602 - val_loss: 7.6466\n",
      "Epoch 2123/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 3.4206 - val_loss: 7.4604\n",
      "Epoch 2124/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1373 - val_loss: 7.3468\n",
      "Epoch 2125/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9665 - val_loss: 7.3580\n",
      "Epoch 2126/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2111 - val_loss: 7.9021\n",
      "Epoch 2127/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2193 - val_loss: 7.3230\n",
      "Epoch 2128/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9971 - val_loss: 7.3656\n",
      "Epoch 2129/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9295 - val_loss: 7.7136\n",
      "Epoch 2130/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9779 - val_loss: 7.5245\n",
      "Epoch 2131/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0659 - val_loss: 7.8250\n",
      "Epoch 2132/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2604 - val_loss: 7.5425\n",
      "Epoch 2133/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0246 - val_loss: 7.7445\n",
      "Epoch 2134/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1663 - val_loss: 7.5187\n",
      "Epoch 2135/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8834 - val_loss: 8.6457\n",
      "Epoch 2136/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2195 - val_loss: 7.5274\n",
      "Epoch 2137/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3371 - val_loss: 7.4957\n",
      "Epoch 2138/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0705 - val_loss: 7.2949\n",
      "Epoch 2139/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8737 - val_loss: 7.3181\n",
      "Epoch 2140/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9470 - val_loss: 8.1386\n",
      "Epoch 2141/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.8099 - val_loss: 7.6930\n",
      "Epoch 2142/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1714 - val_loss: 7.3876\n",
      "Epoch 2143/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9760 - val_loss: 7.7485\n",
      "Epoch 2144/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1748 - val_loss: 7.5478\n",
      "Epoch 2145/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0092 - val_loss: 7.8016\n",
      "Epoch 2146/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0570 - val_loss: 7.5498\n",
      "Epoch 2147/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9824 - val_loss: 7.6815\n",
      "Epoch 2148/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0106 - val_loss: 7.7374\n",
      "Epoch 2149/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9994 - val_loss: 7.3364\n",
      "Epoch 2150/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0686 - val_loss: 7.3607\n",
      "Epoch 2151/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9800 - val_loss: 7.6514\n",
      "Epoch 2152/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1900 - val_loss: 7.6260\n",
      "Epoch 2153/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.4155 - val_loss: 7.3923\n",
      "Epoch 2154/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2162 - val_loss: 7.5779\n",
      "Epoch 2155/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0420 - val_loss: 7.4598\n",
      "Epoch 2156/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0773 - val_loss: 7.4556\n",
      "Epoch 2157/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1697 - val_loss: 7.8460\n",
      "Epoch 2158/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2248 - val_loss: 7.2411\n",
      "Epoch 2159/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0019 - val_loss: 7.6196\n",
      "Epoch 2160/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0960 - val_loss: 7.2406\n",
      "Epoch 2161/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0605 - val_loss: 7.3690\n",
      "Epoch 2162/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9096 - val_loss: 7.2272\n",
      "Epoch 2163/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0872 - val_loss: 7.4319\n",
      "Epoch 2164/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9945 - val_loss: 7.3769\n",
      "Epoch 2165/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9676 - val_loss: 7.8510\n",
      "Epoch 2166/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0963 - val_loss: 7.5894\n",
      "Epoch 2167/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0067 - val_loss: 7.5313\n",
      "Epoch 2168/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8644 - val_loss: 7.3787\n",
      "Epoch 2169/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9377 - val_loss: 7.7349\n",
      "Epoch 2170/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1597 - val_loss: 7.3538\n",
      "Epoch 2171/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1666 - val_loss: 7.5969\n",
      "Epoch 2172/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0711 - val_loss: 8.2789\n",
      "Epoch 2173/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2067 - val_loss: 7.5810\n",
      "Epoch 2174/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2494 - val_loss: 7.4834\n",
      "Epoch 2175/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9399 - val_loss: 7.5819\n",
      "Epoch 2176/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1747 - val_loss: 7.4066\n",
      "Epoch 2177/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9720 - val_loss: 7.9445\n",
      "Epoch 2178/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2803 - val_loss: 7.2190\n",
      "Epoch 2179/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9062 - val_loss: 7.4129\n",
      "Epoch 2180/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9460 - val_loss: 7.5622\n",
      "Epoch 2181/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0098 - val_loss: 7.2062\n",
      "Epoch 2182/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8811 - val_loss: 7.3252\n",
      "Epoch 2183/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9612 - val_loss: 7.6789\n",
      "Epoch 2184/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1382 - val_loss: 7.2754\n",
      "Epoch 2185/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9416 - val_loss: 7.2918\n",
      "Epoch 2186/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0109 - val_loss: 7.6529\n",
      "Epoch 2187/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1350 - val_loss: 7.4005\n",
      "Epoch 2188/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1860 - val_loss: 7.2065\n",
      "Epoch 2189/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0573 - val_loss: 7.4365\n",
      "Epoch 2190/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0208 - val_loss: 7.3394\n",
      "Epoch 2191/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9360 - val_loss: 7.6875\n",
      "Epoch 2192/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9951 - val_loss: 7.1732\n",
      "Epoch 2193/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9339 - val_loss: 7.3001\n",
      "Epoch 2194/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1106 - val_loss: 7.4351\n",
      "Epoch 2195/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9771 - val_loss: 7.6494\n",
      "Epoch 2196/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0142 - val_loss: 7.4388\n",
      "Epoch 2197/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8828 - val_loss: 7.3774\n",
      "Epoch 2198/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1330 - val_loss: 7.4399\n",
      "Epoch 2199/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1453 - val_loss: 7.7823\n",
      "Epoch 2200/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1595 - val_loss: 7.5521\n",
      "Epoch 2201/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1311 - val_loss: 7.7467\n",
      "Epoch 2202/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0955 - val_loss: 7.5210\n",
      "Epoch 2203/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9930 - val_loss: 7.5594\n",
      "Epoch 2204/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9730 - val_loss: 7.5428\n",
      "Epoch 2205/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0238 - val_loss: 8.2700\n",
      "Epoch 2206/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1373 - val_loss: 7.3830\n",
      "Epoch 2207/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9617 - val_loss: 7.4222\n",
      "Epoch 2208/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8114 - val_loss: 7.4178\n",
      "Epoch 2209/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0831 - val_loss: 7.3799\n",
      "Epoch 2210/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8897 - val_loss: 7.3873\n",
      "Epoch 2211/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8683 - val_loss: 7.8692\n",
      "Epoch 2212/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1722 - val_loss: 7.4315\n",
      "Epoch 2213/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2868 - val_loss: 7.4500\n",
      "Epoch 2214/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0665 - val_loss: 7.4967\n",
      "Epoch 2215/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1819 - val_loss: 7.3343\n",
      "Epoch 2216/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.2451 - val_loss: 7.2661\n",
      "Epoch 2217/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 2.0161 - val_loss: 7.3418\n",
      "Epoch 2218/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.9069 - val_loss: 7.6934\n",
      "Epoch 2219/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0920 - val_loss: 7.5324\n",
      "Epoch 2220/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0159 - val_loss: 7.4885\n",
      "Epoch 2221/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0439 - val_loss: 7.5453\n",
      "Epoch 2222/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0356 - val_loss: 7.5755\n",
      "Epoch 2223/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.2248 - val_loss: 7.4819\n",
      "Epoch 2224/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 2.0578 - val_loss: 7.8055\n",
      "Epoch 2225/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0678 - val_loss: 7.5178\n",
      "Epoch 2226/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9901 - val_loss: 7.5104\n",
      "Epoch 2227/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0986 - val_loss: 7.2751\n",
      "Epoch 2228/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0031 - val_loss: 7.2246\n",
      "Epoch 2229/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0072 - val_loss: 7.4804\n",
      "Epoch 2230/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9404 - val_loss: 7.6164\n",
      "Epoch 2231/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0906 - val_loss: 8.1011\n",
      "Epoch 2232/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2063 - val_loss: 7.4941\n",
      "Epoch 2233/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2000 - val_loss: 7.5181\n",
      "Epoch 2234/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9865 - val_loss: 7.3283\n",
      "Epoch 2235/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8809 - val_loss: 7.7004\n",
      "Epoch 2236/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9976 - val_loss: 7.3562\n",
      "Epoch 2237/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8327 - val_loss: 7.6300\n",
      "Epoch 2238/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0331 - val_loss: 7.3778\n",
      "Epoch 2239/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0730 - val_loss: 7.3535\n",
      "Epoch 2240/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2405 - val_loss: 7.7336\n",
      "Epoch 2241/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2375 - val_loss: 7.3453\n",
      "Epoch 2242/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0268 - val_loss: 7.2455\n",
      "Epoch 2243/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0047 - val_loss: 7.8223\n",
      "Epoch 2244/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0917 - val_loss: 7.2149\n",
      "Epoch 2245/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9744 - val_loss: 7.9394\n",
      "Epoch 2246/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1856 - val_loss: 7.2904\n",
      "Epoch 2247/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9057 - val_loss: 7.2387\n",
      "Epoch 2248/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9314 - val_loss: 7.6904\n",
      "Epoch 2249/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0689 - val_loss: 7.3377\n",
      "Epoch 2250/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9390 - val_loss: 7.2274\n",
      "Epoch 2251/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9555 - val_loss: 7.3241\n",
      "Epoch 2252/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8929 - val_loss: 7.5585\n",
      "Epoch 2253/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8033 - val_loss: 7.5445\n",
      "Epoch 2254/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.7677 - val_loss: 7.3814\n",
      "Epoch 2255/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0278 - val_loss: 7.3859\n",
      "Epoch 2256/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9162 - val_loss: 7.3000\n",
      "Epoch 2257/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9084 - val_loss: 7.6216\n",
      "Epoch 2258/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9958 - val_loss: 7.1964\n",
      "Epoch 2259/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7474 - val_loss: 7.4038\n",
      "Epoch 2260/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8413 - val_loss: 7.3313\n",
      "Epoch 2261/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9303 - val_loss: 7.3948\n",
      "Epoch 2262/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9653 - val_loss: 7.2538\n",
      "Epoch 2263/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9135 - val_loss: 7.7005\n",
      "Epoch 2264/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9293 - val_loss: 7.4898\n",
      "Epoch 2265/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9954 - val_loss: 7.5805\n",
      "Epoch 2266/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8328 - val_loss: 7.8466\n",
      "Epoch 2267/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9030 - val_loss: 7.4668\n",
      "Epoch 2268/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9558 - val_loss: 7.8063\n",
      "Epoch 2269/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9404 - val_loss: 7.3185\n",
      "Epoch 2270/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9615 - val_loss: 7.5483\n",
      "Epoch 2271/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9963 - val_loss: 7.3839\n",
      "Epoch 2272/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8876 - val_loss: 7.6738\n",
      "Epoch 2273/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0230 - val_loss: 7.8895\n",
      "Epoch 2274/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1109 - val_loss: 7.5639\n",
      "Epoch 2275/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0229 - val_loss: 7.2842\n",
      "Epoch 2276/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9964 - val_loss: 7.2097\n",
      "Epoch 2277/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8725 - val_loss: 7.6173\n",
      "Epoch 2278/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8973 - val_loss: 7.5309\n",
      "Epoch 2279/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9807 - val_loss: 7.2710\n",
      "Epoch 2280/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8332 - val_loss: 7.6408\n",
      "Epoch 2281/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1154 - val_loss: 7.7801\n",
      "Epoch 2282/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9827 - val_loss: 7.5063\n",
      "Epoch 2283/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0882 - val_loss: 7.7866\n",
      "Epoch 2284/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1414 - val_loss: 7.3318\n",
      "Epoch 2285/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8318 - val_loss: 7.4066\n",
      "Epoch 2286/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8698 - val_loss: 7.1907\n",
      "Epoch 2287/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8586 - val_loss: 7.5191\n",
      "Epoch 2288/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9861 - val_loss: 7.4422\n",
      "Epoch 2289/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8775 - val_loss: 7.1825\n",
      "Epoch 2290/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9505 - val_loss: 7.7173\n",
      "Epoch 2291/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0350 - val_loss: 7.1720\n",
      "Epoch 2292/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8177 - val_loss: 7.0634\n",
      "Epoch 2293/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8165 - val_loss: 7.5747\n",
      "Epoch 2294/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9658 - val_loss: 7.6662\n",
      "Epoch 2295/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0985 - val_loss: 7.6782\n",
      "Epoch 2296/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1344 - val_loss: 7.1368\n",
      "Epoch 2297/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0628 - val_loss: 7.3277\n",
      "Epoch 2298/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0654 - val_loss: 7.4344\n",
      "Epoch 2299/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1410 - val_loss: 7.5449\n",
      "Epoch 2300/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3037 - val_loss: 7.5027\n",
      "Epoch 2301/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1326 - val_loss: 7.2515\n",
      "Epoch 2302/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9714 - val_loss: 7.8318\n",
      "Epoch 2303/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2035 - val_loss: 7.4279\n",
      "Epoch 2304/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9381 - val_loss: 7.5295\n",
      "Epoch 2305/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1958 - val_loss: 7.5550\n",
      "Epoch 2306/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0401 - val_loss: 7.7566\n",
      "Epoch 2307/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0273 - val_loss: 7.4530\n",
      "Epoch 2308/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.2610 - val_loss: 7.5877\n",
      "Epoch 2309/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1270 - val_loss: 7.2632\n",
      "Epoch 2310/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8681 - val_loss: 8.1002\n",
      "Epoch 2311/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5784 - val_loss: 7.1195\n",
      "Epoch 2312/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0148 - val_loss: 7.5656\n",
      "Epoch 2313/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0896 - val_loss: 7.5588\n",
      "Epoch 2314/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0989 - val_loss: 8.1207\n",
      "Epoch 2315/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5737 - val_loss: 7.2890\n",
      "Epoch 2316/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1061 - val_loss: 7.5631\n",
      "Epoch 2317/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9848 - val_loss: 7.5297\n",
      "Epoch 2318/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9607 - val_loss: 7.4921\n",
      "Epoch 2319/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.5490 - val_loss: 7.5971\n",
      "Epoch 2320/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1215 - val_loss: 7.4461\n",
      "Epoch 2321/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8193 - val_loss: 7.3331\n",
      "Epoch 2322/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8653 - val_loss: 7.6212\n",
      "Epoch 2323/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3947 - val_loss: 7.7129\n",
      "Epoch 2324/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1738 - val_loss: 7.3462\n",
      "Epoch 2325/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1254 - val_loss: 7.2750\n",
      "Epoch 2326/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8916 - val_loss: 7.2257\n",
      "Epoch 2327/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8724 - val_loss: 8.5018\n",
      "Epoch 2328/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.3070 - val_loss: 7.8403\n",
      "Epoch 2329/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9391 - val_loss: 8.1377\n",
      "Epoch 2330/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4535 - val_loss: 8.0646\n",
      "Epoch 2331/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.4176 - val_loss: 7.1967\n",
      "Epoch 2332/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8795 - val_loss: 7.3398\n",
      "Epoch 2333/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8491 - val_loss: 7.4534\n",
      "Epoch 2334/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9308 - val_loss: 7.2417\n",
      "Epoch 2335/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8248 - val_loss: 7.2527\n",
      "Epoch 2336/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9924 - val_loss: 7.3695\n",
      "Epoch 2337/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9606 - val_loss: 7.2232\n",
      "Epoch 2338/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0438 - val_loss: 7.7731\n",
      "Epoch 2339/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1433 - val_loss: 7.3733\n",
      "Epoch 2340/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9664 - val_loss: 7.7235\n",
      "Epoch 2341/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0768 - val_loss: 7.6698\n",
      "Epoch 2342/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0987 - val_loss: 7.9354\n",
      "Epoch 2343/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0690 - val_loss: 7.6713\n",
      "Epoch 2344/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0602 - val_loss: 7.1959\n",
      "Epoch 2345/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8758 - val_loss: 7.2546\n",
      "Epoch 2346/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9308 - val_loss: 7.1388\n",
      "Epoch 2347/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9653 - val_loss: 7.3260\n",
      "Epoch 2348/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9683 - val_loss: 7.6099\n",
      "Epoch 2349/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.5865 - val_loss: 7.3672\n",
      "Epoch 2350/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2510 - val_loss: 7.3080\n",
      "Epoch 2351/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1173 - val_loss: 7.5614\n",
      "Epoch 2352/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0764 - val_loss: 7.3337\n",
      "Epoch 2353/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0453 - val_loss: 7.3517\n",
      "Epoch 2354/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9514 - val_loss: 7.3932\n",
      "Epoch 2355/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0494 - val_loss: 7.5418\n",
      "Epoch 2356/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0116 - val_loss: 7.7665\n",
      "Epoch 2357/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1874 - val_loss: 7.6580\n",
      "Epoch 2358/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1876 - val_loss: 7.5178\n",
      "Epoch 2359/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0572 - val_loss: 7.3490\n",
      "Epoch 2360/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9939 - val_loss: 7.2779\n",
      "Epoch 2361/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8765 - val_loss: 7.6337\n",
      "Epoch 2362/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0369 - val_loss: 7.3009\n",
      "Epoch 2363/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.9663 - val_loss: 7.6115\n",
      "Epoch 2364/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.2263 - val_loss: 7.3973\n",
      "Epoch 2365/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0608 - val_loss: 7.5793\n",
      "Epoch 2366/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0364 - val_loss: 7.8299\n",
      "Epoch 2367/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1434 - val_loss: 7.1839\n",
      "Epoch 2368/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9327 - val_loss: 7.1235\n",
      "Epoch 2369/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9735 - val_loss: 7.4657\n",
      "Epoch 2370/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0990 - val_loss: 7.1231\n",
      "Epoch 2371/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9540 - val_loss: 7.6544\n",
      "Epoch 2372/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.0613 - val_loss: 7.5761\n",
      "Epoch 2373/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.8495 - val_loss: 7.2995\n",
      "Epoch 2374/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.0094 - val_loss: 7.4327\n",
      "Epoch 2375/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.8700 - val_loss: 7.9023\n",
      "Epoch 2376/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.1721 - val_loss: 7.3988\n",
      "Epoch 2377/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9372 - val_loss: 7.3922\n",
      "Epoch 2378/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.0519 - val_loss: 7.4740\n",
      "Epoch 2379/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.2162 - val_loss: 7.4068\n",
      "Epoch 2380/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9364 - val_loss: 7.5642\n",
      "Epoch 2381/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.0367 - val_loss: 7.2264\n",
      "Epoch 2382/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.0107 - val_loss: 7.2828\n",
      "Epoch 2383/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.0515 - val_loss: 7.2575\n",
      "Epoch 2384/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9163 - val_loss: 7.3243\n",
      "Epoch 2385/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9397 - val_loss: 7.0970\n",
      "Epoch 2386/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9541 - val_loss: 7.8380\n",
      "Epoch 2387/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.0998 - val_loss: 7.6497\n",
      "Epoch 2388/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.0506 - val_loss: 7.5269\n",
      "Epoch 2389/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9676 - val_loss: 7.2076\n",
      "Epoch 2390/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.8591 - val_loss: 7.5878\n",
      "Epoch 2391/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.2461 - val_loss: 7.3313\n",
      "Epoch 2392/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9994 - val_loss: 7.6048\n",
      "Epoch 2393/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.8871 - val_loss: 7.4247\n",
      "Epoch 2394/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.0435 - val_loss: 7.6854\n",
      "Epoch 2395/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0828 - val_loss: 7.5130\n",
      "Epoch 2396/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9360 - val_loss: 7.4991\n",
      "Epoch 2397/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9513 - val_loss: 7.1166\n",
      "Epoch 2398/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8364 - val_loss: 7.5329\n",
      "Epoch 2399/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9679 - val_loss: 7.4432\n",
      "Epoch 2400/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0656 - val_loss: 7.3697\n",
      "Epoch 2401/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9171 - val_loss: 7.6258\n",
      "Epoch 2402/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8713 - val_loss: 7.5063\n",
      "Epoch 2403/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1438 - val_loss: 7.4703\n",
      "Epoch 2404/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8505 - val_loss: 7.5265\n",
      "Epoch 2405/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9341 - val_loss: 7.4967\n",
      "Epoch 2406/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.7947 - val_loss: 7.3857\n",
      "Epoch 2407/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.7820 - val_loss: 7.2453\n",
      "Epoch 2408/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.8698 - val_loss: 7.7415\n",
      "Epoch 2409/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9572 - val_loss: 7.6477\n",
      "Epoch 2410/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9826 - val_loss: 7.5996\n",
      "Epoch 2411/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9679 - val_loss: 7.3592\n",
      "Epoch 2412/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9441 - val_loss: 7.9553\n",
      "Epoch 2413/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 2.0849 - val_loss: 7.3936\n",
      "Epoch 2414/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8247 - val_loss: 7.7093\n",
      "Epoch 2415/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 2.1513 - val_loss: 7.3237\n",
      "Epoch 2416/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 2.0154 - val_loss: 7.2923\n",
      "Epoch 2417/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.7067 - val_loss: 7.3192\n",
      "Epoch 2418/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.7557 - val_loss: 7.4472\n",
      "Epoch 2419/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.9278 - val_loss: 7.6226\n",
      "Epoch 2420/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8713 - val_loss: 7.4404\n",
      "Epoch 2421/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.7955 - val_loss: 7.5526\n",
      "Epoch 2422/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8670 - val_loss: 7.3064\n",
      "Epoch 2423/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.7809 - val_loss: 7.5927\n",
      "Epoch 2424/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8755 - val_loss: 7.6185\n",
      "Epoch 2425/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.8970 - val_loss: 7.4027\n",
      "Epoch 2426/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0610 - val_loss: 7.6153\n",
      "Epoch 2427/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8856 - val_loss: 7.4464\n",
      "Epoch 2428/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9348 - val_loss: 7.3220\n",
      "Epoch 2429/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8916 - val_loss: 7.6498\n",
      "Epoch 2430/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8968 - val_loss: 7.3051\n",
      "Epoch 2431/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7616 - val_loss: 7.4664\n",
      "Epoch 2432/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8276 - val_loss: 7.5120\n",
      "Epoch 2433/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8348 - val_loss: 7.4230\n",
      "Epoch 2434/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8936 - val_loss: 7.8265\n",
      "Epoch 2435/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9900 - val_loss: 7.5628\n",
      "Epoch 2436/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1753 - val_loss: 7.8397\n",
      "Epoch 2437/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0771 - val_loss: 7.2703\n",
      "Epoch 2438/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9108 - val_loss: 7.3282\n",
      "Epoch 2439/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8525 - val_loss: 7.3836\n",
      "Epoch 2440/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9158 - val_loss: 7.9043\n",
      "Epoch 2441/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9822 - val_loss: 7.1312\n",
      "Epoch 2442/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8712 - val_loss: 7.7174\n",
      "Epoch 2443/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.2154 - val_loss: 7.7766\n",
      "Epoch 2444/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2658 - val_loss: 7.6480\n",
      "Epoch 2445/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1747 - val_loss: 7.2629\n",
      "Epoch 2446/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9917 - val_loss: 7.6125\n",
      "Epoch 2447/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0210 - val_loss: 7.2158\n",
      "Epoch 2448/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1423 - val_loss: 7.3138\n",
      "Epoch 2449/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9187 - val_loss: 7.4849\n",
      "Epoch 2450/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1262 - val_loss: 7.2973\n",
      "Epoch 2451/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8934 - val_loss: 7.0070\n",
      "Epoch 2452/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7977 - val_loss: 7.7726\n",
      "Epoch 2453/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0856 - val_loss: 7.3570\n",
      "Epoch 2454/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8986 - val_loss: 7.7920\n",
      "Epoch 2455/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9300 - val_loss: 7.7127\n",
      "Epoch 2456/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0625 - val_loss: 7.6177\n",
      "Epoch 2457/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9717 - val_loss: 7.4439\n",
      "Epoch 2458/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8209 - val_loss: 7.2664\n",
      "Epoch 2459/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8353 - val_loss: 7.2290\n",
      "Epoch 2460/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9487 - val_loss: 7.5983\n",
      "Epoch 2461/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8050 - val_loss: 7.3936\n",
      "Epoch 2462/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9045 - val_loss: 7.2762\n",
      "Epoch 2463/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9054 - val_loss: 7.3544\n",
      "Epoch 2464/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8144 - val_loss: 7.6505\n",
      "Epoch 2465/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9360 - val_loss: 7.4304\n",
      "Epoch 2466/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8517 - val_loss: 7.2772\n",
      "Epoch 2467/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7615 - val_loss: 7.3683\n",
      "Epoch 2468/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.7824 - val_loss: 7.5977\n",
      "Epoch 2469/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1320 - val_loss: 7.6651\n",
      "Epoch 2470/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9033 - val_loss: 7.6883\n",
      "Epoch 2471/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.1150 - val_loss: 7.4001\n",
      "Epoch 2472/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8522 - val_loss: 7.3567\n",
      "Epoch 2473/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9718 - val_loss: 7.2211\n",
      "Epoch 2474/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.7386 - val_loss: 7.5218\n",
      "Epoch 2475/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8784 - val_loss: 7.3652\n",
      "Epoch 2476/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.7875 - val_loss: 7.3761\n",
      "Epoch 2477/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8706 - val_loss: 7.6212\n",
      "Epoch 2478/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9772 - val_loss: 7.6342\n",
      "Epoch 2479/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.8489 - val_loss: 7.5269\n",
      "Epoch 2480/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8014 - val_loss: 7.4743\n",
      "Epoch 2481/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 2.0504 - val_loss: 7.3508\n",
      "Epoch 2482/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8699 - val_loss: 7.4651\n",
      "Epoch 2483/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8300 - val_loss: 7.2013\n",
      "Epoch 2484/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.7846 - val_loss: 7.7022\n",
      "Epoch 2485/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8219 - val_loss: 7.3822\n",
      "Epoch 2486/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.9357 - val_loss: 7.4092\n",
      "Epoch 2487/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.7500 - val_loss: 7.2508\n",
      "Epoch 2488/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8532 - val_loss: 7.4575\n",
      "Epoch 2489/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 2.0522 - val_loss: 7.3686\n",
      "Epoch 2490/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8649 - val_loss: 7.3637\n",
      "Epoch 2491/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8358 - val_loss: 7.3145\n",
      "Epoch 2492/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.6836 - val_loss: 7.5518\n",
      "Epoch 2493/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8323 - val_loss: 7.3461\n",
      "Epoch 2494/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.7683 - val_loss: 7.3300\n",
      "Epoch 2495/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.7209 - val_loss: 7.3190\n",
      "Epoch 2496/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.7079 - val_loss: 7.6184\n",
      "Epoch 2497/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.7769 - val_loss: 7.3870\n",
      "Epoch 2498/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.7309 - val_loss: 7.5602\n",
      "Epoch 2499/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8326 - val_loss: 7.2234\n",
      "Epoch 2500/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 2.0134 - val_loss: 7.4717\n",
      "Epoch 2501/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9296 - val_loss: 7.4900\n",
      "Epoch 2502/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9315 - val_loss: 7.7482\n",
      "Epoch 2503/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9331 - val_loss: 7.5809\n",
      "Epoch 2504/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9924 - val_loss: 7.3797\n",
      "Epoch 2505/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7466 - val_loss: 7.7474\n",
      "Epoch 2506/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8563 - val_loss: 7.7079\n",
      "Epoch 2507/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9530 - val_loss: 7.8210\n",
      "Epoch 2508/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0131 - val_loss: 7.7352\n",
      "Epoch 2509/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9272 - val_loss: 8.0723\n",
      "Epoch 2510/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0076 - val_loss: 7.2898\n",
      "Epoch 2511/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0085 - val_loss: 7.2347\n",
      "Epoch 2512/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9035 - val_loss: 7.8904\n",
      "Epoch 2513/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1279 - val_loss: 7.4846\n",
      "Epoch 2514/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8890 - val_loss: 7.9596\n",
      "Epoch 2515/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9469 - val_loss: 7.4861\n",
      "Epoch 2516/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8175 - val_loss: 7.6781\n",
      "Epoch 2517/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0255 - val_loss: 7.5003\n",
      "Epoch 2518/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9279 - val_loss: 7.5957\n",
      "Epoch 2519/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0666 - val_loss: 7.1898\n",
      "Epoch 2520/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7532 - val_loss: 7.4522\n",
      "Epoch 2521/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9997 - val_loss: 7.3411\n",
      "Epoch 2522/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0366 - val_loss: 7.5129\n",
      "Epoch 2523/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9079 - val_loss: 7.5829\n",
      "Epoch 2524/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9772 - val_loss: 7.5180\n",
      "Epoch 2525/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9091 - val_loss: 7.2003\n",
      "Epoch 2526/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8820 - val_loss: 7.2754\n",
      "Epoch 2527/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7856 - val_loss: 7.5279\n",
      "Epoch 2528/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9983 - val_loss: 7.8402\n",
      "Epoch 2529/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9263 - val_loss: 7.4197\n",
      "Epoch 2530/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8967 - val_loss: 7.5591\n",
      "Epoch 2531/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8895 - val_loss: 7.5821\n",
      "Epoch 2532/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0248 - val_loss: 7.4372\n",
      "Epoch 2533/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7220 - val_loss: 7.3025\n",
      "Epoch 2534/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9260 - val_loss: 7.5576\n",
      "Epoch 2535/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9337 - val_loss: 7.4388\n",
      "Epoch 2536/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9042 - val_loss: 7.7528\n",
      "Epoch 2537/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8948 - val_loss: 7.4651\n",
      "Epoch 2538/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.7743 - val_loss: 7.5436\n",
      "Epoch 2539/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8282 - val_loss: 7.3704\n",
      "Epoch 2540/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8049 - val_loss: 7.6894\n",
      "Epoch 2541/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9539 - val_loss: 7.3008\n",
      "Epoch 2542/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.7731 - val_loss: 7.3081\n",
      "Epoch 2543/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8536 - val_loss: 7.2428\n",
      "Epoch 2544/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8875 - val_loss: 7.6381\n",
      "Epoch 2545/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8812 - val_loss: 7.4031\n",
      "Epoch 2546/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.7918 - val_loss: 7.4426\n",
      "Epoch 2547/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8575 - val_loss: 7.8568\n",
      "Epoch 2548/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8548 - val_loss: 7.6924\n",
      "Epoch 2549/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0122 - val_loss: 7.3174\n",
      "Epoch 2550/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8360 - val_loss: 7.1935\n",
      "Epoch 2551/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8612 - val_loss: 7.3661\n",
      "Epoch 2552/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8390 - val_loss: 7.3408\n",
      "Epoch 2553/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8314 - val_loss: 7.7159\n",
      "Epoch 2554/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8529 - val_loss: 7.6131\n",
      "Epoch 2555/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9488 - val_loss: 7.5301\n",
      "Epoch 2556/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9290 - val_loss: 7.7024\n",
      "Epoch 2557/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8788 - val_loss: 7.5906\n",
      "Epoch 2558/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8822 - val_loss: 7.3512\n",
      "Epoch 2559/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9105 - val_loss: 7.3533\n",
      "Epoch 2560/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8266 - val_loss: 7.5068\n",
      "Epoch 2561/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.7848 - val_loss: 7.6315\n",
      "Epoch 2562/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0175 - val_loss: 7.3210\n",
      "Epoch 2563/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9579 - val_loss: 7.3834\n",
      "Epoch 2564/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8582 - val_loss: 7.4642\n",
      "Epoch 2565/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8927 - val_loss: 7.6111\n",
      "Epoch 2566/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9042 - val_loss: 7.8834\n",
      "Epoch 2567/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1938 - val_loss: 7.5585\n",
      "Epoch 2568/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1416 - val_loss: 7.6104\n",
      "Epoch 2569/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0144 - val_loss: 7.4197\n",
      "Epoch 2570/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8954 - val_loss: 7.4164\n",
      "Epoch 2571/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8677 - val_loss: 7.4570\n",
      "Epoch 2572/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8317 - val_loss: 7.5291\n",
      "Epoch 2573/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7880 - val_loss: 7.4986\n",
      "Epoch 2574/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7279 - val_loss: 7.4476\n",
      "Epoch 2575/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8003 - val_loss: 7.5726\n",
      "Epoch 2576/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7740 - val_loss: 7.8287\n",
      "Epoch 2577/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1005 - val_loss: 8.5004\n",
      "Epoch 2578/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.2115 - val_loss: 7.5198\n",
      "Epoch 2579/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8158 - val_loss: 7.2597\n",
      "Epoch 2580/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.7878 - val_loss: 7.6963\n",
      "Epoch 2581/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9523 - val_loss: 7.4083\n",
      "Epoch 2582/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8594 - val_loss: 7.4203\n",
      "Epoch 2583/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8142 - val_loss: 8.0270\n",
      "Epoch 2584/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0515 - val_loss: 7.9290\n",
      "Epoch 2585/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9923 - val_loss: 7.4349\n",
      "Epoch 2586/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7523 - val_loss: 8.0190\n",
      "Epoch 2587/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0592 - val_loss: 7.2203\n",
      "Epoch 2588/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.7130 - val_loss: 7.4714\n",
      "Epoch 2589/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.7313 - val_loss: 7.3701\n",
      "Epoch 2590/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.7495 - val_loss: 7.4715\n",
      "Epoch 2591/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9932 - val_loss: 8.3892\n",
      "Epoch 2592/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 2.1345 - val_loss: 7.3607\n",
      "Epoch 2593/3000\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 1.8503 - val_loss: 7.6419\n",
      "Epoch 2594/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.8461 - val_loss: 7.6964\n",
      "Epoch 2595/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.7935 - val_loss: 7.3238\n",
      "Epoch 2596/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8873 - val_loss: 7.4626\n",
      "Epoch 2597/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.7485 - val_loss: 7.5377\n",
      "Epoch 2598/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.8082 - val_loss: 7.8460\n",
      "Epoch 2599/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 2.1282 - val_loss: 7.4448\n",
      "Epoch 2600/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8784 - val_loss: 7.2709\n",
      "Epoch 2601/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8065 - val_loss: 7.6363\n",
      "Epoch 2602/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0498 - val_loss: 7.4893\n",
      "Epoch 2603/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.9585 - val_loss: 7.6380\n",
      "Epoch 2604/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.8429 - val_loss: 7.5066\n",
      "Epoch 2605/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.8059 - val_loss: 7.2111\n",
      "Epoch 2606/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.7132 - val_loss: 7.8127\n",
      "Epoch 2607/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 2.0364 - val_loss: 7.8772\n",
      "Epoch 2608/3000\n",
      "55/55 [==============================] - 2s 30ms/step - loss: 1.9114 - val_loss: 7.3600\n",
      "Epoch 2609/3000\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 1.8357 - val_loss: 7.6399\n",
      "Epoch 2610/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9156 - val_loss: 7.1760\n",
      "Epoch 2611/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.7332 - val_loss: 7.2892\n",
      "Epoch 2612/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8483 - val_loss: 7.3739\n",
      "Epoch 2613/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8499 - val_loss: 7.5612\n",
      "Epoch 2614/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8798 - val_loss: 7.5419\n",
      "Epoch 2615/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8301 - val_loss: 7.5491\n",
      "Epoch 2616/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0005 - val_loss: 7.5876\n",
      "Epoch 2617/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9353 - val_loss: 7.4153\n",
      "Epoch 2618/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8428 - val_loss: 7.2437\n",
      "Epoch 2619/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.7655 - val_loss: 7.5708\n",
      "Epoch 2620/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0015 - val_loss: 7.2234\n",
      "Epoch 2621/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0102 - val_loss: 7.6479\n",
      "Epoch 2622/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0429 - val_loss: 7.1642\n",
      "Epoch 2623/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6891 - val_loss: 7.3510\n",
      "Epoch 2624/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7438 - val_loss: 7.5958\n",
      "Epoch 2625/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7597 - val_loss: 7.5465\n",
      "Epoch 2626/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9460 - val_loss: 7.5117\n",
      "Epoch 2627/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8043 - val_loss: 7.5714\n",
      "Epoch 2628/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8679 - val_loss: 7.4690\n",
      "Epoch 2629/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8640 - val_loss: 7.5790\n",
      "Epoch 2630/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8907 - val_loss: 7.7135\n",
      "Epoch 2631/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9821 - val_loss: 7.5602\n",
      "Epoch 2632/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8834 - val_loss: 8.2971\n",
      "Epoch 2633/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 2.1892 - val_loss: 7.5185\n",
      "Epoch 2634/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8874 - val_loss: 7.4568\n",
      "Epoch 2635/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8350 - val_loss: 7.2690\n",
      "Epoch 2636/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8677 - val_loss: 7.2544\n",
      "Epoch 2637/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.6324 - val_loss: 7.5637\n",
      "Epoch 2638/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9764 - val_loss: 7.4718\n",
      "Epoch 2639/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0735 - val_loss: 7.5901\n",
      "Epoch 2640/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8778 - val_loss: 7.5625\n",
      "Epoch 2641/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.9334 - val_loss: 7.5034\n",
      "Epoch 2642/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0894 - val_loss: 7.4956\n",
      "Epoch 2643/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0561 - val_loss: 7.2765\n",
      "Epoch 2644/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9353 - val_loss: 7.4815\n",
      "Epoch 2645/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9983 - val_loss: 7.3226\n",
      "Epoch 2646/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9576 - val_loss: 7.6287\n",
      "Epoch 2647/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.7887 - val_loss: 7.2427\n",
      "Epoch 2648/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7755 - val_loss: 7.3144\n",
      "Epoch 2649/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7705 - val_loss: 7.3286\n",
      "Epoch 2650/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7931 - val_loss: 7.4051\n",
      "Epoch 2651/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7969 - val_loss: 7.2893\n",
      "Epoch 2652/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7287 - val_loss: 7.4195\n",
      "Epoch 2653/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7537 - val_loss: 7.3615\n",
      "Epoch 2654/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9249 - val_loss: 7.4931\n",
      "Epoch 2655/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8139 - val_loss: 7.7921\n",
      "Epoch 2656/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9259 - val_loss: 7.4455\n",
      "Epoch 2657/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9857 - val_loss: 7.3736\n",
      "Epoch 2658/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7638 - val_loss: 7.5400\n",
      "Epoch 2659/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0682 - val_loss: 7.7559\n",
      "Epoch 2660/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1113 - val_loss: 7.2998\n",
      "Epoch 2661/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7876 - val_loss: 7.3150\n",
      "Epoch 2662/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7804 - val_loss: 7.4916\n",
      "Epoch 2663/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8589 - val_loss: 7.2347\n",
      "Epoch 2664/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7943 - val_loss: 7.3670\n",
      "Epoch 2665/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8657 - val_loss: 7.5674\n",
      "Epoch 2666/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7513 - val_loss: 7.7695\n",
      "Epoch 2667/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1000 - val_loss: 7.6148\n",
      "Epoch 2668/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8877 - val_loss: 7.5682\n",
      "Epoch 2669/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0076 - val_loss: 7.7478\n",
      "Epoch 2670/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8301 - val_loss: 7.1082\n",
      "Epoch 2671/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8306 - val_loss: 7.6052\n",
      "Epoch 2672/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9040 - val_loss: 7.4827\n",
      "Epoch 2673/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8669 - val_loss: 7.6074\n",
      "Epoch 2674/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0388 - val_loss: 7.3218\n",
      "Epoch 2675/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.1828 - val_loss: 7.2200\n",
      "Epoch 2676/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8240 - val_loss: 7.4756\n",
      "Epoch 2677/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9604 - val_loss: 7.2585\n",
      "Epoch 2678/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8659 - val_loss: 7.2376\n",
      "Epoch 2679/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.6821 - val_loss: 7.5136\n",
      "Epoch 2680/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9433 - val_loss: 7.3372\n",
      "Epoch 2681/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.7650 - val_loss: 7.5134\n",
      "Epoch 2682/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9197 - val_loss: 7.4884\n",
      "Epoch 2683/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9685 - val_loss: 7.2972\n",
      "Epoch 2684/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.7970 - val_loss: 7.4091\n",
      "Epoch 2685/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.7558 - val_loss: 7.4710\n",
      "Epoch 2686/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8015 - val_loss: 7.3092\n",
      "Epoch 2687/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8251 - val_loss: 7.4517\n",
      "Epoch 2688/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.7952 - val_loss: 7.7566\n",
      "Epoch 2689/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9635 - val_loss: 7.5105\n",
      "Epoch 2690/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 2.0310 - val_loss: 7.5959\n",
      "Epoch 2691/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9300 - val_loss: 7.2315\n",
      "Epoch 2692/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.7720 - val_loss: 7.4921\n",
      "Epoch 2693/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8557 - val_loss: 7.4328\n",
      "Epoch 2694/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9142 - val_loss: 7.6846\n",
      "Epoch 2695/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9762 - val_loss: 7.4352\n",
      "Epoch 2696/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.7520 - val_loss: 7.3438\n",
      "Epoch 2697/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8255 - val_loss: 7.9114\n",
      "Epoch 2698/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0880 - val_loss: 7.3004\n",
      "Epoch 2699/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9121 - val_loss: 7.3672\n",
      "Epoch 2700/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8913 - val_loss: 7.4911\n",
      "Epoch 2701/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9038 - val_loss: 7.8488\n",
      "Epoch 2702/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8907 - val_loss: 7.3065\n",
      "Epoch 2703/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8013 - val_loss: 7.5408\n",
      "Epoch 2704/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8912 - val_loss: 7.9585\n",
      "Epoch 2705/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.9224 - val_loss: 7.3525\n",
      "Epoch 2706/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8136 - val_loss: 7.4467\n",
      "Epoch 2707/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.7724 - val_loss: 7.5114\n",
      "Epoch 2708/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8307 - val_loss: 7.3413\n",
      "Epoch 2709/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8496 - val_loss: 7.4012\n",
      "Epoch 2710/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.7577 - val_loss: 7.4235\n",
      "Epoch 2711/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8082 - val_loss: 7.6629\n",
      "Epoch 2712/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8604 - val_loss: 7.0639\n",
      "Epoch 2713/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8105 - val_loss: 7.5442\n",
      "Epoch 2714/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7834 - val_loss: 7.2718\n",
      "Epoch 2715/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7032 - val_loss: 7.3763\n",
      "Epoch 2716/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8603 - val_loss: 7.6525\n",
      "Epoch 2717/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8681 - val_loss: 7.3492\n",
      "Epoch 2718/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7818 - val_loss: 7.4327\n",
      "Epoch 2719/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7723 - val_loss: 7.4042\n",
      "Epoch 2720/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7315 - val_loss: 7.3137\n",
      "Epoch 2721/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8271 - val_loss: 7.2754\n",
      "Epoch 2722/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7865 - val_loss: 7.7385\n",
      "Epoch 2723/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8547 - val_loss: 8.1439\n",
      "Epoch 2724/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.1863 - val_loss: 7.3786\n",
      "Epoch 2725/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7280 - val_loss: 7.3719\n",
      "Epoch 2726/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7241 - val_loss: 7.3222\n",
      "Epoch 2727/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8059 - val_loss: 7.7046\n",
      "Epoch 2728/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8853 - val_loss: 7.4374\n",
      "Epoch 2729/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7772 - val_loss: 7.6816\n",
      "Epoch 2730/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.7821 - val_loss: 7.4039\n",
      "Epoch 2731/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7798 - val_loss: 7.6741\n",
      "Epoch 2732/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8429 - val_loss: 7.5000\n",
      "Epoch 2733/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8250 - val_loss: 7.4131\n",
      "Epoch 2734/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8604 - val_loss: 7.6857\n",
      "Epoch 2735/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8277 - val_loss: 7.1867\n",
      "Epoch 2736/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.7046 - val_loss: 7.2350\n",
      "Epoch 2737/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8734 - val_loss: 7.6324\n",
      "Epoch 2738/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.9288 - val_loss: 7.5016\n",
      "Epoch 2739/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.2749 - val_loss: 7.6698\n",
      "Epoch 2740/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 2.0567 - val_loss: 7.5386\n",
      "Epoch 2741/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8875 - val_loss: 7.7368\n",
      "Epoch 2742/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9325 - val_loss: 7.4352\n",
      "Epoch 2743/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8838 - val_loss: 7.6667\n",
      "Epoch 2744/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8333 - val_loss: 7.4485\n",
      "Epoch 2745/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8633 - val_loss: 7.3254\n",
      "Epoch 2746/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9677 - val_loss: 7.7295\n",
      "Epoch 2747/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0690 - val_loss: 7.4964\n",
      "Epoch 2748/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8730 - val_loss: 7.3249\n",
      "Epoch 2749/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9550 - val_loss: 7.5783\n",
      "Epoch 2750/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8435 - val_loss: 7.3505\n",
      "Epoch 2751/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7981 - val_loss: 7.4155\n",
      "Epoch 2752/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8419 - val_loss: 7.4196\n",
      "Epoch 2753/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0837 - val_loss: 8.2507\n",
      "Epoch 2754/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9147 - val_loss: 7.3245\n",
      "Epoch 2755/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7402 - val_loss: 7.4136\n",
      "Epoch 2756/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8392 - val_loss: 7.2525\n",
      "Epoch 2757/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8049 - val_loss: 7.2984\n",
      "Epoch 2758/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6979 - val_loss: 7.2299\n",
      "Epoch 2759/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7381 - val_loss: 7.3989\n",
      "Epoch 2760/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0528 - val_loss: 7.4950\n",
      "Epoch 2761/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7503 - val_loss: 7.6684\n",
      "Epoch 2762/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7093 - val_loss: 7.4042\n",
      "Epoch 2763/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6971 - val_loss: 7.3465\n",
      "Epoch 2764/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7219 - val_loss: 7.2714\n",
      "Epoch 2765/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7048 - val_loss: 7.4878\n",
      "Epoch 2766/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9433 - val_loss: 7.3335\n",
      "Epoch 2767/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8056 - val_loss: 7.3853\n",
      "Epoch 2768/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7369 - val_loss: 8.2917\n",
      "Epoch 2769/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1689 - val_loss: 7.8036\n",
      "Epoch 2770/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9975 - val_loss: 7.4980\n",
      "Epoch 2771/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7673 - val_loss: 7.4200\n",
      "Epoch 2772/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8208 - val_loss: 7.4351\n",
      "Epoch 2773/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8176 - val_loss: 7.7203\n",
      "Epoch 2774/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8838 - val_loss: 7.4288\n",
      "Epoch 2775/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7718 - val_loss: 7.2336\n",
      "Epoch 2776/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6380 - val_loss: 7.3356\n",
      "Epoch 2777/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7489 - val_loss: 7.3717\n",
      "Epoch 2778/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6583 - val_loss: 7.2713\n",
      "Epoch 2779/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6533 - val_loss: 7.3127\n",
      "Epoch 2780/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7637 - val_loss: 7.5595\n",
      "Epoch 2781/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8114 - val_loss: 7.5492\n",
      "Epoch 2782/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7693 - val_loss: 7.8941\n",
      "Epoch 2783/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0653 - val_loss: 7.6863\n",
      "Epoch 2784/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.0030 - val_loss: 7.2056\n",
      "Epoch 2785/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6466 - val_loss: 7.2212\n",
      "Epoch 2786/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6684 - val_loss: 7.4082\n",
      "Epoch 2787/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6977 - val_loss: 7.4041\n",
      "Epoch 2788/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8213 - val_loss: 7.4395\n",
      "Epoch 2789/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7758 - val_loss: 7.2246\n",
      "Epoch 2790/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6635 - val_loss: 7.4661\n",
      "Epoch 2791/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7854 - val_loss: 7.5306\n",
      "Epoch 2792/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7722 - val_loss: 7.3923\n",
      "Epoch 2793/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6914 - val_loss: 7.5692\n",
      "Epoch 2794/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7828 - val_loss: 7.7979\n",
      "Epoch 2795/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8327 - val_loss: 7.3910\n",
      "Epoch 2796/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7841 - val_loss: 7.3137\n",
      "Epoch 2797/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7485 - val_loss: 7.4546\n",
      "Epoch 2798/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8729 - val_loss: 7.6880\n",
      "Epoch 2799/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8049 - val_loss: 7.3414\n",
      "Epoch 2800/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8383 - val_loss: 7.5402\n",
      "Epoch 2801/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9939 - val_loss: 7.7976\n",
      "Epoch 2802/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 2.1147 - val_loss: 7.7886\n",
      "Epoch 2803/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9635 - val_loss: 7.4663\n",
      "Epoch 2804/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7860 - val_loss: 7.3274\n",
      "Epoch 2805/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7548 - val_loss: 7.2573\n",
      "Epoch 2806/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7498 - val_loss: 7.4139\n",
      "Epoch 2807/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7576 - val_loss: 7.2970\n",
      "Epoch 2808/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6246 - val_loss: 7.2145\n",
      "Epoch 2809/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6480 - val_loss: 7.2935\n",
      "Epoch 2810/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7012 - val_loss: 7.6566\n",
      "Epoch 2811/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8061 - val_loss: 7.5148\n",
      "Epoch 2812/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7122 - val_loss: 7.3724\n",
      "Epoch 2813/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7702 - val_loss: 7.5700\n",
      "Epoch 2814/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.7973 - val_loss: 7.5901\n",
      "Epoch 2815/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.7362 - val_loss: 7.5618\n",
      "Epoch 2816/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.8876 - val_loss: 7.4379\n",
      "Epoch 2817/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.7172 - val_loss: 7.4652\n",
      "Epoch 2818/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8799 - val_loss: 7.3316\n",
      "Epoch 2819/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8577 - val_loss: 7.5562\n",
      "Epoch 2820/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8109 - val_loss: 7.3271\n",
      "Epoch 2821/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8595 - val_loss: 7.4388\n",
      "Epoch 2822/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7752 - val_loss: 7.2179\n",
      "Epoch 2823/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6715 - val_loss: 7.5807\n",
      "Epoch 2824/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9050 - val_loss: 7.5681\n",
      "Epoch 2825/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8225 - val_loss: 7.4863\n",
      "Epoch 2826/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7354 - val_loss: 7.3335\n",
      "Epoch 2827/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6374 - val_loss: 7.3557\n",
      "Epoch 2828/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.6667 - val_loss: 7.3749\n",
      "Epoch 2829/3000\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 1.8337 - val_loss: 7.6682\n",
      "Epoch 2830/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8169 - val_loss: 7.2283\n",
      "Epoch 2831/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7258 - val_loss: 7.3384\n",
      "Epoch 2832/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.8087 - val_loss: 7.3871\n",
      "Epoch 2833/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8285 - val_loss: 7.6719\n",
      "Epoch 2834/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8588 - val_loss: 7.4171\n",
      "Epoch 2835/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8044 - val_loss: 8.0055\n",
      "Epoch 2836/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0437 - val_loss: 7.3500\n",
      "Epoch 2837/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8205 - val_loss: 7.7368\n",
      "Epoch 2838/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0003 - val_loss: 7.7821\n",
      "Epoch 2839/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0690 - val_loss: 7.4752\n",
      "Epoch 2840/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8336 - val_loss: 7.5076\n",
      "Epoch 2841/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7529 - val_loss: 7.6922\n",
      "Epoch 2842/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9102 - val_loss: 7.9448\n",
      "Epoch 2843/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8915 - val_loss: 7.5446\n",
      "Epoch 2844/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8752 - val_loss: 7.4756\n",
      "Epoch 2845/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8813 - val_loss: 7.7498\n",
      "Epoch 2846/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0967 - val_loss: 7.9519\n",
      "Epoch 2847/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9880 - val_loss: 7.7491\n",
      "Epoch 2848/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9180 - val_loss: 7.3940\n",
      "Epoch 2849/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8266 - val_loss: 7.3688\n",
      "Epoch 2850/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9111 - val_loss: 7.5155\n",
      "Epoch 2851/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.7878 - val_loss: 7.5491\n",
      "Epoch 2852/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8162 - val_loss: 7.7874\n",
      "Epoch 2853/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8008 - val_loss: 7.2709\n",
      "Epoch 2854/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.6423 - val_loss: 7.3755\n",
      "Epoch 2855/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.8174 - val_loss: 7.7965\n",
      "Epoch 2856/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 2.0175 - val_loss: 7.9565\n",
      "Epoch 2857/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 2.2056 - val_loss: 7.5661\n",
      "Epoch 2858/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.8308 - val_loss: 7.4663\n",
      "Epoch 2859/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.7785 - val_loss: 7.5585\n",
      "Epoch 2860/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6849 - val_loss: 7.4185\n",
      "Epoch 2861/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6943 - val_loss: 7.3538\n",
      "Epoch 2862/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.5993 - val_loss: 7.3433\n",
      "Epoch 2863/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6193 - val_loss: 7.6378\n",
      "Epoch 2864/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6423 - val_loss: 7.2330\n",
      "Epoch 2865/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6033 - val_loss: 7.9453\n",
      "Epoch 2866/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7917 - val_loss: 7.2546\n",
      "Epoch 2867/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6398 - val_loss: 8.3173\n",
      "Epoch 2868/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0738 - val_loss: 7.3329\n",
      "Epoch 2869/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7001 - val_loss: 7.2673\n",
      "Epoch 2870/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7036 - val_loss: 7.2362\n",
      "Epoch 2871/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6371 - val_loss: 7.3781\n",
      "Epoch 2872/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6142 - val_loss: 7.3565\n",
      "Epoch 2873/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7014 - val_loss: 8.1985\n",
      "Epoch 2874/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.2890 - val_loss: 7.3865\n",
      "Epoch 2875/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7435 - val_loss: 7.2710\n",
      "Epoch 2876/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7559 - val_loss: 7.6559\n",
      "Epoch 2877/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0000 - val_loss: 7.5426\n",
      "Epoch 2878/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7354 - val_loss: 7.5000\n",
      "Epoch 2879/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7241 - val_loss: 7.4095\n",
      "Epoch 2880/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7862 - val_loss: 7.6762\n",
      "Epoch 2881/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8183 - val_loss: 7.5459\n",
      "Epoch 2882/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9023 - val_loss: 7.6125\n",
      "Epoch 2883/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7161 - val_loss: 7.5722\n",
      "Epoch 2884/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7093 - val_loss: 7.5079\n",
      "Epoch 2885/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7091 - val_loss: 7.4490\n",
      "Epoch 2886/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6807 - val_loss: 7.4384\n",
      "Epoch 2887/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.8215 - val_loss: 7.7712\n",
      "Epoch 2888/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7446 - val_loss: 7.3440\n",
      "Epoch 2889/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7331 - val_loss: 7.5308\n",
      "Epoch 2890/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8757 - val_loss: 7.4899\n",
      "Epoch 2891/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7638 - val_loss: 7.5697\n",
      "Epoch 2892/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8763 - val_loss: 7.8700\n",
      "Epoch 2893/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9192 - val_loss: 7.7197\n",
      "Epoch 2894/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7303 - val_loss: 7.2609\n",
      "Epoch 2895/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7463 - val_loss: 7.9801\n",
      "Epoch 2896/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8468 - val_loss: 7.5723\n",
      "Epoch 2897/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.6922 - val_loss: 7.6151\n",
      "Epoch 2898/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.3212 - val_loss: 7.6881\n",
      "Epoch 2899/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9229 - val_loss: 7.7875\n",
      "Epoch 2900/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7986 - val_loss: 7.3761\n",
      "Epoch 2901/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7057 - val_loss: 7.5319\n",
      "Epoch 2902/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7629 - val_loss: 7.2620\n",
      "Epoch 2903/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6742 - val_loss: 7.2555\n",
      "Epoch 2904/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6786 - val_loss: 7.3311\n",
      "Epoch 2905/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6658 - val_loss: 7.4682\n",
      "Epoch 2906/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7334 - val_loss: 7.5411\n",
      "Epoch 2907/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7459 - val_loss: 7.3865\n",
      "Epoch 2908/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.5955 - val_loss: 7.3465\n",
      "Epoch 2909/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7104 - val_loss: 7.5778\n",
      "Epoch 2910/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8097 - val_loss: 7.9188\n",
      "Epoch 2911/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7882 - val_loss: 7.4830\n",
      "Epoch 2912/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7986 - val_loss: 7.3889\n",
      "Epoch 2913/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7067 - val_loss: 7.5876\n",
      "Epoch 2914/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6643 - val_loss: 7.1797\n",
      "Epoch 2915/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6787 - val_loss: 7.5233\n",
      "Epoch 2916/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6473 - val_loss: 7.5046\n",
      "Epoch 2917/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7053 - val_loss: 7.4164\n",
      "Epoch 2918/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7169 - val_loss: 7.3393\n",
      "Epoch 2919/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7540 - val_loss: 7.4027\n",
      "Epoch 2920/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7193 - val_loss: 7.6229\n",
      "Epoch 2921/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9163 - val_loss: 7.4922\n",
      "Epoch 2922/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8445 - val_loss: 7.6371\n",
      "Epoch 2923/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9643 - val_loss: 7.6101\n",
      "Epoch 2924/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8869 - val_loss: 7.5106\n",
      "Epoch 2925/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7882 - val_loss: 7.9047\n",
      "Epoch 2926/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8075 - val_loss: 7.5489\n",
      "Epoch 2927/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7742 - val_loss: 7.4268\n",
      "Epoch 2928/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7418 - val_loss: 7.3601\n",
      "Epoch 2929/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6723 - val_loss: 7.4255\n",
      "Epoch 2930/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7460 - val_loss: 7.4749\n",
      "Epoch 2931/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7926 - val_loss: 7.3670\n",
      "Epoch 2932/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6879 - val_loss: 7.5331\n",
      "Epoch 2933/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7816 - val_loss: 7.3554\n",
      "Epoch 2934/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6882 - val_loss: 7.3434\n",
      "Epoch 2935/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.5915 - val_loss: 7.6391\n",
      "Epoch 2936/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7152 - val_loss: 7.5974\n",
      "Epoch 2937/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7226 - val_loss: 7.9146\n",
      "Epoch 2938/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9078 - val_loss: 7.3138\n",
      "Epoch 2939/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8905 - val_loss: 7.3741\n",
      "Epoch 2940/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6607 - val_loss: 7.8505\n",
      "Epoch 2941/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8809 - val_loss: 7.6036\n",
      "Epoch 2942/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8041 - val_loss: 7.6935\n",
      "Epoch 2943/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.0478 - val_loss: 7.3945\n",
      "Epoch 2944/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6983 - val_loss: 7.5702\n",
      "Epoch 2945/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8019 - val_loss: 7.7443\n",
      "Epoch 2946/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8870 - val_loss: 7.7497\n",
      "Epoch 2947/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7861 - val_loss: 7.5542\n",
      "Epoch 2948/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7780 - val_loss: 7.2600\n",
      "Epoch 2949/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6355 - val_loss: 7.5274\n",
      "Epoch 2950/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.6895 - val_loss: 7.2158\n",
      "Epoch 2951/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.5775 - val_loss: 7.3918\n",
      "Epoch 2952/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.6016 - val_loss: 7.9199\n",
      "Epoch 2953/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6944 - val_loss: 7.3487\n",
      "Epoch 2954/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7018 - val_loss: 7.3916\n",
      "Epoch 2955/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7939 - val_loss: 7.6714\n",
      "Epoch 2956/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8806 - val_loss: 7.1885\n",
      "Epoch 2957/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7160 - val_loss: 7.4498\n",
      "Epoch 2958/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8344 - val_loss: 7.3283\n",
      "Epoch 2959/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6349 - val_loss: 7.7766\n",
      "Epoch 2960/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7968 - val_loss: 7.3974\n",
      "Epoch 2961/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7147 - val_loss: 7.7192\n",
      "Epoch 2962/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.7886 - val_loss: 7.2962\n",
      "Epoch 2963/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6797 - val_loss: 7.8057\n",
      "Epoch 2964/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.8530 - val_loss: 7.2440\n",
      "Epoch 2965/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.6268 - val_loss: 7.1403\n",
      "Epoch 2966/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.5649 - val_loss: 7.9029\n",
      "Epoch 2967/3000\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 1.9324 - val_loss: 7.4966\n",
      "Epoch 2968/3000\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 1.7953 - val_loss: 7.2400\n",
      "Epoch 2969/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6530 - val_loss: 7.9793\n",
      "Epoch 2970/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.8561 - val_loss: 7.3812\n",
      "Epoch 2971/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8267 - val_loss: 7.4029\n",
      "Epoch 2972/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8158 - val_loss: 7.4536\n",
      "Epoch 2973/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7440 - val_loss: 7.3434\n",
      "Epoch 2974/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7986 - val_loss: 7.4204\n",
      "Epoch 2975/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7830 - val_loss: 7.6223\n",
      "Epoch 2976/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8301 - val_loss: 7.4605\n",
      "Epoch 2977/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7440 - val_loss: 7.9807\n",
      "Epoch 2978/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 2.3230 - val_loss: 7.4966\n",
      "Epoch 2979/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8493 - val_loss: 7.5917\n",
      "Epoch 2980/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8210 - val_loss: 7.4707\n",
      "Epoch 2981/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6816 - val_loss: 7.3706\n",
      "Epoch 2982/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9362 - val_loss: 7.5108\n",
      "Epoch 2983/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7365 - val_loss: 7.2743\n",
      "Epoch 2984/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8070 - val_loss: 7.4391\n",
      "Epoch 2985/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7932 - val_loss: 7.5267\n",
      "Epoch 2986/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7136 - val_loss: 7.4179\n",
      "Epoch 2987/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7108 - val_loss: 7.3497\n",
      "Epoch 2988/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6924 - val_loss: 7.4300\n",
      "Epoch 2989/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6841 - val_loss: 7.4980\n",
      "Epoch 2990/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7556 - val_loss: 7.4284\n",
      "Epoch 2991/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.5843 - val_loss: 7.4670\n",
      "Epoch 2992/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6566 - val_loss: 7.4467\n",
      "Epoch 2993/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6363 - val_loss: 7.4193\n",
      "Epoch 2994/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7697 - val_loss: 7.6422\n",
      "Epoch 2995/3000\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.7709 - val_loss: 7.7008\n",
      "Epoch 2996/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.9081 - val_loss: 7.4711\n",
      "Epoch 2997/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7443 - val_loss: 7.4397\n",
      "Epoch 2998/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6628 - val_loss: 7.4365\n",
      "Epoch 2999/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.7023 - val_loss: 7.2364\n",
      "Epoch 3000/3000\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.6114 - val_loss: 7.3661\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=\"mae\",)\n",
    "\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=epoch_size,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "history: dict = history.history\n",
    "loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "l = int(len(loss) / 10)\n",
    "history['loss'] = loss[l:]\n",
    "history['val_loss'] = val_loss[l:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [5.5699944496154785, 5.469057083129883, 6.362249851226807, 5.255176067352295, 5.4104084968566895, 5.034018516540527, 5.503445625305176, 5.522520065307617, 4.981854438781738, 5.519603252410889, 5.134392261505127, 5.267996311187744, 5.357560157775879, 5.339993953704834, 5.245916843414307, 5.2104620933532715, 5.136332035064697, 4.923118591308594, 5.415957927703857, 5.405516147613525, 5.361175060272217, 5.442144870758057, 5.236506462097168, 5.81865119934082, 5.355385780334473, 5.439760208129883, 5.603862762451172, 5.858689785003662, 4.991724491119385, 5.46389102935791, 5.107629299163818, 5.2670207023620605, 6.7701616287231445, 5.011580467224121, 5.359111785888672, 5.317408084869385, 5.89078426361084, 5.415897369384766, 5.510366439819336, 5.29884672164917, 6.373866558074951, 6.100428581237793, 5.502155780792236, 5.457208156585693, 5.305866241455078, 5.727027416229248, 5.3847527503967285, 4.762129306793213, 5.1321024894714355, 4.972787380218506, 5.219874858856201, 5.619805812835693, 5.008416652679443, 5.042178153991699, 4.967884540557861, 5.30775785446167, 4.8661675453186035, 5.284644603729248, 5.1305646896362305, 4.963129997253418, 5.2649335861206055, 9.97590446472168, 5.88454532623291, 5.753851413726807, 5.317932605743408, 5.198541641235352, 5.097754001617432, 4.754419803619385, 5.249589920043945, 5.4532928466796875, 5.220049858093262, 5.2036333084106445, 5.077249050140381, 5.009206295013428, 4.912228107452393, 5.1535468101501465, 4.939764022827148, 5.705140590667725, 4.985429763793945, 4.896572589874268, 4.893787860870361, 4.78053617477417, 5.105118274688721, 5.056698799133301, 5.007483005523682, 5.759458541870117, 5.081495761871338, 5.2448835372924805, 4.6477837562561035, 5.197920322418213, 4.820523738861084, 5.139702320098877, 5.286023139953613, 5.569526195526123, 5.036830902099609, 4.857799053192139, 4.852200984954834, 5.043251991271973, 4.92279577255249, 4.785136699676514, 5.266905784606934, 4.972291946411133, 4.584543704986572, 4.686050891876221, 4.9143829345703125, 4.926006317138672, 4.632880687713623, 5.0628252029418945, 4.91880989074707, 4.7268476486206055, 4.598520278930664, 5.196955680847168, 4.950467109680176, 4.657508850097656, 4.590185165405273, 4.61775541305542, 4.543358325958252, 4.127330303192139, 5.10504674911499, 4.8966193199157715, 4.958242416381836, 4.57208776473999, 4.435905933380127, 4.293590068817139, 4.6586480140686035, 5.1076555252075195, 4.824060916900635, 4.6854987144470215, 4.917748928070068, 4.7078022956848145, 4.648591995239258, 4.6151957511901855, 5.123595714569092, 4.490874767303467, 4.705665588378906, 4.374213218688965, 4.925131797790527, 4.383519649505615, 5.122559547424316, 4.534675598144531, 5.097297668457031, 5.537864685058594, 4.991304397583008, 4.498622417449951, 4.477503299713135, 4.57917594909668, 4.776851177215576, 4.674746513366699, 4.763200759887695, 4.2787675857543945, 5.403049945831299, 4.757005214691162, 4.355103492736816, 4.638038635253906, 4.49714469909668, 4.847413063049316, 4.024922847747803, 4.785620212554932, 4.3526082038879395, 4.826310634613037, 4.434416770935059, 4.766227722167969, 4.485969066619873, 4.7597336769104, 4.765256881713867, 4.7812180519104, 5.12664794921875, 4.377557754516602, 4.4093241691589355, 4.6546807289123535, 4.138912200927734, 4.545964241027832, 5.458962917327881, 4.365119934082031, 4.619902610778809, 4.394340991973877, 4.654551982879639, 5.422855854034424, 4.766592979431152, 4.1510186195373535, 4.440518856048584, 5.013193130493164, 4.402119159698486, 4.403250694274902, 4.364436149597168, 4.394207954406738, 4.851336479187012, 4.5645880699157715, 4.348328590393066, 4.358410835266113, 4.201042175292969, 4.524028778076172, 4.603177070617676, 4.247626304626465, 4.313114166259766, 4.304773330688477, 4.23426628112793, 4.466324329376221, 4.06608772277832, 4.140789985656738, 4.8442912101745605, 4.150199890136719, 4.363723278045654, 4.565707206726074, 4.512813091278076, 4.807794570922852, 4.786192417144775, 4.259801864624023, 4.1873321533203125, 3.969403028488159, 4.666656017303467, 4.219809532165527, 4.927248001098633, 4.31447172164917, 4.531064033508301, 4.122012138366699, 4.647563934326172, 4.290174961090088, 4.8617682456970215, 4.233091354370117, 4.633771896362305, 4.490946292877197, 4.613933086395264, 5.013915061950684, 4.3938727378845215, 4.147876739501953, 4.777047634124756, 4.265685558319092, 4.0872039794921875, 4.226339340209961, 4.165847301483154, 4.312930107116699, 4.162667274475098, 3.9210870265960693, 4.016704559326172, 4.187127590179443, 6.953189849853516, 5.091798782348633, 4.278356552124023, 4.234853744506836, 4.739646911621094, 3.998906373977661, 4.410445690155029, 4.483309745788574, 4.002812385559082, 4.771697044372559, 4.462177276611328, 4.316608428955078, 4.104009628295898, 4.13230562210083, 4.172616481781006, 3.9294593334198, 3.8423378467559814, 4.281990051269531, 4.214601516723633, 4.358929634094238, 3.888784646987915, 3.6402761936187744, 4.512794494628906, 4.115180015563965, 4.0139055252075195, 4.311663627624512, 4.078726768493652, 4.042990684509277, 4.230902671813965, 4.324300765991211, 4.2612128257751465, 4.289742469787598, 4.305415153503418, 4.266683578491211, 4.358809947967529, 4.213608264923096, 4.465590476989746, 4.054207801818848, 4.010761260986328, 4.092526435852051, 3.92655611038208, 4.289627552032471, 4.351865768432617, 4.200863838195801, 4.0448737144470215, 4.031064033508301, 5.5278239250183105, 5.492766857147217, 4.556606769561768, 4.161120414733887, 4.219541072845459, 4.377893924713135, 4.031614780426025, 3.778019666671753, 4.332178115844727, 3.8158485889434814, 4.0743584632873535, 4.246488571166992, 3.9775755405426025, 3.8888912200927734, 3.8283653259277344, 4.04295539855957, 3.8324830532073975, 3.8112595081329346, 4.5832319259643555, 4.086195468902588, 4.2002854347229, 4.12135124206543, 4.364442348480225, 4.127689838409424, 3.955742835998535, 3.9615724086761475, 4.015163421630859, 4.522062301635742, 4.435731410980225, 4.262020587921143, 3.6224303245544434, 3.950147867202759, 3.860175609588623, 4.034879207611084, 4.065703868865967, 4.2060723304748535, 3.6306703090667725, 3.759639024734497, 3.8687314987182617, 4.081384658813477, 3.8450958728790283, 3.815586566925049, 3.807786226272583, 3.7604949474334717, 3.6076061725616455, 4.125134468078613, 4.090900421142578, 3.8289592266082764, 3.772799491882324, 3.7239887714385986, 4.361413955688477, 4.2219696044921875, 3.7318637371063232, 4.053091526031494, 4.1109113693237305, 3.9919586181640625, 3.925039291381836, 4.59184455871582, 4.259601593017578, 4.056008338928223, 3.9093809127807617, 3.9570584297180176, 3.740926742553711, 3.6672520637512207, 4.5982794761657715, 4.15266752243042, 4.283295631408691, 3.8131752014160156, 3.849635362625122, 4.2691497802734375, 3.857877254486084, 4.228671550750732, 3.6205480098724365, 3.7936294078826904, 3.781287670135498, 4.39529275894165, 4.026306629180908, 4.059907913208008, 3.8221890926361084, 4.073429584503174, 3.9854629039764404, 3.7735447883605957, 3.5861055850982666, 3.6879847049713135, 3.5411529541015625, 3.619746446609497, 3.8415515422821045, 4.3498663902282715, 3.9486308097839355, 3.6351606845855713, 3.372588872909546, 3.676872491836548, 3.7235944271087646, 3.981865167617798, 3.88205885887146, 3.9920237064361572, 3.6902103424072266, 3.6868035793304443, 3.602670669555664, 3.70953631401062, 3.645293951034546, 3.4424407482147217, 3.976032018661499, 3.5717997550964355, 4.114306926727295, 3.9030380249023438, 3.8119165897369385, 3.8483328819274902, 3.826000928878784, 3.6638123989105225, 3.3893203735351562, 3.5230488777160645, 3.62292218208313, 4.035569190979004, 3.9870896339416504, 3.813222885131836, 3.8735499382019043, 3.8579864501953125, 3.6254940032958984, 4.390913009643555, 4.246901035308838, 3.7496042251586914, 3.8817484378814697, 3.851043224334717, 4.136836051940918, 3.760136365890503, 3.8224730491638184, 3.9033541679382324, 4.066512584686279, 3.5127766132354736, 3.8783862590789795, 3.665782928466797, 4.013182163238525, 3.5594117641448975, 4.0245490074157715, 4.088411331176758, 3.5228664875030518, 3.4069855213165283, 3.8922810554504395, 3.6497585773468018, 3.6675539016723633, 3.4579977989196777, 4.304988384246826, 3.9436593055725098, 3.7270190715789795, 3.4251558780670166, 3.831362247467041, 3.5412895679473877, 4.411564826965332, 3.5756919384002686, 3.699950933456421, 3.4124085903167725, 4.070664882659912, 3.729546070098877, 3.5703125, 3.7811455726623535, 3.7150046825408936, 3.5099525451660156, 3.7804715633392334, 3.397703170776367, 3.8060779571533203, 3.426379442214966, 3.5027904510498047, 3.580230236053467, 3.340102195739746, 3.2834503650665283, 3.5224709510803223, 3.2884578704833984, 3.397301197052002, 3.3322527408599854, 3.695796012878418, 3.7499732971191406, 4.158199787139893, 3.605776786804199, 3.2710278034210205, 3.4174389839172363, 3.85845947265625, 3.370600461959839, 3.555697202682495, 3.337838888168335, 3.625977039337158, 3.4872689247131348, 3.5474963188171387, 3.372190237045288, 3.5996170043945312, 3.609978675842285, 3.36356782913208, 3.694807291030884, 3.500138759613037, 3.5079076290130615, 3.473795175552368, 3.517756938934326, 4.008355140686035, 3.4512221813201904, 3.3054215908050537, 3.7835533618927, 3.593203067779541, 3.521552801132202, 3.5292036533355713, 3.244685173034668, 3.412764549255371, 3.4204366207122803, 3.4420080184936523, 3.764608383178711, 3.571436882019043, 3.185851812362671, 3.588489532470703, 3.783351421356201, 3.3977742195129395, 3.44533634185791, 3.3548319339752197, 3.2284553050994873, 3.5100150108337402, 3.2418267726898193, 3.2656655311584473, 5.971776962280273, 3.9172308444976807, 3.5059118270874023, 3.557406425476074, 3.4158551692962646, 3.4380996227264404, 3.5251893997192383, 3.2364094257354736, 3.388476610183716, 3.501134157180786, 3.225130081176758, 3.645876407623291, 3.219698429107666, 3.0969746112823486, 3.195354700088501, 3.3177855014801025, 3.3141610622406006, 3.6704206466674805, 3.3693957328796387, 3.643589496612549, 3.5226404666900635, 3.2383735179901123, 5.427257537841797, 4.104540824890137, 3.519634246826172, 3.4537315368652344, 3.499330997467041, 3.5284504890441895, 3.471313238143921, 3.326322317123413, 3.2700483798980713, 3.594417095184326, 3.4197535514831543, 3.468581199645996, 3.5729668140411377, 4.381866455078125, 3.4022436141967773, 3.3914988040924072, 3.17288875579834, 3.3383123874664307, 3.4534494876861572, 3.241239547729492, 3.4705917835235596, 3.406649351119995, 3.445899724960327, 3.769895315170288, 3.2107467651367188, 3.1253602504730225, 3.173084259033203, 3.159224510192871, 3.358025074005127, 3.112800121307373, 3.054508686065674, 3.564352035522461, 3.2290027141571045, 3.534379243850708, 3.2148358821868896, 3.1328952312469482, 3.32112455368042, 3.4958577156066895, 3.160451650619507, 3.2973644733428955, 3.419708728790283, 3.488813877105713, 3.1654367446899414, 3.2199652194976807, 3.4144294261932373, 3.318176746368408, 3.5558083057403564, 3.405170440673828, 3.246729850769043, 3.3675944805145264, 3.6464781761169434, 3.323033332824707, 3.3512933254241943, 3.433474063873291, 3.294663429260254, 3.895094633102417, 6.2189106941223145, 3.622040033340454, 3.4300434589385986, 3.303050994873047, 3.447166681289673, 3.2668159008026123, 3.050109624862671, 2.9997808933258057, 3.3893380165100098, 3.4709651470184326, 3.477107048034668, 3.340543508529663, 3.106048583984375, 3.2563765048980713, 3.170969247817993, 3.441096544265747, 4.820889472961426, 3.603343963623047, 3.33587384223938, 3.589651584625244, 3.5794405937194824, 3.488734483718872, 3.263835906982422, 3.339263677597046, 3.2583236694335938, 3.6474597454071045, 3.149134635925293, 3.3563640117645264, 3.444054365158081, 3.3632566928863525, 3.1511473655700684, 3.1097545623779297, 3.0737905502319336, 3.450620651245117, 3.1533679962158203, 3.1242308616638184, 3.082172155380249, 3.0281014442443848, 3.3238332271575928, 3.2498793601989746, 3.3577208518981934, 3.622321844100952, 3.418078660964966, 3.2638611793518066, 3.1617345809936523, 3.354688882827759, 3.1197423934936523, 3.056788921356201, 3.264040231704712, 3.0458524227142334, 3.0927438735961914, 3.0410890579223633, 3.2434120178222656, 2.894406318664551, 3.1886446475982666, 3.0641286373138428, 3.0765929222106934, 3.0749828815460205, 4.068428993225098, 3.3566694259643555, 3.229233503341675, 3.29596209526062, 3.7807679176330566, 3.2884416580200195, 3.1043710708618164, 3.0460877418518066, 3.1255037784576416, 3.488399028778076, 3.105095863342285, 3.2899725437164307, 3.1141858100891113, 3.429102659225464, 3.17716646194458, 3.6561450958251953, 3.2411744594573975, 3.273545265197754, 3.6043214797973633, 3.1309561729431152, 3.7252488136291504, 3.227839469909668, 3.177767276763916, 3.745361089706421, 3.24058198928833, 3.6769425868988037, 3.1888484954833984, 3.108142137527466, 3.3820550441741943, 3.0617635250091553, 3.185182809829712, 3.0773096084594727, 3.2649755477905273, 2.8968589305877686, 3.2498795986175537, 2.848538398742676, 2.9246580600738525, 2.9217400550842285, 3.145458936691284, 2.9977803230285645, 3.2131876945495605, 2.6322996616363525, 3.1548426151275635, 2.9391136169433594, 3.185030460357666, 3.0144762992858887, 2.9607303142547607, 2.9490602016448975, 3.3869707584381104, 3.2064321041107178, 3.108947515487671, 3.1469058990478516, 3.075719118118286, 3.013808012008667, 2.917149066925049, 3.6175944805145264, 3.3899285793304443, 3.1292717456817627, 3.117558002471924, 2.9430744647979736, 3.173753261566162, 3.0374202728271484, 2.918449878692627, 2.9989378452301025, 3.1295382976531982, 2.9171690940856934, 2.6602210998535156, 2.8999691009521484, 3.05635404586792, 3.2008321285247803, 3.060459852218628, 2.823861598968506, 2.6866087913513184, 2.9460482597351074, 2.895552635192871, 3.518899440765381, 3.6531858444213867, 3.357616662979126, 3.0327272415161133, 3.5949015617370605, 3.293057680130005, 3.0245423316955566, 3.0187671184539795, 3.1691555976867676, 3.2355546951293945, 3.005720853805542, 2.9212145805358887, 3.183075189590454, 3.311939001083374, 3.251124382019043, 3.273160934448242, 3.094744920730591, 3.073779582977295, 2.964313507080078, 3.0599634647369385, 3.0272371768951416, 3.267693519592285, 3.568040132522583, 2.938502788543701, 2.807034730911255, 3.1920976638793945, 2.8318934440612793, 2.941425323486328, 3.106409788131714, 3.157207727432251, 3.0078840255737305, 2.94643497467041, 2.9011969566345215, 2.9578545093536377, 3.1775641441345215, 3.0093464851379395, 3.5017969608306885, 2.9649171829223633, 3.0841684341430664, 2.7786521911621094, 2.766094207763672, 3.11759877204895, 3.2404496669769287, 2.824533462524414, 2.924642324447632, 2.9408950805664062, 2.8376200199127197, 3.1150355339050293, 3.1796069145202637, 2.78897762298584, 2.7419142723083496, 3.150214195251465, 3.849282741546631, 3.133455753326416, 2.9493439197540283, 3.012502908706665, 3.213487386703491, 3.1290273666381836, 3.043846607208252, 2.7772178649902344, 2.94315242767334, 2.7998602390289307, 2.978045701980591, 3.485482692718506, 3.3275833129882812, 2.8236067295074463, 3.3693008422851562, 2.8342766761779785, 2.6593434810638428, 2.7148170471191406, 2.7027392387390137, 2.9551923274993896, 2.846230983734131, 3.057267665863037, 2.867933988571167, 3.231952428817749, 2.838329792022705, 3.272184371948242, 3.2665762901306152, 2.8032772541046143, 2.8443357944488525, 3.1684134006500244, 3.3037402629852295, 3.015800952911377, 2.8783767223358154, 2.910222053527832, 2.778482437133789, 2.8973169326782227, 2.795243263244629, 3.201810836791992, 2.773313283920288, 3.0027859210968018, 2.739614725112915, 2.7921142578125, 2.9664292335510254, 2.844228744506836, 3.1922569274902344, 3.1137287616729736, 3.07204008102417, 3.1501033306121826, 2.920959234237671, 2.7029645442962646, 2.815354108810425, 2.855943202972412, 2.9635612964630127, 2.8620517253875732, 2.8845248222351074, 3.2609658241271973, 2.8161988258361816, 2.7166857719421387, 2.674199342727661, 3.00783634185791, 2.868385076522827, 2.8745346069335938, 2.6695241928100586, 2.8203325271606445, 2.957745313644409, 2.79775333404541, 2.945479154586792, 2.7512569427490234, 4.155723571777344, 2.996169090270996, 2.983302116394043, 2.9107933044433594, 3.235968828201294, 3.1668591499328613, 2.865438938140869, 2.950127124786377, 2.8700592517852783, 2.768751382827759, 2.939997673034668, 2.901862621307373, 2.7458012104034424, 2.605436325073242, 2.8460299968719482, 2.8947856426239014, 2.6725616455078125, 3.1115474700927734, 3.0068559646606445, 3.0411226749420166, 3.0504322052001953, 3.1286561489105225, 3.0742180347442627, 2.6853690147399902, 3.0297086238861084, 2.8697781562805176, 2.899327039718628, 2.6737356185913086, 2.8353078365325928, 2.683397054672241, 3.0033528804779053, 2.9723565578460693, 2.8973934650421143, 2.7467644214630127, 2.8037216663360596, 2.7493162155151367, 2.759182929992676, 2.7770931720733643, 3.272622585296631, 2.938514471054077, 2.69921612739563, 2.708760976791382, 2.6855409145355225, 2.736815929412842, 2.952209949493408, 2.783189535140991, 3.177910327911377, 2.7304792404174805, 2.8100805282592773, 2.8067104816436768, 2.9839024543762207, 2.817659378051758, 2.9801294803619385, 3.0874829292297363, 2.831261157989502, 3.177384853363037, 2.9344632625579834, 2.7970902919769287, 2.7448277473449707, 2.68435001373291, 2.754946708679199, 2.7087302207946777, 2.542732000350952, 2.7139763832092285, 2.7208504676818848, 2.6512539386749268, 2.8189117908477783, 2.7370452880859375, 2.7024648189544678, 2.7358639240264893, 2.7109100818634033, 2.8149218559265137, 2.89491868019104, 2.841566562652588, 2.715331554412842, 2.720935583114624, 2.753302574157715, 2.679436683654785, 3.037081241607666, 2.6818320751190186, 2.9339990615844727, 2.7620811462402344, 2.819195508956909, 3.231358528137207, 2.6951799392700195, 2.939716339111328, 2.9679081439971924, 2.879999876022339, 3.015805959701538, 2.6448981761932373, 2.7329366207122803, 2.8733458518981934, 2.6063027381896973, 2.8183624744415283, 2.685314655303955, 2.867258071899414, 2.7801833152770996, 2.9255809783935547, 2.6283862590789795, 2.8336338996887207, 2.909759998321533, 2.799755096435547, 2.583618402481079, 2.866621732711792, 2.6227755546569824, 3.0166449546813965, 2.7150321006774902, 2.7942278385162354, 2.650317430496216, 3.680941581726074, 3.0393264293670654, 2.8101208209991455, 2.884108781814575, 3.145062208175659, 2.6824309825897217, 2.7960543632507324, 2.673771858215332, 2.9711737632751465, 2.764371395111084, 2.787670373916626, 2.6197192668914795, 2.495359182357788, 2.6402125358581543, 2.5999045372009277, 2.613649606704712, 2.5976200103759766, 2.76594877243042, 2.7411718368530273, 2.8783578872680664, 2.830519199371338, 2.8054752349853516, 2.7174320220947266, 3.161501407623291, 2.67740535736084, 2.7135703563690186, 2.7044613361358643, 2.417733669281006, 2.6514785289764404, 2.6927855014801025, 2.496250867843628, 2.911761999130249, 2.690558433532715, 2.5810863971710205, 2.569774627685547, 2.6368327140808105, 2.740516185760498, 2.5611541271209717, 2.6027514934539795, 2.7572708129882812, 2.954343795776367, 2.561211585998535, 2.666600227355957, 2.801345109939575, 3.194518566131592, 2.6048343181610107, 2.7746243476867676, 2.6339938640594482, 2.729362726211548, 2.757955551147461, 2.736518144607544, 2.730966806411743, 2.3577795028686523, 2.7131118774414062, 2.5529651641845703, 2.5510189533233643, 2.617079496383667, 2.5373446941375732, 2.853118658065796, 2.535625696182251, 2.8016884326934814, 2.637819528579712, 2.650888204574585, 2.8048691749572754, 2.6258597373962402, 2.52156138420105, 2.6298813819885254, 2.922253131866455, 2.758950710296631, 2.7366416454315186, 2.713068723678589, 2.553452730178833, 2.3728249073028564, 2.5187435150146484, 2.5872018337249756, 2.8206939697265625, 2.7593564987182617, 2.6825945377349854, 2.5465781688690186, 2.569272756576538, 2.4913249015808105, 2.4493913650512695, 2.4096689224243164, 2.4317214488983154, 2.3265540599823, 2.633058547973633, 2.836827039718628, 2.682312250137329, 2.6090927124023438, 2.6526808738708496, 2.480842351913452, 2.832723617553711, 2.919766902923584, 2.978898048400879, 2.7081055641174316, 2.689863681793213, 2.707017183303833, 2.7467756271362305, 2.940490961074829, 2.726104497909546, 3.01446270942688, 2.8699028491973877, 2.706498622894287, 2.6816601753234863, 2.6981959342956543, 2.493978261947632, 2.7865781784057617, 2.7107295989990234, 2.6712732315063477, 2.743197202682495, 3.0177876949310303, 2.7741994857788086, 2.668424606323242, 2.781794548034668, 2.9691922664642334, 2.496464729309082, 2.6924078464508057, 2.7924129962921143, 2.700176239013672, 2.472581148147583, 2.584303617477417, 2.554229974746704, 3.170088768005371, 2.825404644012451, 2.7296600341796875, 2.422067880630493, 2.382862091064453, 2.5409035682678223, 2.564164638519287, 2.608351707458496, 2.548736095428467, 2.4847428798675537, 2.6059539318084717, 2.7251343727111816, 2.9441919326782227, 2.6158087253570557, 2.724665641784668, 2.85955810546875, 3.2551190853118896, 2.8157217502593994, 2.8137402534484863, 2.962689161300659, 2.6217377185821533, 2.7782185077667236, 2.668455123901367, 2.628605842590332, 2.895153522491455, 2.5301742553710938, 2.545436143875122, 2.587082862854004, 2.629751682281494, 2.568817377090454, 2.564763307571411, 2.4534380435943604, 2.5959107875823975, 2.6914234161376953, 2.5851287841796875, 2.73913311958313, 2.5686988830566406, 2.719749927520752, 2.7245395183563232, 2.434034585952759, 2.525486469268799, 2.611159324645996, 2.5704026222229004, 2.634906768798828, 2.586113214492798, 2.5233302116394043, 2.476067066192627, 2.632631540298462, 2.4969284534454346, 2.4932384490966797, 2.645181894302368, 2.9318089485168457, 2.5638389587402344, 2.8221287727355957, 2.747112512588501, 2.6033072471618652, 2.459866523742676, 2.6171929836273193, 2.486929416656494, 2.5260767936706543, 2.4983437061309814, 2.4168598651885986, 2.5251400470733643, 2.996291160583496, 2.5680043697357178, 2.341789722442627, 2.8247005939483643, 2.3515894412994385, 2.649948835372925, 2.473499298095703, 2.606154680252075, 2.699845790863037, 2.5325942039489746, 2.7243812084198, 2.8552730083465576, 2.5940444469451904, 2.4231882095336914, 2.6336119174957275, 2.3569555282592773, 2.6772713661193848, 2.489851951599121, 2.47554087638855, 2.486056327819824, 2.425217390060425, 2.5058560371398926, 2.5181057453155518, 2.4859890937805176, 2.327816963195801, 2.7841176986694336, 2.497565984725952, 2.721870183944702, 2.5408737659454346, 2.5667459964752197, 2.4816532135009766, 2.4749650955200195, 2.332855701446533, 2.346278190612793, 2.377392530441284, 2.593097448348999, 2.45758318901062, 2.486114501953125, 2.6573092937469482, 2.4679930210113525, 2.5511231422424316, 2.487245798110962, 2.704381227493286, 2.4170877933502197, 2.6915805339813232, 3.047870397567749, 2.8439366817474365, 2.572530746459961, 2.6382863521575928, 3.022261381149292, 2.775650978088379, 2.6415481567382812, 2.705873727798462, 2.6009459495544434, 2.3240087032318115, 2.5058486461639404, 2.4551873207092285, 2.674661159515381, 2.867126226425171, 2.9481403827667236, 2.573284149169922, 2.5026261806488037, 2.286184072494507, 2.6663906574249268, 2.2658531665802, 2.4487950801849365, 2.326862096786499, 2.4291412830352783, 2.4026007652282715, 2.5894460678100586, 2.246864080429077, 2.701005458831787, 2.7355713844299316, 2.447077751159668, 2.7253029346466064, 2.462228775024414, 2.5665974617004395, 2.603043794631958, 2.3877179622650146, 2.337177276611328, 2.3443005084991455, 2.6407253742218018, 2.983168363571167, 2.62126088142395, 2.571840524673462, 2.4889307022094727, 2.56473970413208, 2.5309717655181885, 2.563815116882324, 2.6789135932922363, 2.5700409412384033, 2.3659377098083496, 2.4631152153015137, 4.937734127044678, 2.878568410873413, 2.62269926071167, 2.5382025241851807, 2.364513874053955, 2.725701332092285, 3.0543456077575684, 2.832643747329712, 2.6664116382598877, 2.776947021484375, 2.6415553092956543, 2.500370740890503, 2.4985604286193848, 2.4358253479003906, 2.46562123298645, 2.7528157234191895, 2.7949697971343994, 2.3458943367004395, 2.4948201179504395, 2.5505285263061523, 2.370788335800171, 2.4942448139190674, 2.2767932415008545, 2.455828905105591, 2.548549175262451, 2.438228130340576, 2.48095703125, 2.3644814491271973, 2.3752152919769287, 2.459196090698242, 2.316337823867798, 2.4258432388305664, 2.3707611560821533, 2.6548328399658203, 2.263002395629883, 2.4024221897125244, 2.5559988021850586, 2.596064567565918, 2.5308444499969482, 2.4244799613952637, 2.5964584350585938, 2.3274874687194824, 2.632936716079712, 2.6125659942626953, 2.396336078643799, 2.3255958557128906, 2.46108341217041, 2.5606637001037598, 2.9164865016937256, 2.5145018100738525, 2.66509747505188, 3.008587121963501, 2.417067289352417, 2.6251578330993652, 2.6682686805725098, 2.43156361579895, 2.619847297668457, 2.63905930519104, 2.4256973266601562, 2.7923784255981445, 2.6009716987609863, 2.3519022464752197, 2.621631622314453, 2.440291166305542, 2.3506357669830322, 2.2984368801116943, 2.3409221172332764, 2.2908151149749756, 2.441122055053711, 2.388200283050537, 2.5908141136169434, 2.4026739597320557, 2.452061891555786, 2.4605214595794678, 2.2539331912994385, 2.437952756881714, 2.482611894607544, 2.3654744625091553, 2.6411216259002686, 2.4378161430358887, 2.3497097492218018, 2.850376844406128, 2.4952034950256348, 2.5792477130889893, 2.363284111022949, 2.383559465408325, 2.427124261856079, 2.4916980266571045, 2.346665620803833, 2.3262393474578857, 2.895531177520752, 2.4180335998535156, 2.494940757751465, 2.4527065753936768, 2.545863389968872, 2.282409191131592, 2.3521852493286133, 2.299455165863037, 2.3888161182403564, 2.385739803314209, 2.7440226078033447, 2.2944750785827637, 2.2884061336517334, 2.3773231506347656, 2.2354462146759033, 2.2801547050476074, 2.3110835552215576, 2.4550976753234863, 2.3616998195648193, 2.792207956314087, 2.659524440765381, 2.2881717681884766, 2.399588108062744, 2.3689563274383545, 2.380117177963257, 2.3905086517333984, 2.441879987716675, 2.1534647941589355, 2.570222854614258, 2.3452255725860596, 2.318298101425171, 2.474766731262207, 2.3967318534851074, 2.463606357574463, 2.306091547012329, 2.2525033950805664, 2.984161853790283, 2.611433267593384, 2.3553645610809326, 2.389113426208496, 2.3308498859405518, 2.2545688152313232, 2.3029463291168213, 2.243901252746582, 2.218883752822876, 2.153355598449707, 2.348808526992798, 2.4121034145355225, 2.3633296489715576, 2.529280185699463, 2.3871779441833496, 2.5847530364990234, 2.190786361694336, 2.381112813949585, 2.5864639282226562, 2.3008921146392822, 2.4250526428222656, 2.6696534156799316, 2.8459033966064453, 2.5462048053741455, 2.9083945751190186, 2.4793472290039062, 2.375095844268799, 2.5171453952789307, 2.357030153274536, 2.3283400535583496, 2.4293606281280518, 2.4140052795410156, 2.8407704830169678, 2.5195884704589844, 2.2590491771698, 2.1616885662078857, 2.3563456535339355, 2.3929054737091064, 2.4179751873016357, 2.1796607971191406, 2.6623926162719727, 2.4725351333618164, 2.223361015319824, 2.219416856765747, 2.5608937740325928, 2.303704261779785, 2.303062677383423, 2.2501492500305176, 2.179325580596924, 2.1931252479553223, 2.1915202140808105, 2.4971258640289307, 2.2849128246307373, 2.3227486610412598, 2.500622034072876, 2.318686008453369, 2.2602527141571045, 2.226513624191284, 2.280043601989746, 2.368788719177246, 2.1591949462890625, 2.5071651935577393, 2.6334338188171387, 2.3349926471710205, 2.479761838912964, 2.2490997314453125, 2.2352800369262695, 2.2456438541412354, 2.596111297607422, 2.208186388015747, 2.251155138015747, 2.1815929412841797, 2.2072556018829346, 2.285259246826172, 2.2093825340270996, 2.9329380989074707, 2.3839237689971924, 2.3234710693359375, 2.5291285514831543, 2.2704355716705322, 2.303642988204956, 2.5455126762390137, 2.382190227508545, 2.3616249561309814, 2.2555887699127197, 2.303010940551758, 2.339038372039795, 2.3001859188079834, 2.369765281677246, 2.162769079208374, 2.351738452911377, 2.2149927616119385, 2.20420503616333, 2.319300889968872, 2.156914234161377, 2.3743300437927246, 2.24416446685791, 2.3524794578552246, 2.386741876602173, 2.267890691757202, 2.3110227584838867, 2.1829512119293213, 2.2713372707366943, 2.1859190464019775, 2.5101993083953857, 2.3658313751220703, 2.563610076904297, 2.2220234870910645, 2.36971116065979, 2.343735456466675, 2.397740602493286, 2.2215735912323, 2.3999297618865967, 2.4533424377441406, 2.4115824699401855, 2.114724636077881, 2.188185930252075, 2.3229503631591797, 2.8686680793762207, 2.228407621383667, 2.3800454139709473, 2.300147294998169, 2.3623812198638916, 2.2673635482788086, 2.306901693344116, 2.3198843002319336, 2.169171094894409, 2.2389841079711914, 1.9846913814544678, 2.175757884979248, 2.342146635055542, 2.3152410984039307, 2.210731029510498, 2.3054285049438477, 2.11942195892334, 2.428476095199585, 2.32578706741333, 3.245603561401367, 2.2431018352508545, 2.320631504058838, 2.2512786388397217, 2.1090312004089355, 2.124493360519409, 2.1368789672851562, 2.0605063438415527, 2.0831315517425537, 2.4798717498779297, 2.3103740215301514, 2.2274744510650635, 2.1353604793548584, 2.170847177505493, 2.1468076705932617, 2.24904727935791, 2.162048578262329, 2.4727048873901367, 2.490462303161621, 2.209650993347168, 2.259816884994507, 2.3654673099517822, 2.4026379585266113, 2.2700088024139404, 2.256157875061035, 2.2543892860412598, 2.1266462802886963, 2.0714759826660156, 2.2343719005584717, 2.2515578269958496, 2.196056842803955, 2.1512954235076904, 2.25608229637146, 2.2185182571411133, 2.3747141361236572, 2.1571238040924072, 2.276271343231201, 2.1437418460845947, 2.231851577758789, 2.3382463455200195, 2.2596569061279297, 3.425567388534546, 2.500126361846924, 2.3300366401672363, 2.247887134552002, 2.2412209510803223, 2.2352144718170166, 2.302398204803467, 2.3841705322265625, 2.156200885772705, 2.3653945922851562, 2.3748064041137695, 2.04951548576355, 2.302914619445801, 2.2680420875549316, 2.7158422470092773, 2.3028862476348877, 2.231778383255005, 2.255977153778076, 2.3024985790252686, 2.265953779220581, 2.4202730655670166, 2.2984566688537598, 2.352494716644287, 2.2599003314971924, 2.300603151321411, 2.297250986099243, 2.1406021118164062, 2.328136920928955, 2.3360114097595215, 2.257234811782837, 2.1132614612579346, 2.174476146697998, 2.083604097366333, 2.241293430328369, 2.265909194946289, 2.2723097801208496, 2.2697503566741943, 2.1255810260772705, 2.323573350906372, 2.2073981761932373, 2.1121482849121094, 2.592238426208496, 2.4148430824279785, 2.425926446914673, 2.428597927093506, 2.730161428451538, 2.453500986099243, 2.2009668350219727, 2.4345781803131104, 2.2174720764160156, 2.2498934268951416, 2.4110729694366455, 2.2855870723724365, 2.1083967685699463, 2.0894386768341064, 2.1549339294433594, 2.8731658458709717, 2.294727087020874, 2.211890459060669, 2.3525454998016357, 2.1998379230499268, 2.27349591255188, 2.361053705215454, 2.6364123821258545, 2.4528236389160156, 2.6825690269470215, 2.433614730834961, 2.2852859497070312, 2.2494804859161377, 2.196323871612549, 2.2964558601379395, 2.2070631980895996, 2.27522873878479, 2.371807098388672, 2.1291396617889404, 2.3600800037384033, 2.434093713760376, 2.297076463699341, 2.164133071899414, 2.533182382583618, 2.3040764331817627, 2.3101909160614014, 2.5124945640563965, 2.4325497150421143, 2.3019590377807617, 2.178821086883545, 2.5104591846466064, 2.184429883956909, 2.1166415214538574, 2.2519853115081787, 2.645012378692627, 2.8215417861938477, 2.2951228618621826, 2.2102670669555664, 2.128056764602661, 2.0136404037475586, 2.0056591033935547, 2.1405303478240967, 2.4217073917388916, 2.327941417694092, 2.184790849685669, 2.255646228790283, 2.0826544761657715, 2.257977247238159, 2.3289003372192383, 2.545724868774414, 2.7380714416503906, 2.593811511993408, 2.4305200576782227, 2.137608528137207, 2.133793354034424, 2.0977587699890137, 2.161496162414551, 2.2820937633514404, 2.3769147396087646, 2.7298030853271484, 2.26076078414917, 2.44673752784729, 2.1615428924560547, 2.227611541748047, 2.0667684078216553, 2.1089978218078613, 2.188947916030884, 2.211594581604004, 2.1706268787384033, 2.339951515197754, 2.2959518432617188, 2.1975009441375732, 2.1414248943328857, 2.4559311866760254, 2.3482210636138916, 2.1081197261810303, 2.393187999725342, 2.3959221839904785, 2.4834463596343994, 2.2885544300079346, 2.0773134231567383, 2.262403964996338, 2.084512948989868, 2.3189549446105957, 2.217181444168091, 2.4266858100891113, 2.115013360977173, 2.0439844131469727, 2.603335380554199, 2.3673088550567627, 2.204026937484741, 2.1750752925872803, 2.0156219005584717, 2.3400986194610596, 2.1405317783355713, 2.104841947555542, 2.105088472366333, 2.179056167602539, 2.384329319000244, 2.1491518020629883, 2.1147921085357666, 2.135216474533081, 2.2204723358154297, 2.2615513801574707, 2.289379119873047, 2.0473737716674805, 2.0614969730377197, 2.055467367172241, 2.0323307514190674, 2.111933708190918, 2.090094804763794, 2.0409488677978516, 2.353336811065674, 2.064770460128784, 2.1387624740600586, 2.075289011001587, 1.9495258331298828, 1.9682077169418335, 2.0048301219940186, 2.061469316482544, 2.4282312393188477, 2.1336753368377686, 2.1861095428466797, 2.4721126556396484, 2.1748647689819336, 2.028489828109741, 2.012514352798462, 2.098395824432373, 2.224762439727783, 2.406137704849243, 2.276496171951294, 2.1648240089416504, 2.1377763748168945, 2.1536426544189453, 2.020045757293701, 2.1546030044555664, 2.095654249191284, 2.3056859970092773, 2.1966731548309326, 2.0769705772399902, 2.0651068687438965, 2.2334227561950684, 2.2870876789093018, 2.1034584045410156, 2.2076776027679443, 2.049222230911255, 2.0504870414733887, 2.044308662414551, 2.2530837059020996, 2.1208930015563965, 2.2127668857574463, 1.9044264554977417, 1.9905668497085571, 1.9664031267166138, 1.986321210861206, 2.1541149616241455, 2.2835116386413574, 2.2727694511413574, 2.599891185760498, 2.5746963024139404, 2.172400951385498, 2.2877042293548584, 2.1448733806610107, 2.0343503952026367, 2.236361503601074, 1.976754903793335, 2.0097010135650635, 2.1637303829193115, 2.3415496349334717, 2.1187407970428467, 2.500221014022827, 2.097191572189331, 2.0594725608825684, 2.0006091594696045, 2.249375343322754, 2.2938101291656494, 2.1026039123535156, 2.1593761444091797, 2.1278247833251953, 1.9952303171157837, 2.042257308959961, 2.1099226474761963, 2.117245674133301, 2.0645861625671387, 2.00016450881958, 2.0118370056152344, 2.0653634071350098, 2.145982503890991, 2.0049140453338623, 2.204710006713867, 2.1362602710723877, 2.184803009033203, 2.0841684341430664, 2.2091283798217773, 2.025106430053711, 2.061997175216675, 2.132354974746704, 2.1279890537261963, 2.0036232471466064, 2.0529773235321045, 1.987113356590271, 1.991816520690918, 2.1547024250030518, 2.1160762310028076, 2.241295576095581, 2.2440052032470703, 1.9346847534179688, 2.0608417987823486, 2.204238176345825, 2.125044345855713, 2.2379817962646484, 2.0529122352600098, 2.234717607498169, 2.2921767234802246, 2.304656982421875, 1.9642139673233032, 2.159522771835327, 2.055546522140503, 2.1067724227905273, 1.9170758724212646, 2.058286190032959, 1.9865821599960327, 2.0835213661193848, 2.298320770263672, 2.304955244064331, 2.0128633975982666, 2.0023767948150635, 1.9772511720657349, 2.262299060821533, 2.098097324371338, 2.195786714553833, 2.0012476444244385, 2.082991123199463, 2.0858004093170166, 2.1816368103027344, 2.055403470993042, 2.952619791030884, 2.3133928775787354, 2.259693145751953, 2.1606943607330322, 2.0960617065429688, 1.9644324779510498, 2.1320676803588867, 1.8877824544906616, 1.8661959171295166, 2.0962820053100586, 2.0602478981018066, 3.420649766921997, 2.1373300552368164, 1.9665127992630005, 2.211149215698242, 2.2192769050598145, 1.9971288442611694, 1.9295190572738647, 1.9779173135757446, 2.065875768661499, 2.2604005336761475, 2.0246284008026123, 2.166349411010742, 1.883398175239563, 2.219546318054199, 2.3371026515960693, 2.0704855918884277, 1.8736714124679565, 1.9469720125198364, 2.8099162578582764, 2.1713571548461914, 1.9759690761566162, 2.1748483180999756, 2.009226083755493, 2.0570313930511475, 1.982439637184143, 2.010593891143799, 1.9993760585784912, 2.0686004161834717, 1.979975938796997, 2.1900298595428467, 2.4155349731445312, 2.216176986694336, 2.0419890880584717, 2.077310562133789, 2.1696557998657227, 2.2248036861419678, 2.0019071102142334, 2.09603214263916, 2.0605130195617676, 1.9095635414123535, 2.087189197540283, 1.994525671005249, 1.9675509929656982, 2.0962700843811035, 2.006727933883667, 1.864402174949646, 1.9377331733703613, 2.1597213745117188, 2.166630744934082, 2.0711491107940674, 2.206653118133545, 2.249394178390503, 1.9399231672286987, 2.1747353076934814, 1.9720135927200317, 2.2803499698638916, 1.906183123588562, 1.9459595680236816, 2.009793758392334, 1.8810811042785645, 1.9612374305725098, 2.138237237930298, 1.9415620565414429, 2.010924816131592, 2.135009288787842, 2.185973644256592, 2.0572903156280518, 2.020801305770874, 1.9359798431396484, 1.995113730430603, 1.9338948726654053, 2.1106488704681396, 1.9770538806915283, 2.0142083168029785, 1.8828188180923462, 2.1330487728118896, 2.145348310470581, 2.1594655513763428, 2.131096363067627, 2.095452308654785, 1.9929813146591187, 1.9730300903320312, 2.0238215923309326, 2.1373414993286133, 1.9617137908935547, 1.8114365339279175, 2.083130359649658, 1.8896656036376953, 1.8683093786239624, 2.1721577644348145, 2.286797523498535, 2.06654691696167, 2.1819419860839844, 2.2450573444366455, 2.016125440597534, 1.9068691730499268, 2.0919718742370605, 2.015855312347412, 2.043914318084717, 2.035609483718872, 2.2247893810272217, 2.057833433151245, 2.0677506923675537, 1.9901195764541626, 2.0985829830169678, 2.003119707107544, 2.007194995880127, 1.9403774738311768, 2.090632438659668, 2.206298351287842, 2.2000231742858887, 1.986480951309204, 1.8808503150939941, 1.997563123703003, 1.8326563835144043, 2.033088207244873, 2.0730206966400146, 2.240513324737549, 2.237482786178589, 2.0268304347991943, 2.004739761352539, 2.0916852951049805, 1.9744185209274292, 2.185647964477539, 1.9057246446609497, 1.9314297437667847, 2.0688681602478027, 1.9389774799346924, 1.9554829597473145, 1.8928968906402588, 1.8033480644226074, 1.7677141427993774, 2.027782917022705, 1.916152834892273, 1.908385992050171, 1.9958114624023438, 1.747395396232605, 1.8413176536560059, 1.9302626848220825, 1.965332269668579, 1.9135445356369019, 1.929328203201294, 1.9954243898391724, 1.8328068256378174, 1.9030091762542725, 1.955823540687561, 1.9403951168060303, 1.9615155458450317, 1.9963490962982178, 1.8876144886016846, 2.023038387298584, 2.1108996868133545, 2.0229358673095703, 1.9963668584823608, 1.8724935054779053, 1.8972864151000977, 1.9806503057479858, 1.8331677913665771, 2.115358591079712, 1.9827229976654053, 2.0881736278533936, 2.1413981914520264, 1.8317731618881226, 1.8697872161865234, 1.8585509061813354, 1.9860682487487793, 1.8775027990341187, 1.9505094289779663, 2.0350356101989746, 1.8177368640899658, 1.8164982795715332, 1.9658406972885132, 2.098506450653076, 2.1344423294067383, 2.0627918243408203, 2.0654029846191406, 2.140965223312378, 2.3036675453186035, 2.1325602531433105, 1.9714068174362183, 2.203463554382324, 1.9381473064422607, 2.195828914642334, 2.040116786956787, 2.027297019958496, 2.2609808444976807, 2.126971960067749, 1.8680881261825562, 2.5784153938293457, 2.01476788520813, 2.089585781097412, 2.098891496658325, 2.573744773864746, 2.106137990951538, 1.984783411026001, 1.9607322216033936, 2.548982858657837, 2.121548891067505, 1.819338083267212, 1.8653478622436523, 2.3946588039398193, 2.173807382583618, 2.125401496887207, 1.8915928602218628, 1.8724217414855957, 2.3069844245910645, 1.9391497373580933, 2.453536033630371, 2.417579174041748, 1.8795322179794312, 1.8490835428237915, 1.9308087825775146, 1.824838399887085, 1.9923577308654785, 1.9606261253356934, 2.0437915325164795, 2.143340826034546, 1.966353178024292, 2.076754570007324, 2.0986597537994385, 2.068981170654297, 2.060213804244995, 1.875761866569519, 1.9307661056518555, 1.9653236865997314, 1.9682731628417969, 2.5865185260772705, 2.250993251800537, 2.1172688007354736, 2.076430320739746, 2.0453436374664307, 1.9513518810272217, 2.0493946075439453, 2.011564016342163, 2.1873972415924072, 2.1875898838043213, 2.0572397708892822, 1.993897795677185, 1.8764899969100952, 2.0368568897247314, 1.9663443565368652, 2.2262980937957764, 2.0608437061309814, 2.0364460945129395, 2.1434192657470703, 1.932701587677002, 1.9734930992126465, 2.0989928245544434, 1.9539599418640137, 2.0612874031066895, 1.8494919538497925, 2.0094404220581055, 1.8700498342514038, 2.172084331512451, 1.9371577501296997, 2.0519373416900635, 2.2162489891052246, 1.9364142417907715, 2.0367116928100586, 2.0106804370880127, 2.0515379905700684, 1.916342854499817, 1.9396597146987915, 1.9541208744049072, 2.0998382568359375, 2.0506300926208496, 1.9675958156585693, 1.859114408493042, 2.2460737228393555, 1.9993607997894287, 1.8871026039123535, 2.043522834777832, 2.082758903503418, 1.9359573125839233, 1.9512783288955688, 1.836392879486084, 1.96785569190979, 2.0655510425567627, 1.9171054363250732, 1.8712772130966187, 2.1437580585479736, 1.850545048713684, 1.9340561628341675, 1.7946650981903076, 1.7820124626159668, 1.8697924613952637, 1.9571646451950073, 1.9826128482818604, 1.9679232835769653, 1.9441043138504028, 2.0848910808563232, 1.824668049812317, 2.151331663131714, 2.0153932571411133, 1.7067068815231323, 1.7557452917099, 1.9277830123901367, 1.871321439743042, 1.795466661453247, 1.8670306205749512, 1.780937910079956, 1.8754820823669434, 1.897009015083313, 2.061039924621582, 1.885576605796814, 1.9347513914108276, 1.891575574874878, 1.8968136310577393, 1.761639952659607, 1.8275824785232544, 1.8348065614700317, 1.8935641050338745, 1.9899640083312988, 2.1753463745117188, 2.07710599899292, 1.9107626676559448, 1.8525415658950806, 1.9158377647399902, 1.9822134971618652, 1.8711626529693604, 2.215446949005127, 2.2658238410949707, 2.174671173095703, 1.991673231124878, 2.021047353744507, 2.1422674655914307, 1.91868257522583, 2.1261849403381348, 1.8934144973754883, 1.7976523637771606, 2.0856003761291504, 1.898642659187317, 1.9299877882003784, 2.0625336170196533, 1.9717496633529663, 1.8208767175674438, 1.8353441953659058, 1.9487178325653076, 1.8050363063812256, 1.90449059009552, 1.9054433107376099, 1.8144488334655762, 1.9359601736068726, 1.8517004251480103, 1.761489748954773, 1.782390832901001, 2.1320488452911377, 1.9033443927764893, 2.115046739578247, 1.8522340059280396, 1.9718374013900757, 1.7385929822921753, 1.8783944845199585, 1.78745436668396, 1.8706496953964233, 1.9772065877914429, 1.848872423171997, 1.8013988733291626, 2.0504186153411865, 1.869938611984253, 1.8299980163574219, 1.784613013267517, 1.8218977451324463, 1.9357035160064697, 1.7499617338180542, 1.8531664609909058, 2.052215337753296, 1.8648761510849, 1.8357670307159424, 1.68360435962677, 1.8323383331298828, 1.7682656049728394, 1.7209275960922241, 1.707916021347046, 1.7768869400024414, 1.7309154272079468, 1.8325996398925781, 2.013420581817627, 1.929558277130127, 1.931533694267273, 1.9331433773040771, 1.992417573928833, 1.7466002702713013, 1.8562922477722168, 1.9530478715896606, 2.013123035430908, 1.9272422790527344, 2.0075786113739014, 2.0085270404815674, 1.903475046157837, 2.1278834342956543, 1.8890047073364258, 1.946938157081604, 1.8175398111343384, 2.0255212783813477, 1.9278579950332642, 2.0666046142578125, 1.7532292604446411, 1.9997187852859497, 2.0366034507751465, 1.9078665971755981, 1.977183222770691, 1.9091145992279053, 1.8820289373397827, 1.7855808734893799, 1.9983352422714233, 1.926318883895874, 1.8967007398605347, 1.88945472240448, 2.024808645248413, 1.7220001220703125, 1.9260443449020386, 1.9336981773376465, 1.9041969776153564, 1.8948490619659424, 1.7743343114852905, 1.8281923532485962, 1.804916262626648, 1.9538745880126953, 1.7730633020401, 1.8535658121109009, 1.887521505355835, 1.8812004327774048, 1.7917910814285278, 1.8575283288955688, 1.8548470735549927, 2.0122272968292236, 1.8359848260879517, 1.8612430095672607, 1.8390142917633057, 1.8313980102539062, 1.8528680801391602, 1.9487602710723877, 1.9290213584899902, 1.8787930011749268, 1.8822269439697266, 1.9105205535888672, 1.8265701532363892, 1.7847671508789062, 2.0174689292907715, 1.9579192399978638, 1.8581846952438354, 1.8927034139633179, 1.9042171239852905, 2.1938438415527344, 2.1416001319885254, 2.0144076347351074, 1.8954277038574219, 1.8676954507827759, 1.831682801246643, 1.7879822254180908, 1.727911114692688, 1.8002513647079468, 1.773959994316101, 2.100484848022461, 2.2114999294281006, 1.8158091306686401, 1.787806510925293, 1.9522881507873535, 1.8593703508377075, 1.8142495155334473, 2.0514729022979736, 1.9923076629638672, 1.7522995471954346, 2.0592041015625, 1.712965965270996, 1.7312880754470825, 1.7495440244674683, 1.9932193756103516, 2.134536027908325, 1.8503154516220093, 1.8460549116134644, 1.793516993522644, 1.8872764110565186, 1.7485002279281616, 1.80818772315979, 2.1282365322113037, 1.878369927406311, 1.8065106868743896, 2.049760103225708, 1.9584680795669556, 1.8429286479949951, 1.805917739868164, 1.7131638526916504, 2.036395788192749, 1.9114203453063965, 1.8357350826263428, 1.9156097173690796, 1.7332251071929932, 1.8482577800750732, 1.8498544692993164, 1.8797616958618164, 1.8300855159759521, 2.000455856323242, 1.935333490371704, 1.8427740335464478, 1.7654889822006226, 2.0014989376068115, 2.0101654529571533, 2.042879343032837, 1.689061164855957, 1.7438395023345947, 1.7597453594207764, 1.9460445642471313, 1.804323673248291, 1.867917776107788, 1.8639925718307495, 1.8906774520874023, 1.982130527496338, 1.8833893537521362, 2.1892142295837402, 1.8874069452285767, 1.8349976539611816, 1.8676872253417969, 1.632388949394226, 1.9763727188110352, 2.073457956314087, 1.8778067827224731, 1.9333614110946655, 2.0894320011138916, 2.056121587753296, 1.935280203819275, 1.9982993602752686, 1.9576271772384644, 1.7887345552444458, 1.7755091190338135, 1.7704657316207886, 1.7931047677993774, 1.7968957424163818, 1.7286715507507324, 1.7536519765853882, 1.9248961210250854, 1.813925862312317, 1.9258885383605957, 1.9857323169708252, 1.7637969255447388, 2.068197727203369, 2.111260175704956, 1.787635087966919, 1.7804322242736816, 1.858919620513916, 1.7942930459976196, 1.8656865358352661, 1.7512918710708618, 2.0999958515167236, 1.8877190351486206, 2.007619619369507, 1.8300913572311401, 1.8305660486221313, 1.904021978378296, 1.8669401407241821, 2.0387866497039795, 2.1828453540802, 1.8239879608154297, 1.9604134559631348, 1.8658668994903564, 1.6820577383041382, 1.9432907104492188, 1.76495361328125, 1.919675350189209, 1.9685157537460327, 1.7970356941223145, 1.7558190822601318, 1.8015209436416626, 1.8250751495361328, 1.7951972484588623, 1.9635018110275269, 2.030996322631836, 1.9299665689468384, 1.7720364332199097, 1.85573148727417, 1.9142358303070068, 1.9762321710586548, 1.7520432472229004, 1.8255053758621216, 2.0880231857299805, 1.9121075868606567, 1.8913273811340332, 1.903831124305725, 1.8907251358032227, 1.8013174533843994, 1.8912075757980347, 1.922354817390442, 1.8135616779327393, 1.7724130153656006, 1.8307456970214844, 1.8496135473251343, 1.7577378749847412, 1.8081878423690796, 1.8604425191879272, 1.8105003833770752, 1.7833551168441772, 1.7031569480895996, 1.8602710962295532, 1.8681262731552124, 1.7818289995193481, 1.7722798585891724, 1.7314691543579102, 1.8271225690841675, 1.7864620685577393, 1.854667067527771, 2.186300277709961, 1.7279621362686157, 1.7240569591522217, 1.8058993816375732, 1.8852940797805786, 1.7772130966186523, 1.7820583581924438, 1.7797596454620361, 1.842851161956787, 1.824989676475525, 1.8603618144989014, 1.827658772468567, 1.7045776844024658, 1.8733543157577515, 1.9288201332092285, 2.274888515472412, 2.056713342666626, 1.887542963027954, 1.9325248003005981, 1.8837698698043823, 1.8333462476730347, 1.86334228515625, 1.9677202701568604, 2.068950653076172, 1.8730396032333374, 1.9550315141677856, 1.8434724807739258, 1.7980819940567017, 1.8419338464736938, 2.083652973175049, 1.9146901369094849, 1.7401857376098633, 1.8391704559326172, 1.8048980236053467, 1.69794762134552, 1.7380626201629639, 2.0527727603912354, 1.7503474950790405, 1.7092684507369995, 1.6971378326416016, 1.7219080924987793, 1.7047759294509888, 1.9432634115219116, 1.8055604696273804, 1.736919641494751, 2.1689045429229736, 1.9974738359451294, 1.767286777496338, 1.8207597732543945, 1.8175909519195557, 1.883825421333313, 1.7717925310134888, 1.637994408607483, 1.7488949298858643, 1.6582727432250977, 1.6532940864562988, 1.763684868812561, 1.8114005327224731, 1.769256591796875, 2.0653457641601562, 2.0030293464660645, 1.6466094255447388, 1.66840660572052, 1.6977403163909912, 1.8212772607803345, 1.7757905721664429, 1.6634992361068726, 1.7853593826293945, 1.7721583843231201, 1.6914234161376953, 1.782780647277832, 1.8327170610427856, 1.7841113805770874, 1.7484921216964722, 1.8728914260864258, 1.8048794269561768, 1.838254451751709, 1.9939161539077759, 2.114651918411255, 1.9634654521942139, 1.785992980003357, 1.754846453666687, 1.7497657537460327, 1.7576364278793335, 1.6246336698532104, 1.6479785442352295, 1.7012362480163574, 1.8060520887374878, 1.7121778726577759, 1.7702313661575317, 1.7972543239593506, 1.7361887693405151, 1.8875502347946167, 1.7171695232391357, 1.8799115419387817, 1.8576860427856445, 1.8108562231063843, 1.8595094680786133, 1.7751867771148682, 1.6715303659439087, 1.9049593210220337, 1.8225070238113403, 1.7354085445404053, 1.637369990348816, 1.6667368412017822, 1.833674430847168, 1.8168797492980957, 1.7258033752441406, 1.8087432384490967, 1.8284820318222046, 1.858788251876831, 1.8044087886810303, 2.0437123775482178, 1.8205363750457764, 2.0003280639648438, 2.0690391063690186, 1.8335524797439575, 1.752943992614746, 1.9102228879928589, 1.8914908170700073, 1.875245451927185, 1.8812549114227295, 2.0967257022857666, 1.988004446029663, 1.9179846048355103, 1.8266024589538574, 1.9111149311065674, 1.7877836227416992, 1.8162074089050293, 1.8008215427398682, 1.6422845125198364, 1.8174480199813843, 2.017526865005493, 2.2055609226226807, 1.830762505531311, 1.778546690940857, 1.6848914623260498, 1.6943293809890747, 1.599330186843872, 1.619269609451294, 1.6423448324203491, 1.6032655239105225, 1.7916786670684814, 1.6398046016693115, 2.0737853050231934, 1.700116515159607, 1.7036000490188599, 1.6370700597763062, 1.6141797304153442, 1.7013781070709229, 2.2890396118164062, 1.7435475587844849, 1.7558846473693848, 2.0000107288360596, 1.7354357242584229, 1.72412109375, 1.7862401008605957, 1.8182809352874756, 1.9022877216339111, 1.7160913944244385, 1.7092863321304321, 1.709071159362793, 1.6806776523590088, 1.8215306997299194, 1.7446372509002686, 1.73312246799469, 1.8756855726242065, 1.763788104057312, 1.8763489723205566, 1.919238567352295, 1.7303457260131836, 1.7463260889053345, 1.8467955589294434, 1.692192554473877, 2.3211944103240967, 1.9229402542114258, 1.7986221313476562, 1.7057288885116577, 1.7628847360610962, 1.6741911172866821, 1.6786330938339233, 1.6658291816711426, 1.7333762645721436, 1.7458513975143433, 1.5954681634902954, 1.7103811502456665, 1.8097223043441772, 1.7882187366485596, 1.7986372709274292, 1.7066940069198608, 1.6642862558364868, 1.6786924600601196, 1.647271752357483, 1.7053141593933105, 1.716859221458435, 1.754030704498291, 1.719321608543396, 1.9163329601287842, 1.844517469406128, 1.9642689228057861, 1.8869471549987793, 1.7881994247436523, 1.8074628114700317, 1.7742176055908203, 1.7418416738510132, 1.6722675561904907, 1.745983362197876, 1.7925680875778198, 1.6878745555877686, 1.781557559967041, 1.6882219314575195, 1.59145987033844, 1.7152167558670044, 1.722625494003296, 1.9078396558761597, 1.8904674053192139, 1.6607128381729126, 1.8808552026748657, 1.8040695190429688, 2.047778844833374, 1.6983035802841187, 1.8019105195999146, 1.8870161771774292, 1.7860634326934814, 1.777989387512207, 1.6354660987854004, 1.6895406246185303, 1.5774644613265991, 1.6015592813491821, 1.6944361925125122, 1.701791763305664, 1.7938857078552246, 1.8805595636367798, 1.7159773111343384, 1.8344343900680542, 1.6348885297775269, 1.7968045473098755, 1.7146605253219604, 1.7886443138122559, 1.6797001361846924, 1.8530126810073853, 1.6267707347869873, 1.5648692846298218, 1.9324185848236084, 1.7953194379806519, 1.6529910564422607, 1.856062412261963, 1.8266962766647339, 1.815819263458252, 1.7440385818481445, 1.7986249923706055, 1.78302001953125, 1.8300511837005615, 1.7439672946929932, 2.3229730129241943, 1.8492567539215088, 1.821042776107788, 1.6815866231918335, 1.9362274408340454, 1.736508846282959, 1.8069827556610107, 1.7932205200195312, 1.713584542274475, 1.7107515335083008, 1.6924296617507935, 1.6841398477554321, 1.7556426525115967, 1.5842845439910889, 1.6566468477249146, 1.6362630128860474, 1.7697441577911377, 1.7709252834320068, 1.9080668687820435, 1.7442975044250488, 1.6627609729766846, 1.7022980451583862, 1.6113508939743042], 'val_loss': [10.274114608764648, 11.66525650024414, 9.802078247070312, 9.844717025756836, 9.687317848205566, 9.498326301574707, 10.533781051635742, 9.219438552856445, 10.181138038635254, 9.388222694396973, 9.940618515014648, 10.261778831481934, 10.600903511047363, 9.441484451293945, 9.049566268920898, 9.365220069885254, 9.088897705078125, 8.970088005065918, 9.59530258178711, 9.983426094055176, 10.422045707702637, 9.925342559814453, 9.196455955505371, 10.026695251464844, 10.35920238494873, 9.782115936279297, 10.650364875793457, 9.16115665435791, 9.306376457214355, 9.351700782775879, 10.180753707885742, 10.603819847106934, 9.15187931060791, 9.68465805053711, 8.926249504089355, 12.10088062286377, 9.815277099609375, 10.479447364807129, 9.759759902954102, 10.795121192932129, 11.389080047607422, 10.836543083190918, 10.711068153381348, 9.211469650268555, 10.463364601135254, 9.638559341430664, 9.948210716247559, 9.278192520141602, 9.30984878540039, 9.148965835571289, 11.214942932128906, 8.861112594604492, 9.229622840881348, 9.10022258758545, 9.9656982421875, 8.660174369812012, 9.764296531677246, 9.050253868103027, 8.834019660949707, 9.5477933883667, 12.035059928894043, 10.293143272399902, 10.188653945922852, 9.210306167602539, 9.825153350830078, 10.387941360473633, 8.904814720153809, 10.353373527526855, 10.885520935058594, 10.898032188415527, 9.192727088928223, 9.533164024353027, 9.428503036499023, 10.083556175231934, 9.368474006652832, 9.344239234924316, 10.269649505615234, 9.559134483337402, 9.40538501739502, 9.05587100982666, 9.393671035766602, 9.746978759765625, 9.49242115020752, 8.527979850769043, 11.388976097106934, 9.306139945983887, 10.389339447021484, 9.263907432556152, 9.726911544799805, 10.130130767822266, 9.583870887756348, 9.874555587768555, 9.455171585083008, 9.04974365234375, 8.796656608581543, 8.55865478515625, 9.516446113586426, 8.804463386535645, 9.36868953704834, 9.532215118408203, 8.768057823181152, 8.783040046691895, 8.622640609741211, 9.308257102966309, 8.9915771484375, 8.789677619934082, 9.992855072021484, 8.46877670288086, 9.3720121383667, 8.799176216125488, 10.674638748168945, 9.150627136230469, 9.188878059387207, 9.058204650878906, 9.495392799377441, 8.834527969360352, 8.408106803894043, 9.350247383117676, 8.888256072998047, 10.60409164428711, 9.076239585876465, 8.72027587890625, 8.42526626586914, 8.96522331237793, 9.690372467041016, 10.092981338500977, 9.57901668548584, 8.991127014160156, 8.464072227478027, 9.455055236816406, 8.656120300292969, 9.635969161987305, 9.510480880737305, 8.945613861083984, 9.239123344421387, 8.39639663696289, 8.723599433898926, 9.91265869140625, 8.593118667602539, 9.623891830444336, 9.23159122467041, 9.202714920043945, 9.059045791625977, 8.729301452636719, 8.505449295043945, 10.554014205932617, 9.53365707397461, 9.504572868347168, 9.054729461669922, 9.877904891967773, 9.669906616210938, 8.760201454162598, 9.684416770935059, 8.939634323120117, 8.943268775939941, 8.242478370666504, 8.819480895996094, 9.640753746032715, 8.438688278198242, 9.35705852508545, 9.824758529663086, 8.592095375061035, 8.446761131286621, 8.718711853027344, 8.970943450927734, 10.746163368225098, 9.194684028625488, 9.147314071655273, 8.535805702209473, 8.205052375793457, 9.020547866821289, 10.619013786315918, 8.810463905334473, 8.387795448303223, 8.49803352355957, 9.58328628540039, 9.713133811950684, 9.398131370544434, 8.347830772399902, 9.065336227416992, 9.115179061889648, 8.807516098022461, 8.69480037689209, 8.497908592224121, 9.930252075195312, 8.728031158447266, 10.508224487304688, 8.889142990112305, 9.027463912963867, 8.209196090698242, 9.340224266052246, 9.234869956970215, 8.424200057983398, 8.099139213562012, 8.645233154296875, 8.0716552734375, 9.48385238647461, 9.166948318481445, 9.349425315856934, 9.547207832336426, 8.412223815917969, 9.24828052520752, 9.448161125183105, 8.481988906860352, 9.191459655761719, 9.5277099609375, 8.014684677124023, 8.558874130249023, 8.335342407226562, 9.764448165893555, 8.343111991882324, 8.90416431427002, 9.011269569396973, 9.483016967773438, 9.78042984008789, 8.450798988342285, 8.279603958129883, 8.51266098022461, 9.66325855255127, 10.519109725952148, 8.869321823120117, 9.880480766296387, 10.354913711547852, 9.39176082611084, 8.91642951965332, 9.985058784484863, 8.761214256286621, 8.394216537475586, 8.677861213684082, 8.037384033203125, 8.919940948486328, 9.853137969970703, 8.030391693115234, 8.358858108520508, 8.21975326538086, 9.999173164367676, 10.165240287780762, 8.5265531539917, 8.979923248291016, 10.429609298706055, 8.860053062438965, 9.97240924835205, 10.153383255004883, 8.440375328063965, 9.946833610534668, 8.7641019821167, 9.030807495117188, 9.04423713684082, 8.981215476989746, 9.791245460510254, 8.354520797729492, 8.328046798706055, 8.660656929016113, 8.436424255371094, 9.027641296386719, 8.648419380187988, 7.947552680969238, 9.117786407470703, 8.735491752624512, 8.501641273498535, 9.192511558532715, 8.663439750671387, 8.672313690185547, 8.355809211730957, 8.783648490905762, 9.82582950592041, 8.866180419921875, 8.677857398986816, 8.90141487121582, 8.782110214233398, 9.19096851348877, 8.655964851379395, 8.546683311462402, 8.416053771972656, 8.83053970336914, 8.831565856933594, 8.592013359069824, 9.20749568939209, 9.472911834716797, 8.45741081237793, 8.808863639831543, 10.024087905883789, 10.677241325378418, 9.89609146118164, 8.960402488708496, 9.088059425354004, 9.447388648986816, 8.39566707611084, 8.622702598571777, 9.786752700805664, 8.510601997375488, 8.382741928100586, 8.580918312072754, 9.129605293273926, 8.491317749023438, 8.438006401062012, 8.707277297973633, 8.119622230529785, 9.140222549438477, 10.171831130981445, 9.842584609985352, 8.463549613952637, 9.665974617004395, 9.489776611328125, 8.819613456726074, 8.445329666137695, 8.230583190917969, 8.509490966796875, 8.948028564453125, 8.989283561706543, 9.125287055969238, 8.07156753540039, 8.534947395324707, 8.230866432189941, 8.90202808380127, 8.642030715942383, 8.666483879089355, 8.469461441040039, 8.699980735778809, 8.181922912597656, 8.465248107910156, 8.8870849609375, 7.888335704803467, 8.213703155517578, 8.347149848937988, 7.950218200683594, 8.880358695983887, 8.658564567565918, 8.462733268737793, 8.883267402648926, 8.382378578186035, 8.945796966552734, 8.596802711486816, 8.421581268310547, 9.089856147766113, 9.04063892364502, 8.58037281036377, 8.358725547790527, 9.354275703430176, 8.461674690246582, 9.942700386047363, 8.873306274414062, 10.012654304504395, 8.383601188659668, 8.051716804504395, 9.34746265411377, 8.33446216583252, 8.978665351867676, 8.703336715698242, 8.738188743591309, 8.807332038879395, 8.316926956176758, 8.488513946533203, 7.88134241104126, 8.738924980163574, 9.182965278625488, 10.614376068115234, 9.164300918579102, 8.188581466674805, 8.408639907836914, 8.611172676086426, 8.487260818481445, 8.514735221862793, 8.484736442565918, 7.777212619781494, 9.156524658203125, 8.738472938537598, 8.392882347106934, 9.390070915222168, 8.487067222595215, 8.498832702636719, 8.146568298339844, 8.727743148803711, 8.28994369506836, 8.922636032104492, 8.989472389221191, 8.976366996765137, 8.918314933776855, 8.515684127807617, 8.960906028747559, 8.250481605529785, 8.84882640838623, 8.076512336730957, 9.590072631835938, 8.21695613861084, 8.708767890930176, 7.991617679595947, 8.852726936340332, 8.617342948913574, 8.364253997802734, 8.513607025146484, 7.983567714691162, 7.977968215942383, 8.232752799987793, 8.705002784729004, 8.59426212310791, 8.661650657653809, 8.985980033874512, 8.506035804748535, 8.177045822143555, 9.909347534179688, 8.91706657409668, 8.139517784118652, 9.071989059448242, 8.23082160949707, 8.787059783935547, 8.939414978027344, 8.316141128540039, 9.251437187194824, 8.66756820678711, 8.094030380249023, 8.966409683227539, 8.111809730529785, 9.145283699035645, 8.176514625549316, 9.111309051513672, 8.194074630737305, 8.075117111206055, 7.983587741851807, 8.838918685913086, 8.324673652648926, 9.076480865478516, 7.807987689971924, 9.268568992614746, 8.740133285522461, 8.261602401733398, 7.988792896270752, 8.064925193786621, 8.406980514526367, 7.9946794509887695, 8.784250259399414, 8.232322692871094, 7.821754455566406, 8.902787208557129, 8.094433784484863, 8.160360336303711, 8.32686996459961, 8.477730751037598, 8.697431564331055, 8.253655433654785, 7.765090465545654, 9.748997688293457, 8.486681938171387, 8.228693962097168, 8.643484115600586, 7.986806392669678, 7.646447658538818, 8.103631973266602, 7.7624592781066895, 8.516140937805176, 7.965974807739258, 7.913546562194824, 8.038192749023438, 10.242607116699219, 7.989918231964111, 8.045621871948242, 8.280776023864746, 7.91649866104126, 7.9040093421936035, 8.311808586120605, 8.259729385375977, 7.853465557098389, 8.27463150024414, 8.063417434692383, 8.0709228515625, 8.243311882019043, 8.802985191345215, 8.273043632507324, 9.010104179382324, 8.684082984924316, 9.089075088500977, 7.6938323974609375, 7.8586201667785645, 8.151334762573242, 8.418658256530762, 8.132762908935547, 9.846835136413574, 8.233789443969727, 8.862167358398438, 8.624848365783691, 7.968845844268799, 7.985691547393799, 8.513263702392578, 8.14022445678711, 8.266647338867188, 8.231319427490234, 8.021697998046875, 8.288240432739258, 8.350544929504395, 8.444653511047363, 8.217599868774414, 8.044229507446289, 7.935675621032715, 8.147095680236816, 7.913553714752197, 7.967569351196289, 10.295135498046875, 9.965184211730957, 8.081131935119629, 8.206097602844238, 7.822406768798828, 8.07170295715332, 8.919568061828613, 7.443751335144043, 8.548432350158691, 7.803487777709961, 7.8960371017456055, 7.956921100616455, 8.432454109191895, 7.598201751708984, 7.667685031890869, 8.021855354309082, 8.075729370117188, 7.781904220581055, 8.538904190063477, 8.158488273620605, 8.61972427368164, 7.800310134887695, 8.830955505371094, 9.322064399719238, 8.345763206481934, 8.182650566101074, 7.824406147003174, 8.255963325500488, 8.78210163116455, 7.806818008422852, 7.951756000518799, 8.111442565917969, 8.14174747467041, 8.673625946044922, 9.19663143157959, 9.225131034851074, 8.271162986755371, 8.518346786499023, 8.320476531982422, 7.657336235046387, 7.719542503356934, 7.970764636993408, 7.793361186981201, 7.785052299499512, 8.405818939208984, 8.975679397583008, 7.807863712310791, 7.882349491119385, 7.868189811706543, 8.077823638916016, 7.834497928619385, 7.968353748321533, 7.359477519989014, 8.450165748596191, 8.023447036743164, 8.691483497619629, 7.729796886444092, 7.812345027923584, 7.856431484222412, 9.151359558105469, 8.146598815917969, 7.983693599700928, 8.958501815795898, 7.999926567077637, 8.023975372314453, 8.391430854797363, 8.483542442321777, 8.031837463378906, 8.100682258605957, 8.540717124938965, 7.964945316314697, 8.553812026977539, 8.432785987854004, 7.791783332824707, 8.223470687866211, 8.097800254821777, 8.072763442993164, 8.71493148803711, 10.422290802001953, 8.370394706726074, 8.580759048461914, 8.473015785217285, 8.488183975219727, 7.943868160247803, 8.034921646118164, 7.8327531814575195, 8.4461088180542, 8.183700561523438, 8.504922866821289, 7.9721760749816895, 8.068475723266602, 7.579556941986084, 8.017245292663574, 8.056995391845703, 9.747204780578613, 8.5188627243042, 7.828119277954102, 8.017285346984863, 8.132426261901855, 8.252120018005371, 8.347875595092773, 7.8037919998168945, 7.835580825805664, 8.717219352722168, 8.025872230529785, 7.894125938415527, 8.237631797790527, 8.0206298828125, 8.074750900268555, 8.114862442016602, 8.093517303466797, 8.47639274597168, 8.090614318847656, 7.8167266845703125, 7.925356864929199, 7.711252212524414, 8.071712493896484, 8.083883285522461, 8.121155738830566, 8.919146537780762, 8.95271110534668, 8.011886596679688, 7.45551061630249, 7.8058247566223145, 7.968002796173096, 7.747890949249268, 8.130415916442871, 7.456801891326904, 8.563278198242188, 7.728884696960449, 7.842794418334961, 7.658058166503906, 7.666322708129883, 7.73524284362793, 7.79709529876709, 7.88436222076416, 8.590523719787598, 8.499250411987305, 7.7024030685424805, 7.713247299194336, 9.116541862487793, 8.01715087890625, 8.233696937561035, 7.376834869384766, 8.090968132019043, 7.748794078826904, 8.025279998779297, 8.205301284790039, 7.533003807067871, 8.414928436279297, 7.624573707580566, 8.370591163635254, 8.262752532958984, 7.830010890960693, 8.48086929321289, 7.774327278137207, 9.631933212280273, 7.918811798095703, 7.622191905975342, 8.902642250061035, 8.211565971374512, 8.219154357910156, 8.503640174865723, 8.055436134338379, 8.04112434387207, 8.07979679107666, 8.530173301696777, 8.572959899902344, 9.062895774841309, 7.732875347137451, 8.34094524383545, 7.612427711486816, 8.088654518127441, 8.029891967773438, 7.821584701538086, 7.679667949676514, 8.834773063659668, 7.452197074890137, 8.251496315002441, 8.08203411102295, 8.275649070739746, 8.110288619995117, 7.927043914794922, 8.104464530944824, 7.773759365081787, 8.39206600189209, 7.95791482925415, 8.469898223876953, 7.696518898010254, 7.465478420257568, 7.801870346069336, 8.288143157958984, 8.629446029663086, 7.994011402130127, 7.906075954437256, 7.550514221191406, 7.725462913513184, 7.969583511352539, 8.070379257202148, 8.151721000671387, 8.162253379821777, 7.719620227813721, 7.760269641876221, 7.724323272705078, 8.100123405456543, 8.101234436035156, 8.601643562316895, 7.648837566375732, 7.70550537109375, 7.60139274597168, 7.7994232177734375, 7.407444477081299, 9.083224296569824, 7.723761558532715, 7.763646125793457, 8.887748718261719, 8.107213973999023, 7.779018878936768, 7.4508185386657715, 7.403666019439697, 8.259937286376953, 7.800020217895508, 7.499986171722412, 8.054814338684082, 7.89572811126709, 8.342473983764648, 8.247806549072266, 8.205810546875, 7.879651069641113, 8.343409538269043, 7.753077983856201, 7.582930564880371, 7.877829551696777, 9.377104759216309, 7.515035152435303, 7.44443416595459, 8.236928939819336, 7.465507984161377, 8.21557331085205, 8.156488418579102, 8.229297637939453, 7.513565540313721, 7.929710388183594, 8.184107780456543, 7.613886833190918, 8.858833312988281, 7.874568939208984, 9.019123077392578, 8.074126243591309, 7.711670398712158, 7.944966793060303, 7.715090751647949, 8.019307136535645, 8.505383491516113, 7.771984577178955, 7.929576873779297, 8.052409172058105, 7.776025772094727, 8.084104537963867, 8.872532844543457, 7.45083475112915, 8.067736625671387, 8.139739990234375, 8.15489673614502, 8.377696990966797, 7.599238872528076, 7.75014066696167, 7.7728376388549805, 8.301836013793945, 7.961785316467285, 7.579785346984863, 7.541389465332031, 7.494603157043457, 7.449469089508057, 8.380905151367188, 8.141585350036621, 7.431412696838379, 8.753724098205566, 7.916808128356934, 7.733811378479004, 7.443816184997559, 7.573319435119629, 7.8174729347229, 7.6283111572265625, 7.99393367767334, 7.699983596801758, 8.103321075439453, 7.6114182472229, 8.236763000488281, 8.245118141174316, 7.795709609985352, 7.571707248687744, 8.076510429382324, 8.720492362976074, 7.8776631355285645, 7.899501323699951, 7.633505821228027, 7.664705753326416, 8.065293312072754, 7.842633247375488, 7.938336372375488, 8.11775016784668, 8.035905838012695, 7.749924182891846, 7.541810989379883, 8.057003021240234, 7.594411849975586, 7.941838264465332, 8.019128799438477, 7.770096302032471, 8.246530532836914, 7.596070289611816, 7.465393543243408, 7.489354610443115, 7.470494270324707, 7.682952404022217, 7.51196813583374, 8.102187156677246, 8.438684463500977, 7.501731872558594, 7.371473789215088, 7.318878650665283, 7.663296222686768, 7.528266429901123, 8.024971008300781, 7.376801013946533, 7.441413879394531, 7.9371538162231445, 8.056404113769531, 8.066361427307129, 7.890260696411133, 9.334211349487305, 8.107577323913574, 7.605737209320068, 7.846889495849609, 7.977462291717529, 7.930351257324219, 7.769010543823242, 7.698546886444092, 7.996438980102539, 7.903383731842041, 7.5234551429748535, 7.620786190032959, 7.798086643218994, 7.252039432525635, 7.8939948081970215, 7.9941277503967285, 7.597731113433838, 7.827171802520752, 8.669597625732422, 8.184178352355957, 8.155383110046387, 8.348156929016113, 8.415138244628906, 7.678463459014893, 7.981477737426758, 8.233774185180664, 8.212377548217773, 7.56412935256958, 8.186960220336914, 7.897027015686035, 7.821603775024414, 8.07910442352295, 7.718963623046875, 8.023557662963867, 8.421100616455078, 7.683466911315918, 7.8416314125061035, 7.6425395011901855, 8.31470012664795, 7.725710868835449, 7.701158046722412, 7.445990562438965, 7.324508190155029, 7.553676128387451, 7.816174030303955, 8.019615173339844, 7.709484100341797, 7.631652355194092, 7.501432418823242, 7.87536096572876, 8.056286811828613, 7.778672218322754, 8.839329719543457, 8.085173606872559, 7.566093444824219, 8.701749801635742, 7.974832534790039, 7.413977146148682, 7.743764400482178, 7.397182941436768, 7.5367279052734375, 7.734745979309082, 7.745491981506348, 7.665043354034424, 8.250527381896973, 7.953102111816406, 7.818845272064209, 7.7697529792785645, 8.11440658569336, 7.955877304077148, 7.499209403991699, 8.307616233825684, 8.208271026611328, 7.937586784362793, 7.323427200317383, 7.940097808837891, 7.519140720367432, 7.5898051261901855, 9.056221008300781, 7.698686599731445, 8.049430847167969, 7.98472261428833, 7.808738708496094, 8.267241477966309, 7.769898414611816, 7.963136196136475, 7.831351280212402, 7.611737251281738, 8.691238403320312, 7.6330156326293945, 7.664737701416016, 7.994647979736328, 7.633411407470703, 7.842477798461914, 7.716898441314697, 7.905154228210449, 7.875298976898193, 7.8697638511657715, 7.913562774658203, 7.679529666900635, 7.819267749786377, 7.555602550506592, 7.310503959655762, 7.672845363616943, 7.852716445922852, 8.173250198364258, 7.858471870422363, 8.535835266113281, 7.754120826721191, 7.777916431427002, 7.8136515617370605, 7.931214332580566, 7.402746677398682, 9.332849502563477, 7.896151065826416, 8.079354286193848, 7.4796857833862305, 8.115952491760254, 8.196761131286621, 7.570909023284912, 7.678675651550293, 7.2866082191467285, 7.5762834548950195, 7.72705078125, 7.829456806182861, 7.551840782165527, 8.030149459838867, 7.433707237243652, 7.827860355377197, 7.820565223693848, 7.338048458099365, 7.898581027984619, 8.0938720703125, 7.5052337646484375, 7.623535633087158, 7.679450511932373, 7.307350158691406, 7.36897087097168, 7.562075614929199, 7.657783031463623, 8.194220542907715, 7.485340595245361, 7.425682544708252, 8.048253059387207, 7.7787394523620605, 7.594435691833496, 7.802157878875732, 7.604615211486816, 7.833542823791504, 8.889711380004883, 7.527590274810791, 7.402071952819824, 7.750681400299072, 7.835371971130371, 7.7375993728637695, 7.864269256591797, 7.672374248504639, 7.651234149932861, 7.798360347747803, 7.4378557205200195, 7.6932244300842285, 7.316109657287598, 7.83114767074585, 7.497652530670166, 7.559657096862793, 7.562188625335693, 7.5708842277526855, 8.461567878723145, 7.278217315673828, 7.842852592468262, 7.594027519226074, 7.817671775817871, 8.432610511779785, 7.733630180358887, 7.641453266143799, 7.437150478363037, 7.497466087341309, 7.669762134552002, 8.189231872558594, 7.807583808898926, 7.361432075500488, 7.3252763748168945, 7.887004852294922, 7.439958572387695, 8.615684509277344, 7.467532157897949, 7.851467609405518, 7.596585750579834, 7.933952331542969, 7.199590682983398, 7.4025373458862305, 7.573378562927246, 7.188345432281494, 7.24614953994751, 7.609924793243408, 8.045955657958984, 7.832085132598877, 8.207109451293945, 7.602598667144775, 7.176308631896973, 7.768558979034424, 7.985928535461426, 8.744428634643555, 7.525125980377197, 7.602677345275879, 7.687089443206787, 7.653172969818115, 8.226700782775879, 7.77175235748291, 7.884759426116943, 7.816026210784912, 7.839433193206787, 7.670960426330566, 7.72106409072876, 7.431681156158447, 7.485320091247559, 7.8354620933532715, 7.524816989898682, 7.9949469566345215, 7.712092876434326, 7.820704936981201, 7.7389235496521, 7.507805347442627, 7.99170446395874, 7.421292304992676, 7.836549758911133, 8.01047134399414, 7.454719543457031, 7.641357898712158, 7.602726936340332, 7.370161533355713, 7.744851112365723, 7.9043779373168945, 7.694038391113281, 7.564487457275391, 7.234886169433594, 7.608387470245361, 7.446562767028809, 7.799412250518799, 7.821484565734863, 7.362986087799072, 7.616481781005859, 7.279838562011719, 7.896595001220703, 7.580362319946289, 7.60019588470459, 7.479378700256348, 7.869121551513672, 7.6369218826293945, 8.002778053283691, 8.316278457641602, 7.5292582511901855, 7.916664123535156, 7.738955020904541, 7.556699752807617, 7.725002765655518, 7.65916109085083, 7.736795902252197, 7.468575954437256, 7.887006759643555, 7.537517070770264, 7.643924713134766, 7.489388465881348, 8.257294654846191, 8.627352714538574, 8.0015869140625, 8.172843933105469, 7.6786041259765625, 7.831261157989502, 7.799309253692627, 7.614765644073486, 7.570003509521484, 8.132658004760742, 7.777791976928711, 8.00389575958252, 7.496672630310059, 7.523095607757568, 7.539551258087158, 7.719128131866455, 7.575662136077881, 7.96699333190918, 8.207533836364746, 8.767422676086426, 7.628006935119629, 7.7422380447387695, 7.750441551208496, 7.228291034698486, 7.666330814361572, 7.753376007080078, 7.348848342895508, 7.632749080657959, 7.784189701080322, 7.695618152618408, 7.5608110427856445, 8.01027774810791, 7.817136287689209, 7.416011810302734, 8.245359420776367, 7.2613525390625, 7.380147933959961, 7.875872611999512, 7.345582008361816, 8.353169441223145, 7.5613908767700195, 7.616087436676025, 8.0612154006958, 7.772579193115234, 7.288189888000488, 7.758927345275879, 7.387598514556885, 7.787298679351807, 7.524788856506348, 7.541141033172607, 7.411854267120361, 7.5624189376831055, 7.575093746185303, 7.549627780914307, 7.602750778198242, 7.352314472198486, 7.774042129516602, 7.7752299308776855, 7.702055931091309, 7.919489860534668, 7.548652648925781, 7.635646343231201, 7.437191009521484, 7.567376613616943, 7.702861309051514, 7.4876017570495605, 8.0358247756958, 7.35210657119751, 7.495072364807129, 7.438159465789795, 7.537995338439941, 7.587593078613281, 7.4789958000183105, 7.6278791427612305, 7.790608882904053, 7.741403579711914, 7.746230125427246, 7.6925530433654785, 7.607560157775879, 7.928926467895508, 7.709351539611816, 7.765158176422119, 8.42420482635498, 7.912275314331055, 7.937943935394287, 7.64310884475708, 7.557747840881348, 7.8194379806518555, 7.72913122177124, 7.62766170501709, 8.375188827514648, 8.088789939880371, 7.519067764282227, 7.440269470214844, 7.661932468414307, 7.3933281898498535, 7.203192234039307, 7.236963748931885, 7.598777770996094, 7.914621829986572, 7.963977336883545, 7.572033882141113, 7.7417778968811035, 7.675397872924805, 7.716609477996826, 7.657409191131592, 7.364194393157959, 7.3042683601379395, 7.465827941894531, 7.115002632141113, 7.572309494018555, 7.401247024536133, 7.562640190124512, 8.421602249145508, 7.861361026763916, 7.521843433380127, 7.528172016143799, 7.829561233520508, 8.036059379577637, 7.52262544631958, 7.608817100524902, 8.384342193603516, 7.325166702270508, 7.451272010803223, 8.84151840209961, 7.867351531982422, 7.524111747741699, 7.706574440002441, 7.499408721923828, 7.847637176513672, 8.69672679901123, 8.605888366699219, 7.4743876457214355, 8.847427368164062, 7.9678850173950195, 7.860623836517334, 7.527109622955322, 7.74762487411499, 7.437534332275391, 8.025433540344238, 7.994079113006592, 7.52614688873291, 7.510646343231201, 7.491826057434082, 7.584446907043457, 7.33935022354126, 7.501777172088623, 7.243433952331543, 7.9254679679870605, 7.346056938171387, 7.6918535232543945, 7.5157575607299805, 7.4363627433776855, 7.434019565582275, 7.314378261566162, 7.291436195373535, 7.4792914390563965, 7.673214435577393, 7.223726749420166, 7.355605125427246, 7.441311836242676, 7.387764930725098, 7.5033793449401855, 7.372765064239502, 7.823362350463867, 7.174605846405029, 7.922614574432373, 7.955940246582031, 7.305667877197266, 7.389847278594971, 7.511649131774902, 7.473360538482666, 7.710775375366211, 7.684877872467041, 7.53963565826416, 8.313655853271484, 7.613129138946533, 7.300273895263672, 7.633509635925293, 7.721190929412842, 7.601834774017334, 7.801673412322998, 7.587427616119385, 8.19869327545166, 7.895716667175293, 7.5662455558776855, 7.266520023345947, 7.374851703643799, 7.469485282897949, 7.574869155883789, 7.293435573577881, 7.448447227478027, 7.37677001953125, 7.566904544830322, 7.666866779327393, 7.621346473693848, 7.875022888183594, 7.837234020233154, 7.290639400482178, 7.58336877822876, 7.6393208503723145, 7.416382312774658, 7.381801128387451, 7.314152717590332, 7.528204917907715, 7.6825761795043945, 7.379848480224609, 7.814033031463623, 7.477047443389893, 7.283940315246582, 7.565156936645508, 7.361167907714844, 7.8453474044799805, 7.326234340667725, 8.879669189453125, 7.46871280670166, 7.50150728225708, 7.5659990310668945, 7.986530303955078, 7.577688217163086, 7.941186428070068, 7.50125789642334, 7.476346015930176, 7.552326679229736, 7.926700592041016, 7.152271747589111, 7.707015514373779, 7.301390647888184, 7.394434928894043, 7.225381851196289, 7.439981460571289, 7.451637268066406, 7.537484169006348, 7.484703540802002, 7.863877773284912, 7.19864559173584, 7.425445079803467, 7.594550609588623, 7.800069808959961, 7.509293079376221, 7.812239170074463, 7.284141540527344, 8.064818382263184, 7.523757457733154, 7.315252780914307, 7.925476551055908, 7.525554656982422, 8.182912826538086, 7.479031085968018, 7.165163993835449, 7.459668159484863, 7.502875804901123, 7.918339252471924, 7.570562839508057, 7.425144195556641, 7.151057720184326, 7.280667781829834, 7.398592472076416, 7.245556831359863, 7.225783348083496, 7.635364055633545, 7.311236381530762, 7.617127895355225, 8.150368690490723, 7.3236894607543945, 8.008757591247559, 7.248055934906006, 7.511483669281006, 8.09630012512207, 7.1846537590026855, 7.320154666900635, 7.821895122528076, 7.952773571014404, 7.771073818206787, 7.764901638031006, 7.460355281829834, 7.308649063110352, 7.8837738037109375, 7.313096046447754, 7.371462821960449, 7.5341715812683105, 7.297438621520996, 7.605513095855713, 7.274412631988525, 7.407022476196289, 7.405267238616943, 7.544304847717285, 7.622560977935791, 7.449722766876221, 7.25225830078125, 7.466986179351807, 7.557287216186523, 7.291133880615234, 7.412209987640381, 7.771462440490723, 7.445093154907227, 7.689307689666748, 7.700859069824219, 7.266201496124268, 7.375339984893799, 7.466468811035156, 7.654356002807617, 7.692159175872803, 7.303262710571289, 7.472423076629639, 7.497761249542236, 7.524942398071289, 7.477248191833496, 7.6753339767456055, 7.318592548370361, 7.405843257904053, 7.643683910369873, 7.491386890411377, 7.665571689605713, 7.42071533203125, 7.376713275909424, 7.372766971588135, 7.489214897155762, 8.279388427734375, 7.4437255859375, 7.347517967224121, 7.2062458992004395, 7.328383922576904, 7.235054016113281, 7.467307090759277, 7.61592960357666, 7.800619125366211, 7.447758197784424, 8.178908348083496, 7.526506423950195, 7.5239973068237305, 7.37258768081665, 7.801761627197266, 7.904905319213867, 7.203420162200928, 7.236281394958496, 7.490137577056885, 7.2486677169799805, 7.748160362243652, 7.450235366821289, 7.535131454467773, 7.176327705383301, 7.374843597412109, 7.4929938316345215, 7.405096054077148, 8.135279655456543, 7.268994331359863, 7.561233997344971, 7.735621452331543, 7.3278398513793945, 8.008230209350586, 7.279068470001221, 7.359346389770508, 7.446449279785156, 7.3843231201171875, 7.6159844398498535, 7.92496919631958, 7.277035236358643, 7.704735279083252, 7.376420021057129, 7.581038951873779, 7.312496185302734, 7.3838911056518555, 7.726283073425293, 7.576098442077637, 7.364614486694336, 7.221592903137207, 7.901257514953613, 7.71998929977417, 7.520458221435547, 7.871821880340576, 7.564269542694092, 8.266505241394043, 7.640028476715088, 7.822207450866699, 7.696187496185303, 7.32452392578125, 7.548861026763916, 7.1808319091796875, 7.605362415313721, 7.496105194091797, 7.292052268981934, 7.589747905731201, 7.541162490844727, 7.33629035949707, 8.039198875427246, 7.453592777252197, 7.826175212860107, 7.524369716644287, 7.2884039878845215, 7.693508625030518, 7.315755367279053, 7.283528804779053, 7.287076473236084, 7.3396501541137695, 7.511652946472168, 7.901519775390625, 7.4617919921875, 7.5920610427856445, 7.274281024932861, 7.397321701049805, 7.043088436126709, 7.435726642608643, 7.403851509094238, 7.3816022872924805, 7.512724876403809, 7.521200180053711, 7.320918560028076, 8.150420188903809, 7.520233154296875, 7.918634414672852, 7.835049152374268, 7.819903373718262, 7.300584316253662, 7.4471211433410645, 7.2206854820251465, 7.6305952072143555, 7.670196533203125, 7.583281993865967, 7.222081184387207, 7.519065856933594, 7.383194923400879, 7.3213725090026855, 7.766177177429199, 7.509289264678955, 7.572005748748779, 7.912868022918701, 7.509927272796631, 7.797804832458496, 7.617392539978027, 7.246893405914307, 7.40647554397583, 7.562175750732422, 7.418632507324219, 7.657959461212158, 7.753549575805664, 7.255252838134766, 7.992070198059082, 7.618637561798096, 7.316781044006348, 7.899992942810059, 7.546658992767334, 7.923829555511475, 7.785250186920166, 7.583164691925049, 7.427446365356445, 7.680759906768799, 7.222762584686279, 7.914804935455322, 7.540701389312744, 7.368038177490234, 7.7202277183532715, 7.349377155303955, 7.371095657348633, 7.7836833000183105, 7.647995471954346, 7.79127836227417, 7.896857261657715, 7.368806838989258, 7.306248664855957, 7.615224361419678, 7.2401347160339355, 7.4484944343566895, 7.9388604164123535, 7.340811252593994, 7.4936394691467285, 7.635876655578613, 7.317996501922607, 7.570079326629639, 7.408957481384277, 7.583492755889893, 7.788151741027832, 7.856960296630859, 8.459859848022461, 7.754666328430176, 7.321813583374023, 7.8235554695129395, 7.521542072296143, 7.47599458694458, 7.9677653312683105, 7.517304420471191, 7.134462833404541, 7.204370021820068, 7.481698513031006, 7.575456142425537, 7.477841377258301, 7.538455963134766, 7.5218048095703125, 7.537362575531006, 7.346653938293457, 7.783413410186768, 7.910059928894043, 7.687723159790039, 7.722795486450195, 7.741532802581787, 7.440524578094482, 7.348599910736084, 7.289609909057617, 7.731657028198242, 7.440006732940674, 7.484235763549805, 7.639503002166748, 7.326572895050049, 7.509972095489502, 7.4683685302734375, 7.211395263671875, 7.63451623916626, 7.30470085144043, 7.755719184875488, 7.257158279418945, 8.209634780883789, 7.36003303527832, 7.398789405822754, 7.4564056396484375, 8.125299453735352, 7.46060037612915, 7.483238220214844, 7.589905261993408, 8.08961296081543, 8.90036392211914, 7.776025295257568, 7.359114170074463, 7.260403156280518, 7.435384750366211, 7.182742595672607, 7.214004039764404, 8.384024620056152, 7.277154445648193, 7.30814790725708, 7.706060409545898, 7.356099605560303, 7.352664947509766, 7.326964378356934, 7.5185675621032715, 8.666687965393066, 8.300039291381836, 7.612000465393066, 7.290876388549805, 7.496138095855713, 7.409326553344727, 7.467828750610352, 7.463386058807373, 7.467990875244141, 8.425620079040527, 7.763729572296143, 8.725480079650879, 7.433136463165283, 8.013226509094238, 7.490780830383301, 7.58944034576416, 7.3479905128479, 7.687428951263428, 7.239567279815674, 7.533308982849121, 7.220704555511475, 7.621912479400635, 7.366502285003662, 7.660832405090332, 7.494503498077393, 7.434593200683594, 7.99000883102417, 7.461638450622559, 7.700656890869141, 7.522852420806885, 7.236694812774658, 7.667899131774902, 7.298283576965332, 7.449772357940674, 7.744514465332031, 8.011756896972656, 7.343449592590332, 7.181459426879883, 7.321234703063965, 8.073075294494629, 7.678149700164795, 7.318251132965088, 7.4429931640625, 7.6644086837768555, 7.56178617477417, 7.48477029800415, 7.178101539611816, 7.828561782836914, 7.539243698120117, 7.301118850708008, 7.392488956451416, 7.3596014976501465, 7.737568378448486, 7.5446014404296875, 8.020720481872559, 7.226443290710449, 7.10593843460083, 7.322722911834717, 7.395901203155518, 7.312197685241699, 7.452481746673584, 7.213103294372559, 7.625237464904785, 7.324958324432373, 7.379863262176514, 7.37913179397583, 7.1554999351501465, 7.276186466217041, 7.224283695220947, 7.462582111358643, 7.674098491668701, 7.511771202087402, 7.388227462768555, 8.066901206970215, 7.477243900299072, 7.6410441398620605, 7.751523971557617, 7.684263229370117, 7.316916465759277, 7.6718034744262695, 7.635888576507568, 7.426548004150391, 7.416512966156006, 7.514014720916748, 7.393864154815674, 7.36918306350708, 7.383908271789551, 7.484450817108154, 7.318670272827148, 7.391025066375732, 7.582554817199707, 7.636336326599121, 8.105483055114746, 7.410013675689697, 7.65627908706665, 7.48797607421875, 7.474435806274414, 7.2585530281066895, 7.682610034942627, 7.450581073760986, 7.472345352172852, 7.197742462158203, 7.3054070472717285, 7.534398078918457, 7.3585896492004395, 7.394748687744141, 7.325586795806885, 7.505992889404297, 8.177156448364258, 8.40373420715332, 7.760638236999512, 7.863001346588135, 7.363492965698242, 7.326822757720947, 8.016904830932617, 7.397230625152588, 7.375993251800537, 7.322246551513672, 7.521533966064453, 7.506263256072998, 7.478095531463623, 7.469829559326172, 7.492793083190918, 7.345952033996582, 7.222385883331299, 7.656535625457764, 7.423650741577148, 7.530397415161133, 7.265130996704102, 7.187625885009766, 7.174336910247803, 7.62971305847168, 7.731477737426758, 7.480146884918213, 7.214169502258301, 7.131810188293457, 7.231508731842041, 7.90725040435791, 7.946456432342529, 7.428266525268555, 7.314321517944336, 7.6806230545043945, 7.541522979736328, 7.508847236633301, 7.407104969024658, 7.569436073303223, 7.480466365814209, 7.554373264312744, 7.339164733886719, 7.527630805969238, 7.176319122314453, 7.308094024658203, 7.703144073486328, 7.50736141204834, 7.811282634735107, 7.4681077003479, 7.263083457946777, 7.484375, 7.3921613693237305, 7.450634002685547, 8.134342193603516, 7.624507427215576, 8.220752716064453, 7.599667072296143, 7.998847961425781, 7.338791847229004, 7.674749374389648, 7.408804893493652, 7.743642807006836, 7.7379913330078125, 7.396414756774902, 7.359468936920166, 7.401465892791748, 7.416505813598633, 8.01610279083252, 7.744684219360352, 7.311868667602539, 7.3018059730529785, 8.498777389526367, 7.549515247344971, 7.724684238433838, 7.367846965789795, 7.948096752166748, 7.4896440505981445, 7.664398193359375, 7.3566670417785645, 7.94429874420166, 7.598625659942627, 8.61813735961914, 7.934481620788574, 7.525974750518799, 7.538336277008057, 8.090044975280762, 7.251919746398926, 7.350062370300293, 7.807713508605957, 7.4788432121276855, 7.646569728851318, 7.460364818572998, 7.346812725067139, 7.358005046844482, 7.902096271514893, 7.323023796081543, 7.365575313568115, 7.7136454582214355, 7.524462699890137, 7.824951648712158, 7.542543888092041, 7.74454402923584, 7.518720626831055, 8.64568042755127, 7.527430057525635, 7.495671272277832, 7.29490327835083, 7.318050384521484, 8.13858699798584, 7.693021774291992, 7.387595176696777, 7.748495101928711, 7.547818660736084, 7.8016357421875, 7.5497565269470215, 7.681515216827393, 7.737424850463867, 7.336425304412842, 7.36065673828125, 7.651443958282471, 7.626030445098877, 7.392311096191406, 7.577862739562988, 7.459773540496826, 7.455601692199707, 7.8459672927856445, 7.241077899932861, 7.619625091552734, 7.240570068359375, 7.369027137756348, 7.227248191833496, 7.431869983673096, 7.376898765563965, 7.850956439971924, 7.5893635749816895, 7.531325817108154, 7.37874174118042, 7.734859466552734, 7.353784561157227, 7.596916675567627, 8.278867721557617, 7.580996990203857, 7.4834136962890625, 7.581942081451416, 7.406581878662109, 7.944519996643066, 7.219016075134277, 7.412933826446533, 7.562185764312744, 7.2061991691589355, 7.32520055770874, 7.678901672363281, 7.275363922119141, 7.29176664352417, 7.652853012084961, 7.400494575500488, 7.206491470336914, 7.4365363121032715, 7.339440822601318, 7.687549591064453, 7.173171520233154, 7.300098419189453, 7.43505334854126, 7.649391174316406, 7.4387736320495605, 7.377407073974609, 7.439895153045654, 7.782288551330566, 7.552136421203613, 7.746721267700195, 7.520954132080078, 7.5594096183776855, 7.542775630950928, 8.26999568939209, 7.383001804351807, 7.4221720695495605, 7.417760372161865, 7.3799309730529785, 7.387298107147217, 7.86922025680542, 7.431528091430664, 7.449965000152588, 7.496685028076172, 7.334341526031494, 7.266127109527588, 7.341765403747559, 7.693384170532227, 7.532385349273682, 7.488536357879639, 7.545265197753906, 7.575460433959961, 7.481943130493164, 7.805474281311035, 7.517823696136475, 7.510446548461914, 7.275079727172852, 7.2245635986328125, 7.480374336242676, 7.616440773010254, 8.10106372833252, 7.49407958984375, 7.518134117126465, 7.328293323516846, 7.700380325317383, 7.356247901916504, 7.629958152770996, 7.377808094024658, 7.353462219238281, 7.733584403991699, 7.345309734344482, 7.245505332946777, 7.8223443031311035, 7.21489143371582, 7.939363956451416, 7.290350437164307, 7.238657474517822, 7.690398216247559, 7.3377299308776855, 7.227386474609375, 7.324124813079834, 7.558545112609863, 7.544547080993652, 7.381445407867432, 7.38590669631958, 7.299990653991699, 7.621607303619385, 7.19641637802124, 7.4037604331970215, 7.331328868865967, 7.394824028015137, 7.253775596618652, 7.700538635253906, 7.489799499511719, 7.5804762840271, 7.846550464630127, 7.4667582511901855, 7.806258678436279, 7.318485260009766, 7.548285961151123, 7.383923530578613, 7.673773765563965, 7.889472961425781, 7.563920974731445, 7.284170150756836, 7.2097392082214355, 7.617305755615234, 7.530901908874512, 7.271032810211182, 7.640807628631592, 7.78010892868042, 7.50631046295166, 7.786571025848389, 7.331753253936768, 7.4066362380981445, 7.1906867027282715, 7.519053936004639, 7.442209243774414, 7.182547569274902, 7.717309951782227, 7.172037601470947, 7.063411235809326, 7.574692249298096, 7.666195392608643, 7.678249359130859, 7.136782646179199, 7.327727794647217, 7.4344377517700195, 7.544861793518066, 7.502699375152588, 7.25145959854126, 7.831809043884277, 7.427905559539795, 7.529494285583496, 7.554951190948486, 7.756594181060791, 7.452991962432861, 7.587685585021973, 7.263168811798096, 8.100234031677246, 7.119485378265381, 7.565555095672607, 7.558811664581299, 8.120687484741211, 7.288959503173828, 7.563094139099121, 7.529665946960449, 7.492129802703857, 7.597078800201416, 7.446131229400635, 7.333110332489014, 7.621243000030518, 7.712932586669922, 7.346245288848877, 7.275029182434082, 7.225715637207031, 8.501803398132324, 7.840328216552734, 8.137704849243164, 8.064614295959473, 7.1967034339904785, 7.339751243591309, 7.453389644622803, 7.241700649261475, 7.252734661102295, 7.369513034820557, 7.223176956176758, 7.77311372756958, 7.373307704925537, 7.723457336425781, 7.669820308685303, 7.935379505157471, 7.671328544616699, 7.195930480957031, 7.254640102386475, 7.138831615447998, 7.325984954833984, 7.6098809242248535, 7.367244720458984, 7.308043956756592, 7.561407089233398, 7.33372163772583, 7.351745128631592, 7.393190383911133, 7.541818141937256, 7.766541957855225, 7.658030986785889, 7.517849922180176, 7.348986625671387, 7.2779388427734375, 7.633652687072754, 7.300866603851318, 7.611457347869873, 7.397286891937256, 7.5792670249938965, 7.829873561859131, 7.183938503265381, 7.1234846115112305, 7.465737342834473, 7.1231369972229, 7.654365062713623, 7.576114654541016, 7.299505710601807, 7.432746410369873, 7.902288436889648, 7.398799896240234, 7.392157554626465, 7.473960876464844, 7.4068169593811035, 7.5641679763793945, 7.226444721221924, 7.282782554626465, 7.257453918457031, 7.324334144592285, 7.096996784210205, 7.838019371032715, 7.649709701538086, 7.526930332183838, 7.207607746124268, 7.587833404541016, 7.331342697143555, 7.60481595993042, 7.424717426300049, 7.685351848602295, 7.513017177581787, 7.499096870422363, 7.1166157722473145, 7.532901763916016, 7.443187236785889, 7.369665622711182, 7.625813961029053, 7.506267070770264, 7.470324993133545, 7.526497840881348, 7.496685028076172, 7.385670185089111, 7.245265483856201, 7.741484642028809, 7.647733688354492, 7.599620819091797, 7.359216690063477, 7.955345153808594, 7.393553256988525, 7.709349155426025, 7.323683738708496, 7.292330265045166, 7.319215774536133, 7.447181224822998, 7.622551441192627, 7.440401077270508, 7.552623748779297, 7.306375503540039, 7.592687129974365, 7.618548393249512, 7.402693748474121, 7.61529541015625, 7.446350574493408, 7.322009563446045, 7.649830341339111, 7.305063247680664, 7.466425895690918, 7.511960029602051, 7.4229960441589355, 7.826507568359375, 7.562769889831543, 7.839710235595703, 7.27032470703125, 7.32816219329834, 7.3835625648498535, 7.904267311096191, 7.131218433380127, 7.717395305633545, 7.776581287384033, 7.648038387298584, 7.262936592102051, 7.612452983856201, 7.2158379554748535, 7.313845157623291, 7.484903812408447, 7.29731559753418, 7.006972789764404, 7.772580146789551, 7.357022762298584, 7.791966915130615, 7.712699890136719, 7.617699146270752, 7.443886756896973, 7.266425609588623, 7.228990077972412, 7.598316192626953, 7.393612861633301, 7.276181221008301, 7.35438346862793, 7.650531768798828, 7.430368900299072, 7.277235984802246, 7.36832857131958, 7.59768009185791, 7.66507625579834, 7.688279151916504, 7.4001264572143555, 7.356655597686768, 7.221088409423828, 7.521783351898193, 7.365174770355225, 7.376063823699951, 7.621161460876465, 7.6341552734375, 7.526889801025391, 7.474250316619873, 7.350825309753418, 7.4651055335998535, 7.201277732849121, 7.702233791351318, 7.38215446472168, 7.4091644287109375, 7.250845909118652, 7.4574809074401855, 7.368648529052734, 7.363715171813965, 7.314474105834961, 7.5518412590026855, 7.346080780029297, 7.330037593841553, 7.3189592361450195, 7.618424892425537, 7.38700008392334, 7.560182571411133, 7.223435401916504, 7.471714019775391, 7.490030288696289, 7.748176574707031, 7.580881118774414, 7.379727840423584, 7.747352600097656, 7.707873344421387, 7.821023941040039, 7.735189437866211, 8.072303771972656, 7.289766311645508, 7.2346601486206055, 7.8903985023498535, 7.484617710113525, 7.959634304046631, 7.486108779907227, 7.678128719329834, 7.500324726104736, 7.595664978027344, 7.189752101898193, 7.452234745025635, 7.341060161590576, 7.512925624847412, 7.582919120788574, 7.5179619789123535, 7.200305461883545, 7.275402545928955, 7.52789831161499, 7.840214252471924, 7.419729232788086, 7.55910587310791, 7.582052707672119, 7.437220096588135, 7.302505970001221, 7.557557106018066, 7.438792705535889, 7.752847194671631, 7.465079307556152, 7.5436272621154785, 7.37036657333374, 7.689439296722412, 7.300848484039307, 7.308073997497559, 7.242764949798584, 7.6381378173828125, 7.4031291007995605, 7.442568778991699, 7.856841087341309, 7.692440509796143, 7.317444324493408, 7.193515300750732, 7.366124629974365, 7.340762138366699, 7.7159271240234375, 7.613111972808838, 7.530090808868408, 7.702418804168701, 7.5905890464782715, 7.351232051849365, 7.353296279907227, 7.506770133972168, 7.631511688232422, 7.321005344390869, 7.383405685424805, 7.464153289794922, 7.611064434051514, 7.88344144821167, 7.55846643447876, 7.610443592071533, 7.419740676879883, 7.416413307189941, 7.4569573402404785, 7.52907657623291, 7.498590469360352, 7.447582721710205, 7.5726494789123535, 7.828708171844482, 8.500444412231445, 7.519833564758301, 7.25968074798584, 7.696257591247559, 7.4083170890808105, 7.420295715332031, 8.026982307434082, 7.929044723510742, 7.4348931312561035, 8.019044876098633, 7.220343589782715, 7.471364498138428, 7.370096206665039, 7.471492290496826, 8.38916301727295, 7.360743522644043, 7.641912460327148, 7.6964030265808105, 7.3238205909729, 7.462640285491943, 7.537667751312256, 7.845986843109131, 7.444800853729248, 7.270880699157715, 7.636260032653809, 7.489304065704346, 7.637953758239746, 7.5066094398498535, 7.21110725402832, 7.8126983642578125, 7.877219200134277, 7.36004114151001, 7.639939308166504, 7.1760149002075195, 7.289180755615234, 7.373874664306641, 7.561162948608398, 7.5418806076049805, 7.549139499664307, 7.587564945220947, 7.415348529815674, 7.243704319000244, 7.570840835571289, 7.223441123962402, 7.6479010581970215, 7.164193630218506, 7.3510260581970215, 7.595757484436035, 7.546516418457031, 7.511697769165039, 7.571395397186279, 7.4689764976501465, 7.57902193069458, 7.713461399078369, 7.560181617736816, 8.297147750854492, 7.518460273742676, 7.4568095207214355, 7.268975257873535, 7.254395008087158, 7.56371545791626, 7.471786022186279, 7.590061187744141, 7.562471389770508, 7.503381252288818, 7.495607376098633, 7.2765421867370605, 7.481488227844238, 7.3226318359375, 7.628744602203369, 7.242749214172363, 7.314420223236084, 7.328615188598633, 7.405089855194092, 7.289292335510254, 7.419526100158691, 7.361505031585693, 7.493122100830078, 7.792146682739258, 7.4455132484436035, 7.373596668243408, 7.540046215057373, 7.75590181350708, 7.299835205078125, 7.315021991729736, 7.491583347320557, 7.23469877243042, 7.367035388946533, 7.567389965057373, 7.769525527954102, 7.614796161651611, 7.5681657791137695, 7.747832298278809, 7.108214378356934, 7.605166435241699, 7.48273229598999, 7.607443332672119, 7.321771621704102, 7.2200236320495605, 7.475554466247559, 7.258472442626953, 7.237623691558838, 7.513622283935547, 7.337228298187256, 7.5133538246154785, 7.488371849060059, 7.297241687774658, 7.409079551696777, 7.471048355102539, 7.309163570404053, 7.451704502105713, 7.756560325622559, 7.510455131530762, 7.595891952514648, 7.231539249420166, 7.492089748382568, 7.432817459106445, 7.684630393981934, 7.435182094573975, 7.343773365020752, 7.911438465118408, 7.300354957580566, 7.367172718048096, 7.49113130569458, 7.848761558532715, 7.306474685668945, 7.540780544281006, 7.958479404449463, 7.352503776550293, 7.4467363357543945, 7.511361122131348, 7.341329574584961, 7.401153564453125, 7.423519134521484, 7.662937641143799, 7.063897132873535, 7.544241905212402, 7.2718281745910645, 7.376341342926025, 7.652544975280762, 7.349192142486572, 7.432727336883545, 7.404220104217529, 7.313717365264893, 7.275409698486328, 7.738504409790039, 8.143855094909668, 7.378580570220947, 7.371863842010498, 7.322235107421875, 7.704600811004639, 7.437372207641602, 7.6815900802612305, 7.403874397277832, 7.674103736877441, 7.499970436096191, 7.413076400756836, 7.685664653778076, 7.186652660369873, 7.235022068023682, 7.632424831390381, 7.501607418060303, 7.66984224319458, 7.538605690002441, 7.736772537231445, 7.435154914855957, 7.666650295257568, 7.448475360870361, 7.32544469833374, 7.7294769287109375, 7.4964470863342285, 7.324901580810547, 7.578285217285156, 7.350534439086914, 7.415495872497559, 7.4195685386657715, 8.250676155090332, 7.324530124664307, 7.413590908050537, 7.252496719360352, 7.298442363739014, 7.229869842529297, 7.3989338874816895, 7.494974136352539, 7.668436050415039, 7.4041924476623535, 7.3464765548706055, 7.271403789520264, 7.487820148468018, 7.3334832191467285, 7.385288715362549, 8.291670799255371, 7.803550720214844, 7.497982501983643, 7.420011043548584, 7.435054302215576, 7.720251560211182, 7.428760528564453, 7.233610153198242, 7.335634231567383, 7.371745586395264, 7.271305084228516, 7.3126935958862305, 7.5594868659973145, 7.549189567565918, 7.894103050231934, 7.686339378356934, 7.205634117126465, 7.2212042808532715, 7.4082207679748535, 7.4041361808776855, 7.439481735229492, 7.224646091461182, 7.466142177581787, 7.530578136444092, 7.39231014251709, 7.569242000579834, 7.797896385192871, 7.391039848327637, 7.313684463500977, 7.454634189605713, 7.68795919418335, 7.341432571411133, 7.540189743041992, 7.797643184661865, 7.788633823394775, 7.466287136077881, 7.327414512634277, 7.2572832107543945, 7.4139180183410645, 7.29697322845459, 7.214540481567383, 7.293539524078369, 7.656585216522217, 7.514833450317383, 7.37240743637085, 7.569990634918213, 7.5901103019714355, 7.561797142028809, 7.437921047210693, 7.465240001678467, 7.331579208374023, 7.556181907653809, 7.327072620391846, 7.438811779022217, 7.217933177947998, 7.58071756362915, 7.568066120147705, 7.486297130584717, 7.333456993103027, 7.35573148727417, 7.374902248382568, 7.668228626251221, 7.228268146514893, 7.338449954986572, 7.38707971572876, 7.671877384185791, 7.417130470275879, 8.005510330200195, 7.34999942779541, 7.7368245124816895, 7.78212833404541, 7.4751715660095215, 7.507565975189209, 7.692163467407227, 7.9448089599609375, 7.544606685638428, 7.475640296936035, 7.749793529510498, 7.951901912689209, 7.749085426330566, 7.393958568572998, 7.368772506713867, 7.515501499176025, 7.549148082733154, 7.787380218505859, 7.270851135253906, 7.37550687789917, 7.79645299911499, 7.956548690795898, 7.566105842590332, 7.46633768081665, 7.558485507965088, 7.418476104736328, 7.353802680969238, 7.343263626098633, 7.637775897979736, 7.23300313949585, 7.945333957672119, 7.2545695304870605, 8.317283630371094, 7.33290958404541, 7.267285346984863, 7.236236095428467, 7.378102779388428, 7.356501579284668, 8.198495864868164, 7.38647985458374, 7.270951747894287, 7.6559224128723145, 7.542638301849365, 7.4999847412109375, 7.4095001220703125, 7.67616081237793, 7.545944690704346, 7.612507343292236, 7.572228908538818, 7.5078935623168945, 7.449032783508301, 7.438408851623535, 7.771162509918213, 7.343966484069824, 7.530837535858154, 7.489939212799072, 7.569748878479004, 7.86998987197876, 7.719673156738281, 7.260923385620117, 7.980086326599121, 7.572344779968262, 7.615109443664551, 7.688097953796387, 7.787471771240234, 7.376122951507568, 7.531900882720947, 7.261955738067627, 7.255548000335693, 7.331073760986328, 7.468209266662598, 7.5411295890808105, 7.386450290679932, 7.346527099609375, 7.577805042266846, 7.918816089630127, 7.482960224151611, 7.388946533203125, 7.587639808654785, 7.17969274520874, 7.523281574249268, 7.50456428527832, 7.416429042816162, 7.339325904846191, 7.402655124664307, 7.622929096221924, 7.492231845855713, 7.637124061584473, 7.610132217407227, 7.510634422302246, 7.9046854972839355, 7.548928737640381, 7.42680549621582, 7.360110759735107, 7.425547122955322, 7.4748640060424805, 7.366986274719238, 7.533141613006592, 7.35538911819458, 7.3434295654296875, 7.639111518859863, 7.597356796264648, 7.9146318435668945, 7.313751220703125, 7.3741350173950195, 7.850481033325195, 7.603645324707031, 7.693511486053467, 7.394474029541016, 7.570216178894043, 7.744267463684082, 7.749715805053711, 7.554206848144531, 7.2599639892578125, 7.5274434089660645, 7.215785026550293, 7.3917670249938965, 7.9199395179748535, 7.348679542541504, 7.391563415527344, 7.6714277267456055, 7.188451290130615, 7.449805736541748, 7.328275680541992, 7.776558876037598, 7.397372245788574, 7.719232559204102, 7.296184062957764, 7.80571985244751, 7.243964672088623, 7.140333652496338, 7.902876377105713, 7.496584415435791, 7.240021705627441, 7.979335784912109, 7.3811936378479, 7.40289306640625, 7.453632354736328, 7.343392372131348, 7.420419692993164, 7.622253894805908, 7.460494041442871, 7.9807329177856445, 7.496581554412842, 7.591699123382568, 7.47067928314209, 7.370632171630859, 7.5108232498168945, 7.274337291717529, 7.439083099365234, 7.5267438888549805, 7.417949199676514, 7.349658012390137, 7.429988861083984, 7.498034954071045, 7.4283766746521, 7.466954708099365, 7.446662902832031, 7.419280529022217, 7.642242431640625, 7.700812339782715, 7.47114372253418, 7.4396538734436035, 7.436498641967773, 7.236381530761719, 7.366120338439941]}\n",
      "Minimum validation loss: 7.006972789764404\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(history)\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot()\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))\n",
    "\n",
    "# plt.plot(history.history['accuracy'], label='accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.ylim([0.5, 1])\n",
    "# plt.legend(loc='lower right')\n",
    "\n",
    "# test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_acc)\n",
    "\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: out\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: out\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('out')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
