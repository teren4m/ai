{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from model_profiler import model_profiler\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "batch_size = 90\n",
    "epoch_size = 2500\n",
    "test_len = 8\n",
    "conv_factor = 8\n",
    "dense_base = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape\n",
      "(79, 53)\n",
      "\n",
      "output shape\n",
      "(82,)\n"
     ]
    }
   ],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "def get_txt_data(path: Path) -> np.ndarray:\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        result: list = json.loads(f.readline())\n",
    "        return np.array(flatten(result))\n",
    "\n",
    "\n",
    "input_data: np.ndarray = np.load('data/train_input.npy')\n",
    "output_data: np.ndarray = np.load('data/train_output.npy')\n",
    "input_shape = input_data.shape[1:]\n",
    "output_shape = output_data.shape[1:]\n",
    "\n",
    "print('input shape')\n",
    "print(input_shape)\n",
    "print()\n",
    "print('output shape')\n",
    "print(output_shape)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    l = len(input_data)\n",
    "    last = l - 1\n",
    "    first = int(l-l/test_len)\n",
    "    train_images = input_data[0:first]\n",
    "    train_labels = output_data[0:first]\n",
    "\n",
    "    test_images = input_data[first:last]\n",
    "    test_labels = output_data[first:last]\n",
    "    print('Train shape: {}'.format(train_images.shape))\n",
    "    print('Test shape: {}'.format(test_images.shape))\n",
    "    print('Test labels shape: {}'.format(test_labels.shape))\n",
    "\n",
    "    return (train_images, train_labels), (test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (18061, 79, 53)\n",
      "Test shape: (2580, 79, 53)\n",
      "Test labels shape: (2580, 82)\n",
      "4187\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_data()\n",
    "input_shape = train_images.shape[1:3]\n",
    "labels_shape = test_labels.shape[1]\n",
    "print(np.prod(input_shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 79, 53)           3         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 48, 32)            54304     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 24, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 19, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 9, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               295424    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 82)                42066     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 666,805\n",
      "Trainable params: 666,802\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "normalization = tf.keras.layers.Normalization(axis=None)\n",
    "normalization.adapt([0,255.0])\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Input(input_shape))\n",
    "model.add(normalization)\n",
    "model.add(tf.keras.layers.Conv1D(4 * conv_factor, 32, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(2))\n",
    "model.add(tf.keras.layers.Conv1D(4 * conv_factor * 2,6, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(dense_base * conv_factor, 'relu'))\n",
    "model.add(tf.keras.layers.Dense(dense_base * conv_factor, 'relu'))\n",
    "model.add(tf.keras.layers.Dense(labels_shape))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = model_profiler(model, batch_size)\n",
    "\n",
    "# print(profile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "201/201 [==============================] - 5s 4ms/step - loss: 134.4098 - val_loss: 111.1903\n",
      "Epoch 2/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 108.5585 - val_loss: 104.0142\n",
      "Epoch 3/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 93.6522 - val_loss: 88.7211\n",
      "Epoch 4/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 81.9254 - val_loss: 78.8986\n",
      "Epoch 5/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 75.6906 - val_loss: 75.3190\n",
      "Epoch 6/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 71.9704 - val_loss: 73.4233\n",
      "Epoch 7/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 68.5311 - val_loss: 67.8646\n",
      "Epoch 8/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 65.5187 - val_loss: 65.9167\n",
      "Epoch 9/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 62.7521 - val_loss: 63.4445\n",
      "Epoch 10/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 60.4405 - val_loss: 61.0452\n",
      "Epoch 11/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 57.9272 - val_loss: 58.6950\n",
      "Epoch 12/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 55.5800 - val_loss: 57.1254\n",
      "Epoch 13/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 53.9005 - val_loss: 54.0960\n",
      "Epoch 14/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 51.4421 - val_loss: 54.2487\n",
      "Epoch 15/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 50.3149 - val_loss: 52.4965\n",
      "Epoch 16/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 48.5715 - val_loss: 50.7985\n",
      "Epoch 17/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 47.2499 - val_loss: 49.7830\n",
      "Epoch 18/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 45.9428 - val_loss: 47.6093\n",
      "Epoch 19/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 44.8152 - val_loss: 48.9690\n",
      "Epoch 20/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 43.6287 - val_loss: 47.7178\n",
      "Epoch 21/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 44.0601 - val_loss: 45.2832\n",
      "Epoch 22/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 41.8797 - val_loss: 48.4236\n",
      "Epoch 23/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 41.8935 - val_loss: 43.1768\n",
      "Epoch 24/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 39.8099 - val_loss: 42.5502\n",
      "Epoch 25/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 38.8618 - val_loss: 43.7852\n",
      "Epoch 26/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 38.3277 - val_loss: 42.4244\n",
      "Epoch 27/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 37.4827 - val_loss: 40.7763\n",
      "Epoch 28/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 37.4729 - val_loss: 41.4500\n",
      "Epoch 29/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 35.9288 - val_loss: 40.5645\n",
      "Epoch 30/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 35.9191 - val_loss: 39.2833\n",
      "Epoch 31/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 34.2582 - val_loss: 37.4020\n",
      "Epoch 32/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 33.5286 - val_loss: 38.1753\n",
      "Epoch 33/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 32.9648 - val_loss: 35.9468\n",
      "Epoch 34/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 31.4714 - val_loss: 35.7014\n",
      "Epoch 35/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 30.7583 - val_loss: 35.4538\n",
      "Epoch 36/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 29.3848 - val_loss: 34.0207\n",
      "Epoch 37/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 28.1271 - val_loss: 31.2117\n",
      "Epoch 38/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 27.6155 - val_loss: 31.6435\n",
      "Epoch 39/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 26.7093 - val_loss: 29.1986\n",
      "Epoch 40/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 26.4834 - val_loss: 29.6567\n",
      "Epoch 41/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 24.9872 - val_loss: 29.2665\n",
      "Epoch 42/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 25.7219 - val_loss: 29.4200\n",
      "Epoch 43/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 24.1046 - val_loss: 28.9239\n",
      "Epoch 44/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 23.8533 - val_loss: 29.2975\n",
      "Epoch 45/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 22.8696 - val_loss: 26.3840\n",
      "Epoch 46/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 23.3542 - val_loss: 27.8875\n",
      "Epoch 47/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 22.1967 - val_loss: 26.5076\n",
      "Epoch 48/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 21.5425 - val_loss: 26.6002\n",
      "Epoch 49/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 21.1090 - val_loss: 25.2826\n",
      "Epoch 50/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 21.5972 - val_loss: 25.8136\n",
      "Epoch 51/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 21.3178 - val_loss: 25.0697\n",
      "Epoch 52/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 20.5672 - val_loss: 24.3795\n",
      "Epoch 53/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 19.8141 - val_loss: 24.6586\n",
      "Epoch 54/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 19.5475 - val_loss: 24.2014\n",
      "Epoch 55/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 19.2098 - val_loss: 24.2147\n",
      "Epoch 56/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 19.0083 - val_loss: 23.0294\n",
      "Epoch 57/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 19.0270 - val_loss: 23.8163\n",
      "Epoch 58/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 18.3195 - val_loss: 23.9697\n",
      "Epoch 59/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 17.9081 - val_loss: 22.5968\n",
      "Epoch 60/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 17.6803 - val_loss: 21.9802\n",
      "Epoch 61/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 17.8277 - val_loss: 23.4507\n",
      "Epoch 62/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 17.1388 - val_loss: 22.1854\n",
      "Epoch 63/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 17.3065 - val_loss: 21.7503\n",
      "Epoch 64/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 17.1043 - val_loss: 23.1532\n",
      "Epoch 65/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 16.3202 - val_loss: 21.2650\n",
      "Epoch 66/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 16.4000 - val_loss: 20.5753\n",
      "Epoch 67/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 15.8719 - val_loss: 20.9205\n",
      "Epoch 68/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 15.9744 - val_loss: 20.4964\n",
      "Epoch 69/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 16.2330 - val_loss: 20.6840\n",
      "Epoch 70/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 15.5621 - val_loss: 20.3749\n",
      "Epoch 71/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 15.2162 - val_loss: 20.3077\n",
      "Epoch 72/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 15.0530 - val_loss: 19.7993\n",
      "Epoch 73/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 15.9541 - val_loss: 20.0430\n",
      "Epoch 74/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 14.6776 - val_loss: 19.3161\n",
      "Epoch 75/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 14.6132 - val_loss: 19.8802\n",
      "Epoch 76/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 14.6887 - val_loss: 22.2158\n",
      "Epoch 77/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 15.2827 - val_loss: 19.6440\n",
      "Epoch 78/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 14.3496 - val_loss: 19.3887\n",
      "Epoch 79/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 14.0567 - val_loss: 19.1395\n",
      "Epoch 80/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 13.6982 - val_loss: 20.9430\n",
      "Epoch 81/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 13.1537 - val_loss: 20.3843\n",
      "Epoch 82/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 14.0788 - val_loss: 19.4888\n",
      "Epoch 83/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 13.5665 - val_loss: 18.6981\n",
      "Epoch 84/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 13.4226 - val_loss: 19.3766\n",
      "Epoch 85/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 13.2975 - val_loss: 19.3519\n",
      "Epoch 86/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 12.7159 - val_loss: 18.5159\n",
      "Epoch 87/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 13.6627 - val_loss: 18.4551\n",
      "Epoch 88/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 12.7166 - val_loss: 18.7532\n",
      "Epoch 89/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 13.6965 - val_loss: 19.5229\n",
      "Epoch 90/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 12.7308 - val_loss: 19.2271\n",
      "Epoch 91/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 12.2752 - val_loss: 18.0729\n",
      "Epoch 92/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 12.0919 - val_loss: 17.6944\n",
      "Epoch 93/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 12.3240 - val_loss: 18.2225\n",
      "Epoch 94/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 11.9987 - val_loss: 17.2047\n",
      "Epoch 95/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 11.9000 - val_loss: 18.6545\n",
      "Epoch 96/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 12.1239 - val_loss: 18.5711\n",
      "Epoch 97/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 11.7028 - val_loss: 17.8801\n",
      "Epoch 98/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 11.8301 - val_loss: 17.8579\n",
      "Epoch 99/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 11.3761 - val_loss: 18.2273\n",
      "Epoch 100/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 12.2705 - val_loss: 17.9441\n",
      "Epoch 101/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 11.4686 - val_loss: 16.9592\n",
      "Epoch 102/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 11.0748 - val_loss: 16.5789\n",
      "Epoch 103/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.9247 - val_loss: 16.2423\n",
      "Epoch 104/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.9417 - val_loss: 16.7451\n",
      "Epoch 105/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.8093 - val_loss: 16.2714\n",
      "Epoch 106/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 11.3930 - val_loss: 17.6843\n",
      "Epoch 107/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.8948 - val_loss: 17.7243\n",
      "Epoch 108/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.8262 - val_loss: 16.0768\n",
      "Epoch 109/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.6254 - val_loss: 16.4145\n",
      "Epoch 110/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.8537 - val_loss: 16.3267\n",
      "Epoch 111/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.6827 - val_loss: 19.7059\n",
      "Epoch 112/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.9040 - val_loss: 16.8393\n",
      "Epoch 113/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.5657 - val_loss: 16.6740\n",
      "Epoch 114/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.0085 - val_loss: 16.0722\n",
      "Epoch 115/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.4341 - val_loss: 16.0597\n",
      "Epoch 116/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 11.0613 - val_loss: 15.6822\n",
      "Epoch 117/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.0287 - val_loss: 15.9818\n",
      "Epoch 118/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.4760 - val_loss: 15.8644\n",
      "Epoch 119/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.8197 - val_loss: 16.6557\n",
      "Epoch 120/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.7647 - val_loss: 15.8562\n",
      "Epoch 121/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.8313 - val_loss: 15.2995\n",
      "Epoch 122/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.9857 - val_loss: 15.5912\n",
      "Epoch 123/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.4832 - val_loss: 16.4711\n",
      "Epoch 124/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.4086 - val_loss: 15.4389\n",
      "Epoch 125/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.7362 - val_loss: 15.2371\n",
      "Epoch 126/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.4172 - val_loss: 15.7132\n",
      "Epoch 127/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.0321 - val_loss: 15.5557\n",
      "Epoch 128/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.1199 - val_loss: 15.6837\n",
      "Epoch 129/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.1980 - val_loss: 14.9393\n",
      "Epoch 130/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 10.1643 - val_loss: 15.1903\n",
      "Epoch 131/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.9877 - val_loss: 14.7591\n",
      "Epoch 132/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.3466 - val_loss: 15.1043\n",
      "Epoch 133/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.6736 - val_loss: 14.5839\n",
      "Epoch 134/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.8806 - val_loss: 15.0913\n",
      "Epoch 135/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.1160 - val_loss: 16.5700\n",
      "Epoch 136/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.0980 - val_loss: 14.7471\n",
      "Epoch 137/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.7350 - val_loss: 14.1958\n",
      "Epoch 138/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.6104 - val_loss: 14.2986\n",
      "Epoch 139/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.3434 - val_loss: 14.3296\n",
      "Epoch 140/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.6954 - val_loss: 14.7703\n",
      "Epoch 141/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.0290 - val_loss: 14.0092\n",
      "Epoch 142/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.4308 - val_loss: 14.2633\n",
      "Epoch 143/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.2555 - val_loss: 14.4684\n",
      "Epoch 144/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.3963 - val_loss: 13.8680\n",
      "Epoch 145/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.3908 - val_loss: 14.2515\n",
      "Epoch 146/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.9849 - val_loss: 14.3663\n",
      "Epoch 147/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.7588 - val_loss: 16.1899\n",
      "Epoch 148/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.0053 - val_loss: 14.2994\n",
      "Epoch 149/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.4741 - val_loss: 14.6223\n",
      "Epoch 150/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.4684 - val_loss: 14.3186\n",
      "Epoch 151/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.1921 - val_loss: 14.2804\n",
      "Epoch 152/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.2417 - val_loss: 14.3113\n",
      "Epoch 153/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 9.9688 - val_loss: 14.6758\n",
      "Epoch 154/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.0454 - val_loss: 13.7666\n",
      "Epoch 155/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.1126 - val_loss: 13.4741\n",
      "Epoch 156/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.8495 - val_loss: 13.3202\n",
      "Epoch 157/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.9167 - val_loss: 13.8073\n",
      "Epoch 158/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.9451 - val_loss: 13.6455\n",
      "Epoch 159/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.8614 - val_loss: 13.3268\n",
      "Epoch 160/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.4162 - val_loss: 13.7971\n",
      "Epoch 161/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.9902 - val_loss: 14.0032\n",
      "Epoch 162/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.1581 - val_loss: 14.3089\n",
      "Epoch 163/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.9127 - val_loss: 14.1948\n",
      "Epoch 164/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.9555 - val_loss: 13.4793\n",
      "Epoch 165/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.7448 - val_loss: 14.3146\n",
      "Epoch 166/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.8916 - val_loss: 14.4443\n",
      "Epoch 167/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.6652 - val_loss: 14.4003\n",
      "Epoch 168/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.4500 - val_loss: 13.4631\n",
      "Epoch 169/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.5450 - val_loss: 13.5099\n",
      "Epoch 170/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.6466 - val_loss: 13.0353\n",
      "Epoch 171/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.6743 - val_loss: 14.1948\n",
      "Epoch 172/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.6453 - val_loss: 13.7244\n",
      "Epoch 173/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.6138 - val_loss: 12.8786\n",
      "Epoch 174/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.0512 - val_loss: 15.9106\n",
      "Epoch 175/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.6088 - val_loss: 13.5017\n",
      "Epoch 176/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 8.2053 - val_loss: 13.4965\n",
      "Epoch 177/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.4598 - val_loss: 13.4004\n",
      "Epoch 178/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.3528 - val_loss: 12.8645\n",
      "Epoch 179/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.0478 - val_loss: 12.5859\n",
      "Epoch 180/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.7933 - val_loss: 12.9093\n",
      "Epoch 181/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.7696 - val_loss: 13.2145\n",
      "Epoch 182/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.9285 - val_loss: 12.8003\n",
      "Epoch 183/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.3753 - val_loss: 12.9840\n",
      "Epoch 184/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.2587 - val_loss: 13.7998\n",
      "Epoch 185/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.1716 - val_loss: 13.2040\n",
      "Epoch 186/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.1761 - val_loss: 13.0469\n",
      "Epoch 187/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.1086 - val_loss: 13.7533\n",
      "Epoch 188/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.5445 - val_loss: 13.1032\n",
      "Epoch 189/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.1161 - val_loss: 14.1104\n",
      "Epoch 190/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.2085 - val_loss: 12.8814\n",
      "Epoch 191/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.1263 - val_loss: 12.9989\n",
      "Epoch 192/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.1069 - val_loss: 12.9267\n",
      "Epoch 193/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.1557 - val_loss: 13.4848\n",
      "Epoch 194/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.9374 - val_loss: 13.0096\n",
      "Epoch 195/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.8761 - val_loss: 13.1276\n",
      "Epoch 196/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.5104 - val_loss: 12.6414\n",
      "Epoch 197/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.5508 - val_loss: 13.5876\n",
      "Epoch 198/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.5267 - val_loss: 13.2571\n",
      "Epoch 199/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.8482 - val_loss: 12.8404\n",
      "Epoch 200/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.5746 - val_loss: 13.1347\n",
      "Epoch 201/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.7055 - val_loss: 13.8328\n",
      "Epoch 202/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.9619 - val_loss: 13.7468\n",
      "Epoch 203/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.7199 - val_loss: 12.8592\n",
      "Epoch 204/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.8987 - val_loss: 13.0815\n",
      "Epoch 205/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.7821 - val_loss: 13.1140\n",
      "Epoch 206/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.7540 - val_loss: 12.9541\n",
      "Epoch 207/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.2287 - val_loss: 12.5670\n",
      "Epoch 208/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.8684 - val_loss: 13.2172\n",
      "Epoch 209/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.5620 - val_loss: 13.1124\n",
      "Epoch 210/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.8996 - val_loss: 13.4520\n",
      "Epoch 211/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.6476 - val_loss: 14.0731\n",
      "Epoch 212/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.7521 - val_loss: 12.7407\n",
      "Epoch 213/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.6534 - val_loss: 13.5205\n",
      "Epoch 214/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.8748 - val_loss: 12.7175\n",
      "Epoch 215/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.4440 - val_loss: 12.8299\n",
      "Epoch 216/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.3861 - val_loss: 12.7995\n",
      "Epoch 217/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.7798 - val_loss: 13.1965\n",
      "Epoch 218/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.4655 - val_loss: 12.8267\n",
      "Epoch 219/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.6179 - val_loss: 13.6939\n",
      "Epoch 220/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.1270 - val_loss: 12.5223\n",
      "Epoch 221/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 7.1796 - val_loss: 12.7608\n",
      "Epoch 222/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.4481 - val_loss: 12.3639\n",
      "Epoch 223/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.4137 - val_loss: 12.4144\n",
      "Epoch 224/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.6212 - val_loss: 12.9059\n",
      "Epoch 225/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.1984 - val_loss: 12.2209\n",
      "Epoch 226/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.9062 - val_loss: 16.3159\n",
      "Epoch 227/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.5159 - val_loss: 12.3781\n",
      "Epoch 228/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.8067 - val_loss: 12.6785\n",
      "Epoch 229/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.3082 - val_loss: 12.8283\n",
      "Epoch 230/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.2649 - val_loss: 12.8704\n",
      "Epoch 231/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.7754 - val_loss: 12.2216\n",
      "Epoch 232/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.3875 - val_loss: 12.2948\n",
      "Epoch 233/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.2465 - val_loss: 12.6019\n",
      "Epoch 234/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.9232 - val_loss: 12.5368\n",
      "Epoch 235/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.1809 - val_loss: 12.1655\n",
      "Epoch 236/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.5571 - val_loss: 13.5157\n",
      "Epoch 237/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.1500 - val_loss: 12.2510\n",
      "Epoch 238/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.8114 - val_loss: 11.8941\n",
      "Epoch 239/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.9587 - val_loss: 12.7326\n",
      "Epoch 240/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.7272 - val_loss: 12.2884\n",
      "Epoch 241/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.4103 - val_loss: 12.3291\n",
      "Epoch 242/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.2066 - val_loss: 12.0983\n",
      "Epoch 243/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.1685 - val_loss: 12.0246\n",
      "Epoch 244/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.1849 - val_loss: 12.9497\n",
      "Epoch 245/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.4806 - val_loss: 12.1929\n",
      "Epoch 246/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.0488 - val_loss: 13.0691\n",
      "Epoch 247/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.9588 - val_loss: 12.0651\n",
      "Epoch 248/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.1177 - val_loss: 12.2641\n",
      "Epoch 249/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.8892 - val_loss: 12.3608\n",
      "Epoch 250/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.2482 - val_loss: 12.1489\n",
      "Epoch 251/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.7344 - val_loss: 12.2667\n",
      "Epoch 252/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.9688 - val_loss: 12.2385\n",
      "Epoch 253/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.9468 - val_loss: 12.0799\n",
      "Epoch 254/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.9956 - val_loss: 12.6773\n",
      "Epoch 255/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.2019 - val_loss: 12.2252\n",
      "Epoch 256/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.0182 - val_loss: 13.1179\n",
      "Epoch 257/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.9309 - val_loss: 12.8089\n",
      "Epoch 258/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.0109 - val_loss: 12.1277\n",
      "Epoch 259/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.5919 - val_loss: 12.4663\n",
      "Epoch 260/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.2078 - val_loss: 12.4079\n",
      "Epoch 261/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.6118 - val_loss: 11.7673\n",
      "Epoch 262/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.3681 - val_loss: 11.8521\n",
      "Epoch 263/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.6900 - val_loss: 12.0903\n",
      "Epoch 264/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.0049 - val_loss: 11.8387\n",
      "Epoch 265/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.8190 - val_loss: 12.4944\n",
      "Epoch 266/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.9639 - val_loss: 11.8088\n",
      "Epoch 267/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.7715 - val_loss: 12.1994\n",
      "Epoch 268/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.5923 - val_loss: 12.1664\n",
      "Epoch 269/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.0035 - val_loss: 11.8030\n",
      "Epoch 270/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.7504 - val_loss: 11.8403\n",
      "Epoch 271/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.5868 - val_loss: 12.6174\n",
      "Epoch 272/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.7347 - val_loss: 12.1195\n",
      "Epoch 273/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.6148 - val_loss: 11.5707\n",
      "Epoch 274/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.6044 - val_loss: 11.7285\n",
      "Epoch 275/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.5387 - val_loss: 11.4233\n",
      "Epoch 276/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.9109 - val_loss: 11.9097\n",
      "Epoch 277/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.9216 - val_loss: 12.7849\n",
      "Epoch 278/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.5807 - val_loss: 11.5827\n",
      "Epoch 279/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.6240 - val_loss: 11.7592\n",
      "Epoch 280/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.5679 - val_loss: 11.7962\n",
      "Epoch 281/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.5522 - val_loss: 12.6495\n",
      "Epoch 282/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.1324 - val_loss: 12.1469\n",
      "Epoch 283/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.6892 - val_loss: 11.7037\n",
      "Epoch 284/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.4436 - val_loss: 12.4033\n",
      "Epoch 285/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.6499 - val_loss: 11.5827\n",
      "Epoch 286/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.7505 - val_loss: 11.4691\n",
      "Epoch 287/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.3832 - val_loss: 12.1958\n",
      "Epoch 288/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.8060 - val_loss: 13.1126\n",
      "Epoch 289/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.9157 - val_loss: 11.9576\n",
      "Epoch 290/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.5574 - val_loss: 12.7664\n",
      "Epoch 291/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.7687 - val_loss: 11.9218\n",
      "Epoch 292/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.3478 - val_loss: 11.4359\n",
      "Epoch 293/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.9438 - val_loss: 11.6112\n",
      "Epoch 294/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.3190 - val_loss: 11.6819\n",
      "Epoch 295/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.4072 - val_loss: 11.6065\n",
      "Epoch 296/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.3841 - val_loss: 11.7025\n",
      "Epoch 297/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.9243 - val_loss: 12.1332\n",
      "Epoch 298/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.4654 - val_loss: 12.4075\n",
      "Epoch 299/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.3181 - val_loss: 11.8852\n",
      "Epoch 300/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.5174 - val_loss: 12.1662\n",
      "Epoch 301/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.6046 - val_loss: 12.1709\n",
      "Epoch 302/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.2850 - val_loss: 11.2915\n",
      "Epoch 303/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.3144 - val_loss: 11.4850\n",
      "Epoch 304/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.3747 - val_loss: 13.0001\n",
      "Epoch 305/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.9786 - val_loss: 11.2798\n",
      "Epoch 306/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.2193 - val_loss: 11.6968\n",
      "Epoch 307/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.1365 - val_loss: 11.5429\n",
      "Epoch 308/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.3538 - val_loss: 11.2019\n",
      "Epoch 309/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0812 - val_loss: 11.2038\n",
      "Epoch 310/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.3537 - val_loss: 12.1437\n",
      "Epoch 311/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.8726 - val_loss: 12.7079\n",
      "Epoch 312/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.3216 - val_loss: 12.0502\n",
      "Epoch 313/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.3788 - val_loss: 11.1424\n",
      "Epoch 314/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0376 - val_loss: 11.9307\n",
      "Epoch 315/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.4284 - val_loss: 11.4731\n",
      "Epoch 316/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.2515 - val_loss: 11.3811\n",
      "Epoch 317/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.2700 - val_loss: 11.3603\n",
      "Epoch 318/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.2251 - val_loss: 11.4031\n",
      "Epoch 319/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0219 - val_loss: 11.5559\n",
      "Epoch 320/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.2428 - val_loss: 11.2878\n",
      "Epoch 321/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.6319 - val_loss: 11.6992\n",
      "Epoch 322/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.2644 - val_loss: 13.5003\n",
      "Epoch 323/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.1687 - val_loss: 11.2291\n",
      "Epoch 324/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0891 - val_loss: 11.6811\n",
      "Epoch 325/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.3484 - val_loss: 11.2153\n",
      "Epoch 326/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.2876 - val_loss: 12.7789\n",
      "Epoch 327/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0804 - val_loss: 11.5663\n",
      "Epoch 328/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.2851 - val_loss: 11.6798\n",
      "Epoch 329/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.1921 - val_loss: 11.3953\n",
      "Epoch 330/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0495 - val_loss: 11.6713\n",
      "Epoch 331/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.7841 - val_loss: 11.6123\n",
      "Epoch 332/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0545 - val_loss: 11.3506\n",
      "Epoch 333/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0774 - val_loss: 11.7884\n",
      "Epoch 334/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.2431 - val_loss: 11.2615\n",
      "Epoch 335/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.8775 - val_loss: 14.0162\n",
      "Epoch 336/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.1457 - val_loss: 10.9900\n",
      "Epoch 337/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.9453 - val_loss: 11.4749\n",
      "Epoch 338/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.2479 - val_loss: 13.2408\n",
      "Epoch 339/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.2767 - val_loss: 11.7345\n",
      "Epoch 340/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.2360 - val_loss: 11.1266\n",
      "Epoch 341/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8699 - val_loss: 11.6523\n",
      "Epoch 342/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0212 - val_loss: 11.3665\n",
      "Epoch 343/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.9045 - val_loss: 11.7030\n",
      "Epoch 344/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.1115 - val_loss: 11.4961\n",
      "Epoch 345/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8350 - val_loss: 12.9525\n",
      "Epoch 346/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.7871 - val_loss: 11.6749\n",
      "Epoch 347/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0617 - val_loss: 11.2149\n",
      "Epoch 348/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0498 - val_loss: 11.3998\n",
      "Epoch 349/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.3417 - val_loss: 11.9754\n",
      "Epoch 350/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8772 - val_loss: 11.2604\n",
      "Epoch 351/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.9810 - val_loss: 12.0238\n",
      "Epoch 352/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0000 - val_loss: 11.2252\n",
      "Epoch 353/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.1960 - val_loss: 11.7903\n",
      "Epoch 354/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0358 - val_loss: 12.1131\n",
      "Epoch 355/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0197 - val_loss: 12.1641\n",
      "Epoch 356/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8771 - val_loss: 11.4550\n",
      "Epoch 357/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0024 - val_loss: 11.2638\n",
      "Epoch 358/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8028 - val_loss: 10.8210\n",
      "Epoch 359/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8731 - val_loss: 12.7823\n",
      "Epoch 360/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.4162 - val_loss: 11.2502\n",
      "Epoch 361/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0013 - val_loss: 12.2884\n",
      "Epoch 362/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8512 - val_loss: 10.9927\n",
      "Epoch 363/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8364 - val_loss: 11.1646\n",
      "Epoch 364/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.2614 - val_loss: 11.7158\n",
      "Epoch 365/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.8408 - val_loss: 11.8335\n",
      "Epoch 366/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0726 - val_loss: 11.0270\n",
      "Epoch 367/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6681 - val_loss: 11.0502\n",
      "Epoch 368/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7515 - val_loss: 10.9431\n",
      "Epoch 369/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7965 - val_loss: 11.1015\n",
      "Epoch 370/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.3468 - val_loss: 13.3921\n",
      "Epoch 371/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.9643 - val_loss: 11.2743\n",
      "Epoch 372/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.9025 - val_loss: 11.4978\n",
      "Epoch 373/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.9347 - val_loss: 12.3573\n",
      "Epoch 374/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0286 - val_loss: 11.0439\n",
      "Epoch 375/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.1086 - val_loss: 11.0160\n",
      "Epoch 376/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.9039 - val_loss: 11.4108\n",
      "Epoch 377/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6719 - val_loss: 10.9675\n",
      "Epoch 378/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8011 - val_loss: 11.4791\n",
      "Epoch 379/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8080 - val_loss: 11.1369\n",
      "Epoch 380/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8409 - val_loss: 11.1205\n",
      "Epoch 381/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7684 - val_loss: 11.5191\n",
      "Epoch 382/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6848 - val_loss: 11.6884\n",
      "Epoch 383/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8044 - val_loss: 11.5333\n",
      "Epoch 384/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.1126 - val_loss: 11.4382\n",
      "Epoch 385/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8262 - val_loss: 11.0686\n",
      "Epoch 386/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7713 - val_loss: 11.1573\n",
      "Epoch 387/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7002 - val_loss: 15.0483\n",
      "Epoch 388/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.1486 - val_loss: 10.8160\n",
      "Epoch 389/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6569 - val_loss: 11.1448\n",
      "Epoch 390/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6998 - val_loss: 10.8066\n",
      "Epoch 391/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7853 - val_loss: 10.9032\n",
      "Epoch 392/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7185 - val_loss: 11.0656\n",
      "Epoch 393/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5180 - val_loss: 11.1536\n",
      "Epoch 394/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.1814 - val_loss: 11.5358\n",
      "Epoch 395/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7206 - val_loss: 11.1448\n",
      "Epoch 396/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5634 - val_loss: 11.4529\n",
      "Epoch 397/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6820 - val_loss: 11.3670\n",
      "Epoch 398/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6113 - val_loss: 10.8196\n",
      "Epoch 399/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7175 - val_loss: 11.3023\n",
      "Epoch 400/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4882 - val_loss: 11.0547\n",
      "Epoch 401/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8056 - val_loss: 12.0149\n",
      "Epoch 402/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.1403 - val_loss: 11.7185\n",
      "Epoch 403/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7118 - val_loss: 10.5995\n",
      "Epoch 404/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8741 - val_loss: 12.1515\n",
      "Epoch 405/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7465 - val_loss: 10.9652\n",
      "Epoch 406/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4183 - val_loss: 11.0362\n",
      "Epoch 407/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5772 - val_loss: 11.1747\n",
      "Epoch 408/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4166 - val_loss: 11.7185\n",
      "Epoch 409/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7517 - val_loss: 11.5249\n",
      "Epoch 410/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6744 - val_loss: 10.9928\n",
      "Epoch 411/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4505 - val_loss: 11.0088\n",
      "Epoch 412/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6712 - val_loss: 11.2701\n",
      "Epoch 413/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.4936 - val_loss: 12.4295\n",
      "Epoch 414/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7041 - val_loss: 10.6918\n",
      "Epoch 415/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7692 - val_loss: 12.6796\n",
      "Epoch 416/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6498 - val_loss: 11.2636\n",
      "Epoch 417/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4651 - val_loss: 13.3355\n",
      "Epoch 418/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4916 - val_loss: 11.5453\n",
      "Epoch 419/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2837 - val_loss: 10.8748\n",
      "Epoch 420/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6614 - val_loss: 11.2681\n",
      "Epoch 421/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6787 - val_loss: 11.4617\n",
      "Epoch 422/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4355 - val_loss: 11.2740\n",
      "Epoch 423/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7232 - val_loss: 11.1960\n",
      "Epoch 424/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5225 - val_loss: 11.1739\n",
      "Epoch 425/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4962 - val_loss: 11.2551\n",
      "Epoch 426/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7056 - val_loss: 11.2038\n",
      "Epoch 427/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6929 - val_loss: 11.4023\n",
      "Epoch 428/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4578 - val_loss: 11.2551\n",
      "Epoch 429/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.5336 - val_loss: 11.7176\n",
      "Epoch 430/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4554 - val_loss: 11.8196\n",
      "Epoch 431/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5229 - val_loss: 10.8679\n",
      "Epoch 432/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.1294 - val_loss: 11.4247\n",
      "Epoch 433/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7631 - val_loss: 11.4746\n",
      "Epoch 434/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3177 - val_loss: 10.6479\n",
      "Epoch 435/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3524 - val_loss: 11.2132\n",
      "Epoch 436/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2868 - val_loss: 11.2982\n",
      "Epoch 437/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5704 - val_loss: 11.3130\n",
      "Epoch 438/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6317 - val_loss: 11.4827\n",
      "Epoch 439/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5145 - val_loss: 10.7291\n",
      "Epoch 440/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3462 - val_loss: 11.0297\n",
      "Epoch 441/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.1478 - val_loss: 12.2712\n",
      "Epoch 442/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8158 - val_loss: 10.8055\n",
      "Epoch 443/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.9042 - val_loss: 10.9444\n",
      "Epoch 444/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5157 - val_loss: 10.9429\n",
      "Epoch 445/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8905 - val_loss: 11.0222\n",
      "Epoch 446/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1375 - val_loss: 10.8085\n",
      "Epoch 447/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6917 - val_loss: 11.1244\n",
      "Epoch 448/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3251 - val_loss: 11.3838\n",
      "Epoch 449/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4709 - val_loss: 11.0207\n",
      "Epoch 450/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5116 - val_loss: 11.3178\n",
      "Epoch 451/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2982 - val_loss: 10.6687\n",
      "Epoch 452/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3041 - val_loss: 10.8312\n",
      "Epoch 453/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5829 - val_loss: 11.3983\n",
      "Epoch 454/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3714 - val_loss: 11.1182\n",
      "Epoch 455/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3798 - val_loss: 10.8239\n",
      "Epoch 456/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5297 - val_loss: 11.0174\n",
      "Epoch 457/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1995 - val_loss: 10.9377\n",
      "Epoch 458/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2925 - val_loss: 10.7440\n",
      "Epoch 459/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8629 - val_loss: 11.2234\n",
      "Epoch 460/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5040 - val_loss: 10.6124\n",
      "Epoch 461/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4304 - val_loss: 10.7165\n",
      "Epoch 462/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4505 - val_loss: 12.0566\n",
      "Epoch 463/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4567 - val_loss: 12.1639\n",
      "Epoch 464/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3460 - val_loss: 11.4062\n",
      "Epoch 465/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3413 - val_loss: 11.1379\n",
      "Epoch 466/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7333 - val_loss: 11.1038\n",
      "Epoch 467/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8021 - val_loss: 11.1285\n",
      "Epoch 468/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3457 - val_loss: 11.4008\n",
      "Epoch 469/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1900 - val_loss: 11.9451\n",
      "Epoch 470/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4062 - val_loss: 11.2103\n",
      "Epoch 471/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3355 - val_loss: 11.4623\n",
      "Epoch 472/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3650 - val_loss: 11.4011\n",
      "Epoch 473/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3774 - val_loss: 10.8323\n",
      "Epoch 474/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0896 - val_loss: 11.4136\n",
      "Epoch 475/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3497 - val_loss: 12.0039\n",
      "Epoch 476/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2942 - val_loss: 11.0478\n",
      "Epoch 477/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3631 - val_loss: 12.6663\n",
      "Epoch 478/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4577 - val_loss: 11.0126\n",
      "Epoch 479/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2804 - val_loss: 11.2841\n",
      "Epoch 480/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3779 - val_loss: 11.5076\n",
      "Epoch 481/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3483 - val_loss: 11.6698\n",
      "Epoch 482/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1745 - val_loss: 10.8911\n",
      "Epoch 483/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5022 - val_loss: 11.6555\n",
      "Epoch 484/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4506 - val_loss: 11.5141\n",
      "Epoch 485/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.7985 - val_loss: 12.3842\n",
      "Epoch 486/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5612 - val_loss: 10.8358\n",
      "Epoch 487/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0893 - val_loss: 11.1639\n",
      "Epoch 488/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2734 - val_loss: 11.0165\n",
      "Epoch 489/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2475 - val_loss: 10.9004\n",
      "Epoch 490/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0052 - val_loss: 10.7898\n",
      "Epoch 491/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3978 - val_loss: 11.0100\n",
      "Epoch 492/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3684 - val_loss: 11.0837\n",
      "Epoch 493/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1837 - val_loss: 11.6964\n",
      "Epoch 494/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8211 - val_loss: 13.3973\n",
      "Epoch 495/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5506 - val_loss: 11.1611\n",
      "Epoch 496/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1510 - val_loss: 11.0907\n",
      "Epoch 497/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1393 - val_loss: 11.1982\n",
      "Epoch 498/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0869 - val_loss: 10.9784\n",
      "Epoch 499/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4166 - val_loss: 11.0806\n",
      "Epoch 500/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3928 - val_loss: 11.2895\n",
      "Epoch 501/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2661 - val_loss: 12.8832\n",
      "Epoch 502/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1518 - val_loss: 11.0981\n",
      "Epoch 503/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3211 - val_loss: 10.7520\n",
      "Epoch 504/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6800 - val_loss: 10.6389\n",
      "Epoch 505/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4554 - val_loss: 10.7856\n",
      "Epoch 506/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4622 - val_loss: 11.1062\n",
      "Epoch 507/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3870 - val_loss: 10.9018\n",
      "Epoch 508/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0204 - val_loss: 11.5206\n",
      "Epoch 509/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2198 - val_loss: 10.8045\n",
      "Epoch 510/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2295 - val_loss: 10.9348\n",
      "Epoch 511/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4040 - val_loss: 10.7894\n",
      "Epoch 512/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1797 - val_loss: 11.5455\n",
      "Epoch 513/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3162 - val_loss: 10.8708\n",
      "Epoch 514/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0327 - val_loss: 10.8058\n",
      "Epoch 515/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1259 - val_loss: 10.7750\n",
      "Epoch 516/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4294 - val_loss: 10.8109\n",
      "Epoch 517/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7519 - val_loss: 11.0463\n",
      "Epoch 518/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1378 - val_loss: 11.2945\n",
      "Epoch 519/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3806 - val_loss: 11.1728\n",
      "Epoch 520/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0929 - val_loss: 11.0017\n",
      "Epoch 521/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1841 - val_loss: 11.0334\n",
      "Epoch 522/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2163 - val_loss: 11.1837\n",
      "Epoch 523/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1176 - val_loss: 10.6902\n",
      "Epoch 524/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5864 - val_loss: 10.7742\n",
      "Epoch 525/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2568 - val_loss: 10.7855\n",
      "Epoch 526/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2383 - val_loss: 11.1972\n",
      "Epoch 527/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4476 - val_loss: 11.2515\n",
      "Epoch 528/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4961 - val_loss: 11.1927\n",
      "Epoch 529/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0275 - val_loss: 11.2905\n",
      "Epoch 530/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0833 - val_loss: 11.2275\n",
      "Epoch 531/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4383 - val_loss: 11.1692\n",
      "Epoch 532/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0177 - val_loss: 11.6550\n",
      "Epoch 533/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2082 - val_loss: 10.8772\n",
      "Epoch 534/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0715 - val_loss: 10.8037\n",
      "Epoch 535/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1237 - val_loss: 13.1807\n",
      "Epoch 536/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2847 - val_loss: 11.0884\n",
      "Epoch 537/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6344 - val_loss: 11.0555\n",
      "Epoch 538/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2628 - val_loss: 11.3924\n",
      "Epoch 539/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1061 - val_loss: 10.8563\n",
      "Epoch 540/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4929 - val_loss: 10.9341\n",
      "Epoch 541/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2451 - val_loss: 11.6284\n",
      "Epoch 542/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.0118 - val_loss: 11.1166\n",
      "Epoch 543/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0985 - val_loss: 10.9978\n",
      "Epoch 544/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0212 - val_loss: 10.8286\n",
      "Epoch 545/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8660 - val_loss: 10.8120\n",
      "Epoch 546/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9503 - val_loss: 11.0613\n",
      "Epoch 547/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3305 - val_loss: 10.9652\n",
      "Epoch 548/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4696 - val_loss: 11.4305\n",
      "Epoch 549/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7299 - val_loss: 11.2546\n",
      "Epoch 550/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2935 - val_loss: 11.2135\n",
      "Epoch 551/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1595 - val_loss: 11.3120\n",
      "Epoch 552/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5753 - val_loss: 11.2256\n",
      "Epoch 553/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9291 - val_loss: 10.8004\n",
      "Epoch 554/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9508 - val_loss: 10.8301\n",
      "Epoch 555/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8672 - val_loss: 11.1242\n",
      "Epoch 556/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4696 - val_loss: 10.7019\n",
      "Epoch 557/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9509 - val_loss: 10.6462\n",
      "Epoch 558/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.7191 - val_loss: 13.0944\n",
      "Epoch 559/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2309 - val_loss: 10.8245\n",
      "Epoch 560/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8510 - val_loss: 11.1868\n",
      "Epoch 561/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0929 - val_loss: 10.9744\n",
      "Epoch 562/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9726 - val_loss: 11.4125\n",
      "Epoch 563/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9170 - val_loss: 10.9784\n",
      "Epoch 564/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2681 - val_loss: 11.3471\n",
      "Epoch 565/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0216 - val_loss: 10.8527\n",
      "Epoch 566/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5424 - val_loss: 10.7391\n",
      "Epoch 567/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1032 - val_loss: 11.2561\n",
      "Epoch 568/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9422 - val_loss: 11.0782\n",
      "Epoch 569/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8174 - val_loss: 10.6851\n",
      "Epoch 570/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8727 - val_loss: 11.4644\n",
      "Epoch 571/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2505 - val_loss: 12.6689\n",
      "Epoch 572/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1055 - val_loss: 10.8287\n",
      "Epoch 573/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9853 - val_loss: 11.4496\n",
      "Epoch 574/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0379 - val_loss: 11.0895\n",
      "Epoch 575/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0444 - val_loss: 11.9174\n",
      "Epoch 576/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1183 - val_loss: 10.9967\n",
      "Epoch 577/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8814 - val_loss: 11.0214\n",
      "Epoch 578/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5526 - val_loss: 11.3968\n",
      "Epoch 579/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2460 - val_loss: 11.4636\n",
      "Epoch 580/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9248 - val_loss: 10.4736\n",
      "Epoch 581/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8429 - val_loss: 10.5551\n",
      "Epoch 582/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1538 - val_loss: 11.2943\n",
      "Epoch 583/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2455 - val_loss: 10.9161\n",
      "Epoch 584/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1094 - val_loss: 10.8573\n",
      "Epoch 585/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9843 - val_loss: 10.9026\n",
      "Epoch 586/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0713 - val_loss: 10.8137\n",
      "Epoch 587/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4816 - val_loss: 11.1010\n",
      "Epoch 588/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8668 - val_loss: 11.1882\n",
      "Epoch 589/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9819 - val_loss: 11.7002\n",
      "Epoch 590/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4405 - val_loss: 11.0583\n",
      "Epoch 591/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5091 - val_loss: 11.3445\n",
      "Epoch 592/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8920 - val_loss: 10.5601\n",
      "Epoch 593/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9698 - val_loss: 10.9181\n",
      "Epoch 594/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8772 - val_loss: 10.6237\n",
      "Epoch 595/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7855 - val_loss: 11.9552\n",
      "Epoch 596/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0186 - val_loss: 11.5799\n",
      "Epoch 597/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9473 - val_loss: 10.8851\n",
      "Epoch 598/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0812 - val_loss: 10.9464\n",
      "Epoch 599/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9174 - val_loss: 11.0269\n",
      "Epoch 600/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8962 - val_loss: 10.8662\n",
      "Epoch 601/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0832 - val_loss: 11.1877\n",
      "Epoch 602/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0476 - val_loss: 11.2535\n",
      "Epoch 603/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3549 - val_loss: 11.0258\n",
      "Epoch 604/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9593 - val_loss: 11.1172\n",
      "Epoch 605/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4537 - val_loss: 11.3775\n",
      "Epoch 606/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2803 - val_loss: 11.0385\n",
      "Epoch 607/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1465 - val_loss: 10.9835\n",
      "Epoch 608/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8594 - val_loss: 10.9669\n",
      "Epoch 609/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1551 - val_loss: 10.8916\n",
      "Epoch 610/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9352 - val_loss: 10.7623\n",
      "Epoch 611/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7994 - val_loss: 10.8032\n",
      "Epoch 612/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8708 - val_loss: 10.5863\n",
      "Epoch 613/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1531 - val_loss: 11.3068\n",
      "Epoch 614/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4555 - val_loss: 11.5900\n",
      "Epoch 615/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3517 - val_loss: 10.7705\n",
      "Epoch 616/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9135 - val_loss: 11.1147\n",
      "Epoch 617/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8306 - val_loss: 11.0991\n",
      "Epoch 618/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2195 - val_loss: 12.3290\n",
      "Epoch 619/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0948 - val_loss: 10.3960\n",
      "Epoch 620/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9243 - val_loss: 10.5781\n",
      "Epoch 621/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6268 - val_loss: 11.0914\n",
      "Epoch 622/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.8226 - val_loss: 11.8511\n",
      "Epoch 623/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8646 - val_loss: 10.9402\n",
      "Epoch 624/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9018 - val_loss: 11.4328\n",
      "Epoch 625/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8511 - val_loss: 10.5021\n",
      "Epoch 626/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7537 - val_loss: 10.7498\n",
      "Epoch 627/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7432 - val_loss: 10.7322\n",
      "Epoch 628/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3944 - val_loss: 12.1121\n",
      "Epoch 629/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4680 - val_loss: 10.6602\n",
      "Epoch 630/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7927 - val_loss: 10.6500\n",
      "Epoch 631/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8334 - val_loss: 12.5391\n",
      "Epoch 632/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1861 - val_loss: 10.8217\n",
      "Epoch 633/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7895 - val_loss: 10.7550\n",
      "Epoch 634/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8273 - val_loss: 10.8722\n",
      "Epoch 635/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7225 - val_loss: 10.8238\n",
      "Epoch 636/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6951 - val_loss: 10.9645\n",
      "Epoch 637/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0089 - val_loss: 11.0924\n",
      "Epoch 638/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0740 - val_loss: 12.7012\n",
      "Epoch 639/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0802 - val_loss: 10.5746\n",
      "Epoch 640/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8441 - val_loss: 11.0305\n",
      "Epoch 641/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9330 - val_loss: 10.7858\n",
      "Epoch 642/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9546 - val_loss: 10.5637\n",
      "Epoch 643/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1549 - val_loss: 10.8349\n",
      "Epoch 644/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9395 - val_loss: 11.2989\n",
      "Epoch 645/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4211 - val_loss: 11.0495\n",
      "Epoch 646/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9215 - val_loss: 11.3337\n",
      "Epoch 647/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0132 - val_loss: 10.5580\n",
      "Epoch 648/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6489 - val_loss: 10.6098\n",
      "Epoch 649/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6034 - val_loss: 10.6641\n",
      "Epoch 650/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8142 - val_loss: 10.8828\n",
      "Epoch 651/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9340 - val_loss: 10.8252\n",
      "Epoch 652/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4746 - val_loss: 10.9688\n",
      "Epoch 653/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7289 - val_loss: 10.6339\n",
      "Epoch 654/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1556 - val_loss: 11.4438\n",
      "Epoch 655/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7256 - val_loss: 10.8637\n",
      "Epoch 656/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1568 - val_loss: 11.1873\n",
      "Epoch 657/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6438 - val_loss: 11.0561\n",
      "Epoch 658/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7580 - val_loss: 10.9809\n",
      "Epoch 659/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9286 - val_loss: 10.8158\n",
      "Epoch 660/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7976 - val_loss: 10.4781\n",
      "Epoch 661/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8203 - val_loss: 10.8003\n",
      "Epoch 662/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6795 - val_loss: 10.8816\n",
      "Epoch 663/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2078 - val_loss: 10.8859\n",
      "Epoch 664/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7542 - val_loss: 10.8717\n",
      "Epoch 665/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9774 - val_loss: 11.1916\n",
      "Epoch 666/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6771 - val_loss: 10.6094\n",
      "Epoch 667/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7393 - val_loss: 10.7560\n",
      "Epoch 668/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5492 - val_loss: 10.6332\n",
      "Epoch 669/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9478 - val_loss: 10.9076\n",
      "Epoch 670/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1258 - val_loss: 10.6090\n",
      "Epoch 671/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7660 - val_loss: 10.7697\n",
      "Epoch 672/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9840 - val_loss: 10.8050\n",
      "Epoch 673/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6394 - val_loss: 10.7791\n",
      "Epoch 674/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7187 - val_loss: 10.9522\n",
      "Epoch 675/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6245 - val_loss: 10.5299\n",
      "Epoch 676/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8691 - val_loss: 11.0418\n",
      "Epoch 677/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8074 - val_loss: 10.9612\n",
      "Epoch 678/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8286 - val_loss: 11.3182\n",
      "Epoch 679/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6601 - val_loss: 10.7850\n",
      "Epoch 680/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1066 - val_loss: 11.3839\n",
      "Epoch 681/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0142 - val_loss: 12.5322\n",
      "Epoch 682/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7848 - val_loss: 10.6547\n",
      "Epoch 683/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6931 - val_loss: 11.0986\n",
      "Epoch 684/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7453 - val_loss: 10.6662\n",
      "Epoch 685/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8177 - val_loss: 11.5487\n",
      "Epoch 686/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7093 - val_loss: 11.9585\n",
      "Epoch 687/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9075 - val_loss: 10.6378\n",
      "Epoch 688/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7069 - val_loss: 10.6098\n",
      "Epoch 689/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7130 - val_loss: 10.8437\n",
      "Epoch 690/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7452 - val_loss: 10.6362\n",
      "Epoch 691/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9701 - val_loss: 12.3353\n",
      "Epoch 692/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7813 - val_loss: 11.0456\n",
      "Epoch 693/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7774 - val_loss: 10.6219\n",
      "Epoch 694/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7029 - val_loss: 10.9232\n",
      "Epoch 695/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8257 - val_loss: 11.5283\n",
      "Epoch 696/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7857 - val_loss: 10.9076\n",
      "Epoch 697/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6703 - val_loss: 10.5771\n",
      "Epoch 698/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7696 - val_loss: 11.0170\n",
      "Epoch 699/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6689 - val_loss: 10.5595\n",
      "Epoch 700/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6853 - val_loss: 11.4174\n",
      "Epoch 701/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6370 - val_loss: 10.5460\n",
      "Epoch 702/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0227 - val_loss: 10.7371\n",
      "Epoch 703/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6271 - val_loss: 11.1933\n",
      "Epoch 704/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5318 - val_loss: 10.4516\n",
      "Epoch 705/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6540 - val_loss: 10.6675\n",
      "Epoch 706/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7755 - val_loss: 11.2836\n",
      "Epoch 707/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0190 - val_loss: 11.0300\n",
      "Epoch 708/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6237 - val_loss: 11.9750\n",
      "Epoch 709/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6423 - val_loss: 10.5961\n",
      "Epoch 710/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7014 - val_loss: 10.4600\n",
      "Epoch 711/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4996 - val_loss: 10.9050\n",
      "Epoch 712/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7060 - val_loss: 11.0974\n",
      "Epoch 713/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8806 - val_loss: 10.6903\n",
      "Epoch 714/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7454 - val_loss: 10.6797\n",
      "Epoch 715/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9338 - val_loss: 10.8528\n",
      "Epoch 716/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8065 - val_loss: 11.0457\n",
      "Epoch 717/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6628 - val_loss: 11.7116\n",
      "Epoch 718/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8248 - val_loss: 11.0728\n",
      "Epoch 719/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4384 - val_loss: 10.8636\n",
      "Epoch 720/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7017 - val_loss: 10.6618\n",
      "Epoch 721/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8111 - val_loss: 11.2064\n",
      "Epoch 722/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1295 - val_loss: 11.7888\n",
      "Epoch 723/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6631 - val_loss: 10.4881\n",
      "Epoch 724/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3938 - val_loss: 11.5171\n",
      "Epoch 725/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6475 - val_loss: 10.4521\n",
      "Epoch 726/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6576 - val_loss: 10.8916\n",
      "Epoch 727/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5645 - val_loss: 11.4115\n",
      "Epoch 728/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3797 - val_loss: 10.7788\n",
      "Epoch 729/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1686 - val_loss: 11.3780\n",
      "Epoch 730/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0393 - val_loss: 11.0019\n",
      "Epoch 731/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5561 - val_loss: 10.6105\n",
      "Epoch 732/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8888 - val_loss: 10.9480\n",
      "Epoch 733/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9604 - val_loss: 11.1787\n",
      "Epoch 734/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7693 - val_loss: 10.9101\n",
      "Epoch 735/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0533 - val_loss: 10.4729\n",
      "Epoch 736/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4442 - val_loss: 10.7205\n",
      "Epoch 737/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4994 - val_loss: 10.7525\n",
      "Epoch 738/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8231 - val_loss: 11.0340\n",
      "Epoch 739/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4187 - val_loss: 10.4150\n",
      "Epoch 740/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4010 - val_loss: 10.8023\n",
      "Epoch 741/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6352 - val_loss: 10.6786\n",
      "Epoch 742/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9850 - val_loss: 11.5651\n",
      "Epoch 743/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9323 - val_loss: 10.8993\n",
      "Epoch 744/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8776 - val_loss: 10.8110\n",
      "Epoch 745/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6147 - val_loss: 10.7270\n",
      "Epoch 746/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7461 - val_loss: 11.9840\n",
      "Epoch 747/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8748 - val_loss: 10.7615\n",
      "Epoch 748/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5261 - val_loss: 11.0099\n",
      "Epoch 749/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6912 - val_loss: 10.9609\n",
      "Epoch 750/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7407 - val_loss: 12.4977\n",
      "Epoch 751/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7605 - val_loss: 10.5784\n",
      "Epoch 752/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4364 - val_loss: 10.6709\n",
      "Epoch 753/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5820 - val_loss: 10.8725\n",
      "Epoch 754/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7236 - val_loss: 10.6841\n",
      "Epoch 755/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0036 - val_loss: 11.8058\n",
      "Epoch 756/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6682 - val_loss: 10.4755\n",
      "Epoch 757/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4839 - val_loss: 10.9854\n",
      "Epoch 758/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5479 - val_loss: 11.1393\n",
      "Epoch 759/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7363 - val_loss: 10.8490\n",
      "Epoch 760/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4271 - val_loss: 10.8912\n",
      "Epoch 761/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8008 - val_loss: 11.4959\n",
      "Epoch 762/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7317 - val_loss: 10.6494\n",
      "Epoch 763/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6540 - val_loss: 11.2148\n",
      "Epoch 764/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8992 - val_loss: 11.0294\n",
      "Epoch 765/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7179 - val_loss: 11.1799\n",
      "Epoch 766/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4786 - val_loss: 11.3280\n",
      "Epoch 767/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4582 - val_loss: 10.7871\n",
      "Epoch 768/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3520 - val_loss: 10.3361\n",
      "Epoch 769/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4805 - val_loss: 10.6005\n",
      "Epoch 770/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9895 - val_loss: 11.4382\n",
      "Epoch 771/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7675 - val_loss: 10.8329\n",
      "Epoch 772/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5979 - val_loss: 10.7938\n",
      "Epoch 773/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9053 - val_loss: 11.4105\n",
      "Epoch 774/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5569 - val_loss: 10.7886\n",
      "Epoch 775/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3810 - val_loss: 10.5706\n",
      "Epoch 776/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4278 - val_loss: 10.6360\n",
      "Epoch 777/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2518 - val_loss: 10.8107\n",
      "Epoch 778/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5366 - val_loss: 10.8113\n",
      "Epoch 779/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6372 - val_loss: 11.8847\n",
      "Epoch 780/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6895 - val_loss: 11.1721\n",
      "Epoch 781/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0938 - val_loss: 11.4562\n",
      "Epoch 782/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0706 - val_loss: 10.7885\n",
      "Epoch 783/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4373 - val_loss: 10.7034\n",
      "Epoch 784/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4178 - val_loss: 10.8356\n",
      "Epoch 785/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8793 - val_loss: 12.2730\n",
      "Epoch 786/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9235 - val_loss: 10.8094\n",
      "Epoch 787/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3923 - val_loss: 10.7792\n",
      "Epoch 788/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6657 - val_loss: 10.7845\n",
      "Epoch 789/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4888 - val_loss: 11.2885\n",
      "Epoch 790/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4406 - val_loss: 10.8254\n",
      "Epoch 791/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3911 - val_loss: 10.4893\n",
      "Epoch 792/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4568 - val_loss: 11.3596\n",
      "Epoch 793/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5335 - val_loss: 10.6618\n",
      "Epoch 794/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3751 - val_loss: 10.8311\n",
      "Epoch 795/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1276 - val_loss: 11.0539\n",
      "Epoch 796/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9151 - val_loss: 12.4209\n",
      "Epoch 797/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9090 - val_loss: 11.0240\n",
      "Epoch 798/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7060 - val_loss: 11.5751\n",
      "Epoch 799/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1011 - val_loss: 13.0956\n",
      "Epoch 800/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6875 - val_loss: 10.5062\n",
      "Epoch 801/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4890 - val_loss: 10.8050\n",
      "Epoch 802/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8416 - val_loss: 10.7246\n",
      "Epoch 803/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1732 - val_loss: 10.6468\n",
      "Epoch 804/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5551 - val_loss: 11.2622\n",
      "Epoch 805/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1186 - val_loss: 10.5333\n",
      "Epoch 806/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5853 - val_loss: 10.7714\n",
      "Epoch 807/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4956 - val_loss: 11.6625\n",
      "Epoch 808/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2850 - val_loss: 11.4118\n",
      "Epoch 809/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7625 - val_loss: 10.8258\n",
      "Epoch 810/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8214 - val_loss: 10.8092\n",
      "Epoch 811/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4345 - val_loss: 10.6653\n",
      "Epoch 812/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4164 - val_loss: 10.7124\n",
      "Epoch 813/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5431 - val_loss: 10.8473\n",
      "Epoch 814/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2834 - val_loss: 10.6562\n",
      "Epoch 815/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7609 - val_loss: 10.5061\n",
      "Epoch 816/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6174 - val_loss: 10.7674\n",
      "Epoch 817/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8554 - val_loss: 11.2511\n",
      "Epoch 818/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3641 - val_loss: 11.2577\n",
      "Epoch 819/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5729 - val_loss: 10.4172\n",
      "Epoch 820/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3270 - val_loss: 10.4245\n",
      "Epoch 821/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4383 - val_loss: 10.8740\n",
      "Epoch 822/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3870 - val_loss: 10.6020\n",
      "Epoch 823/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3761 - val_loss: 10.5644\n",
      "Epoch 824/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5684 - val_loss: 10.8201\n",
      "Epoch 825/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4541 - val_loss: 11.0961\n",
      "Epoch 826/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5561 - val_loss: 11.6279\n",
      "Epoch 827/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6783 - val_loss: 11.7037\n",
      "Epoch 828/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8717 - val_loss: 10.8328\n",
      "Epoch 829/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3762 - val_loss: 10.7440\n",
      "Epoch 830/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5655 - val_loss: 10.8902\n",
      "Epoch 831/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7060 - val_loss: 10.9007\n",
      "Epoch 832/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6995 - val_loss: 11.2129\n",
      "Epoch 833/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8448 - val_loss: 11.1052\n",
      "Epoch 834/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7463 - val_loss: 11.3388\n",
      "Epoch 835/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4161 - val_loss: 10.7259\n",
      "Epoch 836/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8468 - val_loss: 10.9798\n",
      "Epoch 837/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5306 - val_loss: 11.4548\n",
      "Epoch 838/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3680 - val_loss: 10.6059\n",
      "Epoch 839/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3886 - val_loss: 10.6392\n",
      "Epoch 840/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4982 - val_loss: 10.6783\n",
      "Epoch 841/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4721 - val_loss: 10.7561\n",
      "Epoch 842/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3577 - val_loss: 11.2971\n",
      "Epoch 843/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4640 - val_loss: 10.4441\n",
      "Epoch 844/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8301 - val_loss: 13.7260\n",
      "Epoch 845/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6837 - val_loss: 10.7656\n",
      "Epoch 846/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5085 - val_loss: 13.6143\n",
      "Epoch 847/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3679 - val_loss: 10.8643\n",
      "Epoch 848/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7913 - val_loss: 11.7632\n",
      "Epoch 849/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6814 - val_loss: 10.7114\n",
      "Epoch 850/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4730 - val_loss: 10.7290\n",
      "Epoch 851/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3469 - val_loss: 10.6955\n",
      "Epoch 852/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4014 - val_loss: 10.3707\n",
      "Epoch 853/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4691 - val_loss: 11.0087\n",
      "Epoch 854/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4446 - val_loss: 10.5744\n",
      "Epoch 855/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9932 - val_loss: 10.4219\n",
      "Epoch 856/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8164 - val_loss: 10.7281\n",
      "Epoch 857/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5111 - val_loss: 11.0022\n",
      "Epoch 858/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3273 - val_loss: 10.5831\n",
      "Epoch 859/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3137 - val_loss: 10.5711\n",
      "Epoch 860/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3330 - val_loss: 10.9047\n",
      "Epoch 861/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7587 - val_loss: 10.7776\n",
      "Epoch 862/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7067 - val_loss: 10.8106\n",
      "Epoch 863/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3985 - val_loss: 10.6986\n",
      "Epoch 864/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4878 - val_loss: 10.8292\n",
      "Epoch 865/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2694 - val_loss: 11.2554\n",
      "Epoch 866/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6162 - val_loss: 10.9065\n",
      "Epoch 867/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4112 - val_loss: 10.7166\n",
      "Epoch 868/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9114 - val_loss: 11.3454\n",
      "Epoch 869/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5458 - val_loss: 10.9952\n",
      "Epoch 870/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4817 - val_loss: 11.2002\n",
      "Epoch 871/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4845 - val_loss: 10.9776\n",
      "Epoch 872/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3525 - val_loss: 10.6616\n",
      "Epoch 873/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7693 - val_loss: 11.3419\n",
      "Epoch 874/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5986 - val_loss: 10.8502\n",
      "Epoch 875/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2476 - val_loss: 10.7746\n",
      "Epoch 876/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3125 - val_loss: 10.8209\n",
      "Epoch 877/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4813 - val_loss: 10.9080\n",
      "Epoch 878/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1966 - val_loss: 10.9448\n",
      "Epoch 879/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4547 - val_loss: 10.7376\n",
      "Epoch 880/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5413 - val_loss: 10.7470\n",
      "Epoch 881/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4732 - val_loss: 10.9277\n",
      "Epoch 882/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4750 - val_loss: 10.8354\n",
      "Epoch 883/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5466 - val_loss: 10.6649\n",
      "Epoch 884/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2764 - val_loss: 10.7069\n",
      "Epoch 885/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7107 - val_loss: 13.3549\n",
      "Epoch 886/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8502 - val_loss: 11.0395\n",
      "Epoch 887/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2570 - val_loss: 10.5172\n",
      "Epoch 888/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3958 - val_loss: 10.7553\n",
      "Epoch 889/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3930 - val_loss: 10.9680\n",
      "Epoch 890/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4086 - val_loss: 11.2228\n",
      "Epoch 891/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8712 - val_loss: 11.9281\n",
      "Epoch 892/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5446 - val_loss: 10.8627\n",
      "Epoch 893/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8892 - val_loss: 11.0016\n",
      "Epoch 894/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5906 - val_loss: 10.8473\n",
      "Epoch 895/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3372 - val_loss: 10.3703\n",
      "Epoch 896/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4327 - val_loss: 10.6694\n",
      "Epoch 897/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3328 - val_loss: 10.6732\n",
      "Epoch 898/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2886 - val_loss: 10.7911\n",
      "Epoch 899/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3599 - val_loss: 10.8775\n",
      "Epoch 900/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2702 - val_loss: 11.1626\n",
      "Epoch 901/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5961 - val_loss: 10.8622\n",
      "Epoch 902/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3056 - val_loss: 11.0397\n",
      "Epoch 903/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6387 - val_loss: 10.8316\n",
      "Epoch 904/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2908 - val_loss: 10.7764\n",
      "Epoch 905/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5498 - val_loss: 10.7812\n",
      "Epoch 906/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4863 - val_loss: 11.5426\n",
      "Epoch 907/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6188 - val_loss: 11.7224\n",
      "Epoch 908/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4983 - val_loss: 11.2472\n",
      "Epoch 909/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7260 - val_loss: 10.9508\n",
      "Epoch 910/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4321 - val_loss: 10.5520\n",
      "Epoch 911/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1666 - val_loss: 10.7318\n",
      "Epoch 912/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3495 - val_loss: 11.1506\n",
      "Epoch 913/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3317 - val_loss: 11.0319\n",
      "Epoch 914/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5772 - val_loss: 10.6952\n",
      "Epoch 915/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3118 - val_loss: 11.3890\n",
      "Epoch 916/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3309 - val_loss: 10.9584\n",
      "Epoch 917/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4371 - val_loss: 10.5346\n",
      "Epoch 918/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6899 - val_loss: 11.7943\n",
      "Epoch 919/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1974 - val_loss: 11.1490\n",
      "Epoch 920/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4614 - val_loss: 11.2188\n",
      "Epoch 921/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6231 - val_loss: 10.8372\n",
      "Epoch 922/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6845 - val_loss: 10.7365\n",
      "Epoch 923/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1292 - val_loss: 11.1202\n",
      "Epoch 924/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2437 - val_loss: 10.7635\n",
      "Epoch 925/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2738 - val_loss: 11.6497\n",
      "Epoch 926/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4375 - val_loss: 10.7401\n",
      "Epoch 927/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3553 - val_loss: 10.6968\n",
      "Epoch 928/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5610 - val_loss: 10.8527\n",
      "Epoch 929/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2501 - val_loss: 10.6063\n",
      "Epoch 930/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3628 - val_loss: 10.6527\n",
      "Epoch 931/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2211 - val_loss: 10.9424\n",
      "Epoch 932/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3286 - val_loss: 10.7492\n",
      "Epoch 933/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5827 - val_loss: 10.5000\n",
      "Epoch 934/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7095 - val_loss: 10.8984\n",
      "Epoch 935/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8017 - val_loss: 11.0238\n",
      "Epoch 936/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4364 - val_loss: 10.7097\n",
      "Epoch 937/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2886 - val_loss: 10.4851\n",
      "Epoch 938/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3004 - val_loss: 10.7894\n",
      "Epoch 939/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4199 - val_loss: 11.4173\n",
      "Epoch 940/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3508 - val_loss: 10.6869\n",
      "Epoch 941/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2328 - val_loss: 10.7992\n",
      "Epoch 942/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5280 - val_loss: 10.7272\n",
      "Epoch 943/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2022 - val_loss: 10.8180\n",
      "Epoch 944/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3572 - val_loss: 11.3654\n",
      "Epoch 945/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2601 - val_loss: 10.6940\n",
      "Epoch 946/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3331 - val_loss: 10.7387\n",
      "Epoch 947/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3581 - val_loss: 10.7011\n",
      "Epoch 948/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2766 - val_loss: 11.4050\n",
      "Epoch 949/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2784 - val_loss: 10.7770\n",
      "Epoch 950/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2012 - val_loss: 11.0863\n",
      "Epoch 951/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6990 - val_loss: 12.3808\n",
      "Epoch 952/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6885 - val_loss: 11.0155\n",
      "Epoch 953/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9631 - val_loss: 12.7315\n",
      "Epoch 954/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5209 - val_loss: 10.6922\n",
      "Epoch 955/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0980 - val_loss: 10.5571\n",
      "Epoch 956/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1078 - val_loss: 10.5814\n",
      "Epoch 957/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1822 - val_loss: 10.9174\n",
      "Epoch 958/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2995 - val_loss: 10.7826\n",
      "Epoch 959/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1926 - val_loss: 10.9453\n",
      "Epoch 960/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3022 - val_loss: 10.8186\n",
      "Epoch 961/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3802 - val_loss: 11.2710\n",
      "Epoch 962/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5427 - val_loss: 10.8494\n",
      "Epoch 963/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2280 - val_loss: 11.2854\n",
      "Epoch 964/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2979 - val_loss: 10.7192\n",
      "Epoch 965/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1212 - val_loss: 10.7960\n",
      "Epoch 966/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7652 - val_loss: 11.9083\n",
      "Epoch 967/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7187 - val_loss: 11.4697\n",
      "Epoch 968/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8082 - val_loss: 10.8574\n",
      "Epoch 969/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7041 - val_loss: 10.6304\n",
      "Epoch 970/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2321 - val_loss: 10.5569\n",
      "Epoch 971/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1420 - val_loss: 10.5327\n",
      "Epoch 972/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0793 - val_loss: 10.4908\n",
      "Epoch 973/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2719 - val_loss: 10.5974\n",
      "Epoch 974/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3879 - val_loss: 10.6606\n",
      "Epoch 975/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4331 - val_loss: 10.6830\n",
      "Epoch 976/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3621 - val_loss: 11.1780\n",
      "Epoch 977/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6425 - val_loss: 10.6728\n",
      "Epoch 978/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0934 - val_loss: 10.9973\n",
      "Epoch 979/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6515 - val_loss: 11.0073\n",
      "Epoch 980/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9906 - val_loss: 10.5211\n",
      "Epoch 981/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2892 - val_loss: 10.6254\n",
      "Epoch 982/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3224 - val_loss: 10.7644\n",
      "Epoch 983/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1874 - val_loss: 10.9073\n",
      "Epoch 984/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3800 - val_loss: 10.9090\n",
      "Epoch 985/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4794 - val_loss: 10.9458\n",
      "Epoch 986/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5350 - val_loss: 11.2200\n",
      "Epoch 987/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1334 - val_loss: 10.9524\n",
      "Epoch 988/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1892 - val_loss: 10.5535\n",
      "Epoch 989/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4691 - val_loss: 10.9328\n",
      "Epoch 990/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4388 - val_loss: 11.3508\n",
      "Epoch 991/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0986 - val_loss: 10.8284\n",
      "Epoch 992/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1138 - val_loss: 10.7722\n",
      "Epoch 993/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2759 - val_loss: 10.7201\n",
      "Epoch 994/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1587 - val_loss: 10.4606\n",
      "Epoch 995/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1870 - val_loss: 10.8119\n",
      "Epoch 996/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1580 - val_loss: 10.6763\n",
      "Epoch 997/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2806 - val_loss: 11.0338\n",
      "Epoch 998/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5618 - val_loss: 10.9265\n",
      "Epoch 999/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2023 - val_loss: 10.6605\n",
      "Epoch 1000/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1449 - val_loss: 11.1132\n",
      "Epoch 1001/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4966 - val_loss: 10.8402\n",
      "Epoch 1002/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3774 - val_loss: 11.1952\n",
      "Epoch 1003/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2986 - val_loss: 11.3911\n",
      "Epoch 1004/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7687 - val_loss: 11.1253\n",
      "Epoch 1005/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3871 - val_loss: 10.6614\n",
      "Epoch 1006/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5201 - val_loss: 10.7040\n",
      "Epoch 1007/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0577 - val_loss: 10.7538\n",
      "Epoch 1008/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0427 - val_loss: 10.9007\n",
      "Epoch 1009/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4128 - val_loss: 10.8042\n",
      "Epoch 1010/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2210 - val_loss: 10.9374\n",
      "Epoch 1011/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4813 - val_loss: 10.5021\n",
      "Epoch 1012/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6497 - val_loss: 10.6139\n",
      "Epoch 1013/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1824 - val_loss: 10.9940\n",
      "Epoch 1014/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5071 - val_loss: 11.2671\n",
      "Epoch 1015/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1448 - val_loss: 11.1474\n",
      "Epoch 1016/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3332 - val_loss: 11.8794\n",
      "Epoch 1017/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0573 - val_loss: 10.5162\n",
      "Epoch 1018/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4614 - val_loss: 10.7674\n",
      "Epoch 1019/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6432 - val_loss: 10.6013\n",
      "Epoch 1020/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3739 - val_loss: 10.5903\n",
      "Epoch 1021/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4035 - val_loss: 10.8161\n",
      "Epoch 1022/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1906 - val_loss: 10.9933\n",
      "Epoch 1023/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1924 - val_loss: 10.8308\n",
      "Epoch 1024/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6088 - val_loss: 10.7054\n",
      "Epoch 1025/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3751 - val_loss: 10.8792\n",
      "Epoch 1026/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4018 - val_loss: 10.8040\n",
      "Epoch 1027/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2522 - val_loss: 11.1237\n",
      "Epoch 1028/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1506 - val_loss: 10.6521\n",
      "Epoch 1029/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5297 - val_loss: 10.7043\n",
      "Epoch 1030/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1358 - val_loss: 10.9457\n",
      "Epoch 1031/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1354 - val_loss: 10.5878\n",
      "Epoch 1032/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2185 - val_loss: 11.0108\n",
      "Epoch 1033/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7798 - val_loss: 10.7482\n",
      "Epoch 1034/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6375 - val_loss: 11.1406\n",
      "Epoch 1035/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0660 - val_loss: 11.8531\n",
      "Epoch 1036/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3631 - val_loss: 12.4057\n",
      "Epoch 1037/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4693 - val_loss: 11.1251\n",
      "Epoch 1038/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3801 - val_loss: 10.9413\n",
      "Epoch 1039/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2447 - val_loss: 10.7503\n",
      "Epoch 1040/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0871 - val_loss: 10.5616\n",
      "Epoch 1041/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3771 - val_loss: 10.4943\n",
      "Epoch 1042/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2043 - val_loss: 10.6179\n",
      "Epoch 1043/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5735 - val_loss: 10.6805\n",
      "Epoch 1044/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2034 - val_loss: 11.0813\n",
      "Epoch 1045/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1778 - val_loss: 10.9920\n",
      "Epoch 1046/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0686 - val_loss: 10.9230\n",
      "Epoch 1047/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7063 - val_loss: 11.9507\n",
      "Epoch 1048/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4780 - val_loss: 10.7460\n",
      "Epoch 1049/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1723 - val_loss: 10.7183\n",
      "Epoch 1050/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2823 - val_loss: 10.8585\n",
      "Epoch 1051/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0768 - val_loss: 10.5119\n",
      "Epoch 1052/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1596 - val_loss: 11.4183\n",
      "Epoch 1053/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2009 - val_loss: 10.6665\n",
      "Epoch 1054/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3920 - val_loss: 10.4992\n",
      "Epoch 1055/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1092 - val_loss: 10.9484\n",
      "Epoch 1056/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0778 - val_loss: 11.0278\n",
      "Epoch 1057/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1494 - val_loss: 10.7544\n",
      "Epoch 1058/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2084 - val_loss: 10.7521\n",
      "Epoch 1059/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5340 - val_loss: 11.2595\n",
      "Epoch 1060/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5521 - val_loss: 11.2339\n",
      "Epoch 1061/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9749 - val_loss: 11.4926\n",
      "Epoch 1062/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5411 - val_loss: 10.6678\n",
      "Epoch 1063/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3739 - val_loss: 10.4907\n",
      "Epoch 1064/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2187 - val_loss: 11.1020\n",
      "Epoch 1065/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0038 - val_loss: 10.5927\n",
      "Epoch 1066/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2177 - val_loss: 10.7434\n",
      "Epoch 1067/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1393 - val_loss: 10.5761\n",
      "Epoch 1068/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0884 - val_loss: 11.5201\n",
      "Epoch 1069/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2495 - val_loss: 10.6246\n",
      "Epoch 1070/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4399 - val_loss: 10.8394\n",
      "Epoch 1071/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1797 - val_loss: 10.7198\n",
      "Epoch 1072/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1327 - val_loss: 10.5534\n",
      "Epoch 1073/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3771 - val_loss: 10.8832\n",
      "Epoch 1074/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2468 - val_loss: 11.1093\n",
      "Epoch 1075/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5512 - val_loss: 10.8178\n",
      "Epoch 1076/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2327 - val_loss: 10.9320\n",
      "Epoch 1077/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1312 - val_loss: 10.7257\n",
      "Epoch 1078/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0393 - val_loss: 10.7183\n",
      "Epoch 1079/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0618 - val_loss: 10.5652\n",
      "Epoch 1080/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1345 - val_loss: 10.5616\n",
      "Epoch 1081/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2472 - val_loss: 10.8601\n",
      "Epoch 1082/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2538 - val_loss: 10.6603\n",
      "Epoch 1083/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1764 - val_loss: 10.5267\n",
      "Epoch 1084/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3774 - val_loss: 10.6468\n",
      "Epoch 1085/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2472 - val_loss: 11.2486\n",
      "Epoch 1086/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2857 - val_loss: 10.6449\n",
      "Epoch 1087/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0327 - val_loss: 10.7224\n",
      "Epoch 1088/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2054 - val_loss: 11.5811\n",
      "Epoch 1089/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0227 - val_loss: 10.6901\n",
      "Epoch 1090/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3046 - val_loss: 10.6577\n",
      "Epoch 1091/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2070 - val_loss: 10.5590\n",
      "Epoch 1092/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3777 - val_loss: 11.1553\n",
      "Epoch 1093/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0591 - val_loss: 10.5625\n",
      "Epoch 1094/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5842 - val_loss: 11.6606\n",
      "Epoch 1095/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6588 - val_loss: 13.4525\n",
      "Epoch 1096/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.5316 - val_loss: 10.4850\n",
      "Epoch 1097/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1174 - val_loss: 10.3863\n",
      "Epoch 1098/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1337 - val_loss: 10.6221\n",
      "Epoch 1099/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0078 - val_loss: 10.3533\n",
      "Epoch 1100/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2181 - val_loss: 10.6740\n",
      "Epoch 1101/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3991 - val_loss: 10.5954\n",
      "Epoch 1102/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0844 - val_loss: 10.6433\n",
      "Epoch 1103/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0367 - val_loss: 10.9353\n",
      "Epoch 1104/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1186 - val_loss: 10.4806\n",
      "Epoch 1105/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0928 - val_loss: 10.5368\n",
      "Epoch 1106/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3741 - val_loss: 10.8507\n",
      "Epoch 1107/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0680 - val_loss: 10.9498\n",
      "Epoch 1108/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1164 - val_loss: 10.7096\n",
      "Epoch 1109/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1980 - val_loss: 10.6339\n",
      "Epoch 1110/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1419 - val_loss: 11.2755\n",
      "Epoch 1111/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3600 - val_loss: 11.2596\n",
      "Epoch 1112/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2893 - val_loss: 10.5980\n",
      "Epoch 1113/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2426 - val_loss: 10.7816\n",
      "Epoch 1114/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0234 - val_loss: 10.5425\n",
      "Epoch 1115/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4215 - val_loss: 10.6800\n",
      "Epoch 1116/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3374 - val_loss: 10.6588\n",
      "Epoch 1117/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1237 - val_loss: 10.7312\n",
      "Epoch 1118/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1133 - val_loss: 10.3574\n",
      "Epoch 1119/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0789 - val_loss: 10.9457\n",
      "Epoch 1120/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1696 - val_loss: 11.0569\n",
      "Epoch 1121/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0516 - val_loss: 10.6893\n",
      "Epoch 1122/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0327 - val_loss: 11.5392\n",
      "Epoch 1123/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3077 - val_loss: 10.6750\n",
      "Epoch 1124/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1953 - val_loss: 10.9753\n",
      "Epoch 1125/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4972 - val_loss: 10.6862\n",
      "Epoch 1126/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1249 - val_loss: 10.6817\n",
      "Epoch 1127/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5148 - val_loss: 10.7067\n",
      "Epoch 1128/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2382 - val_loss: 11.3845\n",
      "Epoch 1129/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3652 - val_loss: 11.0569\n",
      "Epoch 1130/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2963 - val_loss: 10.6208\n",
      "Epoch 1131/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2479 - val_loss: 10.6418\n",
      "Epoch 1132/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0426 - val_loss: 10.9530\n",
      "Epoch 1133/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1284 - val_loss: 11.1354\n",
      "Epoch 1134/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3104 - val_loss: 10.8698\n",
      "Epoch 1135/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0648 - val_loss: 10.7795\n",
      "Epoch 1136/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6006 - val_loss: 10.5227\n",
      "Epoch 1137/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1954 - val_loss: 11.0508\n",
      "Epoch 1138/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3672 - val_loss: 11.0117\n",
      "Epoch 1139/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2650 - val_loss: 10.4988\n",
      "Epoch 1140/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0254 - val_loss: 10.4966\n",
      "Epoch 1141/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0702 - val_loss: 10.6759\n",
      "Epoch 1142/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2152 - val_loss: 10.7159\n",
      "Epoch 1143/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3568 - val_loss: 10.9039\n",
      "Epoch 1144/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0616 - val_loss: 10.5624\n",
      "Epoch 1145/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1884 - val_loss: 10.6919\n",
      "Epoch 1146/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0426 - val_loss: 10.4558\n",
      "Epoch 1147/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0990 - val_loss: 10.5728\n",
      "Epoch 1148/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2470 - val_loss: 11.3480\n",
      "Epoch 1149/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6714 - val_loss: 11.0950\n",
      "Epoch 1150/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0810 - val_loss: 11.1882\n",
      "Epoch 1151/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2632 - val_loss: 11.6867\n",
      "Epoch 1152/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2738 - val_loss: 11.0783\n",
      "Epoch 1153/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1343 - val_loss: 10.7917\n",
      "Epoch 1154/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2899 - val_loss: 10.6493\n",
      "Epoch 1155/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5526 - val_loss: 11.3198\n",
      "Epoch 1156/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2509 - val_loss: 10.6171\n",
      "Epoch 1157/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2917 - val_loss: 11.5368\n",
      "Epoch 1158/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3149 - val_loss: 11.0108\n",
      "Epoch 1159/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5341 - val_loss: 11.2722\n",
      "Epoch 1160/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5704 - val_loss: 11.1298\n",
      "Epoch 1161/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0906 - val_loss: 10.9318\n",
      "Epoch 1162/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3638 - val_loss: 10.9104\n",
      "Epoch 1163/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1064 - val_loss: 10.8108\n",
      "Epoch 1164/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1697 - val_loss: 10.9329\n",
      "Epoch 1165/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5915 - val_loss: 10.7265\n",
      "Epoch 1166/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1167 - val_loss: 10.5313\n",
      "Epoch 1167/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9589 - val_loss: 10.7367\n",
      "Epoch 1168/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0734 - val_loss: 11.2359\n",
      "Epoch 1169/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2466 - val_loss: 11.2978\n",
      "Epoch 1170/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2754 - val_loss: 10.7050\n",
      "Epoch 1171/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9370 - val_loss: 10.5748\n",
      "Epoch 1172/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0212 - val_loss: 10.4744\n",
      "Epoch 1173/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0790 - val_loss: 10.9211\n",
      "Epoch 1174/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0423 - val_loss: 11.1557\n",
      "Epoch 1175/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3942 - val_loss: 11.1618\n",
      "Epoch 1176/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4481 - val_loss: 11.3118\n",
      "Epoch 1177/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3076 - val_loss: 10.7385\n",
      "Epoch 1178/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4599 - val_loss: 11.0443\n",
      "Epoch 1179/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2688 - val_loss: 10.9195\n",
      "Epoch 1180/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3857 - val_loss: 11.8576\n",
      "Epoch 1181/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1203 - val_loss: 10.8258\n",
      "Epoch 1182/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1075 - val_loss: 11.1421\n",
      "Epoch 1183/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3485 - val_loss: 10.7932\n",
      "Epoch 1184/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1475 - val_loss: 10.6679\n",
      "Epoch 1185/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0193 - val_loss: 10.7125\n",
      "Epoch 1186/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0645 - val_loss: 10.5260\n",
      "Epoch 1187/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2379 - val_loss: 10.5793\n",
      "Epoch 1188/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0227 - val_loss: 11.1489\n",
      "Epoch 1189/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3840 - val_loss: 10.7607\n",
      "Epoch 1190/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6211 - val_loss: 11.1518\n",
      "Epoch 1191/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3309 - val_loss: 11.1201\n",
      "Epoch 1192/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1707 - val_loss: 10.9510\n",
      "Epoch 1193/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4827 - val_loss: 10.7886\n",
      "Epoch 1194/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0654 - val_loss: 10.9230\n",
      "Epoch 1195/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9404 - val_loss: 12.4448\n",
      "Epoch 1196/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1025 - val_loss: 10.4461\n",
      "Epoch 1197/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2438 - val_loss: 11.0287\n",
      "Epoch 1198/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2294 - val_loss: 11.2800\n",
      "Epoch 1199/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9046 - val_loss: 10.6664\n",
      "Epoch 1200/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2227 - val_loss: 10.9483\n",
      "Epoch 1201/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4012 - val_loss: 10.8080\n",
      "Epoch 1202/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0978 - val_loss: 10.5832\n",
      "Epoch 1203/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0216 - val_loss: 10.5221\n",
      "Epoch 1204/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2472 - val_loss: 10.6091\n",
      "Epoch 1205/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5363 - val_loss: 10.7949\n",
      "Epoch 1206/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3317 - val_loss: 10.3801\n",
      "Epoch 1207/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3121 - val_loss: 10.8898\n",
      "Epoch 1208/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0768 - val_loss: 10.9316\n",
      "Epoch 1209/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0127 - val_loss: 10.6026\n",
      "Epoch 1210/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0385 - val_loss: 10.6967\n",
      "Epoch 1211/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1326 - val_loss: 12.8979\n",
      "Epoch 1212/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3715 - val_loss: 10.9193\n",
      "Epoch 1213/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0877 - val_loss: 11.7080\n",
      "Epoch 1214/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1688 - val_loss: 11.6739\n",
      "Epoch 1215/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1919 - val_loss: 10.7250\n",
      "Epoch 1216/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9764 - val_loss: 10.8457\n",
      "Epoch 1217/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0762 - val_loss: 10.6866\n",
      "Epoch 1218/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0901 - val_loss: 10.6134\n",
      "Epoch 1219/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2342 - val_loss: 10.5817\n",
      "Epoch 1220/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0850 - val_loss: 10.5885\n",
      "Epoch 1221/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0122 - val_loss: 10.8111\n",
      "Epoch 1222/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0036 - val_loss: 10.7654\n",
      "Epoch 1223/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1758 - val_loss: 10.8795\n",
      "Epoch 1224/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0929 - val_loss: 10.9147\n",
      "Epoch 1225/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4111 - val_loss: 10.5826\n",
      "Epoch 1226/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1221 - val_loss: 10.5546\n",
      "Epoch 1227/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3145 - val_loss: 10.9143\n",
      "Epoch 1228/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0500 - val_loss: 10.7675\n",
      "Epoch 1229/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0359 - val_loss: 10.8630\n",
      "Epoch 1230/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0689 - val_loss: 11.0058\n",
      "Epoch 1231/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0436 - val_loss: 10.7335\n",
      "Epoch 1232/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2008 - val_loss: 11.1461\n",
      "Epoch 1233/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1686 - val_loss: 10.9100\n",
      "Epoch 1234/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0308 - val_loss: 10.5674\n",
      "Epoch 1235/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6088 - val_loss: 12.1196\n",
      "Epoch 1236/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3743 - val_loss: 10.5834\n",
      "Epoch 1237/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9182 - val_loss: 10.6995\n",
      "Epoch 1238/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9133 - val_loss: 10.5765\n",
      "Epoch 1239/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0623 - val_loss: 10.6389\n",
      "Epoch 1240/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9116 - val_loss: 11.1293\n",
      "Epoch 1241/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5298 - val_loss: 11.2489\n",
      "Epoch 1242/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1179 - val_loss: 10.7697\n",
      "Epoch 1243/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3461 - val_loss: 11.3917\n",
      "Epoch 1244/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9275 - val_loss: 10.6708\n",
      "Epoch 1245/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9384 - val_loss: 10.6318\n",
      "Epoch 1246/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1895 - val_loss: 10.6738\n",
      "Epoch 1247/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9641 - val_loss: 10.6207\n",
      "Epoch 1248/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1991 - val_loss: 11.3516\n",
      "Epoch 1249/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0527 - val_loss: 11.3378\n",
      "Epoch 1250/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0308 - val_loss: 10.8899\n",
      "Epoch 1251/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0786 - val_loss: 10.8842\n",
      "Epoch 1252/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1528 - val_loss: 11.0437\n",
      "Epoch 1253/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1014 - val_loss: 11.0258\n",
      "Epoch 1254/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0088 - val_loss: 10.5403\n",
      "Epoch 1255/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0641 - val_loss: 11.8350\n",
      "Epoch 1256/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4843 - val_loss: 11.0218\n",
      "Epoch 1257/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2364 - val_loss: 10.7100\n",
      "Epoch 1258/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8788 - val_loss: 10.7576\n",
      "Epoch 1259/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1120 - val_loss: 10.9286\n",
      "Epoch 1260/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0487 - val_loss: 10.9018\n",
      "Epoch 1261/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1470 - val_loss: 12.3780\n",
      "Epoch 1262/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2005 - val_loss: 10.6798\n",
      "Epoch 1263/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3441 - val_loss: 10.9061\n",
      "Epoch 1264/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9898 - val_loss: 10.6441\n",
      "Epoch 1265/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0792 - val_loss: 10.5259\n",
      "Epoch 1266/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9577 - val_loss: 11.6513\n",
      "Epoch 1267/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8199 - val_loss: 10.6950\n",
      "Epoch 1268/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0805 - val_loss: 10.4232\n",
      "Epoch 1269/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0501 - val_loss: 10.9622\n",
      "Epoch 1270/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9681 - val_loss: 10.6439\n",
      "Epoch 1271/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0292 - val_loss: 10.9191\n",
      "Epoch 1272/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3540 - val_loss: 12.2060\n",
      "Epoch 1273/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0526 - val_loss: 12.0511\n",
      "Epoch 1274/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6106 - val_loss: 11.2878\n",
      "Epoch 1275/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2516 - val_loss: 11.4276\n",
      "Epoch 1276/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3431 - val_loss: 10.7480\n",
      "Epoch 1277/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1215 - val_loss: 10.6127\n",
      "Epoch 1278/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9818 - val_loss: 10.7328\n",
      "Epoch 1279/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9528 - val_loss: 11.0962\n",
      "Epoch 1280/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0778 - val_loss: 10.4912\n",
      "Epoch 1281/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0452 - val_loss: 11.0696\n",
      "Epoch 1282/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8647 - val_loss: 10.6102\n",
      "Epoch 1283/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0067 - val_loss: 10.9077\n",
      "Epoch 1284/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0211 - val_loss: 11.2220\n",
      "Epoch 1285/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8291 - val_loss: 10.5713\n",
      "Epoch 1286/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1128 - val_loss: 10.7709\n",
      "Epoch 1287/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5288 - val_loss: 11.5799\n",
      "Epoch 1288/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6200 - val_loss: 10.6679\n",
      "Epoch 1289/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0936 - val_loss: 11.0298\n",
      "Epoch 1290/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9852 - val_loss: 10.4183\n",
      "Epoch 1291/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6105 - val_loss: 10.8101\n",
      "Epoch 1292/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2054 - val_loss: 10.8696\n",
      "Epoch 1293/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9340 - val_loss: 10.5118\n",
      "Epoch 1294/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0097 - val_loss: 10.3460\n",
      "Epoch 1295/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9892 - val_loss: 10.6065\n",
      "Epoch 1296/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0141 - val_loss: 10.6336\n",
      "Epoch 1297/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2003 - val_loss: 10.6471\n",
      "Epoch 1298/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3300 - val_loss: 10.4768\n",
      "Epoch 1299/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2338 - val_loss: 11.0603\n",
      "Epoch 1300/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9559 - val_loss: 11.1701\n",
      "Epoch 1301/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0417 - val_loss: 10.8814\n",
      "Epoch 1302/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0165 - val_loss: 10.7565\n",
      "Epoch 1303/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2480 - val_loss: 10.9948\n",
      "Epoch 1304/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0603 - val_loss: 10.9603\n",
      "Epoch 1305/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9449 - val_loss: 11.2124\n",
      "Epoch 1306/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2543 - val_loss: 10.6552\n",
      "Epoch 1307/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0170 - val_loss: 11.1199\n",
      "Epoch 1308/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0861 - val_loss: 10.7061\n",
      "Epoch 1309/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9224 - val_loss: 10.6350\n",
      "Epoch 1310/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1467 - val_loss: 13.0390\n",
      "Epoch 1311/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3538 - val_loss: 10.6258\n",
      "Epoch 1312/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9515 - val_loss: 10.8852\n",
      "Epoch 1313/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0070 - val_loss: 10.6106\n",
      "Epoch 1314/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8959 - val_loss: 10.8108\n",
      "Epoch 1315/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9415 - val_loss: 11.1188\n",
      "Epoch 1316/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7089 - val_loss: 10.7432\n",
      "Epoch 1317/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9672 - val_loss: 10.7846\n",
      "Epoch 1318/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3719 - val_loss: 10.7283\n",
      "Epoch 1319/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8126 - val_loss: 10.5480\n",
      "Epoch 1320/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8672 - val_loss: 10.6430\n",
      "Epoch 1321/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7070 - val_loss: 10.6098\n",
      "Epoch 1322/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6992 - val_loss: 11.2916\n",
      "Epoch 1323/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2629 - val_loss: 10.6576\n",
      "Epoch 1324/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7977 - val_loss: 10.7450\n",
      "Epoch 1325/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2508 - val_loss: 10.5416\n",
      "Epoch 1326/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9970 - val_loss: 11.6263\n",
      "Epoch 1327/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4937 - val_loss: 11.2961\n",
      "Epoch 1328/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2511 - val_loss: 10.6804\n",
      "Epoch 1329/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0585 - val_loss: 11.1533\n",
      "Epoch 1330/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0219 - val_loss: 10.5400\n",
      "Epoch 1331/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8843 - val_loss: 10.6015\n",
      "Epoch 1332/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9431 - val_loss: 10.6824\n",
      "Epoch 1333/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9106 - val_loss: 10.6523\n",
      "Epoch 1334/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9492 - val_loss: 12.7100\n",
      "Epoch 1335/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4021 - val_loss: 10.7123\n",
      "Epoch 1336/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0681 - val_loss: 10.7550\n",
      "Epoch 1337/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1687 - val_loss: 10.5927\n",
      "Epoch 1338/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8703 - val_loss: 10.9158\n",
      "Epoch 1339/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0458 - val_loss: 10.8882\n",
      "Epoch 1340/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9174 - val_loss: 10.7895\n",
      "Epoch 1341/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1612 - val_loss: 11.9588\n",
      "Epoch 1342/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2858 - val_loss: 10.9276\n",
      "Epoch 1343/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5508 - val_loss: 10.8759\n",
      "Epoch 1344/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0022 - val_loss: 10.7804\n",
      "Epoch 1345/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0207 - val_loss: 11.2118\n",
      "Epoch 1346/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9022 - val_loss: 10.6158\n",
      "Epoch 1347/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9047 - val_loss: 10.5181\n",
      "Epoch 1348/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1927 - val_loss: 10.5324\n",
      "Epoch 1349/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0750 - val_loss: 10.9449\n",
      "Epoch 1350/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0072 - val_loss: 10.8970\n",
      "Epoch 1351/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9793 - val_loss: 11.0986\n",
      "Epoch 1352/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3918 - val_loss: 12.0436\n",
      "Epoch 1353/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1424 - val_loss: 10.7332\n",
      "Epoch 1354/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9287 - val_loss: 10.9239\n",
      "Epoch 1355/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3803 - val_loss: 11.1047\n",
      "Epoch 1356/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1710 - val_loss: 10.6417\n",
      "Epoch 1357/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0007 - val_loss: 10.9544\n",
      "Epoch 1358/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9855 - val_loss: 10.8165\n",
      "Epoch 1359/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0274 - val_loss: 10.7942\n",
      "Epoch 1360/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9490 - val_loss: 10.7878\n",
      "Epoch 1361/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0341 - val_loss: 11.1500\n",
      "Epoch 1362/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3713 - val_loss: 10.7365\n",
      "Epoch 1363/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0412 - val_loss: 10.5121\n",
      "Epoch 1364/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8527 - val_loss: 10.8192\n",
      "Epoch 1365/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0859 - val_loss: 10.9326\n",
      "Epoch 1366/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0294 - val_loss: 10.7668\n",
      "Epoch 1367/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4968 - val_loss: 13.0244\n",
      "Epoch 1368/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.5347 - val_loss: 11.5898\n",
      "Epoch 1369/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6651 - val_loss: 10.6174\n",
      "Epoch 1370/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8346 - val_loss: 10.5214\n",
      "Epoch 1371/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9387 - val_loss: 10.5333\n",
      "Epoch 1372/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8912 - val_loss: 12.6599\n",
      "Epoch 1373/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0569 - val_loss: 10.4890\n",
      "Epoch 1374/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8857 - val_loss: 10.4888\n",
      "Epoch 1375/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8913 - val_loss: 10.7040\n",
      "Epoch 1376/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8539 - val_loss: 10.4829\n",
      "Epoch 1377/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0642 - val_loss: 11.7071\n",
      "Epoch 1378/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0599 - val_loss: 10.6335\n",
      "Epoch 1379/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8002 - val_loss: 10.5148\n",
      "Epoch 1380/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0003 - val_loss: 11.0058\n",
      "Epoch 1381/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0100 - val_loss: 10.8876\n",
      "Epoch 1382/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0325 - val_loss: 10.7393\n",
      "Epoch 1383/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7994 - val_loss: 10.5960\n",
      "Epoch 1384/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0356 - val_loss: 11.6491\n",
      "Epoch 1385/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1599 - val_loss: 10.7907\n",
      "Epoch 1386/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8839 - val_loss: 10.6928\n",
      "Epoch 1387/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1522 - val_loss: 10.5396\n",
      "Epoch 1388/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9953 - val_loss: 10.5366\n",
      "Epoch 1389/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9242 - val_loss: 11.1035\n",
      "Epoch 1390/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9384 - val_loss: 10.9756\n",
      "Epoch 1391/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3514 - val_loss: 11.0560\n",
      "Epoch 1392/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9103 - val_loss: 10.7224\n",
      "Epoch 1393/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9084 - val_loss: 10.9746\n",
      "Epoch 1394/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9318 - val_loss: 10.9689\n",
      "Epoch 1395/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0328 - val_loss: 10.8909\n",
      "Epoch 1396/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0781 - val_loss: 10.9107\n",
      "Epoch 1397/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8878 - val_loss: 10.9730\n",
      "Epoch 1398/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0434 - val_loss: 11.0338\n",
      "Epoch 1399/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9954 - val_loss: 11.0061\n",
      "Epoch 1400/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0188 - val_loss: 12.8862\n",
      "Epoch 1401/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3703 - val_loss: 10.7578\n",
      "Epoch 1402/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9604 - val_loss: 10.7978\n",
      "Epoch 1403/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9452 - val_loss: 10.7269\n",
      "Epoch 1404/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9779 - val_loss: 11.1498\n",
      "Epoch 1405/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3019 - val_loss: 11.1522\n",
      "Epoch 1406/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9071 - val_loss: 12.6348\n",
      "Epoch 1407/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1928 - val_loss: 11.6408\n",
      "Epoch 1408/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1555 - val_loss: 10.9819\n",
      "Epoch 1409/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9999 - val_loss: 11.1193\n",
      "Epoch 1410/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3569 - val_loss: 11.9395\n",
      "Epoch 1411/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0097 - val_loss: 10.8644\n",
      "Epoch 1412/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0168 - val_loss: 11.1750\n",
      "Epoch 1413/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9989 - val_loss: 11.1588\n",
      "Epoch 1414/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2986 - val_loss: 10.9622\n",
      "Epoch 1415/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9180 - val_loss: 11.0520\n",
      "Epoch 1416/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9737 - val_loss: 10.9674\n",
      "Epoch 1417/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8872 - val_loss: 11.0824\n",
      "Epoch 1418/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7914 - val_loss: 10.8646\n",
      "Epoch 1419/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3858 - val_loss: 11.0015\n",
      "Epoch 1420/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9597 - val_loss: 10.8889\n",
      "Epoch 1421/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0121 - val_loss: 10.7841\n",
      "Epoch 1422/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9423 - val_loss: 10.9558\n",
      "Epoch 1423/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1638 - val_loss: 11.0459\n",
      "Epoch 1424/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8528 - val_loss: 11.0430\n",
      "Epoch 1425/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2624 - val_loss: 10.7427\n",
      "Epoch 1426/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9790 - val_loss: 11.0641\n",
      "Epoch 1427/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8707 - val_loss: 11.1656\n",
      "Epoch 1428/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9647 - val_loss: 11.2740\n",
      "Epoch 1429/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0180 - val_loss: 11.0897\n",
      "Epoch 1430/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1330 - val_loss: 11.0026\n",
      "Epoch 1431/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8558 - val_loss: 11.2716\n",
      "Epoch 1432/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0111 - val_loss: 10.9038\n",
      "Epoch 1433/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0121 - val_loss: 10.9959\n",
      "Epoch 1434/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9247 - val_loss: 10.7675\n",
      "Epoch 1435/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8800 - val_loss: 11.1226\n",
      "Epoch 1436/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1637 - val_loss: 11.6292\n",
      "Epoch 1437/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1557 - val_loss: 11.5498\n",
      "Epoch 1438/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7537 - val_loss: 10.6331\n",
      "Epoch 1439/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2525 - val_loss: 11.2494\n",
      "Epoch 1440/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1996 - val_loss: 10.8758\n",
      "Epoch 1441/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8691 - val_loss: 10.6452\n",
      "Epoch 1442/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9027 - val_loss: 10.7939\n",
      "Epoch 1443/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9420 - val_loss: 11.0127\n",
      "Epoch 1444/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8538 - val_loss: 10.6244\n",
      "Epoch 1445/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0168 - val_loss: 10.9557\n",
      "Epoch 1446/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9190 - val_loss: 10.7013\n",
      "Epoch 1447/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8819 - val_loss: 11.5731\n",
      "Epoch 1448/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8944 - val_loss: 10.7016\n",
      "Epoch 1449/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9514 - val_loss: 10.9198\n",
      "Epoch 1450/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1659 - val_loss: 11.1854\n",
      "Epoch 1451/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3368 - val_loss: 10.9050\n",
      "Epoch 1452/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0837 - val_loss: 11.2831\n",
      "Epoch 1453/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0540 - val_loss: 11.0363\n",
      "Epoch 1454/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9679 - val_loss: 10.7959\n",
      "Epoch 1455/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8787 - val_loss: 11.2756\n",
      "Epoch 1456/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9269 - val_loss: 11.4060\n",
      "Epoch 1457/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8802 - val_loss: 10.7697\n",
      "Epoch 1458/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2393 - val_loss: 10.9538\n",
      "Epoch 1459/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9033 - val_loss: 11.2005\n",
      "Epoch 1460/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8784 - val_loss: 11.0011\n",
      "Epoch 1461/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1179 - val_loss: 11.0785\n",
      "Epoch 1462/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9271 - val_loss: 10.6876\n",
      "Epoch 1463/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8301 - val_loss: 11.1650\n",
      "Epoch 1464/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9587 - val_loss: 10.9047\n",
      "Epoch 1465/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8152 - val_loss: 11.2860\n",
      "Epoch 1466/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0938 - val_loss: 11.2319\n",
      "Epoch 1467/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7330 - val_loss: 12.8226\n",
      "Epoch 1468/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6831 - val_loss: 11.6189\n",
      "Epoch 1469/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4373 - val_loss: 13.0071\n",
      "Epoch 1470/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5291 - val_loss: 10.7958\n",
      "Epoch 1471/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8610 - val_loss: 11.4356\n",
      "Epoch 1472/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0396 - val_loss: 11.0396\n",
      "Epoch 1473/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6571 - val_loss: 10.8397\n",
      "Epoch 1474/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8149 - val_loss: 10.8752\n",
      "Epoch 1475/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8221 - val_loss: 11.0917\n",
      "Epoch 1476/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7804 - val_loss: 11.4094\n",
      "Epoch 1477/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8422 - val_loss: 10.7018\n",
      "Epoch 1478/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9590 - val_loss: 11.2759\n",
      "Epoch 1479/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9134 - val_loss: 10.7934\n",
      "Epoch 1480/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1982 - val_loss: 12.0370\n",
      "Epoch 1481/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2075 - val_loss: 11.5174\n",
      "Epoch 1482/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9292 - val_loss: 11.2444\n",
      "Epoch 1483/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8237 - val_loss: 10.7449\n",
      "Epoch 1484/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8839 - val_loss: 11.6875\n",
      "Epoch 1485/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9161 - val_loss: 10.9725\n",
      "Epoch 1486/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8888 - val_loss: 11.1022\n",
      "Epoch 1487/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8104 - val_loss: 11.0941\n",
      "Epoch 1488/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8683 - val_loss: 11.1909\n",
      "Epoch 1489/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1011 - val_loss: 11.3455\n",
      "Epoch 1490/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1341 - val_loss: 11.7194\n",
      "Epoch 1491/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0066 - val_loss: 11.8771\n",
      "Epoch 1492/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8693 - val_loss: 10.9308\n",
      "Epoch 1493/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8992 - val_loss: 10.9355\n",
      "Epoch 1494/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8795 - val_loss: 11.2106\n",
      "Epoch 1495/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0326 - val_loss: 11.2456\n",
      "Epoch 1496/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9470 - val_loss: 11.0186\n",
      "Epoch 1497/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0028 - val_loss: 10.9653\n",
      "Epoch 1498/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9432 - val_loss: 10.7461\n",
      "Epoch 1499/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6794 - val_loss: 12.8347\n",
      "Epoch 1500/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1602 - val_loss: 11.1086\n",
      "Epoch 1501/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3814 - val_loss: 11.3160\n",
      "Epoch 1502/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9956 - val_loss: 10.8537\n",
      "Epoch 1503/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8535 - val_loss: 10.8073\n",
      "Epoch 1504/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7920 - val_loss: 10.7754\n",
      "Epoch 1505/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9059 - val_loss: 10.7173\n",
      "Epoch 1506/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9296 - val_loss: 11.0828\n",
      "Epoch 1507/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7778 - val_loss: 10.8134\n",
      "Epoch 1508/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1113 - val_loss: 11.6638\n",
      "Epoch 1509/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9735 - val_loss: 10.8302\n",
      "Epoch 1510/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9036 - val_loss: 10.9069\n",
      "Epoch 1511/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7647 - val_loss: 11.5631\n",
      "Epoch 1512/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1620 - val_loss: 11.0182\n",
      "Epoch 1513/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1843 - val_loss: 10.9881\n",
      "Epoch 1514/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8922 - val_loss: 10.5439\n",
      "Epoch 1515/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9841 - val_loss: 11.5200\n",
      "Epoch 1516/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9104 - val_loss: 10.8577\n",
      "Epoch 1517/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8967 - val_loss: 10.8276\n",
      "Epoch 1518/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2143 - val_loss: 11.1654\n",
      "Epoch 1519/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8331 - val_loss: 10.8639\n",
      "Epoch 1520/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8937 - val_loss: 10.7389\n",
      "Epoch 1521/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0263 - val_loss: 11.3203\n",
      "Epoch 1522/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9593 - val_loss: 11.1221\n",
      "Epoch 1523/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9467 - val_loss: 11.1819\n",
      "Epoch 1524/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9699 - val_loss: 11.0950\n",
      "Epoch 1525/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8879 - val_loss: 10.5701\n",
      "Epoch 1526/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9107 - val_loss: 12.2729\n",
      "Epoch 1527/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4167 - val_loss: 11.1729\n",
      "Epoch 1528/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7793 - val_loss: 10.8334\n",
      "Epoch 1529/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8264 - val_loss: 10.9802\n",
      "Epoch 1530/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8285 - val_loss: 10.8157\n",
      "Epoch 1531/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8471 - val_loss: 10.9459\n",
      "Epoch 1532/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9474 - val_loss: 11.7958\n",
      "Epoch 1533/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6066 - val_loss: 12.8602\n",
      "Epoch 1534/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6052 - val_loss: 10.8007\n",
      "Epoch 1535/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0427 - val_loss: 11.7737\n",
      "Epoch 1536/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7567 - val_loss: 10.6915\n",
      "Epoch 1537/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8678 - val_loss: 11.1800\n",
      "Epoch 1538/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7921 - val_loss: 11.0168\n",
      "Epoch 1539/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1374 - val_loss: 10.8941\n",
      "Epoch 1540/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8492 - val_loss: 10.9285\n",
      "Epoch 1541/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0208 - val_loss: 11.2791\n",
      "Epoch 1542/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8965 - val_loss: 10.7324\n",
      "Epoch 1543/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9652 - val_loss: 10.8598\n",
      "Epoch 1544/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8937 - val_loss: 10.9676\n",
      "Epoch 1545/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8835 - val_loss: 10.8151\n",
      "Epoch 1546/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0203 - val_loss: 10.7509\n",
      "Epoch 1547/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1330 - val_loss: 10.9673\n",
      "Epoch 1548/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7831 - val_loss: 10.9351\n",
      "Epoch 1549/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7459 - val_loss: 10.9948\n",
      "Epoch 1550/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2026 - val_loss: 11.5754\n",
      "Epoch 1551/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2331 - val_loss: 13.3258\n",
      "Epoch 1552/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2255 - val_loss: 10.9769\n",
      "Epoch 1553/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8233 - val_loss: 11.0940\n",
      "Epoch 1554/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8414 - val_loss: 10.7892\n",
      "Epoch 1555/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9916 - val_loss: 11.0447\n",
      "Epoch 1556/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9868 - val_loss: 11.1049\n",
      "Epoch 1557/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7884 - val_loss: 11.3151\n",
      "Epoch 1558/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9758 - val_loss: 11.1922\n",
      "Epoch 1559/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1716 - val_loss: 11.2379\n",
      "Epoch 1560/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7924 - val_loss: 11.0163\n",
      "Epoch 1561/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8709 - val_loss: 10.8487\n",
      "Epoch 1562/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8028 - val_loss: 10.8141\n",
      "Epoch 1563/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8563 - val_loss: 11.4793\n",
      "Epoch 1564/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8517 - val_loss: 11.3812\n",
      "Epoch 1565/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9942 - val_loss: 10.7700\n",
      "Epoch 1566/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8785 - val_loss: 11.3482\n",
      "Epoch 1567/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9786 - val_loss: 11.3329\n",
      "Epoch 1568/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0482 - val_loss: 11.4060\n",
      "Epoch 1569/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2572 - val_loss: 11.7289\n",
      "Epoch 1570/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8360 - val_loss: 11.5209\n",
      "Epoch 1571/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1594 - val_loss: 10.8278\n",
      "Epoch 1572/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7927 - val_loss: 10.9209\n",
      "Epoch 1573/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8122 - val_loss: 10.6833\n",
      "Epoch 1574/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0552 - val_loss: 11.0106\n",
      "Epoch 1575/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8257 - val_loss: 11.0827\n",
      "Epoch 1576/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9440 - val_loss: 11.8856\n",
      "Epoch 1577/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9730 - val_loss: 11.9807\n",
      "Epoch 1578/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9084 - val_loss: 10.9386\n",
      "Epoch 1579/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8826 - val_loss: 11.0951\n",
      "Epoch 1580/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0489 - val_loss: 11.5320\n",
      "Epoch 1581/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8409 - val_loss: 10.9950\n",
      "Epoch 1582/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8454 - val_loss: 11.0829\n",
      "Epoch 1583/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1986 - val_loss: 12.3040\n",
      "Epoch 1584/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0461 - val_loss: 11.8212\n",
      "Epoch 1585/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0995 - val_loss: 10.9944\n",
      "Epoch 1586/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8535 - val_loss: 10.7191\n",
      "Epoch 1587/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8267 - val_loss: 11.2415\n",
      "Epoch 1588/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8403 - val_loss: 10.8602\n",
      "Epoch 1589/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8878 - val_loss: 11.0653\n",
      "Epoch 1590/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1208 - val_loss: 12.0877\n",
      "Epoch 1591/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2266 - val_loss: 11.1974\n",
      "Epoch 1592/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7521 - val_loss: 10.8570\n",
      "Epoch 1593/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8943 - val_loss: 11.0508\n",
      "Epoch 1594/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8876 - val_loss: 10.8300\n",
      "Epoch 1595/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8739 - val_loss: 10.9968\n",
      "Epoch 1596/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9622 - val_loss: 10.7747\n",
      "Epoch 1597/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8295 - val_loss: 11.0261\n",
      "Epoch 1598/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0578 - val_loss: 11.2866\n",
      "Epoch 1599/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9026 - val_loss: 10.7024\n",
      "Epoch 1600/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9533 - val_loss: 11.6444\n",
      "Epoch 1601/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9701 - val_loss: 10.7909\n",
      "Epoch 1602/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8135 - val_loss: 10.8911\n",
      "Epoch 1603/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2731 - val_loss: 11.6939\n",
      "Epoch 1604/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2177 - val_loss: 11.0591\n",
      "Epoch 1605/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3409 - val_loss: 11.4703\n",
      "Epoch 1606/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8893 - val_loss: 11.0225\n",
      "Epoch 1607/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2430 - val_loss: 11.1017\n",
      "Epoch 1608/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6735 - val_loss: 10.9692\n",
      "Epoch 1609/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6747 - val_loss: 11.1811\n",
      "Epoch 1610/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8105 - val_loss: 10.7442\n",
      "Epoch 1611/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7215 - val_loss: 10.9010\n",
      "Epoch 1612/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8706 - val_loss: 10.9476\n",
      "Epoch 1613/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8789 - val_loss: 11.0502\n",
      "Epoch 1614/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7811 - val_loss: 11.1344\n",
      "Epoch 1615/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0465 - val_loss: 11.1533\n",
      "Epoch 1616/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0005 - val_loss: 11.3466\n",
      "Epoch 1617/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8803 - val_loss: 11.1287\n",
      "Epoch 1618/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9463 - val_loss: 11.2424\n",
      "Epoch 1619/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1281 - val_loss: 10.9777\n",
      "Epoch 1620/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7429 - val_loss: 10.9948\n",
      "Epoch 1621/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8778 - val_loss: 11.3919\n",
      "Epoch 1622/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8673 - val_loss: 11.8672\n",
      "Epoch 1623/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9190 - val_loss: 11.0099\n",
      "Epoch 1624/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0774 - val_loss: 10.8609\n",
      "Epoch 1625/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7653 - val_loss: 10.8713\n",
      "Epoch 1626/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7987 - val_loss: 11.3735\n",
      "Epoch 1627/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2241 - val_loss: 11.1767\n",
      "Epoch 1628/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8341 - val_loss: 10.8324\n",
      "Epoch 1629/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6957 - val_loss: 11.0241\n",
      "Epoch 1630/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8733 - val_loss: 11.1922\n",
      "Epoch 1631/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8254 - val_loss: 11.1122\n",
      "Epoch 1632/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1038 - val_loss: 11.1133\n",
      "Epoch 1633/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9614 - val_loss: 14.0792\n",
      "Epoch 1634/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7798 - val_loss: 10.8693\n",
      "Epoch 1635/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0052 - val_loss: 10.8329\n",
      "Epoch 1636/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8611 - val_loss: 10.7182\n",
      "Epoch 1637/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6407 - val_loss: 10.6595\n",
      "Epoch 1638/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8470 - val_loss: 11.4551\n",
      "Epoch 1639/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9572 - val_loss: 10.9835\n",
      "Epoch 1640/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8441 - val_loss: 11.0651\n",
      "Epoch 1641/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6898 - val_loss: 11.1520\n",
      "Epoch 1642/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7671 - val_loss: 11.1707\n",
      "Epoch 1643/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8407 - val_loss: 10.7615\n",
      "Epoch 1644/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6757 - val_loss: 10.9163\n",
      "Epoch 1645/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8179 - val_loss: 10.8125\n",
      "Epoch 1646/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8122 - val_loss: 11.1392\n",
      "Epoch 1647/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8601 - val_loss: 11.1190\n",
      "Epoch 1648/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7791 - val_loss: 10.8852\n",
      "Epoch 1649/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8460 - val_loss: 11.1817\n",
      "Epoch 1650/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8245 - val_loss: 10.7461\n",
      "Epoch 1651/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1286 - val_loss: 10.7747\n",
      "Epoch 1652/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9674 - val_loss: 10.9486\n",
      "Epoch 1653/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0444 - val_loss: 11.4472\n",
      "Epoch 1654/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7216 - val_loss: 10.7086\n",
      "Epoch 1655/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9015 - val_loss: 11.0225\n",
      "Epoch 1656/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9021 - val_loss: 11.1143\n",
      "Epoch 1657/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9061 - val_loss: 11.3301\n",
      "Epoch 1658/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7645 - val_loss: 10.9720\n",
      "Epoch 1659/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7881 - val_loss: 11.3314\n",
      "Epoch 1660/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0982 - val_loss: 12.1006\n",
      "Epoch 1661/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3624 - val_loss: 10.7022\n",
      "Epoch 1662/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9425 - val_loss: 11.7899\n",
      "Epoch 1663/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4567 - val_loss: 11.6145\n",
      "Epoch 1664/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8544 - val_loss: 10.7442\n",
      "Epoch 1665/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9062 - val_loss: 10.8455\n",
      "Epoch 1666/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7182 - val_loss: 10.8928\n",
      "Epoch 1667/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8217 - val_loss: 10.7721\n",
      "Epoch 1668/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8726 - val_loss: 10.9687\n",
      "Epoch 1669/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9633 - val_loss: 10.9961\n",
      "Epoch 1670/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7480 - val_loss: 10.8152\n",
      "Epoch 1671/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7419 - val_loss: 10.8246\n",
      "Epoch 1672/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7808 - val_loss: 10.6425\n",
      "Epoch 1673/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8732 - val_loss: 11.2257\n",
      "Epoch 1674/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0583 - val_loss: 11.0534\n",
      "Epoch 1675/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3905 - val_loss: 11.7535\n",
      "Epoch 1676/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9637 - val_loss: 11.0551\n",
      "Epoch 1677/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1943 - val_loss: 11.3390\n",
      "Epoch 1678/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6835 - val_loss: 10.8747\n",
      "Epoch 1679/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9097 - val_loss: 11.1457\n",
      "Epoch 1680/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6760 - val_loss: 11.2114\n",
      "Epoch 1681/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7981 - val_loss: 10.9301\n",
      "Epoch 1682/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7253 - val_loss: 11.3611\n",
      "Epoch 1683/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7845 - val_loss: 10.9768\n",
      "Epoch 1684/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0164 - val_loss: 12.1450\n",
      "Epoch 1685/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4294 - val_loss: 10.9240\n",
      "Epoch 1686/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9195 - val_loss: 11.0749\n",
      "Epoch 1687/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8036 - val_loss: 11.0739\n",
      "Epoch 1688/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6462 - val_loss: 10.7628\n",
      "Epoch 1689/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9867 - val_loss: 12.4841\n",
      "Epoch 1690/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0753 - val_loss: 11.0649\n",
      "Epoch 1691/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8449 - val_loss: 11.1547\n",
      "Epoch 1692/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9407 - val_loss: 11.7331\n",
      "Epoch 1693/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0506 - val_loss: 10.6763\n",
      "Epoch 1694/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7233 - val_loss: 10.7316\n",
      "Epoch 1695/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7980 - val_loss: 10.9757\n",
      "Epoch 1696/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8467 - val_loss: 10.7398\n",
      "Epoch 1697/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7486 - val_loss: 11.2747\n",
      "Epoch 1698/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8864 - val_loss: 11.1248\n",
      "Epoch 1699/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8962 - val_loss: 11.9967\n",
      "Epoch 1700/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0160 - val_loss: 11.3114\n",
      "Epoch 1701/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8669 - val_loss: 11.0691\n",
      "Epoch 1702/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8342 - val_loss: 11.2329\n",
      "Epoch 1703/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0505 - val_loss: 11.5795\n",
      "Epoch 1704/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8988 - val_loss: 10.9803\n",
      "Epoch 1705/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0804 - val_loss: 12.0533\n",
      "Epoch 1706/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7580 - val_loss: 10.9435\n",
      "Epoch 1707/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8205 - val_loss: 11.1826\n",
      "Epoch 1708/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0458 - val_loss: 11.1447\n",
      "Epoch 1709/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0921 - val_loss: 11.7509\n",
      "Epoch 1710/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7835 - val_loss: 10.9430\n",
      "Epoch 1711/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8839 - val_loss: 11.1620\n",
      "Epoch 1712/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2440 - val_loss: 11.6212\n",
      "Epoch 1713/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8505 - val_loss: 11.1404\n",
      "Epoch 1714/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.0876 - val_loss: 11.9691\n",
      "Epoch 1715/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0289 - val_loss: 10.8951\n",
      "Epoch 1716/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1425 - val_loss: 11.2575\n",
      "Epoch 1717/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9707 - val_loss: 11.3740\n",
      "Epoch 1718/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8174 - val_loss: 11.0963\n",
      "Epoch 1719/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6473 - val_loss: 10.8867\n",
      "Epoch 1720/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0135 - val_loss: 11.0516\n",
      "Epoch 1721/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8987 - val_loss: 11.0717\n",
      "Epoch 1722/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7189 - val_loss: 10.8200\n",
      "Epoch 1723/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7101 - val_loss: 11.2470\n",
      "Epoch 1724/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6522 - val_loss: 11.0303\n",
      "Epoch 1725/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9287 - val_loss: 10.7225\n",
      "Epoch 1726/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0005 - val_loss: 10.8013\n",
      "Epoch 1727/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0034 - val_loss: 11.3952\n",
      "Epoch 1728/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8487 - val_loss: 11.0693\n",
      "Epoch 1729/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2017 - val_loss: 10.9463\n",
      "Epoch 1730/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8410 - val_loss: 10.9993\n",
      "Epoch 1731/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6432 - val_loss: 11.2243\n",
      "Epoch 1732/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7297 - val_loss: 10.7741\n",
      "Epoch 1733/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1741 - val_loss: 11.1846\n",
      "Epoch 1734/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8812 - val_loss: 11.1367\n",
      "Epoch 1735/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8843 - val_loss: 11.1812\n",
      "Epoch 1736/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0333 - val_loss: 11.0400\n",
      "Epoch 1737/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9282 - val_loss: 11.4193\n",
      "Epoch 1738/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8257 - val_loss: 11.3130\n",
      "Epoch 1739/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7389 - val_loss: 10.9334\n",
      "Epoch 1740/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7455 - val_loss: 10.9039\n",
      "Epoch 1741/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7519 - val_loss: 10.8046\n",
      "Epoch 1742/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7648 - val_loss: 10.8500\n",
      "Epoch 1743/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8199 - val_loss: 10.7194\n",
      "Epoch 1744/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1606 - val_loss: 12.2091\n",
      "Epoch 1745/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1456 - val_loss: 11.9544\n",
      "Epoch 1746/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9477 - val_loss: 11.2675\n",
      "Epoch 1747/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8764 - val_loss: 11.5083\n",
      "Epoch 1748/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1017 - val_loss: 10.9826\n",
      "Epoch 1749/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7235 - val_loss: 11.8631\n",
      "Epoch 1750/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2578 - val_loss: 10.9693\n",
      "Epoch 1751/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7597 - val_loss: 11.1987\n",
      "Epoch 1752/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6532 - val_loss: 11.0148\n",
      "Epoch 1753/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8856 - val_loss: 10.9416\n",
      "Epoch 1754/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9539 - val_loss: 11.1374\n",
      "Epoch 1755/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7446 - val_loss: 11.1303\n",
      "Epoch 1756/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7533 - val_loss: 11.0111\n",
      "Epoch 1757/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 11.0472\n",
      "Epoch 1758/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0330 - val_loss: 10.8802\n",
      "Epoch 1759/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8709 - val_loss: 11.2261\n",
      "Epoch 1760/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1578 - val_loss: 11.4253\n",
      "Epoch 1761/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8445 - val_loss: 10.8670\n",
      "Epoch 1762/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8933 - val_loss: 11.0143\n",
      "Epoch 1763/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9107 - val_loss: 11.6894\n",
      "Epoch 1764/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7818 - val_loss: 10.8235\n",
      "Epoch 1765/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7931 - val_loss: 11.7501\n",
      "Epoch 1766/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8009 - val_loss: 11.2361\n",
      "Epoch 1767/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7213 - val_loss: 11.3667\n",
      "Epoch 1768/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7489 - val_loss: 10.9620\n",
      "Epoch 1769/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7313 - val_loss: 11.2167\n",
      "Epoch 1770/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8407 - val_loss: 11.0251\n",
      "Epoch 1771/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9453 - val_loss: 11.3348\n",
      "Epoch 1772/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6966 - val_loss: 11.1364\n",
      "Epoch 1773/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8225 - val_loss: 12.3173\n",
      "Epoch 1774/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9249 - val_loss: 10.9758\n",
      "Epoch 1775/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0471 - val_loss: 11.8617\n",
      "Epoch 1776/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8262 - val_loss: 11.2425\n",
      "Epoch 1777/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0825 - val_loss: 11.1625\n",
      "Epoch 1778/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9426 - val_loss: 10.9457\n",
      "Epoch 1779/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7833 - val_loss: 11.0747\n",
      "Epoch 1780/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8907 - val_loss: 11.3526\n",
      "Epoch 1781/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7952 - val_loss: 10.9534\n",
      "Epoch 1782/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1135 - val_loss: 11.6707\n",
      "Epoch 1783/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1075 - val_loss: 10.8541\n",
      "Epoch 1784/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8155 - val_loss: 10.6950\n",
      "Epoch 1785/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6515 - val_loss: 11.0621\n",
      "Epoch 1786/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7517 - val_loss: 10.9551\n",
      "Epoch 1787/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7524 - val_loss: 11.0743\n",
      "Epoch 1788/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9390 - val_loss: 11.0236\n",
      "Epoch 1789/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2516 - val_loss: 11.1824\n",
      "Epoch 1790/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8646 - val_loss: 11.2822\n",
      "Epoch 1791/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1036 - val_loss: 10.8766\n",
      "Epoch 1792/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6860 - val_loss: 11.4848\n",
      "Epoch 1793/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8274 - val_loss: 11.0509\n",
      "Epoch 1794/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6967 - val_loss: 10.9722\n",
      "Epoch 1795/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6475 - val_loss: 10.7829\n",
      "Epoch 1796/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7059 - val_loss: 11.1260\n",
      "Epoch 1797/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1036 - val_loss: 12.0461\n",
      "Epoch 1798/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1762 - val_loss: 12.5560\n",
      "Epoch 1799/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9376 - val_loss: 11.0203\n",
      "Epoch 1800/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3199 - val_loss: 11.0721\n",
      "Epoch 1801/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7531 - val_loss: 11.4359\n",
      "Epoch 1802/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0624 - val_loss: 10.8693\n",
      "Epoch 1803/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6721 - val_loss: 11.0699\n",
      "Epoch 1804/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6005 - val_loss: 10.8789\n",
      "Epoch 1805/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6128 - val_loss: 11.1837\n",
      "Epoch 1806/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8397 - val_loss: 10.9398\n",
      "Epoch 1807/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7615 - val_loss: 11.4835\n",
      "Epoch 1808/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8369 - val_loss: 11.3262\n",
      "Epoch 1809/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1993 - val_loss: 11.1055\n",
      "Epoch 1810/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0173 - val_loss: 11.2007\n",
      "Epoch 1811/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.4947 - val_loss: 11.0922\n",
      "Epoch 1812/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8688 - val_loss: 11.0815\n",
      "Epoch 1813/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8889 - val_loss: 10.9674\n",
      "Epoch 1814/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0815 - val_loss: 10.9817\n",
      "Epoch 1815/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7089 - val_loss: 11.1724\n",
      "Epoch 1816/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6706 - val_loss: 10.7228\n",
      "Epoch 1817/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6286 - val_loss: 10.9263\n",
      "Epoch 1818/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7927 - val_loss: 10.5708\n",
      "Epoch 1819/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0389 - val_loss: 11.5395\n",
      "Epoch 1820/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6601 - val_loss: 11.0275\n",
      "Epoch 1821/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6110 - val_loss: 11.1355\n",
      "Epoch 1822/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6345 - val_loss: 11.2675\n",
      "Epoch 1823/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7691 - val_loss: 11.2409\n",
      "Epoch 1824/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7269 - val_loss: 11.2376\n",
      "Epoch 1825/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9865 - val_loss: 11.0187\n",
      "Epoch 1826/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8411 - val_loss: 11.0228\n",
      "Epoch 1827/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0132 - val_loss: 11.1304\n",
      "Epoch 1828/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7562 - val_loss: 10.9324\n",
      "Epoch 1829/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0601 - val_loss: 12.4498\n",
      "Epoch 1830/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3743 - val_loss: 11.0989\n",
      "Epoch 1831/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9157 - val_loss: 11.1050\n",
      "Epoch 1832/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8241 - val_loss: 11.2822\n",
      "Epoch 1833/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0872 - val_loss: 10.8525\n",
      "Epoch 1834/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6470 - val_loss: 11.4138\n",
      "Epoch 1835/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7790 - val_loss: 10.8101\n",
      "Epoch 1836/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8818 - val_loss: 10.8618\n",
      "Epoch 1837/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5752 - val_loss: 11.4874\n",
      "Epoch 1838/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9772 - val_loss: 11.3951\n",
      "Epoch 1839/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7620 - val_loss: 11.0746\n",
      "Epoch 1840/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7555 - val_loss: 11.0028\n",
      "Epoch 1841/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6268 - val_loss: 10.9076\n",
      "Epoch 1842/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7976 - val_loss: 11.3190\n",
      "Epoch 1843/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1845 - val_loss: 11.3142\n",
      "Epoch 1844/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8409 - val_loss: 11.1173\n",
      "Epoch 1845/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6591 - val_loss: 10.9017\n",
      "Epoch 1846/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9340 - val_loss: 10.8684\n",
      "Epoch 1847/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6473 - val_loss: 11.0653\n",
      "Epoch 1848/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8623 - val_loss: 11.1190\n",
      "Epoch 1849/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9061 - val_loss: 12.1751\n",
      "Epoch 1850/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1839 - val_loss: 11.9752\n",
      "Epoch 1851/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8252 - val_loss: 11.1775\n",
      "Epoch 1852/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9705 - val_loss: 11.5709\n",
      "Epoch 1853/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7466 - val_loss: 10.9128\n",
      "Epoch 1854/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9145 - val_loss: 10.7456\n",
      "Epoch 1855/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8017 - val_loss: 11.0458\n",
      "Epoch 1856/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0797 - val_loss: 12.1807\n",
      "Epoch 1857/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8022 - val_loss: 11.1800\n",
      "Epoch 1858/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8596 - val_loss: 11.0988\n",
      "Epoch 1859/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2694 - val_loss: 11.0744\n",
      "Epoch 1860/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6140 - val_loss: 10.9659\n",
      "Epoch 1861/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7128 - val_loss: 11.0757\n",
      "Epoch 1862/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6684 - val_loss: 11.0930\n",
      "Epoch 1863/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9373 - val_loss: 10.8286\n",
      "Epoch 1864/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6842 - val_loss: 10.7514\n",
      "Epoch 1865/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6233 - val_loss: 11.0120\n",
      "Epoch 1866/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6772 - val_loss: 10.7565\n",
      "Epoch 1867/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8221 - val_loss: 11.2093\n",
      "Epoch 1868/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5844 - val_loss: 10.7202\n",
      "Epoch 1869/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6292 - val_loss: 11.1710\n",
      "Epoch 1870/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8904 - val_loss: 10.8460\n",
      "Epoch 1871/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8210 - val_loss: 10.8267\n",
      "Epoch 1872/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 10.7241\n",
      "Epoch 1873/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6049 - val_loss: 10.8075\n",
      "Epoch 1874/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7413 - val_loss: 11.0773\n",
      "Epoch 1875/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5920 - val_loss: 11.0974\n",
      "Epoch 1876/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6693 - val_loss: 11.1246\n",
      "Epoch 1877/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8470 - val_loss: 11.1675\n",
      "Epoch 1878/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7611 - val_loss: 10.7596\n",
      "Epoch 1879/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1766 - val_loss: 12.0414\n",
      "Epoch 1880/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8501 - val_loss: 11.5547\n",
      "Epoch 1881/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2651 - val_loss: 11.3040\n",
      "Epoch 1882/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0606 - val_loss: 11.0367\n",
      "Epoch 1883/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6715 - val_loss: 11.5493\n",
      "Epoch 1884/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7522 - val_loss: 11.0897\n",
      "Epoch 1885/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8353 - val_loss: 11.0725\n",
      "Epoch 1886/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6091 - val_loss: 11.2186\n",
      "Epoch 1887/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6534 - val_loss: 11.1155\n",
      "Epoch 1888/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8177 - val_loss: 11.5378\n",
      "Epoch 1889/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6725 - val_loss: 11.2096\n",
      "Epoch 1890/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0002 - val_loss: 10.8638\n",
      "Epoch 1891/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5810 - val_loss: 10.9198\n",
      "Epoch 1892/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7520 - val_loss: 11.3279\n",
      "Epoch 1893/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7254 - val_loss: 10.6475\n",
      "Epoch 1894/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6915 - val_loss: 10.9002\n",
      "Epoch 1895/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7225 - val_loss: 11.0261\n",
      "Epoch 1896/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0772 - val_loss: 11.2006\n",
      "Epoch 1897/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6646 - val_loss: 11.3368\n",
      "Epoch 1898/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6198 - val_loss: 11.0322\n",
      "Epoch 1899/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 11.1377\n",
      "Epoch 1900/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6892 - val_loss: 11.0532\n",
      "Epoch 1901/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7760 - val_loss: 10.7749\n",
      "Epoch 1902/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8733 - val_loss: 11.1465\n",
      "Epoch 1903/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7372 - val_loss: 11.3767\n",
      "Epoch 1904/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0459 - val_loss: 11.8130\n",
      "Epoch 1905/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.2320 - val_loss: 12.1542\n",
      "Epoch 1906/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1494 - val_loss: 10.7549\n",
      "Epoch 1907/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7706 - val_loss: 10.6882\n",
      "Epoch 1908/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6584 - val_loss: 10.8283\n",
      "Epoch 1909/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6167 - val_loss: 10.7063\n",
      "Epoch 1910/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7185 - val_loss: 10.7788\n",
      "Epoch 1911/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7045 - val_loss: 10.8632\n",
      "Epoch 1912/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9401 - val_loss: 11.2658\n",
      "Epoch 1913/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1817 - val_loss: 10.8696\n",
      "Epoch 1914/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8472 - val_loss: 11.2584\n",
      "Epoch 1915/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6447 - val_loss: 10.7419\n",
      "Epoch 1916/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7332 - val_loss: 11.4736\n",
      "Epoch 1917/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8914 - val_loss: 11.0623\n",
      "Epoch 1918/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7957 - val_loss: 10.6300\n",
      "Epoch 1919/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0923 - val_loss: 10.6481\n",
      "Epoch 1920/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9866 - val_loss: 11.5444\n",
      "Epoch 1921/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7316 - val_loss: 10.9138\n",
      "Epoch 1922/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5992 - val_loss: 10.5995\n",
      "Epoch 1923/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9100 - val_loss: 11.0228\n",
      "Epoch 1924/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7150 - val_loss: 10.6776\n",
      "Epoch 1925/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9476 - val_loss: 11.4900\n",
      "Epoch 1926/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1477 - val_loss: 10.9515\n",
      "Epoch 1927/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5647 - val_loss: 10.8266\n",
      "Epoch 1928/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6154 - val_loss: 10.9280\n",
      "Epoch 1929/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6247 - val_loss: 10.9253\n",
      "Epoch 1930/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6780 - val_loss: 11.5076\n",
      "Epoch 1931/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0433 - val_loss: 11.0800\n",
      "Epoch 1932/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8252 - val_loss: 11.3237\n",
      "Epoch 1933/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7376 - val_loss: 11.0203\n",
      "Epoch 1934/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7601 - val_loss: 11.3409\n",
      "Epoch 1935/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6893 - val_loss: 11.3639\n",
      "Epoch 1936/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8712 - val_loss: 11.0596\n",
      "Epoch 1937/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8386 - val_loss: 10.8494\n",
      "Epoch 1938/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6067 - val_loss: 10.9813\n",
      "Epoch 1939/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7392 - val_loss: 11.4176\n",
      "Epoch 1940/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6787 - val_loss: 11.0612\n",
      "Epoch 1941/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7131 - val_loss: 11.3647\n",
      "Epoch 1942/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7505 - val_loss: 11.1126\n",
      "Epoch 1943/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6596 - val_loss: 12.6106\n",
      "Epoch 1944/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7572 - val_loss: 11.5486\n",
      "Epoch 1945/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7997 - val_loss: 10.5859\n",
      "Epoch 1946/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5997 - val_loss: 10.8595\n",
      "Epoch 1947/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7069 - val_loss: 11.2447\n",
      "Epoch 1948/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7644 - val_loss: 10.9765\n",
      "Epoch 1949/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8269 - val_loss: 10.5926\n",
      "Epoch 1950/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7359 - val_loss: 11.1002\n",
      "Epoch 1951/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5319 - val_loss: 10.7021\n",
      "Epoch 1952/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6668 - val_loss: 11.1286\n",
      "Epoch 1953/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7689 - val_loss: 10.8385\n",
      "Epoch 1954/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7794 - val_loss: 10.9112\n",
      "Epoch 1955/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7947 - val_loss: 10.8328\n",
      "Epoch 1956/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7505 - val_loss: 10.7152\n",
      "Epoch 1957/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7762 - val_loss: 11.3966\n",
      "Epoch 1958/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8454 - val_loss: 10.9643\n",
      "Epoch 1959/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7715 - val_loss: 10.9715\n",
      "Epoch 1960/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9973 - val_loss: 11.2923\n",
      "Epoch 1961/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9995 - val_loss: 10.8954\n",
      "Epoch 1962/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8687 - val_loss: 10.8708\n",
      "Epoch 1963/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9011 - val_loss: 10.9262\n",
      "Epoch 1964/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6581 - val_loss: 10.8920\n",
      "Epoch 1965/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7765 - val_loss: 10.9241\n",
      "Epoch 1966/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7321 - val_loss: 11.0431\n",
      "Epoch 1967/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7060 - val_loss: 10.7837\n",
      "Epoch 1968/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7903 - val_loss: 11.3685\n",
      "Epoch 1969/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6970 - val_loss: 11.2807\n",
      "Epoch 1970/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8006 - val_loss: 10.8997\n",
      "Epoch 1971/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6375 - val_loss: 11.6621\n",
      "Epoch 1972/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6726 - val_loss: 10.7141\n",
      "Epoch 1973/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7079 - val_loss: 11.0718\n",
      "Epoch 1974/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9324 - val_loss: 11.8651\n",
      "Epoch 1975/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5861 - val_loss: 11.3158\n",
      "Epoch 1976/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6323 - val_loss: 10.8646\n",
      "Epoch 1977/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6130 - val_loss: 11.3452\n",
      "Epoch 1978/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7177 - val_loss: 11.0337\n",
      "Epoch 1979/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7567 - val_loss: 11.6389\n",
      "Epoch 1980/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6920 - val_loss: 10.8000\n",
      "Epoch 1981/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7420 - val_loss: 11.0706\n",
      "Epoch 1982/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6679 - val_loss: 10.9025\n",
      "Epoch 1983/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6903 - val_loss: 10.8796\n",
      "Epoch 1984/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6845 - val_loss: 11.1290\n",
      "Epoch 1985/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7832 - val_loss: 11.0652\n",
      "Epoch 1986/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7101 - val_loss: 11.1486\n",
      "Epoch 1987/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6395 - val_loss: 10.9650\n",
      "Epoch 1988/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7541 - val_loss: 10.9658\n",
      "Epoch 1989/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0126 - val_loss: 11.0396\n",
      "Epoch 1990/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3551 - val_loss: 11.1772\n",
      "Epoch 1991/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 11.1744\n",
      "Epoch 1992/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7650 - val_loss: 11.4337\n",
      "Epoch 1993/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6877 - val_loss: 11.2144\n",
      "Epoch 1994/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8858 - val_loss: 10.8573\n",
      "Epoch 1995/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6361 - val_loss: 10.8750\n",
      "Epoch 1996/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5639 - val_loss: 10.9106\n",
      "Epoch 1997/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5874 - val_loss: 10.9130\n",
      "Epoch 1998/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7018 - val_loss: 11.1212\n",
      "Epoch 1999/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8410 - val_loss: 11.0206\n",
      "Epoch 2000/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6507 - val_loss: 11.2584\n",
      "Epoch 2001/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8040 - val_loss: 10.9110\n",
      "Epoch 2002/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6562 - val_loss: 11.1466\n",
      "Epoch 2003/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1085 - val_loss: 11.4597\n",
      "Epoch 2004/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0831 - val_loss: 11.2385\n",
      "Epoch 2005/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9638 - val_loss: 11.4201\n",
      "Epoch 2006/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7288 - val_loss: 10.7370\n",
      "Epoch 2007/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6337 - val_loss: 10.9895\n",
      "Epoch 2008/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5796 - val_loss: 11.0328\n",
      "Epoch 2009/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8102 - val_loss: 12.2196\n",
      "Epoch 2010/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9575 - val_loss: 12.0377\n",
      "Epoch 2011/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6957 - val_loss: 10.7936\n",
      "Epoch 2012/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6442 - val_loss: 10.8219\n",
      "Epoch 2013/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7806 - val_loss: 11.2730\n",
      "Epoch 2014/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5881 - val_loss: 11.0096\n",
      "Epoch 2015/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5898 - val_loss: 10.8223\n",
      "Epoch 2016/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6380 - val_loss: 10.7811\n",
      "Epoch 2017/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9741 - val_loss: 11.3473\n",
      "Epoch 2018/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7666 - val_loss: 11.4391\n",
      "Epoch 2019/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6101 - val_loss: 11.0199\n",
      "Epoch 2020/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6937 - val_loss: 10.8689\n",
      "Epoch 2021/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7102 - val_loss: 11.4846\n",
      "Epoch 2022/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8161 - val_loss: 11.3609\n",
      "Epoch 2023/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5590 - val_loss: 10.9778\n",
      "Epoch 2024/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7555 - val_loss: 11.6446\n",
      "Epoch 2025/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.1006 - val_loss: 13.9879\n",
      "Epoch 2026/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9401 - val_loss: 11.2282\n",
      "Epoch 2027/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8968 - val_loss: 10.9923\n",
      "Epoch 2028/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8499 - val_loss: 11.6293\n",
      "Epoch 2029/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8657 - val_loss: 10.8964\n",
      "Epoch 2030/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8290 - val_loss: 10.8156\n",
      "Epoch 2031/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5120 - val_loss: 10.8862\n",
      "Epoch 2032/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6861 - val_loss: 10.9054\n",
      "Epoch 2033/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0154 - val_loss: 10.9456\n",
      "Epoch 2034/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5009 - val_loss: 11.2168\n",
      "Epoch 2035/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4512 - val_loss: 11.1545\n",
      "Epoch 2036/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9363 - val_loss: 10.9603\n",
      "Epoch 2037/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7247 - val_loss: 11.2931\n",
      "Epoch 2038/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5093 - val_loss: 10.9706\n",
      "Epoch 2039/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6059 - val_loss: 11.0663\n",
      "Epoch 2040/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6169 - val_loss: 11.1253\n",
      "Epoch 2041/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6133 - val_loss: 11.1786\n",
      "Epoch 2042/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5713 - val_loss: 10.7108\n",
      "Epoch 2043/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5750 - val_loss: 10.7957\n",
      "Epoch 2044/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6988 - val_loss: 10.9108\n",
      "Epoch 2045/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6814 - val_loss: 11.0544\n",
      "Epoch 2046/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0048 - val_loss: 10.7931\n",
      "Epoch 2047/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8567 - val_loss: 11.2071\n",
      "Epoch 2048/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9504 - val_loss: 11.1759\n",
      "Epoch 2049/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8963 - val_loss: 11.4889\n",
      "Epoch 2050/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9527 - val_loss: 10.7260\n",
      "Epoch 2051/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5308 - val_loss: 10.7235\n",
      "Epoch 2052/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9292 - val_loss: 12.6669\n",
      "Epoch 2053/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.4213 - val_loss: 11.5377\n",
      "Epoch 2054/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0720 - val_loss: 11.3937\n",
      "Epoch 2055/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6964 - val_loss: 10.9782\n",
      "Epoch 2056/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5824 - val_loss: 10.8261\n",
      "Epoch 2057/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5416 - val_loss: 10.7105\n",
      "Epoch 2058/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7284 - val_loss: 12.3771\n",
      "Epoch 2059/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7757 - val_loss: 11.4344\n",
      "Epoch 2060/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6690 - val_loss: 11.0798\n",
      "Epoch 2061/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8721 - val_loss: 11.6323\n",
      "Epoch 2062/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6651 - val_loss: 11.1736\n",
      "Epoch 2063/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7439 - val_loss: 11.2701\n",
      "Epoch 2064/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7559 - val_loss: 11.2719\n",
      "Epoch 2065/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5652 - val_loss: 10.7989\n",
      "Epoch 2066/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5794 - val_loss: 11.2935\n",
      "Epoch 2067/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5408 - val_loss: 11.0184\n",
      "Epoch 2068/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6440 - val_loss: 10.9911\n",
      "Epoch 2069/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6312 - val_loss: 10.8031\n",
      "Epoch 2070/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7610 - val_loss: 11.0316\n",
      "Epoch 2071/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6562 - val_loss: 11.1792\n",
      "Epoch 2072/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9538 - val_loss: 11.1905\n",
      "Epoch 2073/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5996 - val_loss: 11.6488\n",
      "Epoch 2074/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7146 - val_loss: 10.9921\n",
      "Epoch 2075/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7509 - val_loss: 11.5449\n",
      "Epoch 2076/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7954 - val_loss: 10.9974\n",
      "Epoch 2077/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5742 - val_loss: 10.8783\n",
      "Epoch 2078/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7614 - val_loss: 10.8804\n",
      "Epoch 2079/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6312 - val_loss: 11.0566\n",
      "Epoch 2080/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6173 - val_loss: 11.0394\n",
      "Epoch 2081/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7303 - val_loss: 11.0077\n",
      "Epoch 2082/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7814 - val_loss: 11.4166\n",
      "Epoch 2083/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9449 - val_loss: 11.4762\n",
      "Epoch 2084/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0227 - val_loss: 11.1717\n",
      "Epoch 2085/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7250 - val_loss: 11.3191\n",
      "Epoch 2086/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6523 - val_loss: 11.1908\n",
      "Epoch 2087/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7356 - val_loss: 11.1008\n",
      "Epoch 2088/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6094 - val_loss: 11.9561\n",
      "Epoch 2089/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9265 - val_loss: 11.2206\n",
      "Epoch 2090/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6286 - val_loss: 11.1548\n",
      "Epoch 2091/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7284 - val_loss: 11.3338\n",
      "Epoch 2092/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5720 - val_loss: 11.8573\n",
      "Epoch 2093/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1381 - val_loss: 11.1308\n",
      "Epoch 2094/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8445 - val_loss: 11.9427\n",
      "Epoch 2095/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7517 - val_loss: 10.8040\n",
      "Epoch 2096/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6214 - val_loss: 11.3605\n",
      "Epoch 2097/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5913 - val_loss: 10.9250\n",
      "Epoch 2098/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6996 - val_loss: 10.7638\n",
      "Epoch 2099/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6570 - val_loss: 11.0710\n",
      "Epoch 2100/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1629 - val_loss: 11.3868\n",
      "Epoch 2101/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1887 - val_loss: 11.0408\n",
      "Epoch 2102/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8638 - val_loss: 10.9476\n",
      "Epoch 2103/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5588 - val_loss: 11.0322\n",
      "Epoch 2104/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6769 - val_loss: 11.2212\n",
      "Epoch 2105/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6371 - val_loss: 11.3355\n",
      "Epoch 2106/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7127 - val_loss: 11.2607\n",
      "Epoch 2107/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6800 - val_loss: 11.6259\n",
      "Epoch 2108/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6650 - val_loss: 10.9532\n",
      "Epoch 2109/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7655 - val_loss: 11.5884\n",
      "Epoch 2110/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8164 - val_loss: 10.9823\n",
      "Epoch 2111/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5908 - val_loss: 11.1845\n",
      "Epoch 2112/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6123 - val_loss: 10.9730\n",
      "Epoch 2113/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6814 - val_loss: 11.6868\n",
      "Epoch 2114/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8879 - val_loss: 10.9761\n",
      "Epoch 2115/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6017 - val_loss: 10.9127\n",
      "Epoch 2116/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5610 - val_loss: 11.1464\n",
      "Epoch 2117/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8173 - val_loss: 12.7270\n",
      "Epoch 2118/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8543 - val_loss: 10.8657\n",
      "Epoch 2119/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5656 - val_loss: 10.7811\n",
      "Epoch 2120/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9128 - val_loss: 11.5733\n",
      "Epoch 2121/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1869 - val_loss: 11.5084\n",
      "Epoch 2122/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6700 - val_loss: 11.2693\n",
      "Epoch 2123/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7358 - val_loss: 10.8497\n",
      "Epoch 2124/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6993 - val_loss: 11.3234\n",
      "Epoch 2125/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6056 - val_loss: 11.0526\n",
      "Epoch 2126/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6712 - val_loss: 11.3481\n",
      "Epoch 2127/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9580 - val_loss: 11.9822\n",
      "Epoch 2128/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7439 - val_loss: 10.9660\n",
      "Epoch 2129/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6539 - val_loss: 11.0144\n",
      "Epoch 2130/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6502 - val_loss: 11.0043\n",
      "Epoch 2131/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5905 - val_loss: 10.8619\n",
      "Epoch 2132/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5521 - val_loss: 10.9214\n",
      "Epoch 2133/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5908 - val_loss: 10.9912\n",
      "Epoch 2134/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6113 - val_loss: 11.0989\n",
      "Epoch 2135/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6914 - val_loss: 10.8563\n",
      "Epoch 2136/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7011 - val_loss: 10.8712\n",
      "Epoch 2137/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7163 - val_loss: 11.1488\n",
      "Epoch 2138/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8180 - val_loss: 11.4201\n",
      "Epoch 2139/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7117 - val_loss: 11.4062\n",
      "Epoch 2140/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8431 - val_loss: 10.9274\n",
      "Epoch 2141/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6164 - val_loss: 10.7883\n",
      "Epoch 2142/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7659 - val_loss: 11.7501\n",
      "Epoch 2143/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9550 - val_loss: 12.3617\n",
      "Epoch 2144/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8982 - val_loss: 11.4651\n",
      "Epoch 2145/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7450 - val_loss: 11.5673\n",
      "Epoch 2146/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5919 - val_loss: 11.0047\n",
      "Epoch 2147/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6553 - val_loss: 11.0936\n",
      "Epoch 2148/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7817 - val_loss: 11.2962\n",
      "Epoch 2149/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6929 - val_loss: 11.4281\n",
      "Epoch 2150/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7461 - val_loss: 11.1052\n",
      "Epoch 2151/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6857 - val_loss: 11.1363\n",
      "Epoch 2152/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6684 - val_loss: 11.0345\n",
      "Epoch 2153/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6900 - val_loss: 11.0213\n",
      "Epoch 2154/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8885 - val_loss: 10.9994\n",
      "Epoch 2155/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6611 - val_loss: 11.2010\n",
      "Epoch 2156/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6042 - val_loss: 10.9327\n",
      "Epoch 2157/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5782 - val_loss: 11.1617\n",
      "Epoch 2158/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6633 - val_loss: 10.9600\n",
      "Epoch 2159/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0629 - val_loss: 10.9585\n",
      "Epoch 2160/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6485 - val_loss: 11.5825\n",
      "Epoch 2161/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5479 - val_loss: 10.8579\n",
      "Epoch 2162/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7550 - val_loss: 12.6741\n",
      "Epoch 2163/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.1220 - val_loss: 11.8946\n",
      "Epoch 2164/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0822 - val_loss: 10.9095\n",
      "Epoch 2165/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6510 - val_loss: 10.8247\n",
      "Epoch 2166/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5978 - val_loss: 10.7692\n",
      "Epoch 2167/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6343 - val_loss: 10.9095\n",
      "Epoch 2168/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7398 - val_loss: 11.0230\n",
      "Epoch 2169/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7223 - val_loss: 11.0888\n",
      "Epoch 2170/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6547 - val_loss: 11.1507\n",
      "Epoch 2171/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8477 - val_loss: 10.9573\n",
      "Epoch 2172/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6517 - val_loss: 11.1024\n",
      "Epoch 2173/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7276 - val_loss: 10.9661\n",
      "Epoch 2174/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6569 - val_loss: 10.8813\n",
      "Epoch 2175/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7945 - val_loss: 10.9166\n",
      "Epoch 2176/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6356 - val_loss: 11.1315\n",
      "Epoch 2177/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6757 - val_loss: 11.1734\n",
      "Epoch 2178/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7212 - val_loss: 12.1633\n",
      "Epoch 2179/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7205 - val_loss: 11.0458\n",
      "Epoch 2180/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5271 - val_loss: 11.1648\n",
      "Epoch 2181/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6353 - val_loss: 11.1408\n",
      "Epoch 2182/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9796 - val_loss: 11.2124\n",
      "Epoch 2183/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5619 - val_loss: 11.1398\n",
      "Epoch 2184/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5870 - val_loss: 10.8978\n",
      "Epoch 2185/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5296 - val_loss: 10.8691\n",
      "Epoch 2186/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6953 - val_loss: 11.8265\n",
      "Epoch 2187/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7712 - val_loss: 11.0122\n",
      "Epoch 2188/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0298 - val_loss: 12.3339\n",
      "Epoch 2189/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6981 - val_loss: 11.3412\n",
      "Epoch 2190/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6745 - val_loss: 11.5001\n",
      "Epoch 2191/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5372 - val_loss: 11.0354\n",
      "Epoch 2192/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6196 - val_loss: 10.8570\n",
      "Epoch 2193/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7931 - val_loss: 11.1965\n",
      "Epoch 2194/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6560 - val_loss: 11.0114\n",
      "Epoch 2195/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0553 - val_loss: 11.0433\n",
      "Epoch 2196/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4911 - val_loss: 11.0372\n",
      "Epoch 2197/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6698 - val_loss: 10.7963\n",
      "Epoch 2198/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6679 - val_loss: 11.3414\n",
      "Epoch 2199/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.6606 - val_loss: 12.9917\n",
      "Epoch 2200/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6369 - val_loss: 11.2580\n",
      "Epoch 2201/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7279 - val_loss: 10.9226\n",
      "Epoch 2202/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5775 - val_loss: 10.8479\n",
      "Epoch 2203/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5417 - val_loss: 10.8872\n",
      "Epoch 2204/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7920 - val_loss: 11.8178\n",
      "Epoch 2205/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6516 - val_loss: 11.2155\n",
      "Epoch 2206/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6078 - val_loss: 11.0602\n",
      "Epoch 2207/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8265 - val_loss: 11.3035\n",
      "Epoch 2208/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5687 - val_loss: 10.9370\n",
      "Epoch 2209/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6209 - val_loss: 11.0043\n",
      "Epoch 2210/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5289 - val_loss: 11.0903\n",
      "Epoch 2211/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6452 - val_loss: 10.9073\n",
      "Epoch 2212/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6984 - val_loss: 11.1393\n",
      "Epoch 2213/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6639 - val_loss: 11.1339\n",
      "Epoch 2214/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7065 - val_loss: 10.9614\n",
      "Epoch 2215/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5575 - val_loss: 10.9965\n",
      "Epoch 2216/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7004 - val_loss: 10.9217\n",
      "Epoch 2217/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9339 - val_loss: 12.3458\n",
      "Epoch 2218/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.5339 - val_loss: 11.8939\n",
      "Epoch 2219/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2827 - val_loss: 11.0731\n",
      "Epoch 2220/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7073 - val_loss: 11.9814\n",
      "Epoch 2221/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6748 - val_loss: 11.1395\n",
      "Epoch 2222/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5081 - val_loss: 11.1072\n",
      "Epoch 2223/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7260 - val_loss: 11.1554\n",
      "Epoch 2224/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5473 - val_loss: 11.1262\n",
      "Epoch 2225/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8433 - val_loss: 11.3653\n",
      "Epoch 2226/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5465 - val_loss: 11.1614\n",
      "Epoch 2227/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6574 - val_loss: 11.0333\n",
      "Epoch 2228/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6116 - val_loss: 11.1163\n",
      "Epoch 2229/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6060 - val_loss: 11.1170\n",
      "Epoch 2230/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9333 - val_loss: 10.9343\n",
      "Epoch 2231/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6358 - val_loss: 10.8341\n",
      "Epoch 2232/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5303 - val_loss: 10.9704\n",
      "Epoch 2233/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5636 - val_loss: 11.1697\n",
      "Epoch 2234/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5623 - val_loss: 11.4971\n",
      "Epoch 2235/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7865 - val_loss: 11.1965\n",
      "Epoch 2236/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7145 - val_loss: 11.1040\n",
      "Epoch 2237/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6752 - val_loss: 10.8752\n",
      "Epoch 2238/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6404 - val_loss: 11.1480\n",
      "Epoch 2239/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6266 - val_loss: 12.7596\n",
      "Epoch 2240/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6652 - val_loss: 11.1543\n",
      "Epoch 2241/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7971 - val_loss: 11.0813\n",
      "Epoch 2242/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6202 - val_loss: 11.1169\n",
      "Epoch 2243/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6316 - val_loss: 11.4789\n",
      "Epoch 2244/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9268 - val_loss: 11.3133\n",
      "Epoch 2245/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6472 - val_loss: 11.5987\n",
      "Epoch 2246/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7311 - val_loss: 11.0389\n",
      "Epoch 2247/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6043 - val_loss: 11.4564\n",
      "Epoch 2248/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5374 - val_loss: 11.2658\n",
      "Epoch 2249/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6199 - val_loss: 10.8995\n",
      "Epoch 2250/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6077 - val_loss: 11.1522\n",
      "Epoch 2251/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6351 - val_loss: 11.3499\n",
      "Epoch 2252/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6959 - val_loss: 11.1104\n",
      "Epoch 2253/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7864 - val_loss: 11.2461\n",
      "Epoch 2254/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6181 - val_loss: 10.9648\n",
      "Epoch 2255/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6001 - val_loss: 10.9707\n",
      "Epoch 2256/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6052 - val_loss: 11.3629\n",
      "Epoch 2257/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8387 - val_loss: 11.0449\n",
      "Epoch 2258/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5894 - val_loss: 11.0315\n",
      "Epoch 2259/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4999 - val_loss: 11.2729\n",
      "Epoch 2260/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5635 - val_loss: 10.9199\n",
      "Epoch 2261/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7187 - val_loss: 11.3610\n",
      "Epoch 2262/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6734 - val_loss: 11.5373\n",
      "Epoch 2263/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7822 - val_loss: 11.2513\n",
      "Epoch 2264/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7838 - val_loss: 10.9113\n",
      "Epoch 2265/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6004 - val_loss: 10.9895\n",
      "Epoch 2266/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6635 - val_loss: 11.4878\n",
      "Epoch 2267/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7375 - val_loss: 10.9674\n",
      "Epoch 2268/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6786 - val_loss: 11.0734\n",
      "Epoch 2269/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6655 - val_loss: 10.9437\n",
      "Epoch 2270/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6692 - val_loss: 11.2532\n",
      "Epoch 2271/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8024 - val_loss: 11.2212\n",
      "Epoch 2272/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6188 - val_loss: 11.0722\n",
      "Epoch 2273/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7509 - val_loss: 11.4307\n",
      "Epoch 2274/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7571 - val_loss: 10.8958\n",
      "Epoch 2275/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5773 - val_loss: 11.0375\n",
      "Epoch 2276/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7154 - val_loss: 10.9899\n",
      "Epoch 2277/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6100 - val_loss: 11.0702\n",
      "Epoch 2278/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5646 - val_loss: 11.0820\n",
      "Epoch 2279/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6067 - val_loss: 11.3495\n",
      "Epoch 2280/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6908 - val_loss: 11.1844\n",
      "Epoch 2281/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8845 - val_loss: 11.2453\n",
      "Epoch 2282/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6757 - val_loss: 11.1330\n",
      "Epoch 2283/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6554 - val_loss: 11.0771\n",
      "Epoch 2284/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5471 - val_loss: 10.9381\n",
      "Epoch 2285/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5434 - val_loss: 11.3736\n",
      "Epoch 2286/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7046 - val_loss: 11.1792\n",
      "Epoch 2287/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6760 - val_loss: 11.3389\n",
      "Epoch 2288/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7039 - val_loss: 11.0861\n",
      "Epoch 2289/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6443 - val_loss: 11.2402\n",
      "Epoch 2290/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6524 - val_loss: 11.2680\n",
      "Epoch 2291/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6111 - val_loss: 11.4280\n",
      "Epoch 2292/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6232 - val_loss: 11.1284\n",
      "Epoch 2293/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.8595 - val_loss: 12.1872\n",
      "Epoch 2294/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1891 - val_loss: 11.7310\n",
      "Epoch 2295/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9478 - val_loss: 10.9483\n",
      "Epoch 2296/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5071 - val_loss: 10.8240\n",
      "Epoch 2297/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5605 - val_loss: 10.7999\n",
      "Epoch 2298/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6101 - val_loss: 10.9838\n",
      "Epoch 2299/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5768 - val_loss: 11.1186\n",
      "Epoch 2300/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7594 - val_loss: 10.9267\n",
      "Epoch 2301/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6149 - val_loss: 11.1503\n",
      "Epoch 2302/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8771 - val_loss: 11.0599\n",
      "Epoch 2303/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5575 - val_loss: 10.9957\n",
      "Epoch 2304/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6350 - val_loss: 11.1007\n",
      "Epoch 2305/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6885 - val_loss: 11.0809\n",
      "Epoch 2306/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5609 - val_loss: 11.0492\n",
      "Epoch 2307/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5934 - val_loss: 10.9848\n",
      "Epoch 2308/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0427 - val_loss: 11.6758\n",
      "Epoch 2309/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5775 - val_loss: 10.9977\n",
      "Epoch 2310/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5701 - val_loss: 11.2025\n",
      "Epoch 2311/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7272 - val_loss: 11.0381\n",
      "Epoch 2312/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6288 - val_loss: 11.1063\n",
      "Epoch 2313/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5148 - val_loss: 11.0241\n",
      "Epoch 2314/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6225 - val_loss: 11.2069\n",
      "Epoch 2315/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8145 - val_loss: 11.3114\n",
      "Epoch 2316/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5533 - val_loss: 10.9939\n",
      "Epoch 2317/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5874 - val_loss: 10.7395\n",
      "Epoch 2318/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6392 - val_loss: 10.9517\n",
      "Epoch 2319/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5322 - val_loss: 11.1510\n",
      "Epoch 2320/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7382 - val_loss: 10.9060\n",
      "Epoch 2321/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6797 - val_loss: 11.2272\n",
      "Epoch 2322/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8181 - val_loss: 10.9992\n",
      "Epoch 2323/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6479 - val_loss: 10.9471\n",
      "Epoch 2324/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5176 - val_loss: 11.4903\n",
      "Epoch 2325/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4891 - val_loss: 10.9625\n",
      "Epoch 2326/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6367 - val_loss: 10.8516\n",
      "Epoch 2327/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6041 - val_loss: 11.0352\n",
      "Epoch 2328/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6269 - val_loss: 11.5223\n",
      "Epoch 2329/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6957 - val_loss: 10.8947\n",
      "Epoch 2330/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6203 - val_loss: 10.7522\n",
      "Epoch 2331/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6074 - val_loss: 11.0991\n",
      "Epoch 2332/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6581 - val_loss: 11.1814\n",
      "Epoch 2333/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.7153 - val_loss: 13.8491\n",
      "Epoch 2334/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.5595 - val_loss: 11.8856\n",
      "Epoch 2335/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.1403 - val_loss: 10.9568\n",
      "Epoch 2336/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8110 - val_loss: 10.8200\n",
      "Epoch 2337/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5078 - val_loss: 10.7237\n",
      "Epoch 2338/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4451 - val_loss: 10.8442\n",
      "Epoch 2339/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4441 - val_loss: 11.1050\n",
      "Epoch 2340/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4800 - val_loss: 10.9848\n",
      "Epoch 2341/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4053 - val_loss: 11.3574\n",
      "Epoch 2342/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9429 - val_loss: 11.2479\n",
      "Epoch 2343/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5847 - val_loss: 11.6020\n",
      "Epoch 2344/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7343 - val_loss: 10.8010\n",
      "Epoch 2345/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.3820 - val_loss: 10.8263\n",
      "Epoch 2346/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5940 - val_loss: 11.2332\n",
      "Epoch 2347/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4564 - val_loss: 11.0980\n",
      "Epoch 2348/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4914 - val_loss: 10.8502\n",
      "Epoch 2349/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6012 - val_loss: 11.3057\n",
      "Epoch 2350/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6212 - val_loss: 11.0539\n",
      "Epoch 2351/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5664 - val_loss: 10.8778\n",
      "Epoch 2352/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5436 - val_loss: 11.2900\n",
      "Epoch 2353/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9559 - val_loss: 11.0097\n",
      "Epoch 2354/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4925 - val_loss: 11.2041\n",
      "Epoch 2355/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6767 - val_loss: 10.9793\n",
      "Epoch 2356/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7031 - val_loss: 10.9215\n",
      "Epoch 2357/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7819 - val_loss: 11.8532\n",
      "Epoch 2358/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2459 - val_loss: 11.5380\n",
      "Epoch 2359/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9545 - val_loss: 12.1136\n",
      "Epoch 2360/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0033 - val_loss: 11.6126\n",
      "Epoch 2361/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6114 - val_loss: 11.0800\n",
      "Epoch 2362/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5670 - val_loss: 11.0329\n",
      "Epoch 2363/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6016 - val_loss: 10.9509\n",
      "Epoch 2364/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6087 - val_loss: 10.8502\n",
      "Epoch 2365/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5042 - val_loss: 10.9420\n",
      "Epoch 2366/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5429 - val_loss: 11.3692\n",
      "Epoch 2367/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5908 - val_loss: 11.5879\n",
      "Epoch 2368/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5781 - val_loss: 11.4799\n",
      "Epoch 2369/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5462 - val_loss: 11.1814\n",
      "Epoch 2370/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5347 - val_loss: 11.0732\n",
      "Epoch 2371/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5557 - val_loss: 11.2543\n",
      "Epoch 2372/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7873 - val_loss: 11.2312\n",
      "Epoch 2373/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9092 - val_loss: 11.2664\n",
      "Epoch 2374/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7663 - val_loss: 11.3472\n",
      "Epoch 2375/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6220 - val_loss: 10.9301\n",
      "Epoch 2376/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6232 - val_loss: 11.0284\n",
      "Epoch 2377/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8350 - val_loss: 10.9757\n",
      "Epoch 2378/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5231 - val_loss: 10.8201\n",
      "Epoch 2379/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4870 - val_loss: 11.2434\n",
      "Epoch 2380/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7443 - val_loss: 11.5848\n",
      "Epoch 2381/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9033 - val_loss: 11.1711\n",
      "Epoch 2382/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5921 - val_loss: 11.0114\n",
      "Epoch 2383/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6465 - val_loss: 11.7185\n",
      "Epoch 2384/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6511 - val_loss: 11.2129\n",
      "Epoch 2385/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5660 - val_loss: 10.8021\n",
      "Epoch 2386/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6471 - val_loss: 10.8202\n",
      "Epoch 2387/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6134 - val_loss: 11.5306\n",
      "Epoch 2388/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.3965 - val_loss: 11.5655\n",
      "Epoch 2389/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6231 - val_loss: 11.4494\n",
      "Epoch 2390/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6098 - val_loss: 11.3595\n",
      "Epoch 2391/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6693 - val_loss: 11.1484\n",
      "Epoch 2392/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6432 - val_loss: 11.1251\n",
      "Epoch 2393/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5957 - val_loss: 11.0417\n",
      "Epoch 2394/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5564 - val_loss: 10.8300\n",
      "Epoch 2395/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5134 - val_loss: 11.4301\n",
      "Epoch 2396/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7277 - val_loss: 11.0818\n",
      "Epoch 2397/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6438 - val_loss: 11.3425\n",
      "Epoch 2398/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 6.1451 - val_loss: 12.7128\n",
      "Epoch 2399/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6385 - val_loss: 11.0892\n",
      "Epoch 2400/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6944 - val_loss: 11.0041\n",
      "Epoch 2401/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7044 - val_loss: 10.9026\n",
      "Epoch 2402/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6529 - val_loss: 10.9675\n",
      "Epoch 2403/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6188 - val_loss: 11.0434\n",
      "Epoch 2404/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.3849 - val_loss: 10.8289\n",
      "Epoch 2405/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4870 - val_loss: 10.9552\n",
      "Epoch 2406/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6745 - val_loss: 10.8990\n",
      "Epoch 2407/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5126 - val_loss: 11.2396\n",
      "Epoch 2408/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4937 - val_loss: 11.4422\n",
      "Epoch 2409/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6608 - val_loss: 11.9680\n",
      "Epoch 2410/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5168 - val_loss: 11.0450\n",
      "Epoch 2411/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.0569 - val_loss: 10.7646\n",
      "Epoch 2412/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7429 - val_loss: 11.0367\n",
      "Epoch 2413/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6362 - val_loss: 10.7855\n",
      "Epoch 2414/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9877 - val_loss: 10.8960\n",
      "Epoch 2415/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.3482 - val_loss: 10.7811\n",
      "Epoch 2416/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5236 - val_loss: 10.8416\n",
      "Epoch 2417/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5346 - val_loss: 11.4032\n",
      "Epoch 2418/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7320 - val_loss: 11.6509\n",
      "Epoch 2419/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5935 - val_loss: 10.9963\n",
      "Epoch 2420/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4741 - val_loss: 11.4387\n",
      "Epoch 2421/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5336 - val_loss: 11.0301\n",
      "Epoch 2422/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5320 - val_loss: 10.9938\n",
      "Epoch 2423/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6353 - val_loss: 11.1759\n",
      "Epoch 2424/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6291 - val_loss: 11.1751\n",
      "Epoch 2425/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7098 - val_loss: 11.2017\n",
      "Epoch 2426/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6166 - val_loss: 10.9468\n",
      "Epoch 2427/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6318 - val_loss: 11.3231\n",
      "Epoch 2428/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7258 - val_loss: 11.0158\n",
      "Epoch 2429/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5949 - val_loss: 11.1682\n",
      "Epoch 2430/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4843 - val_loss: 11.0012\n",
      "Epoch 2431/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4363 - val_loss: 11.4098\n",
      "Epoch 2432/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6144 - val_loss: 11.1115\n",
      "Epoch 2433/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7325 - val_loss: 11.0857\n",
      "Epoch 2434/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7777 - val_loss: 12.4170\n",
      "Epoch 2435/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.1227 - val_loss: 12.3382\n",
      "Epoch 2436/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.6134 - val_loss: 10.9507\n",
      "Epoch 2437/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6783 - val_loss: 10.8184\n",
      "Epoch 2438/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8197 - val_loss: 11.3840\n",
      "Epoch 2439/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7374 - val_loss: 11.0483\n",
      "Epoch 2440/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4749 - val_loss: 10.7322\n",
      "Epoch 2441/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4398 - val_loss: 11.0653\n",
      "Epoch 2442/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8800 - val_loss: 10.7094\n",
      "Epoch 2443/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5098 - val_loss: 11.0871\n",
      "Epoch 2444/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5326 - val_loss: 11.0927\n",
      "Epoch 2445/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8253 - val_loss: 11.3144\n",
      "Epoch 2446/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5610 - val_loss: 10.6820\n",
      "Epoch 2447/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5039 - val_loss: 11.0767\n",
      "Epoch 2448/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4493 - val_loss: 10.6980\n",
      "Epoch 2449/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5347 - val_loss: 10.7554\n",
      "Epoch 2450/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4280 - val_loss: 11.0079\n",
      "Epoch 2451/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5805 - val_loss: 10.9094\n",
      "Epoch 2452/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4246 - val_loss: 10.7065\n",
      "Epoch 2453/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5918 - val_loss: 10.9350\n",
      "Epoch 2454/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6855 - val_loss: 11.1022\n",
      "Epoch 2455/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9225 - val_loss: 10.8049\n",
      "Epoch 2456/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4560 - val_loss: 10.8205\n",
      "Epoch 2457/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5532 - val_loss: 10.5849\n",
      "Epoch 2458/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6653 - val_loss: 10.9999\n",
      "Epoch 2459/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5093 - val_loss: 10.9467\n",
      "Epoch 2460/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6304 - val_loss: 11.1032\n",
      "Epoch 2461/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6250 - val_loss: 11.0675\n",
      "Epoch 2462/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6117 - val_loss: 11.1095\n",
      "Epoch 2463/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5835 - val_loss: 10.8416\n",
      "Epoch 2464/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5919 - val_loss: 11.0767\n",
      "Epoch 2465/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5396 - val_loss: 11.0372\n",
      "Epoch 2466/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5301 - val_loss: 10.9930\n",
      "Epoch 2467/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6856 - val_loss: 11.2783\n",
      "Epoch 2468/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8413 - val_loss: 11.2779\n",
      "Epoch 2469/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8868 - val_loss: 11.2516\n",
      "Epoch 2470/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4026 - val_loss: 11.2493\n",
      "Epoch 2471/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8196 - val_loss: 11.4701\n",
      "Epoch 2472/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6798 - val_loss: 11.3461\n",
      "Epoch 2473/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5259 - val_loss: 11.1581\n",
      "Epoch 2474/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6040 - val_loss: 11.4566\n",
      "Epoch 2475/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 4.3427 - val_loss: 12.3436\n",
      "Epoch 2476/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.2881 - val_loss: 11.1653\n",
      "Epoch 2477/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7324 - val_loss: 11.0833\n",
      "Epoch 2478/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7194 - val_loss: 10.7862\n",
      "Epoch 2479/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5496 - val_loss: 10.8859\n",
      "Epoch 2480/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7684 - val_loss: 11.3475\n",
      "Epoch 2481/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5774 - val_loss: 10.9369\n",
      "Epoch 2482/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4175 - val_loss: 11.0027\n",
      "Epoch 2483/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.6740 - val_loss: 11.1789\n",
      "Epoch 2484/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4864 - val_loss: 10.8797\n",
      "Epoch 2485/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5227 - val_loss: 10.9807\n",
      "Epoch 2486/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4850 - val_loss: 10.9184\n",
      "Epoch 2487/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7031 - val_loss: 10.9678\n",
      "Epoch 2488/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5157 - val_loss: 12.0996\n",
      "Epoch 2489/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.8161 - val_loss: 10.9608\n",
      "Epoch 2490/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4844 - val_loss: 10.9485\n",
      "Epoch 2491/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4621 - val_loss: 11.0044\n",
      "Epoch 2492/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4753 - val_loss: 10.7904\n",
      "Epoch 2493/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5603 - val_loss: 10.9416\n",
      "Epoch 2494/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7520 - val_loss: 11.2107\n",
      "Epoch 2495/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.7636 - val_loss: 11.1144\n",
      "Epoch 2496/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.5730 - val_loss: 11.2157\n",
      "Epoch 2497/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 5.7054 - val_loss: 13.4496\n",
      "Epoch 2498/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 3.9765 - val_loss: 11.1477\n",
      "Epoch 2499/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.9310 - val_loss: 10.8946\n",
      "Epoch 2500/2500\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 2.4673 - val_loss: 10.7801\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=\"mae\",)\n",
    "\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=epoch_size,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "history: dict = history.history\n",
    "loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "l = int(len(loss) / 10)\n",
    "history['loss'] = loss[l:]\n",
    "history['val_loss'] = val_loss[l:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [5.734358310699463, 5.9687628746032715, 5.946781635284424, 5.995620250701904, 6.201939582824707, 6.018238067626953, 5.930852890014648, 6.010906219482422, 6.59189510345459, 6.20781135559082, 5.61176061630249, 6.368113040924072, 5.690041542053223, 6.004947662353516, 5.819002628326416, 5.963945388793945, 5.771535396575928, 6.592287540435791, 6.003543376922607, 5.750421524047852, 5.5868144035339355, 5.7346577644348145, 5.614777088165283, 5.604424953460693, 5.538725852966309, 5.910946369171143, 5.921643257141113, 5.580680847167969, 5.624049186706543, 5.567918300628662, 5.552240371704102, 6.132391929626465, 5.689221382141113, 5.443641185760498, 5.6498637199401855, 5.7505011558532715, 5.383169651031494, 5.806023597717285, 5.915694713592529, 5.5573506355285645, 5.7686567306518555, 5.347788333892822, 5.943798065185547, 5.319010257720947, 5.407230854034424, 5.384062767028809, 5.924293041229248, 5.4653706550598145, 5.31810188293457, 5.5174455642700195, 5.604647159576416, 5.2850165367126465, 5.314375400543213, 5.374693870544434, 5.978623390197754, 5.219268321990967, 5.136495113372803, 5.353803634643555, 5.0811872482299805, 5.353713512420654, 5.872567176818848, 5.321637153625488, 5.378812789916992, 5.037593841552734, 5.428431510925293, 5.251483917236328, 5.269992828369141, 5.225148677825928, 5.021865367889404, 5.242794513702393, 5.631939888000488, 5.264441967010498, 5.16867208480835, 5.089122295379639, 5.348382949829102, 5.287606716156006, 5.080430030822754, 5.285096168518066, 5.192142963409424, 5.0494771003723145, 5.784067153930664, 5.054529190063477, 5.077360153198242, 5.24313497543335, 5.87750244140625, 6.145722389221191, 4.945322036743164, 5.247888088226318, 5.276691436767578, 5.235992908477783, 4.869858741760254, 5.021189212799072, 4.904500484466553, 5.111515522003174, 4.834981441497803, 5.787095069885254, 5.061718463897705, 5.049792766571045, 5.341660499572754, 4.877214431762695, 4.981034278869629, 4.999960899353027, 5.196023941040039, 5.03579568862915, 5.019662857055664, 4.877110004425049, 5.002409934997559, 4.802812099456787, 4.873109340667725, 5.416156768798828, 5.001277923583984, 4.8511505126953125, 4.83636474609375, 5.261448860168457, 5.840755462646484, 5.072606086730957, 4.668106555938721, 4.751485824584961, 4.796452522277832, 5.346775054931641, 4.964325428009033, 4.902470588684082, 4.934709548950195, 5.0285515785217285, 5.108644962310791, 4.903871059417725, 4.671878814697266, 4.801086902618408, 4.808045387268066, 4.840888500213623, 4.768442630767822, 4.6847734451293945, 4.8043646812438965, 5.112611293792725, 4.826236724853516, 4.771263122558594, 4.700234889984131, 5.148649215698242, 4.656895637512207, 4.699759006500244, 4.785314559936523, 4.718499183654785, 4.517955780029297, 5.181367874145508, 4.720591068267822, 4.563374042510986, 4.682028770446777, 4.611303806304932, 4.717525959014893, 4.488241672515869, 4.805596351623535, 5.140329837799072, 4.711803913116455, 4.874126434326172, 4.746469020843506, 4.418257236480713, 4.577198505401611, 4.416585445404053, 4.751676559448242, 4.674426078796387, 4.450531959533691, 4.671176433563232, 5.493582725524902, 4.704137325286865, 4.7692036628723145, 4.649753570556641, 4.46507453918457, 4.491589069366455, 4.283687591552734, 4.661410331726074, 4.678675651550293, 4.435489177703857, 4.72322940826416, 4.52247428894043, 4.496189594268799, 4.705610275268555, 4.692895412445068, 4.457848072052002, 5.533563137054443, 4.455427646636963, 4.522884845733643, 5.129418849945068, 4.763088226318359, 4.3177008628845215, 4.352365970611572, 4.28676700592041, 4.570430278778076, 4.631703853607178, 4.514476776123047, 4.346240997314453, 5.1478447914123535, 4.8158369064331055, 4.904191970825195, 4.515748500823975, 4.890451431274414, 4.137514114379883, 4.691736221313477, 4.325104236602783, 4.470887660980225, 4.511593341827393, 4.298200607299805, 4.304140090942383, 4.582897663116455, 4.37140417098999, 4.379789352416992, 4.5297417640686035, 4.199512004852295, 4.292466640472412, 4.86287784576416, 4.504015922546387, 4.430414199829102, 4.450500011444092, 4.456660270690918, 4.346018314361572, 4.341277599334717, 4.733323574066162, 4.802112579345703, 4.345650672912598, 4.190030097961426, 4.406215667724609, 4.3354811668396, 4.36495304107666, 4.377354145050049, 4.08964729309082, 4.349710941314697, 4.294161319732666, 4.363132476806641, 4.45768928527832, 4.280357360839844, 4.377902984619141, 4.348331928253174, 4.1744585037231445, 4.502195358276367, 4.450569152832031, 5.798543930053711, 4.561234951019287, 4.089259624481201, 4.273355960845947, 4.247516632080078, 4.005199909210205, 4.397790908813477, 4.368414878845215, 4.183671474456787, 4.821115970611572, 4.550561428070068, 4.151010036468506, 4.139256477355957, 4.086903095245361, 4.41655158996582, 4.392815589904785, 4.266125202178955, 4.151757717132568, 4.321123123168945, 4.680022239685059, 4.4554123878479, 4.462193012237549, 4.386969089508057, 4.020387649536133, 4.219763278961182, 4.229458332061768, 4.403975963592529, 4.17974328994751, 4.316187381744385, 4.032657623291016, 4.125916004180908, 4.429426670074463, 4.751949787139893, 4.137762546539307, 4.380646705627441, 4.092906475067139, 4.184096336364746, 4.216257572174072, 4.117558479309082, 4.586401462554932, 4.256782054901123, 4.238317489624023, 4.4475884437561035, 4.4960618019104, 4.02751350402832, 4.083331108093262, 4.438258171081543, 4.017665386199951, 4.208183765411377, 4.071542739868164, 4.123654842376709, 4.28466796875, 4.634359359741211, 4.2627668380737305, 4.106131076812744, 4.492919445037842, 4.2451066970825195, 5.0118255615234375, 4.0985188484191895, 4.021243095397949, 3.8659896850585938, 3.9503402709960938, 4.330487251281738, 4.469596862792969, 4.729866027832031, 4.293501377105713, 4.159462928771973, 4.575267314910889, 3.9291157722473145, 3.9508206844329834, 3.86722731590271, 4.469602108001709, 3.9508891105651855, 4.719058513641357, 4.230865001678467, 3.8510260581970215, 4.0929436683654785, 3.9726197719573975, 3.9169511795043945, 4.268093109130859, 4.021576404571533, 4.542357921600342, 4.103249549865723, 3.942216634750366, 3.8173537254333496, 4.872746467590332, 4.250485420227051, 4.105489730834961, 3.9853193759918213, 4.037886142730713, 4.044410228729248, 4.118291854858398, 3.8813772201538086, 4.552585124969482, 4.246005535125732, 3.9248359203338623, 3.8428683280944824, 4.15383243560791, 4.245484352111816, 4.109408855438232, 3.984288454055786, 4.071261882781982, 4.481590747833252, 3.8668346405029297, 3.9819488525390625, 4.440498352050781, 4.509123802185059, 3.891993284225464, 3.9698405265808105, 3.8771636486053467, 3.7855262756347656, 4.018645286560059, 3.947286605834961, 4.081180095672607, 3.9173803329467773, 3.896217107772827, 4.083212852478027, 4.047576904296875, 4.354903221130371, 3.9592669010162354, 4.453650951385498, 4.2802605628967285, 4.146465301513672, 3.8594179153442383, 4.1550612449646, 3.935166835784912, 3.7994015216827393, 3.8708019256591797, 4.1531476974487305, 4.455480098724365, 4.351681709289551, 3.9135005474090576, 3.83064341545105, 4.219482421875, 4.094815731048584, 3.9243125915527344, 3.626767158508301, 4.822635173797607, 3.8646466732025146, 3.901761770248413, 3.8510901927948, 3.753746509552002, 3.743154764175415, 4.394384384155273, 4.468041896820068, 3.792692184448242, 3.833449363708496, 4.186140060424805, 3.7895071506500244, 3.827328681945801, 3.7224795818328857, 3.6951324939727783, 4.008861064910889, 4.074008464813232, 4.080235004425049, 3.8440539836883545, 3.9330039024353027, 3.954585313796997, 4.154891014099121, 3.9394946098327637, 4.421138286590576, 3.921469211578369, 4.0132365226745605, 3.6489202976226807, 3.6033740043640137, 3.8141918182373047, 3.9340391159057617, 4.47462797164917, 3.7289493083953857, 4.155588626861572, 3.7255849838256836, 4.156823635101318, 3.643836259841919, 3.757956027984619, 3.9286181926727295, 3.797635793685913, 3.820326328277588, 3.679517984390259, 4.2077555656433105, 3.7541868686676025, 3.977409839630127, 3.677091598510742, 3.739305257797241, 3.5491998195648193, 3.947822332382202, 4.125778675079346, 3.766047239303589, 3.9839987754821777, 3.639360189437866, 3.71871018409729, 3.6244583129882812, 3.869124174118042, 3.8073785305023193, 3.828568696975708, 3.660128355026245, 4.106645107269287, 4.01416540145874, 3.7847931385040283, 3.69305419921875, 3.745328664779663, 3.8176791667938232, 3.7092669010162354, 3.907536029815674, 3.7069156169891357, 3.7129931449890137, 3.7452239990234375, 3.970104455947876, 3.781344413757324, 3.7773923873901367, 3.7028908729553223, 3.8257083892822266, 3.785696268081665, 3.6702892780303955, 3.7696309089660645, 3.6689400672912598, 3.685256242752075, 3.636991500854492, 4.022693157196045, 3.62707257270813, 3.5318267345428467, 3.654041290283203, 3.7754926681518555, 4.019033908843994, 3.6236767768859863, 3.6423258781433105, 3.7013726234436035, 3.4995713233947754, 3.7059988975524902, 3.880568742752075, 3.7454395294189453, 3.933750629425049, 3.8065457344055176, 3.662834405899048, 3.8248159885406494, 4.438429355621338, 3.701725721359253, 3.8111400604248047, 4.129537582397461, 3.6631338596343994, 3.3938474655151367, 3.647463321685791, 3.6576273441314697, 3.5645058155059814, 3.379692316055298, 4.168591022491455, 4.039341926574707, 3.5561435222625732, 3.8888354301452637, 3.9604036808013916, 3.7693142890930176, 4.053319931030273, 3.444176435470581, 3.4994022846221924, 3.823108673095703, 3.418729782104492, 3.4010009765625, 3.6352317333221436, 3.9849767684936523, 3.9323277473449707, 3.877605438232422, 3.6146512031555176, 3.7461090087890625, 3.8747520446777344, 3.526054620742798, 3.6911680698394775, 3.7407398223876953, 3.7605249881744385, 3.4363696575164795, 3.582026958465576, 3.7235777378082275, 4.003624439239502, 3.6681935787200928, 3.4839494228363037, 3.547902822494507, 3.736320734024048, 3.427053928375244, 3.800839424133301, 3.731733798980713, 3.6540088653564453, 3.899229049682617, 3.7178735733032227, 3.478616952896118, 3.4582324028015137, 3.3519818782806396, 3.4804775714874268, 3.989527702331543, 3.7674763202667236, 3.5978856086730957, 3.9052677154541016, 3.556875228881836, 3.3809595108032227, 3.4277706146240234, 4.251789569854736, 3.5365958213806152, 3.637178421020508, 3.6894924640655518, 4.0937957763671875, 4.07064151763916, 3.4373090267181396, 3.417823076248169, 3.8792707920074463, 3.9235212802886963, 3.392256498336792, 3.665663480758667, 3.4887795448303223, 3.4405925273895264, 3.391059398651123, 3.456834554672241, 3.533503532409668, 3.3750722408294678, 4.127553939819336, 3.915114402770996, 3.9090001583099365, 3.705962657928467, 4.101127624511719, 3.687520742416382, 3.4890029430389404, 3.8416430950164795, 3.1732101440429688, 3.555114984512329, 4.118648052215576, 3.58526873588562, 3.495603322982788, 4.285005569458008, 3.7625486850738525, 3.8213939666748047, 3.434548854827881, 3.416428327560425, 3.5430593490600586, 3.283444404602051, 3.7608673572540283, 3.6173975467681885, 3.8553929328918457, 3.3640565872192383, 3.572852611541748, 3.327040672302246, 3.438326835632324, 3.387000799179077, 3.3761467933654785, 3.568439245223999, 3.454148530960083, 3.556060552597046, 3.6782889366149902, 3.871666193008423, 3.3761978149414062, 3.5654923915863037, 3.7060205936431885, 3.699504852294922, 3.8447911739349365, 3.74629282951355, 3.4161360263824463, 3.846794843673706, 3.5306012630462646, 3.3679826259613037, 3.3886311054229736, 3.4982287883758545, 3.4721148014068604, 3.3577218055725098, 3.463959217071533, 3.8300905227661133, 3.683701992034912, 3.5085020065307617, 3.3678648471832275, 3.791283369064331, 3.6814393997192383, 3.4730076789855957, 3.346902847290039, 3.401355028152466, 3.469088077545166, 3.4446091651916504, 3.9932191371917725, 3.816359758377075, 3.511068344116211, 3.3273439407348633, 3.3136775493621826, 3.3330302238464355, 3.758678436279297, 3.706709623336792, 3.3984954357147217, 3.4877843856811523, 3.2694153785705566, 3.616225242614746, 3.4111526012420654, 3.9114038944244385, 3.5458483695983887, 3.4816689491271973, 3.48453688621521, 3.352534532546997, 3.7692904472351074, 3.598574638366699, 3.247593641281128, 3.3124840259552, 3.481316089630127, 3.1965537071228027, 3.4547338485717773, 3.5413177013397217, 3.4731814861297607, 3.474975824356079, 3.546605348587036, 3.2764406204223633, 3.710747241973877, 3.8501791954040527, 3.256981134414673, 3.395803928375244, 3.3929555416107178, 3.4086053371429443, 3.8711812496185303, 3.544600009918213, 3.889178991317749, 3.590599775314331, 3.3371715545654297, 3.432734727859497, 3.332843065261841, 3.2886369228363037, 3.359875440597534, 3.2701892852783203, 3.5961122512817383, 3.3055684566497803, 3.6386971473693848, 3.2908356189727783, 3.5497655868530273, 3.4863126277923584, 3.6188395023345947, 3.4983224868774414, 3.725965976715088, 3.432070255279541, 3.166590690612793, 3.3494608402252197, 3.33172607421875, 3.5771830081939697, 3.311774253845215, 3.3308629989624023, 3.4371249675750732, 3.6898820400238037, 4.19736909866333, 3.461406946182251, 3.623094081878662, 3.6844918727874756, 3.1292457580566406, 3.2437398433685303, 3.273817539215088, 3.437512159347534, 3.3552730083465576, 3.560967206954956, 3.2501137256622314, 3.3627727031707764, 3.221097946166992, 3.3285698890686035, 3.582733154296875, 3.709507942199707, 3.801680326461792, 3.4364445209503174, 3.2885608673095703, 3.300429344177246, 3.4198555946350098, 3.3507559299468994, 3.2327756881713867, 3.528047800064087, 3.2022202014923096, 3.3571996688842773, 3.2601358890533447, 3.333078622817993, 3.358063220977783, 3.2766058444976807, 3.278416633605957, 4.201216220855713, 3.6990010738372803, 3.6884753704071045, 3.9631426334381104, 3.520897388458252, 3.0980091094970703, 3.107761859893799, 3.1822359561920166, 3.299511671066284, 3.1926329135894775, 3.3021745681762695, 3.380213975906372, 3.5426573753356934, 3.227958917617798, 3.2978782653808594, 3.121190309524536, 3.765211582183838, 3.7186532020568848, 3.8082332611083984, 3.7040722370147705, 3.232067823410034, 3.141956090927124, 3.0792791843414307, 3.2719290256500244, 3.387939929962158, 3.4331119060516357, 3.3621490001678467, 3.6424543857574463, 3.093395233154297, 3.6514532566070557, 3.990588665008545, 3.2891597747802734, 3.322387456893921, 3.187425136566162, 3.3800437450408936, 3.479367971420288, 3.5350213050842285, 3.13344669342041, 3.1891703605651855, 3.46911358833313, 3.438812017440796, 4.098601818084717, 3.113806962966919, 3.275911331176758, 3.158738136291504, 3.1870222091674805, 3.1579580307006836, 3.28059983253479, 3.5618457794189453, 3.2022898197174072, 3.1449460983276367, 3.496641159057617, 3.3773810863494873, 3.2986180782318115, 3.768730878829956, 3.3871309757232666, 3.520080804824829, 3.0577449798583984, 3.0426595211029053, 3.4128386974334717, 3.221022605895996, 3.4813339710235596, 3.649658203125, 3.182387113571167, 3.507059335708618, 3.144805908203125, 3.333204507827759, 3.0573267936706543, 3.4613828659057617, 3.643228054046631, 3.373879909515381, 3.4035282135009766, 3.190617799758911, 3.192415714263916, 3.608778953552246, 3.375128746032715, 3.401836633682251, 3.252167224884033, 3.150585412979126, 3.5297439098358154, 3.135810136795044, 3.1354446411132812, 3.218465805053711, 3.779843807220459, 3.637528657913208, 3.0659708976745605, 3.3631370067596436, 3.4693233966827393, 3.3800907135009766, 3.2447073459625244, 3.0870590209960938, 3.377070426940918, 3.204282760620117, 3.5735156536102295, 3.203409194946289, 3.1777901649475098, 3.0685527324676514, 3.70625376701355, 3.478036642074585, 3.1723265647888184, 3.28232741355896, 3.0767710208892822, 3.159639358520508, 3.200934648513794, 3.391962766647339, 3.109212636947632, 3.077763557434082, 3.1493964195251465, 3.2083706855773926, 3.5339832305908203, 3.552131175994873, 3.9749057292938232, 3.5411155223846436, 3.3738791942596436, 3.2187423706054688, 3.003788471221924, 3.217686176300049, 3.139348268508911, 3.0883941650390625, 3.2494595050811768, 3.439919948577881, 3.179734230041504, 3.132676839828491, 3.3770923614501953, 3.246798276901245, 3.551156997680664, 3.2327442169189453, 3.131244421005249, 3.039322853088379, 3.061756134033203, 3.1345083713531494, 3.2472083568573, 3.253842353820801, 3.1763687133789062, 3.377432107925415, 3.2471866607666016, 3.285698413848877, 3.032740831375122, 3.20538330078125, 3.022691011428833, 3.304595708847046, 3.2069618701934814, 3.377739191055298, 3.059131383895874, 3.5841801166534424, 4.658804416656494, 4.531561851501465, 3.117389440536499, 3.1337032318115234, 3.0077648162841797, 3.2181215286254883, 3.399123430252075, 3.0843963623046875, 3.0367326736450195, 3.118638753890991, 3.0928354263305664, 3.3741490840911865, 3.0679614543914795, 3.1164257526397705, 3.197991132736206, 3.1419498920440674, 3.36000394821167, 3.289283037185669, 3.242554187774658, 3.0233981609344482, 3.4215407371520996, 3.3373639583587646, 3.1237199306488037, 3.1133408546447754, 3.078906774520874, 3.1696484088897705, 3.0516092777252197, 3.0326571464538574, 3.307659387588501, 3.195295572280884, 3.4972217082977295, 3.124887704849243, 3.5147814750671387, 3.2381503582000732, 3.3651678562164307, 3.2963459491729736, 3.2479491233825684, 3.04263973236084, 3.128437042236328, 3.3104405403137207, 3.0648274421691895, 3.60062837600708, 3.19539737701416, 3.3672101497650146, 3.265014886856079, 3.025438070297241, 3.0702061653137207, 3.215230703353882, 3.3568103313446045, 3.061575412750244, 3.188385248184204, 3.04264497756958, 3.0989575386047363, 3.2470006942749023, 3.6714346408843994, 3.081047773361206, 3.2631804943084717, 3.273829460144043, 3.1343188285827637, 3.2899281978607178, 3.552564859390259, 3.2509236335754395, 3.2917110919952393, 3.314857006072998, 3.5340588092803955, 3.570401430130005, 3.0906333923339844, 3.3638410568237305, 3.106400966644287, 3.1696603298187256, 3.5915281772613525, 3.116743803024292, 2.958923578262329, 3.073392391204834, 3.2466254234313965, 3.2754082679748535, 2.936978578567505, 3.0211877822875977, 3.0790212154388428, 3.0422780513763428, 3.3942315578460693, 3.448068857192993, 3.3076331615448, 3.459855318069458, 3.268841028213501, 3.385692596435547, 3.1203198432922363, 3.107456684112549, 3.348505973815918, 3.1475343704223633, 3.019268035888672, 3.0645394325256348, 3.237941026687622, 3.0226657390594482, 3.384044647216797, 3.6210978031158447, 3.330864429473877, 3.1706504821777344, 3.482738733291626, 3.06536865234375, 2.940359592437744, 3.102526903152466, 3.2438125610351562, 3.229377031326294, 2.9046332836151123, 3.2226734161376953, 3.401181936264038, 3.0977888107299805, 3.021559238433838, 3.247197389602661, 3.5362648963928223, 3.331693649291992, 3.3120651245117188, 3.0767838954925537, 3.012667417526245, 3.0384674072265625, 3.1326355934143066, 3.3714895248413086, 3.0877139568328857, 3.1688239574432373, 3.1919479370117188, 2.9764034748077393, 3.0762100219726562, 3.09010910987854, 3.2342193126678467, 3.085045099258423, 3.012160062789917, 3.0035593509674072, 3.175759792327881, 3.092895984649658, 3.4111227989196777, 3.122067928314209, 3.314539670944214, 3.0499815940856934, 3.0358822345733643, 3.0689196586608887, 3.0435848236083984, 3.2008450031280518, 3.168639898300171, 3.030778408050537, 3.6088404655456543, 3.3743350505828857, 2.9181571006774902, 2.9132564067840576, 3.0622618198394775, 2.9116344451904297, 3.5298056602478027, 3.1178627014160156, 3.3460586071014404, 2.9274868965148926, 2.9384407997131348, 3.1895220279693604, 2.9640731811523438, 3.199126958847046, 3.052657127380371, 3.0308454036712646, 3.078619956970215, 3.152758836746216, 3.1013941764831543, 3.0087783336639404, 4.064096927642822, 4.48427677154541, 3.2364401817321777, 2.878788709640503, 3.112028121948242, 3.0487163066864014, 3.147043466567993, 3.2005372047424316, 3.344146728515625, 2.9897589683532715, 3.079225778579712, 2.957730531692505, 2.8198776245117188, 3.080498695373535, 3.050095796585083, 2.968130111694336, 3.0291967391967773, 3.3539559841156006, 3.0526199340820312, 3.6105973720550537, 3.2516071796417236, 3.3431499004364014, 3.1214821338653564, 2.9818289279937744, 2.9528112411499023, 3.0778141021728516, 3.045239210128784, 2.864659309387207, 3.006730318069458, 3.0211243629455566, 2.829051971435547, 3.1128289699554443, 3.528836488723755, 3.6199917793273926, 3.0935983657836914, 2.9852287769317627, 3.6105175018310547, 3.2053849697113037, 2.934020519256592, 3.009725332260132, 2.989187240600586, 3.0140743255615234, 3.20031476020813, 3.329958915710449, 3.2337870597839355, 2.955946922302246, 3.0416972637176514, 3.0165441036224365, 3.248021364212036, 3.060342311859131, 2.9449310302734375, 3.2542548179626465, 3.016983985900879, 3.0861289501190186, 2.9223520755767822, 3.1467111110687256, 3.35382342338562, 2.951482057571411, 3.0070416927337646, 2.89591908454895, 2.941486120223999, 3.7089126110076904, 2.9672398567199707, 3.3718905448913574, 2.812568426132202, 2.867213249206543, 3.707017183303833, 3.6991546154022217, 3.2628817558288574, 2.797739028930664, 3.250758647918701, 2.9970364570617676, 3.4937093257904053, 3.251061201095581, 3.0584962368011475, 3.021859645843506, 2.8843441009521484, 2.943148612976074, 2.910639524459839, 2.9492154121398926, 3.4021217823028564, 3.068096399307251, 3.1687066555023193, 2.8702597618103027, 3.0457851886749268, 2.9174187183380127, 3.1611850261688232, 3.2858400344848633, 3.5508246421813965, 3.002187967300415, 3.0206737518310547, 2.90218448638916, 2.9046952724456787, 3.192687749862671, 3.0749945640563965, 3.007244110107422, 2.9793176651000977, 3.391791582107544, 3.142374277114868, 2.9287126064300537, 3.3803303241729736, 3.1710355281829834, 3.000732660293579, 2.9855003356933594, 3.0273990631103516, 2.948956251144409, 3.0341155529022217, 3.371253728866577, 3.041167736053467, 2.85268235206604, 3.0858500003814697, 3.0293564796447754, 3.4967966079711914, 6.534698009490967, 3.665132761001587, 2.8346033096313477, 2.9387333393096924, 2.8911664485931396, 3.056899070739746, 2.885727643966675, 2.8913002014160156, 2.853926420211792, 3.0641651153564453, 3.059858798980713, 2.800152063369751, 3.0002760887145996, 3.010026454925537, 3.032548666000366, 2.7994320392608643, 3.0355935096740723, 3.1598923206329346, 2.8839340209960938, 3.152247667312622, 2.9953324794769287, 2.924224853515625, 2.9383699893951416, 3.35138201713562, 2.9102749824523926, 2.9083948135375977, 3.9317831993103027, 3.03279185295105, 3.0780832767486572, 2.887824058532715, 3.0433828830718994, 2.995434045791626, 3.01884126663208, 3.3703227043151855, 2.960374355316162, 2.945230722427368, 2.9779484272003174, 3.3019070625305176, 2.9070651531219482, 3.192828893661499, 3.1555299758911133, 2.9999446868896484, 3.3569178581237793, 3.009687900543213, 3.0167927742004395, 2.9988622665405273, 3.298585891723633, 2.918046474456787, 2.973686456680298, 2.8871986865997314, 2.79140043258667, 3.385780096054077, 2.959747552871704, 3.0121445655822754, 2.9422969818115234, 3.1637589931488037, 2.852787971496582, 3.262394428253174, 2.97900128364563, 2.870687246322632, 2.9646894931793213, 3.017953395843506, 3.1330325603485107, 2.8557868003845215, 3.011141300201416, 3.012129306793213, 2.924727439880371, 2.8800323009490967, 3.1637251377105713, 3.1556715965270996, 3.7537074089050293, 3.252537727355957, 3.199579954147339, 2.8690598011016846, 2.9027082920074463, 2.942028522491455, 2.8538315296173096, 3.01676082611084, 2.918952465057373, 2.8819189071655273, 2.8943872451782227, 2.9514079093933105, 3.1658785343170166, 3.3367695808410645, 3.083686113357544, 3.054037570953369, 2.9679343700408936, 2.8787477016448975, 2.926913022994995, 2.880249500274658, 3.239349603652954, 2.9033281803131104, 2.878380060195923, 3.1178977489471436, 2.9271488189697266, 2.830068826675415, 2.9587461948394775, 2.8151700496673584, 3.0937511920928955, 3.732999086380005, 4.683145523071289, 3.437283754348755, 3.529054641723633, 2.860987663269043, 3.0396041870117188, 2.6571390628814697, 2.8148953914642334, 2.822113037109375, 2.7804293632507324, 2.8421630859375, 2.958958864212036, 2.9133687019348145, 3.198176383972168, 3.207481622695923, 2.929152727127075, 2.823734760284424, 2.8838999271392822, 2.9161181449890137, 2.888784170150757, 2.810426712036133, 2.868274450302124, 3.1010546684265137, 3.134129762649536, 3.006591320037842, 2.869288444519043, 2.8991589546203613, 2.8794796466827393, 3.0325992107391357, 2.946990728378296, 3.0027825832366943, 2.9431962966918945, 3.6794421672821045, 4.160205841064453, 3.3813750743865967, 2.995624303817749, 2.853470802307129, 2.792046308517456, 2.9058985710144043, 2.929560661315918, 2.7777669429779053, 3.111300230026245, 2.973500967025757, 2.9036107063293457, 2.7646560668945312, 3.162003517150879, 3.1843371391296387, 2.8921985626220703, 2.984056234359741, 2.91044545173645, 2.8966760635375977, 3.2143163681030273, 2.833080291748047, 2.893671751022339, 3.0263214111328125, 2.9593396186828613, 2.9466776847839355, 2.9698917865753174, 2.88785982131958, 2.910735607147217, 3.4167397022247314, 2.7793326377868652, 2.8264214992523193, 2.8284683227539062, 2.8471407890319824, 2.9474377632141113, 3.6065709590911865, 4.605226993560791, 3.0426502227783203, 2.7566938400268555, 2.867799758911133, 2.79209303855896, 3.13735294342041, 2.8492367267608643, 3.0207765102386475, 2.896514654159546, 2.965163469314575, 2.893728017807007, 2.8835394382476807, 3.020275831222534, 3.133013963699341, 2.7830588817596436, 2.7458739280700684, 3.2026381492614746, 3.2331223487854004, 3.225485324859619, 2.823315143585205, 2.8414416313171387, 2.9916281700134277, 2.9867758750915527, 2.788360595703125, 2.9758150577545166, 3.171574831008911, 2.792386531829834, 2.870924472808838, 2.802769184112549, 2.856299877166748, 2.8516788482666016, 2.994198799133301, 2.8785126209259033, 2.9786393642425537, 3.048241376876831, 3.2572031021118164, 2.836031198501587, 3.159362316131592, 2.7926979064941406, 2.812178373336792, 3.055152416229248, 2.825698137283325, 2.9439713954925537, 2.972977638244629, 2.908419609069824, 2.8825550079345703, 3.048905849456787, 2.840909242630005, 2.845442056655884, 3.1985909938812256, 4.046106338500977, 3.099475145339966, 2.8535358905792236, 2.826657295227051, 2.8402836322784424, 2.887786865234375, 3.1208481788635254, 3.226576328277588, 2.75209641456604, 2.894348382949829, 2.8875930309295654, 2.873936176300049, 2.962209939956665, 2.829500436782837, 3.057793378829956, 2.902554750442505, 2.953277587890625, 2.9700722694396973, 2.8134562969207764, 3.273078203201294, 3.217679262161255, 3.3408987522125244, 2.889319896697998, 3.2429842948913574, 2.6735050678253174, 2.6746602058410645, 2.8105435371398926, 2.721517324447632, 2.8706395626068115, 2.8789119720458984, 2.7810685634613037, 3.0465078353881836, 3.0005242824554443, 2.8802618980407715, 3.9462568759918213, 3.128081798553467, 2.7429137229919434, 2.8778176307678223, 2.8672726154327393, 2.9190433025360107, 3.0774013996124268, 2.765284538269043, 2.798682928085327, 3.2241086959838867, 2.8340823650360107, 2.6957058906555176, 2.8733325004577637, 2.825371742248535, 3.1037850379943848, 3.9614150524139404, 3.779782295227051, 3.0051612854003906, 2.861088514328003, 2.6407482624053955, 2.846972703933716, 2.957193374633789, 2.8440515995025635, 2.6897830963134766, 2.767101764678955, 2.8407487869262695, 2.675734043121338, 2.817899703979492, 2.812183141708374, 2.860142469406128, 2.7791430950164795, 2.8459858894348145, 2.824462652206421, 3.128566026687622, 2.967365026473999, 3.0444178581237793, 2.721550941467285, 2.901543140411377, 2.9021384716033936, 2.906078577041626, 2.764467477798462, 2.7881202697753906, 3.0981616973876953, 3.362427234649658, 2.9424874782562256, 3.45674991607666, 2.854440212249756, 2.9062070846557617, 2.7182044982910156, 2.8216500282287598, 2.872589349746704, 2.9632935523986816, 2.748046875, 2.741854190826416, 2.780815839767456, 2.8731682300567627, 3.0583159923553467, 3.3905043601989746, 2.963683843612671, 3.194333553314209, 2.683452844619751, 2.9096834659576416, 2.6759912967681885, 2.7981135845184326, 2.725334882736206, 2.7844948768615723, 3.0164167881011963, 3.429410696029663, 2.9195024967193604, 2.8036394119262695, 2.646192789077759, 2.986732244491577, 3.0753347873687744, 2.8449161052703857, 2.940674066543579, 3.0506062507629395, 2.7233481407165527, 2.797991991043091, 2.846672296524048, 2.7485921382904053, 2.8864381313323975, 2.8962290287017822, 3.0160131454467773, 2.866860866546631, 2.8341543674468994, 3.0505049228668213, 2.898775339126587, 3.080411911010742, 2.758023738861084, 2.8205313682556152, 3.0458409786224365, 3.092078447341919, 2.783473253250122, 2.8839404582977295, 3.243957757949829, 2.850492477416992, 4.087624549865723, 3.0288517475128174, 3.142549753189087, 2.9706876277923584, 2.8173553943634033, 2.6473240852355957, 3.0134902000427246, 2.8987274169921875, 2.7189133167266846, 2.710108995437622, 2.6522040367126465, 2.9287309646606445, 3.0005011558532715, 3.0034165382385254, 2.8487112522125244, 3.2017252445220947, 2.8409876823425293, 2.643152952194214, 2.7296783924102783, 3.1741390228271484, 2.8811891078948975, 2.8842833042144775, 3.0332882404327393, 2.9282405376434326, 2.825714111328125, 2.738924026489258, 2.745500326156616, 2.751903533935547, 2.764840841293335, 2.819868564605713, 3.1606268882751465, 3.145592212677002, 2.9477007389068604, 2.8763508796691895, 3.101701259613037, 2.7234902381896973, 3.2578420639038086, 2.7596518993377686, 2.6532230377197266, 2.885587215423584, 2.9539272785186768, 2.7446482181549072, 2.753291130065918, 2.762716293334961, 3.032960891723633, 2.870936632156372, 3.15779185295105, 2.844512701034546, 2.8933024406433105, 2.910693883895874, 2.7817742824554443, 2.793120861053467, 2.8008790016174316, 2.721287250518799, 2.748932361602783, 2.7313413619995117, 2.8406927585601807, 2.945256471633911, 2.696550130844116, 2.82253360748291, 2.9248993396759033, 3.047057628631592, 2.8261990547180176, 3.082498073577881, 2.942620038986206, 2.7832977771759033, 2.890681743621826, 2.7952253818511963, 3.113471746444702, 3.107492208480835, 2.8155148029327393, 2.6514856815338135, 2.7517435550689697, 2.752368450164795, 2.9390175342559814, 3.251636028289795, 2.864563465118408, 3.1035892963409424, 2.6859593391418457, 2.827388286590576, 2.6967215538024902, 2.6474735736846924, 2.705853223800659, 3.1035661697387695, 3.1761951446533203, 2.937614917755127, 3.319906711578369, 2.753093957901001, 3.0624003410339355, 2.6720833778381348, 2.600468635559082, 2.6127805709838867, 2.8396639823913574, 2.7614917755126953, 2.836879253387451, 3.1992976665496826, 3.017310619354248, 3.494729995727539, 2.8688340187072754, 2.8888955116271973, 3.0814876556396484, 2.708942413330078, 2.670609951019287, 2.6285719871520996, 2.792703866958618, 3.0388948917388916, 2.6600561141967773, 2.6110148429870605, 2.634485960006714, 2.769110918045044, 2.7269370555877686, 2.9864518642425537, 2.8410632610321045, 3.013160467147827, 2.756153106689453, 3.0600953102111816, 3.374303102493286, 2.915715456008911, 2.82405161857605, 3.0872466564178467, 2.64703631401062, 2.7790441513061523, 2.8817548751831055, 2.5751726627349854, 2.9771933555603027, 2.7619593143463135, 2.755488395690918, 2.6268057823181152, 2.797600030899048, 3.1845486164093018, 2.840947151184082, 2.6590535640716553, 2.9340262413024902, 2.6473424434661865, 2.8622677326202393, 2.906055450439453, 3.18391752243042, 2.825195789337158, 2.970529556274414, 2.7465553283691406, 2.9145004749298096, 2.8016741275787354, 3.0797173976898193, 3.802154064178467, 2.859642744064331, 3.269441843032837, 2.6140148639678955, 2.712792158126831, 2.668377637863159, 2.9373176097869873, 2.6842100620269775, 2.6233022212982178, 2.677244186401367, 2.8221194744110107, 2.584415912628174, 2.629185438156128, 2.8904385566711426, 2.821019411087036, 2.76381254196167, 2.6048572063446045, 2.7413442134857178, 2.591984748840332, 2.669346332550049, 2.847036123275757, 2.7610950469970703, 3.1765859127044678, 3.8500783443450928, 3.2651283740997314, 3.060554265975952, 2.671520471572876, 2.7521681785583496, 2.835334539413452, 2.6091349124908447, 2.6533570289611816, 2.817746162414551, 2.672537326812744, 3.000189781188965, 2.5810205936431885, 2.7520298957824707, 2.72540283203125, 2.6914687156677246, 2.722505807876587, 3.0771777629852295, 2.664600133895874, 2.619760751724243, 2.758716344833374, 2.689154863357544, 2.7759509086608887, 2.8732588291168213, 2.7371673583984375, 3.0458734035491943, 4.232017993927002, 3.149442672729492, 2.770552635192871, 2.6584484577178955, 2.616732120513916, 2.7184934616088867, 2.704498052597046, 2.9401397705078125, 3.181715250015259, 2.8471944332122803, 2.644740343093872, 2.73317813873291, 2.891401767730713, 2.7956833839416504, 3.0923430919647217, 2.986635446548462, 2.7315785884857178, 2.599163770675659, 2.9100356101989746, 2.71501088142395, 2.9475784301757812, 3.1476829051971436, 2.56472110748291, 2.615438938140869, 2.6246771812438965, 2.678025484085083, 3.0433104038238525, 2.8251583576202393, 2.7375683784484863, 2.76005220413208, 2.689276695251465, 2.8711698055267334, 2.8386406898498535, 2.606729745864868, 2.7391862869262695, 2.6787383556365967, 2.7130656242370605, 2.7505247592926025, 3.6595945358276367, 3.7572414875030518, 2.799656867980957, 2.599726438522339, 2.706941604614258, 2.764401435852051, 2.826887607574463, 2.735933542251587, 2.5319223403930664, 2.6667919158935547, 2.7688679695129395, 2.7793900966644287, 2.7947239875793457, 2.7505199909210205, 2.7761759757995605, 2.8454227447509766, 2.7714974880218506, 2.997338056564331, 2.9994826316833496, 2.868720293045044, 2.9010934829711914, 2.6580827236175537, 2.7765066623687744, 2.7321481704711914, 2.7059948444366455, 2.7902679443359375, 2.697036027908325, 2.800605297088623, 2.6375157833099365, 2.672614336013794, 2.707899808883667, 2.9323880672454834, 3.5860586166381836, 2.6322758197784424, 2.613016128540039, 2.717664957046509, 2.7566957473754883, 2.691986322402954, 2.741976737976074, 2.6679348945617676, 2.690325975418091, 2.6844632625579834, 2.7832396030426025, 2.7101211547851562, 2.6395318508148193, 2.754054069519043, 3.0125558376312256, 3.3550896644592285, 2.79487681388855, 2.7649714946746826, 2.687668800354004, 2.885798215866089, 2.6360924243927, 2.563908576965332, 2.5874404907226562, 2.7018370628356934, 2.8409841060638428, 2.6507225036621094, 2.8039727210998535, 2.6561789512634277, 3.1084611415863037, 3.0831024646759033, 2.9638071060180664, 2.728771209716797, 2.6337413787841797, 2.5795822143554688, 2.8102056980133057, 2.957456588745117, 2.6956915855407715, 2.64420485496521, 2.7806262969970703, 2.5880799293518066, 2.5897974967956543, 2.637960195541382, 2.9741265773773193, 2.766603469848633, 2.610124111175537, 2.6937174797058105, 2.7102158069610596, 2.816056966781616, 2.5590431690216064, 2.7554779052734375, 5.100575923919678, 3.9400742053985596, 2.896834373474121, 2.849851131439209, 2.865713357925415, 2.8289990425109863, 2.512032985687256, 2.6861355304718018, 3.0153865814208984, 2.50091814994812, 2.451153516769409, 2.9362969398498535, 2.724665880203247, 2.50932240486145, 2.6058778762817383, 2.616908550262451, 2.613284111022949, 2.571321487426758, 2.5750491619110107, 2.698824644088745, 2.6814377307891846, 3.0047948360443115, 2.856663942337036, 2.9503626823425293, 2.896341323852539, 2.9527034759521484, 2.530803918838501, 2.929154872894287, 4.421253681182861, 3.0720345973968506, 2.6963753700256348, 2.582447052001953, 2.5416173934936523, 2.728367805480957, 2.7756690979003906, 2.669034481048584, 2.872121810913086, 2.6651124954223633, 2.7439374923706055, 2.7559165954589844, 2.56522274017334, 2.5793607234954834, 2.540825128555298, 2.6439826488494873, 2.6311888694763184, 2.7609989643096924, 2.6562161445617676, 2.953824758529663, 2.599634885787964, 2.7145934104919434, 2.7508835792541504, 2.7953927516937256, 2.574162721633911, 2.761359214782715, 2.631197929382324, 2.6172797679901123, 2.7303245067596436, 2.781409502029419, 2.944939374923706, 3.0227162837982178, 2.7249555587768555, 2.6522650718688965, 2.735630750656128, 2.609365940093994, 2.9265222549438477, 2.628556251525879, 2.7284154891967773, 3.5720036029815674, 3.1381430625915527, 2.844531536102295, 2.75167179107666, 2.621387243270874, 2.591323137283325, 2.6995790004730225, 2.657015323638916, 3.1629385948181152, 3.1886799335479736, 2.8638174533843994, 2.558847188949585, 2.6769301891326904, 2.6370832920074463, 2.712667226791382, 2.680044651031494, 2.6650266647338867, 2.7655370235443115, 2.816416025161743, 2.5907680988311768, 2.612332582473755, 2.6814169883728027, 2.8879387378692627, 2.601714849472046, 2.5610029697418213, 2.8173108100891113, 2.854278087615967, 2.565624713897705, 2.912806749343872, 3.1869399547576904, 2.669980049133301, 2.7358412742614746, 2.6993041038513184, 2.605605125427246, 2.6711678504943848, 2.9579789638519287, 2.743859052658081, 2.653893232345581, 2.6501693725585938, 2.590524911880493, 2.552116870880127, 2.590787410736084, 2.6112725734710693, 2.6914496421813965, 2.701103687286377, 2.716306447982788, 2.8180148601531982, 2.711726188659668, 2.8430545330047607, 2.616396903991699, 2.7658932209014893, 2.95497465133667, 2.898181915283203, 2.74503231048584, 2.5919227600097656, 2.6553406715393066, 2.781733751296997, 2.6928551197052, 2.7461493015289307, 2.685659170150757, 2.6684212684631348, 2.6899936199188232, 2.8884644508361816, 2.6610732078552246, 2.6041688919067383, 2.578187942504883, 2.6633384227752686, 3.062938928604126, 2.648488998413086, 2.5478856563568115, 2.7549984455108643, 4.122047424316406, 3.082167148590088, 2.651038885116577, 2.5977871417999268, 2.6343142986297607, 2.7398221492767334, 2.722327947616577, 2.654695510864258, 2.8476545810699463, 2.651679039001465, 2.727623462677002, 2.6568715572357178, 2.7945125102996826, 2.6356072425842285, 2.6756961345672607, 2.721247911453247, 2.720463514328003, 2.527113437652588, 2.6352803707122803, 2.9796175956726074, 2.5619261264801025, 2.5869762897491455, 2.5295603275299072, 2.695300579071045, 2.771206855773926, 3.0298352241516113, 2.6980957984924316, 2.6744890213012695, 2.5372164249420166, 2.6196448802948, 2.7931182384490967, 2.6559629440307617, 3.0553138256073, 2.4910643100738525, 2.6697757244110107, 2.6678621768951416, 4.660586357116699, 3.6369378566741943, 2.7279043197631836, 2.577523946762085, 2.5416908264160156, 2.7919633388519287, 2.651566505432129, 2.6078078746795654, 2.8265116214752197, 2.568692684173584, 2.62094783782959, 2.5289416313171387, 2.645242929458618, 2.6983609199523926, 2.6639366149902344, 2.7064502239227295, 2.557513952255249, 2.7003698348999023, 2.933873176574707, 3.5338621139526367, 3.2827281951904297, 2.707282304763794, 2.6747593879699707, 2.508056402206421, 2.7260313034057617, 2.5473098754882812, 2.843280553817749, 2.5464768409729004, 2.657421350479126, 2.611562490463257, 2.6059765815734863, 2.933269500732422, 2.6358182430267334, 2.5303497314453125, 2.5636003017425537, 2.562269687652588, 2.7864575386047363, 2.7145378589630127, 2.675185441970825, 2.6404054164886475, 2.6265625953674316, 2.665160655975342, 2.7970550060272217, 2.6201977729797363, 2.6316049098968506, 2.926805019378662, 2.647191286087036, 2.7311034202575684, 2.604344367980957, 2.53741717338562, 2.619889259338379, 2.607673406600952, 2.6350746154785156, 2.695864677429199, 2.786388397216797, 2.618149995803833, 2.60005521774292, 2.605152130126953, 2.838726758956909, 2.589381694793701, 2.499882221221924, 2.5634732246398926, 2.7187047004699707, 2.673431873321533, 2.7822113037109375, 2.783751964569092, 2.600384473800659, 2.66348934173584, 2.737522840499878, 2.678603410720825, 2.665473222732544, 2.669236421585083, 2.802417755126953, 2.618842363357544, 2.7508602142333984, 2.7570579051971436, 2.5773417949676514, 2.715416193008423, 2.610015392303467, 2.5646023750305176, 2.6066718101501465, 2.6908435821533203, 2.884518623352051, 2.6757466793060303, 2.655449867248535, 2.5471484661102295, 2.5434231758117676, 2.7046496868133545, 2.6759510040283203, 2.703871488571167, 2.644348621368408, 2.6524343490600586, 2.611051082611084, 2.623248815536499, 3.859506130218506, 3.18906569480896, 2.947831869125366, 2.5071425437927246, 2.5604910850524902, 2.6101183891296387, 2.5768210887908936, 2.75940203666687, 2.614920139312744, 2.8770525455474854, 2.5575413703918457, 2.635035991668701, 2.6884655952453613, 2.5608716011047363, 2.5934362411499023, 3.0427260398864746, 2.5775349140167236, 2.570145845413208, 2.727233648300171, 2.628821849822998, 2.514767646789551, 2.6224517822265625, 2.8144781589508057, 2.5532853603363037, 2.587404727935791, 2.63923978805542, 2.5321855545043945, 2.7382216453552246, 2.6797497272491455, 2.8180911540985107, 2.6478896141052246, 2.517610788345337, 2.4890997409820557, 2.63665771484375, 2.6041312217712402, 2.6269218921661377, 2.695728302001953, 2.6202783584594727, 2.607368230819702, 2.658111333847046, 3.7153263092041016, 6.559484004974365, 3.140277624130249, 2.810978889465332, 2.5077896118164062, 2.445107936859131, 2.444091558456421, 2.4799644947052, 2.405318260192871, 2.942931890487671, 2.584721326828003, 2.7342748641967773, 2.3820104598999023, 2.594013214111328, 2.4563589096069336, 2.4913599491119385, 2.6011850833892822, 2.621177911758423, 2.5664074420928955, 2.5435781478881836, 2.955878973007202, 2.492483615875244, 2.6766796112060547, 2.703111410140991, 2.7819058895111084, 3.245896816253662, 2.954543352127075, 3.003342866897583, 2.611417531967163, 2.566967725753784, 2.6016061305999756, 2.608729839324951, 2.5041961669921875, 2.5428550243377686, 2.590789794921875, 2.5780508518218994, 2.546186923980713, 2.534733533859253, 2.5556907653808594, 2.787325859069824, 2.909207820892334, 2.766258716583252, 2.621960401535034, 2.6232073307037354, 2.835000991821289, 2.5231010913848877, 2.487025737762451, 2.744271755218506, 2.9033427238464355, 2.5920655727386475, 2.6465225219726562, 2.6510517597198486, 2.5660154819488525, 2.64705491065979, 2.613382577896118, 3.3965394496917725, 2.623138189315796, 2.60976505279541, 2.669339179992676, 2.643238067626953, 2.5956990718841553, 2.556370973587036, 2.513395309448242, 2.727710723876953, 2.643799304962158, 6.145123481750488, 3.638514995574951, 2.6944382190704346, 2.704397439956665, 2.65291690826416, 2.6187703609466553, 2.3848862648010254, 2.486963987350464, 2.6745059490203857, 2.5125925540924072, 2.493748664855957, 2.66076397895813, 2.51680850982666, 3.0568888187408447, 2.742901563644409, 2.636197328567505, 2.98765230178833, 2.3482024669647217, 2.5236048698425293, 2.534566879272461, 2.732048273086548, 2.5934956073760986, 2.474071502685547, 2.5335707664489746, 2.5319886207580566, 2.635279893875122, 2.6291024684906006, 2.7097809314727783, 2.6166253089904785, 2.6317808628082275, 2.7258188724517822, 2.594881534576416, 2.4842915534973145, 2.4363439083099365, 2.614356279373169, 2.732455253601074, 2.7777347564697266, 5.122663974761963, 3.613356351852417, 2.678255796432495, 2.8196635246276855, 2.7374484539031982, 2.4748544692993164, 2.4397823810577393, 2.879967451095581, 2.5097861289978027, 2.532566547393799, 2.825310707092285, 2.5609755516052246, 2.5039467811584473, 2.4492619037628174, 2.5347373485565186, 2.4280006885528564, 2.5804877281188965, 2.4246299266815186, 2.5918140411376953, 2.6854710578918457, 2.9224753379821777, 2.4559714794158936, 2.55317759513855, 2.6653025150299072, 2.5092692375183105, 2.6303951740264893, 2.6250338554382324, 2.611675262451172, 2.583505868911743, 2.5918922424316406, 2.5396385192871094, 2.530148506164551, 2.685610055923462, 2.841327667236328, 2.8868486881256104, 2.4026365280151367, 2.819611072540283, 2.6797585487365723, 2.5259079933166504, 2.6039979457855225, 4.3426899909973145, 3.288073778152466, 2.732407808303833, 2.7193617820739746, 2.549647092819214, 2.768399953842163, 2.5774357318878174, 2.4174981117248535, 2.6740260124206543, 2.486375570297241, 2.5226540565490723, 2.4850335121154785, 2.703120231628418, 2.5156872272491455, 2.8161442279815674, 2.4844307899475098, 2.462094306945801, 2.475346326828003, 2.5602641105651855, 2.7520408630371094, 2.763563632965088, 2.5729758739471436, 5.705364227294922, 3.9764657020568848, 2.9309825897216797, 2.467310667037964], 'val_loss': [12.26667594909668, 12.238490104675293, 12.079901695251465, 12.67728328704834, 12.225213050842285, 13.117935180664062, 12.808874130249023, 12.127689361572266, 12.466348648071289, 12.407873153686523, 11.767329216003418, 11.852112770080566, 12.090307235717773, 11.83874797821045, 12.494373321533203, 11.808839797973633, 12.199431419372559, 12.16639232635498, 11.802984237670898, 11.840344429016113, 12.617372512817383, 12.11946964263916, 11.570698738098145, 11.728458404541016, 11.423308372497559, 11.909697532653809, 12.784927368164062, 11.582743644714355, 11.759172439575195, 11.796182632446289, 12.649483680725098, 12.14688491821289, 11.703747749328613, 12.403285026550293, 11.582661628723145, 11.469143867492676, 12.19580078125, 13.11259651184082, 11.957646369934082, 12.766356468200684, 11.921799659729004, 11.435870170593262, 11.611223220825195, 11.681905746459961, 11.606468200683594, 11.702526092529297, 12.133231163024902, 12.407539367675781, 11.885198593139648, 12.166208267211914, 12.170893669128418, 11.291518211364746, 11.485015869140625, 13.000093460083008, 11.279812812805176, 11.696776390075684, 11.542929649353027, 11.201948165893555, 11.203834533691406, 12.143653869628906, 12.707914352416992, 12.050222396850586, 11.14238166809082, 11.930651664733887, 11.473122596740723, 11.381112098693848, 11.360347747802734, 11.403109550476074, 11.555896759033203, 11.287840843200684, 11.6991605758667, 13.500324249267578, 11.22909927368164, 11.68106746673584, 11.215254783630371, 12.778886795043945, 11.566312789916992, 11.679791450500488, 11.395251274108887, 11.671263694763184, 11.612286567687988, 11.350639343261719, 11.788429260253906, 11.261472702026367, 14.016155242919922, 10.990046501159668, 11.474903106689453, 13.240791320800781, 11.734456062316895, 11.126606941223145, 11.652325630187988, 11.366485595703125, 11.702974319458008, 11.496124267578125, 12.952542304992676, 11.674906730651855, 11.214924812316895, 11.399812698364258, 11.975441932678223, 11.260437965393066, 12.023789405822754, 11.225238800048828, 11.790291786193848, 12.113146781921387, 12.164088249206543, 11.454960823059082, 11.26381778717041, 10.821028709411621, 12.782282829284668, 11.250246047973633, 12.288421630859375, 10.992691993713379, 11.16455364227295, 11.715775489807129, 11.833501815795898, 11.02700424194336, 11.050158500671387, 10.943134307861328, 11.101520538330078, 13.392108917236328, 11.274333953857422, 11.497798919677734, 12.357285499572754, 11.04392147064209, 11.015958786010742, 11.410799980163574, 10.967458724975586, 11.4791259765625, 11.136853218078613, 11.120527267456055, 11.519144058227539, 11.688375473022461, 11.533348083496094, 11.43823528289795, 11.068562507629395, 11.157251358032227, 15.04826831817627, 10.815991401672363, 11.144783973693848, 10.806645393371582, 10.903155326843262, 11.065645217895508, 11.153571128845215, 11.535811424255371, 11.144755363464355, 11.452929496765137, 11.366989135742188, 10.819552421569824, 11.30229377746582, 11.054664611816406, 12.01490306854248, 11.718549728393555, 10.599458694458008, 12.151480674743652, 10.965230941772461, 11.036184310913086, 11.174734115600586, 11.718456268310547, 11.524909973144531, 10.992822647094727, 11.008793830871582, 11.27011489868164, 12.429544448852539, 10.691755294799805, 12.679630279541016, 11.26359748840332, 13.335532188415527, 11.545289039611816, 10.874753952026367, 11.268054962158203, 11.461688995361328, 11.27401351928711, 11.196032524108887, 11.173943519592285, 11.255146026611328, 11.203754425048828, 11.402305603027344, 11.255112648010254, 11.717599868774414, 11.819588661193848, 10.867929458618164, 11.424667358398438, 11.474592208862305, 10.647870063781738, 11.213242530822754, 11.29820442199707, 11.313045501708984, 11.482688903808594, 10.729107856750488, 11.029696464538574, 12.271177291870117, 10.805498123168945, 10.94435977935791, 10.9429349899292, 11.022238731384277, 10.80849552154541, 11.124448776245117, 11.383798599243164, 11.020711898803711, 11.31775951385498, 10.668712615966797, 10.831180572509766, 11.398338317871094, 11.118160247802734, 10.823864936828613, 11.017403602600098, 10.937726974487305, 10.744028091430664, 11.223423957824707, 10.612401008605957, 10.71654224395752, 12.056587219238281, 12.163946151733398, 11.406216621398926, 11.137939453125, 11.103846549987793, 11.128523826599121, 11.400806427001953, 11.945109367370605, 11.210288047790527, 11.462261199951172, 11.40109634399414, 10.832296371459961, 11.413580894470215, 12.003897666931152, 11.04776668548584, 12.666271209716797, 11.012601852416992, 11.284074783325195, 11.507599830627441, 11.66981029510498, 10.891140937805176, 11.655522346496582, 11.514140129089355, 12.384166717529297, 10.835836410522461, 11.163888931274414, 11.016534805297852, 10.900425910949707, 10.789793968200684, 11.009987831115723, 11.083684921264648, 11.696390151977539, 13.397337913513184, 11.161065101623535, 11.09066104888916, 11.19821834564209, 10.978400230407715, 11.080595970153809, 11.289450645446777, 12.88318157196045, 11.09811019897461, 10.752023696899414, 10.638883590698242, 10.785648345947266, 11.106221199035645, 10.901776313781738, 11.520601272583008, 10.80449104309082, 10.934767723083496, 10.789377212524414, 11.545525550842285, 10.870765686035156, 10.805809020996094, 10.775031089782715, 10.810930252075195, 11.046332359313965, 11.294501304626465, 11.172839164733887, 11.001676559448242, 11.033381462097168, 11.183683395385742, 10.69019889831543, 10.774195671081543, 10.785459518432617, 11.197183609008789, 11.251533508300781, 11.192675590515137, 11.290511131286621, 11.227466583251953, 11.169153213500977, 11.654963493347168, 10.877150535583496, 10.803668975830078, 13.180706024169922, 11.088427543640137, 11.05553913116455, 11.392447471618652, 10.856340408325195, 10.934050559997559, 11.62844467163086, 11.116558074951172, 10.997849464416504, 10.828642845153809, 10.811968803405762, 11.061273574829102, 10.965191841125488, 11.4304780960083, 11.254575729370117, 11.213513374328613, 11.311965942382812, 11.225550651550293, 10.800415992736816, 10.830123901367188, 11.124201774597168, 10.701889038085938, 10.646170616149902, 13.09439754486084, 10.824451446533203, 11.186844825744629, 10.974380493164062, 11.412543296813965, 10.97836685180664, 11.347082138061523, 10.852727890014648, 10.739092826843262, 11.256053924560547, 11.07819652557373, 10.685120582580566, 11.464408874511719, 12.668899536132812, 10.82870864868164, 11.449568748474121, 11.089468002319336, 11.917445182800293, 10.99665641784668, 11.021393775939941, 11.39680004119873, 11.46362018585205, 10.473610877990723, 10.555078506469727, 11.294304847717285, 10.916122436523438, 10.857279777526855, 10.90257740020752, 10.81373405456543, 11.101038932800293, 11.188173294067383, 11.700175285339355, 11.058345794677734, 11.344480514526367, 10.560127258300781, 10.918149948120117, 10.623705863952637, 11.955171585083008, 11.579947471618652, 10.885122299194336, 10.946444511413574, 11.026906967163086, 10.866161346435547, 11.187718391418457, 11.253525733947754, 11.025760650634766, 11.117205619812012, 11.37745475769043, 11.038458824157715, 10.983494758605957, 10.966948509216309, 10.891619682312012, 10.762290000915527, 10.803171157836914, 10.586333274841309, 11.306827545166016, 11.590004920959473, 10.770480155944824, 11.114718437194824, 11.099089622497559, 12.32901668548584, 10.395964622497559, 10.578083038330078, 11.091408729553223, 11.851147651672363, 10.94015121459961, 11.432772636413574, 10.502106666564941, 10.749809265136719, 10.732157707214355, 12.112090110778809, 10.660234451293945, 10.64998722076416, 12.539087295532227, 10.821662902832031, 10.755044937133789, 10.87217903137207, 10.823837280273438, 10.964499473571777, 11.092381477355957, 12.701212882995605, 10.57459831237793, 11.030513763427734, 10.785826683044434, 10.563651084899902, 10.834851264953613, 11.298893928527832, 11.049518585205078, 11.333698272705078, 10.558032035827637, 10.609783172607422, 10.664050102233887, 10.882770538330078, 10.825217247009277, 10.968812942504883, 10.633879661560059, 11.443772315979004, 10.86366081237793, 11.187326431274414, 11.056058883666992, 10.980942726135254, 10.815783500671387, 10.47807502746582, 10.800273895263672, 10.881621360778809, 10.885894775390625, 10.87166690826416, 11.191593170166016, 10.609442710876465, 10.755974769592285, 10.633190155029297, 10.90755844116211, 10.609017372131348, 10.769668579101562, 10.805041313171387, 10.779051780700684, 10.952184677124023, 10.529900550842285, 11.041845321655273, 10.961206436157227, 11.318236351013184, 10.784963607788086, 11.383920669555664, 12.532210350036621, 10.654731750488281, 11.098614692687988, 10.666172981262207, 11.548684120178223, 11.958537101745605, 10.637829780578613, 10.609784126281738, 10.84372329711914, 10.636211395263672, 12.335285186767578, 11.045554161071777, 10.621939659118652, 10.923245429992676, 11.528260231018066, 10.907594680786133, 10.577073097229004, 11.017041206359863, 10.559475898742676, 11.41736125946045, 10.546013832092285, 10.737072944641113, 11.193302154541016, 10.451555252075195, 10.667492866516113, 11.283580780029297, 11.029979705810547, 11.974996566772461, 10.596051216125488, 10.460043907165527, 10.905014038085938, 11.09740924835205, 10.690313339233398, 10.679733276367188, 10.852808952331543, 11.04569149017334, 11.711634635925293, 11.072829246520996, 10.86361312866211, 10.661760330200195, 11.206396102905273, 11.788784980773926, 10.488057136535645, 11.51708984375, 10.452142715454102, 10.891600608825684, 11.41146183013916, 10.778763771057129, 11.378046035766602, 11.001946449279785, 10.610498428344727, 10.94804573059082, 11.178665161132812, 10.910141944885254, 10.472856521606445, 10.720513343811035, 10.752527236938477, 11.034015655517578, 10.414963722229004, 10.802335739135742, 10.67863941192627, 11.565086364746094, 10.899291038513184, 10.811026573181152, 10.7269868850708, 11.984049797058105, 10.761529922485352, 11.009929656982422, 10.960925102233887, 12.497665405273438, 10.578407287597656, 10.670907974243164, 10.872457504272461, 10.68407154083252, 11.805753707885742, 10.475547790527344, 10.985442161560059, 11.139305114746094, 10.84899616241455, 10.891221046447754, 11.495941162109375, 10.649368286132812, 11.214752197265625, 11.029437065124512, 11.179913520812988, 11.328017234802246, 10.78705883026123, 10.336069107055664, 10.600469589233398, 11.438163757324219, 10.832945823669434, 10.793802261352539, 11.410521507263184, 10.788596153259277, 10.570613861083984, 10.636015892028809, 10.810701370239258, 10.811310768127441, 11.88465690612793, 11.172144889831543, 11.456177711486816, 10.788548469543457, 10.703437805175781, 10.835622787475586, 12.272955894470215, 10.80943775177002, 10.779159545898438, 10.784504890441895, 11.288461685180664, 10.825396537780762, 10.489347457885742, 11.359594345092773, 10.661778450012207, 10.831094741821289, 11.053927421569824, 12.420860290527344, 11.024033546447754, 11.575063705444336, 13.095550537109375, 10.50623893737793, 10.804965019226074, 10.724581718444824, 10.646801948547363, 11.262231826782227, 10.533272743225098, 10.77136516571045, 11.662463188171387, 11.411809921264648, 10.825798988342285, 10.809178352355957, 10.665324211120605, 10.712385177612305, 10.847310066223145, 10.656188011169434, 10.506085395812988, 10.767385482788086, 11.251128196716309, 11.2576904296875, 10.417159080505371, 10.424541473388672, 10.874038696289062, 10.60203742980957, 10.564407348632812, 10.820054054260254, 11.096084594726562, 11.627942085266113, 11.703662872314453, 10.832755088806152, 10.74401569366455, 10.890182495117188, 10.900708198547363, 11.212864875793457, 11.105213165283203, 11.338766098022461, 10.725906372070312, 10.979841232299805, 11.454795837402344, 10.605921745300293, 10.639228820800781, 10.678298950195312, 10.75605583190918, 11.297136306762695, 10.444079399108887, 13.725990295410156, 10.765617370605469, 13.614295959472656, 10.864323616027832, 11.763192176818848, 10.711417198181152, 10.728974342346191, 10.695501327514648, 10.370739936828613, 11.008686065673828, 10.574429512023926, 10.421852111816406, 10.728102684020996, 11.002248764038086, 10.583073616027832, 10.571093559265137, 10.904741287231445, 10.777572631835938, 10.810566902160645, 10.698585510253906, 10.829191207885742, 11.255352973937988, 10.906455993652344, 10.716573715209961, 11.345351219177246, 10.995245933532715, 11.200246810913086, 10.977630615234375, 10.661592483520508, 11.341879844665527, 10.850214004516602, 10.774560928344727, 10.820858001708984, 10.908047676086426, 10.944833755493164, 10.737643241882324, 10.746970176696777, 10.927708625793457, 10.835355758666992, 10.664941787719727, 10.706937789916992, 13.354925155639648, 11.039470672607422, 10.517165184020996, 10.755264282226562, 10.96800422668457, 11.222810745239258, 11.92814826965332, 10.862707138061523, 11.001606941223145, 10.847282409667969, 10.370331764221191, 10.66942310333252, 10.673224449157715, 10.791064262390137, 10.877480506896973, 11.162575721740723, 10.862247467041016, 11.039674758911133, 10.831647872924805, 10.776426315307617, 10.781233787536621, 11.542646408081055, 11.722418785095215, 11.247248649597168, 10.950774192810059, 10.551974296569824, 10.731833457946777, 11.150588989257812, 11.031942367553711, 10.695169448852539, 11.389034271240234, 10.958375930786133, 10.534639358520508, 11.794330596923828, 11.149026870727539, 11.218810081481934, 10.837162971496582, 10.736469268798828, 11.12017822265625, 10.763479232788086, 11.649679183959961, 10.740071296691895, 10.696797370910645, 10.852727890014648, 10.606335639953613, 10.652739524841309, 10.942375183105469, 10.749227523803711, 10.500016212463379, 10.898426055908203, 11.023768424987793, 10.709671974182129, 10.485064506530762, 10.789373397827148, 11.417267799377441, 10.686905860900879, 10.799181938171387, 10.727150917053223, 10.818024635314941, 11.365447044372559, 10.69403076171875, 10.738697052001953, 10.701083183288574, 11.404986381530762, 10.777003288269043, 11.086308479309082, 12.380841255187988, 11.015466690063477, 12.731480598449707, 10.692166328430176, 10.557096481323242, 10.58139419555664, 10.917435646057129, 10.782554626464844, 10.945302963256836, 10.818607330322266, 11.271008491516113, 10.849445343017578, 11.285404205322266, 10.719158172607422, 10.795977592468262, 11.908329010009766, 11.469742774963379, 10.857369422912598, 10.630393981933594, 10.556867599487305, 10.532710075378418, 10.490763664245605, 10.597407341003418, 10.660591125488281, 10.683034896850586, 11.177972793579102, 10.672831535339355, 10.997307777404785, 11.007322311401367, 10.521075248718262, 10.625374794006348, 10.764437675476074, 10.907307624816895, 10.909040451049805, 10.945836067199707, 11.219958305358887, 10.952370643615723, 10.553466796875, 10.932794570922852, 11.350836753845215, 10.828407287597656, 10.77224349975586, 10.720123291015625, 10.460638999938965, 10.811912536621094, 10.676261901855469, 11.033792495727539, 10.92646598815918, 10.660545349121094, 11.113221168518066, 10.840209007263184, 11.195222854614258, 11.391127586364746, 11.125343322753906, 10.661412239074707, 10.703974723815918, 10.75379467010498, 10.900704383850098, 10.804200172424316, 10.93743896484375, 10.502054214477539, 10.613903999328613, 10.994013786315918, 11.267112731933594, 11.147388458251953, 11.879446029663086, 10.516240119934082, 10.767415046691895, 10.601263046264648, 10.590295791625977, 10.816147804260254, 10.993288040161133, 10.830829620361328, 10.705431938171387, 10.879196166992188, 10.803987503051758, 11.123675346374512, 10.652050018310547, 10.704280853271484, 10.945706367492676, 10.587821960449219, 11.01076889038086, 10.748177528381348, 11.140565872192383, 11.85314655303955, 12.405657768249512, 11.125057220458984, 10.941327095031738, 10.750288963317871, 10.561559677124023, 10.494315147399902, 10.61787223815918, 10.680534362792969, 11.081263542175293, 10.992011070251465, 10.92300796508789, 11.950732231140137, 10.746026039123535, 10.718323707580566, 10.858495712280273, 10.511896133422852, 11.418266296386719, 10.666520118713379, 10.499185562133789, 10.948382377624512, 11.027826309204102, 10.75436782836914, 10.752053260803223, 11.259498596191406, 11.233880043029785, 11.492608070373535, 10.667845726013184, 10.490690231323242, 11.101983070373535, 10.5927095413208, 10.743433952331543, 10.576090812683105, 11.52005672454834, 10.624625205993652, 10.83937931060791, 10.719769477844238, 10.553369522094727, 10.883157730102539, 11.109332084655762, 10.817835807800293, 10.931974411010742, 10.725706100463867, 10.718267440795898, 10.56523323059082, 10.561552047729492, 10.860118865966797, 10.660347938537598, 10.526693344116211, 10.646778106689453, 11.24863338470459, 10.644909858703613, 10.722448348999023, 11.581099510192871, 10.69005012512207, 10.657675743103027, 10.558952331542969, 11.155304908752441, 10.562454223632812, 11.660609245300293, 13.452465057373047, 10.485042572021484, 10.38634204864502, 10.622052192687988, 10.353303909301758, 10.674015045166016, 10.595355033874512, 10.643336296081543, 10.935258865356445, 10.480613708496094, 10.53683090209961, 10.850691795349121, 10.949836730957031, 10.709550857543945, 10.633907318115234, 11.275546073913574, 11.259637832641602, 10.597962379455566, 10.78162670135498, 10.542487144470215, 10.679967880249023, 10.658805847167969, 10.731204986572266, 10.357358932495117, 10.945710182189941, 11.056861877441406, 10.689313888549805, 11.539243698120117, 10.675012588500977, 10.975303649902344, 10.686190605163574, 10.681720733642578, 10.706732749938965, 11.384481430053711, 11.05693244934082, 10.620843887329102, 10.641782760620117, 10.952972412109375, 11.135354995727539, 10.869806289672852, 10.77953052520752, 10.522690773010254, 11.050792694091797, 11.011714935302734, 10.498839378356934, 10.496601104736328, 10.675908088684082, 10.715851783752441, 10.903889656066895, 10.562419891357422, 10.691909790039062, 10.455792427062988, 10.57282829284668, 11.348029136657715, 11.094965934753418, 11.188243865966797, 11.686691284179688, 11.078325271606445, 10.791727066040039, 10.649276733398438, 11.31983757019043, 10.617096900939941, 11.536758422851562, 11.010773658752441, 11.272196769714355, 11.129817008972168, 10.931795120239258, 10.910378456115723, 10.810826301574707, 10.93294620513916, 10.72645378112793, 10.531281471252441, 10.73673152923584, 11.235872268676758, 11.297804832458496, 10.704975128173828, 10.574848175048828, 10.474446296691895, 10.921056747436523, 11.15573501586914, 11.161782264709473, 11.311841011047363, 10.738533020019531, 11.04428768157959, 10.919466972351074, 11.857583045959473, 10.825841903686523, 11.142102241516113, 10.79316520690918, 10.667947769165039, 10.712491989135742, 10.525980949401855, 10.579272270202637, 11.148935317993164, 10.76069450378418, 11.151789665222168, 11.120104789733887, 10.950956344604492, 10.788647651672363, 10.922983169555664, 12.44476318359375, 10.446094512939453, 11.02869701385498, 11.279999732971191, 10.66644287109375, 10.948272705078125, 10.808026313781738, 10.583189010620117, 10.522055625915527, 10.609089851379395, 10.794921875, 10.380106925964355, 10.889816284179688, 10.931563377380371, 10.602614402770996, 10.696680068969727, 12.897871017456055, 10.919286727905273, 11.708022117614746, 11.673900604248047, 10.72495174407959, 10.84565544128418, 10.68657112121582, 10.613415718078613, 10.581694602966309, 10.588486671447754, 10.811073303222656, 10.765377044677734, 10.879463195800781, 10.914678573608398, 10.582642555236816, 10.554556846618652, 10.914346694946289, 10.767538070678711, 10.862991333007812, 11.005847930908203, 10.733495712280273, 11.146097183227539, 10.910028457641602, 10.567435264587402, 12.119583129882812, 10.583449363708496, 10.699542999267578, 10.576497077941895, 10.638917922973633, 11.129267692565918, 11.248946189880371, 10.769736289978027, 11.391679763793945, 10.67075252532959, 10.631778717041016, 10.673826217651367, 10.62072467803955, 11.351593017578125, 11.337762832641602, 10.889945030212402, 10.884175300598145, 11.043657302856445, 11.025798797607422, 10.540306091308594, 11.834973335266113, 11.021827697753906, 10.710036277770996, 10.757556915283203, 10.928585052490234, 10.901753425598145, 12.378009796142578, 10.679847717285156, 10.906089782714844, 10.644118309020996, 10.525882720947266, 11.651339530944824, 10.695018768310547, 10.42321491241455, 10.962220191955566, 10.643912315368652, 10.91906452178955, 12.206048965454102, 12.051124572753906, 11.287757873535156, 11.427593231201172, 10.747979164123535, 10.612678527832031, 10.7327880859375, 11.096246719360352, 10.49118423461914, 11.069592475891113, 10.610169410705566, 10.90767765045166, 11.221999168395996, 10.571329116821289, 10.770914077758789, 11.579851150512695, 10.667925834655762, 11.029753684997559, 10.418339729309082, 10.810126304626465, 10.869626998901367, 10.51183795928955, 10.345956802368164, 10.606492042541504, 10.63364315032959, 10.647137641906738, 10.476778984069824, 11.060260772705078, 11.170056343078613, 10.88136100769043, 10.756498336791992, 10.994789123535156, 10.96028995513916, 11.212384223937988, 10.655231475830078, 11.119912147521973, 10.706123352050781, 10.634998321533203, 13.039003372192383, 10.625833511352539, 10.885163307189941, 10.610567092895508, 10.810831069946289, 11.118804931640625, 10.743191719055176, 10.784565925598145, 10.72834300994873, 10.548026084899902, 10.642983436584473, 10.609773635864258, 11.291555404663086, 10.657580375671387, 10.744954109191895, 10.541589736938477, 11.626334190368652, 11.29605770111084, 10.680380821228027, 11.153298377990723, 10.540023803710938, 10.601531028747559, 10.68238639831543, 10.652261734008789, 12.709980964660645, 10.712320327758789, 10.75499439239502, 10.592738151550293, 10.915799140930176, 10.888182640075684, 10.789493560791016, 11.958806037902832, 10.927559852600098, 10.87591552734375, 10.780390739440918, 11.211767196655273, 10.615846633911133, 10.518098831176758, 10.532429695129395, 10.944860458374023, 10.897008895874023, 11.098591804504395, 12.043644905090332, 10.73323917388916, 10.923853874206543, 11.104705810546875, 10.641687393188477, 10.954414367675781, 10.816511154174805, 10.794163703918457, 10.787805557250977, 11.149998664855957, 10.736462593078613, 10.512069702148438, 10.819245338439941, 10.932639122009277, 10.766812324523926, 13.024429321289062, 11.589771270751953, 10.617383003234863, 10.521388053894043, 10.53330135345459, 12.659852981567383, 10.489018440246582, 10.488849639892578, 10.703972816467285, 10.482874870300293, 11.707051277160645, 10.633456230163574, 10.51480770111084, 11.005815505981445, 10.887572288513184, 10.739255905151367, 10.59604549407959, 11.649077415466309, 10.790698051452637, 10.692774772644043, 10.539604187011719, 10.53656005859375, 11.103493690490723, 10.975630760192871, 11.055952072143555, 10.72239875793457, 10.97457218170166, 10.968852043151855, 10.890890121459961, 10.9107084274292, 10.973043441772461, 11.033757209777832, 11.006061553955078, 12.886151313781738, 10.757845878601074, 10.797820091247559, 10.726874351501465, 11.149796485900879, 11.1522216796875, 12.63481330871582, 11.640783309936523, 10.981915473937988, 11.119270324707031, 11.939546585083008, 10.86441421508789, 11.175033569335938, 11.158804893493652, 10.962227821350098, 11.052044868469238, 10.967429161071777, 11.082358360290527, 10.864571571350098, 11.001489639282227, 10.888876914978027, 10.784073829650879, 10.955818176269531, 11.04594612121582, 11.043035507202148, 10.742701530456543, 11.064080238342285, 11.165610313415527, 11.274042129516602, 11.089676856994629, 11.002602577209473, 11.271641731262207, 10.903844833374023, 10.995942115783691, 10.76745891571045, 11.122621536254883, 11.629216194152832, 11.549827575683594, 10.633111953735352, 11.249438285827637, 10.875758171081543, 10.645186424255371, 10.793862342834473, 11.01270580291748, 10.624449729919434, 10.955728530883789, 10.701298713684082, 11.573112487792969, 10.70158863067627, 10.919818878173828, 11.185409545898438, 10.905003547668457, 11.28309154510498, 11.036280632019043, 10.7958984375, 11.275582313537598, 11.406005859375, 10.769668579101562, 10.953834533691406, 11.200542449951172, 11.001121520996094, 11.07851505279541, 10.68757438659668, 11.164978981018066, 10.904687881469727, 11.285999298095703, 11.231863021850586, 12.82255744934082, 11.618926048278809, 13.007070541381836, 10.795809745788574, 11.435647964477539, 11.039565086364746, 10.839670181274414, 10.87517261505127, 11.091650009155273, 11.409363746643066, 10.701751708984375, 11.27585506439209, 10.793438911437988, 12.037015914916992, 11.517419815063477, 11.244399070739746, 10.744876861572266, 11.687474250793457, 10.972513198852539, 11.102161407470703, 11.094144821166992, 11.190882682800293, 11.345536231994629, 11.719365119934082, 11.877097129821777, 10.930808067321777, 10.935501098632812, 11.210576057434082, 11.245577812194824, 11.018635749816895, 10.96528434753418, 10.746133804321289, 12.834691047668457, 11.108551025390625, 11.316001892089844, 10.853693962097168, 10.807281494140625, 10.775364875793457, 10.717253684997559, 11.082812309265137, 10.813426971435547, 11.663800239562988, 10.830166816711426, 10.906854629516602, 11.563125610351562, 11.018218994140625, 10.988099098205566, 10.543859481811523, 11.519956588745117, 10.857654571533203, 10.827590942382812, 11.165399551391602, 10.863870620727539, 10.738869667053223, 11.320282936096191, 11.122133255004883, 11.181896209716797, 11.094964981079102, 10.570104598999023, 12.27294921875, 11.172944068908691, 10.833391189575195, 10.98022747039795, 10.81571102142334, 10.945935249328613, 11.79584789276123, 12.860245704650879, 10.800650596618652, 11.773676872253418, 10.691473960876465, 11.180033683776855, 11.016841888427734, 10.894116401672363, 10.928500175476074, 11.2791109085083, 10.732446670532227, 10.859809875488281, 10.96756649017334, 10.815108299255371, 10.750926971435547, 10.9673490524292, 10.935134887695312, 10.994796752929688, 11.5753755569458, 13.325777053833008, 10.976877212524414, 11.094040870666504, 10.78917407989502, 11.044670104980469, 11.10489273071289, 11.315130233764648, 11.192174911499023, 11.237872123718262, 11.01634407043457, 10.848678588867188, 10.8141450881958, 11.479268074035645, 11.381184577941895, 10.770020484924316, 11.348190307617188, 11.332889556884766, 11.405959129333496, 11.728902816772461, 11.520920753479004, 10.827781677246094, 10.920876502990723, 10.683311462402344, 11.010554313659668, 11.082727432250977, 11.885640144348145, 11.980737686157227, 10.938623428344727, 11.095078468322754, 11.532005310058594, 10.994986534118652, 11.082940101623535, 12.30396556854248, 11.821154594421387, 10.994396209716797, 10.71914291381836, 11.241509437561035, 10.860167503356934, 11.06531810760498, 12.087656021118164, 11.19742488861084, 10.857046127319336, 11.050806045532227, 10.830034255981445, 10.996827125549316, 10.774746894836426, 11.026097297668457, 11.286598205566406, 10.702449798583984, 11.644359588623047, 10.790877342224121, 10.891066551208496, 11.693878173828125, 11.059052467346191, 11.470293045043945, 11.022542953491211, 11.101678848266602, 10.969249725341797, 11.18114948272705, 10.744243621826172, 10.901030540466309, 10.947572708129883, 11.050189018249512, 11.134383201599121, 11.153329849243164, 11.346598625183105, 11.128669738769531, 11.242420196533203, 10.977696418762207, 10.994756698608398, 11.391899108886719, 11.867159843444824, 11.009892463684082, 10.860925674438477, 10.871277809143066, 11.373529434204102, 11.176712989807129, 10.832389831542969, 11.024079322814941, 11.192212104797363, 11.112161636352539, 11.113273620605469, 14.079168319702148, 10.869261741638184, 10.832854270935059, 10.718226432800293, 10.659529685974121, 11.455131530761719, 10.983516693115234, 11.065072059631348, 11.152027130126953, 11.170658111572266, 10.761539459228516, 10.91631031036377, 10.812460899353027, 11.139226913452148, 11.118971824645996, 10.885218620300293, 11.181730270385742, 10.746136665344238, 10.774689674377441, 10.948553085327148, 11.447175979614258, 10.708597183227539, 11.022472381591797, 11.114311218261719, 11.330098152160645, 10.971970558166504, 11.331399917602539, 12.100634574890137, 10.70215129852295, 11.78989315032959, 11.614513397216797, 10.744165420532227, 10.845537185668945, 10.892805099487305, 10.77208423614502, 10.968729972839355, 10.996127128601074, 10.815231323242188, 10.82462215423584, 10.642488479614258, 11.22565746307373, 11.053377151489258, 11.75352668762207, 11.055118560791016, 11.339028358459473, 10.874731063842773, 11.145726203918457, 11.211442947387695, 10.9300537109375, 11.361072540283203, 10.976780891418457, 12.145015716552734, 10.923991203308105, 11.07486629486084, 11.073862075805664, 10.762823104858398, 12.484108924865723, 11.064921379089355, 11.154704093933105, 11.73305892944336, 10.676304817199707, 10.73155403137207, 10.975688934326172, 10.739829063415527, 11.274686813354492, 11.12475299835205, 11.996670722961426, 11.311422348022461, 11.069097518920898, 11.23294448852539, 11.5794677734375, 10.980347633361816, 12.053264617919922, 10.943487167358398, 11.182584762573242, 11.144673347473145, 11.750853538513184, 10.942978858947754, 11.162029266357422, 11.62117862701416, 11.140351295471191, 11.969078063964844, 10.895096778869629, 11.257488250732422, 11.373961448669434, 11.096317291259766, 10.886677742004395, 11.051573753356934, 11.071650505065918, 10.819965362548828, 11.246957778930664, 11.030255317687988, 10.722455978393555, 10.801253318786621, 11.395150184631348, 11.069334030151367, 10.946305274963379, 10.99932861328125, 11.22428035736084, 10.774092674255371, 11.184589385986328, 11.136720657348633, 11.181221961975098, 11.039958953857422, 11.419323921203613, 11.313011169433594, 10.93344497680664, 10.903935432434082, 10.804557800292969, 10.85001277923584, 10.719395637512207, 12.209094047546387, 11.954410552978516, 11.267512321472168, 11.508292198181152, 10.98259449005127, 11.863059997558594, 10.969268798828125, 11.198747634887695, 11.014796257019043, 10.941564559936523, 11.137369155883789, 11.130255699157715, 11.011080741882324, 11.047225952148438, 10.880226135253906, 11.226127624511719, 11.425260543823242, 10.86703109741211, 11.01430892944336, 11.689395904541016, 10.823525428771973, 11.750093460083008, 11.23614501953125, 11.366663932800293, 10.961997985839844, 11.216665267944336, 11.02505874633789, 11.334845542907715, 11.136445045471191, 12.317347526550293, 10.975835800170898, 11.861673355102539, 11.242499351501465, 11.162543296813965, 10.94565486907959, 11.07474422454834, 11.352628707885742, 10.953381538391113, 11.670686721801758, 10.85408878326416, 10.695049285888672, 11.062135696411133, 10.95506477355957, 11.074286460876465, 11.02359676361084, 11.182442665100098, 11.2822265625, 10.876591682434082, 11.484847068786621, 11.050907135009766, 10.972213745117188, 10.782888412475586, 11.125953674316406, 12.046074867248535, 12.556000709533691, 11.020272254943848, 11.072062492370605, 11.435916900634766, 10.869281768798828, 11.069942474365234, 10.878890037536621, 11.18372631072998, 10.93984317779541, 11.483466148376465, 11.326172828674316, 11.105527877807617, 11.200726509094238, 11.092195510864258, 11.081462860107422, 10.967419624328613, 10.981659889221191, 11.172441482543945, 10.722821235656738, 10.926348686218262, 10.570844650268555, 11.539475440979004, 11.027499198913574, 11.135516166687012, 11.267486572265625, 11.240926742553711, 11.237570762634277, 11.01870059967041, 11.02284049987793, 11.130370140075684, 10.93238353729248, 12.449782371520996, 11.098938941955566, 11.105005264282227, 11.282172203063965, 10.852484703063965, 11.413812637329102, 10.810149192810059, 10.861847877502441, 11.487427711486816, 11.39509105682373, 11.074553489685059, 11.002795219421387, 10.90760612487793, 11.319019317626953, 11.314172744750977, 11.11734676361084, 10.901701927185059, 10.868443489074707, 11.065265655517578, 11.11904239654541, 12.175092697143555, 11.975164413452148, 11.177508354187012, 11.570884704589844, 10.91284465789795, 10.745575904846191, 11.045843124389648, 12.180724143981934, 11.180030822753906, 11.098791122436523, 11.074440002441406, 10.965906143188477, 11.075668334960938, 11.092988014221191, 10.828598976135254, 10.751407623291016, 11.01197338104248, 10.756470680236816, 11.209346771240234, 10.72021770477295, 11.170957565307617, 10.846004486083984, 10.826723098754883, 10.724091529846191, 10.807541847229004, 11.077322006225586, 11.09738540649414, 11.124604225158691, 11.167464256286621, 10.759621620178223, 12.04143238067627, 11.554672241210938, 11.303997993469238, 11.036713600158691, 11.549281120300293, 11.089704513549805, 11.072454452514648, 11.21859359741211, 11.115523338317871, 11.537834167480469, 11.209644317626953, 10.863751411437988, 10.919790267944336, 11.327878952026367, 10.647464752197266, 10.900168418884277, 11.026063919067383, 11.200636863708496, 11.336828231811523, 11.032170295715332, 11.137653350830078, 11.05316162109375, 10.77487564086914, 11.146470069885254, 11.376690864562988, 11.812975883483887, 12.154150009155273, 10.754899024963379, 10.68818473815918, 10.828303337097168, 10.706306457519531, 10.778761863708496, 10.863166809082031, 11.265830039978027, 10.869607925415039, 11.25841236114502, 10.741877555847168, 11.473565101623535, 11.062317848205566, 10.630043983459473, 10.6481351852417, 11.544353485107422, 10.913811683654785, 10.599520683288574, 11.022775650024414, 10.677569389343262, 11.489958763122559, 10.951537132263184, 10.826577186584473, 10.927953720092773, 10.925280570983887, 11.507575988769531, 11.080029487609863, 11.323659896850586, 11.020293235778809, 11.340919494628906, 11.363903999328613, 11.059605598449707, 10.849376678466797, 10.981341361999512, 11.417614936828613, 11.06116771697998, 11.364691734313965, 11.112617492675781, 12.610562324523926, 11.548629760742188, 10.585914611816406, 10.859489440917969, 11.244677543640137, 10.976529121398926, 10.592552185058594, 11.100177764892578, 10.702126502990723, 11.128565788269043, 10.838537216186523, 10.91119384765625, 10.832799911499023, 10.715194702148438, 11.396614074707031, 10.964327812194824, 10.971464157104492, 11.292272567749023, 10.895410537719727, 10.870818138122559, 10.926214218139648, 10.891973495483398, 10.924105644226074, 11.043123245239258, 10.783713340759277, 11.368484497070312, 11.280734062194824, 10.899687767028809, 11.662117004394531, 10.714079856872559, 11.071793556213379, 11.865070343017578, 11.315794944763184, 10.864598274230957, 11.34520435333252, 11.033699989318848, 11.638908386230469, 10.79998779296875, 11.070569038391113, 10.902460098266602, 10.879560470581055, 11.128998756408691, 11.065152168273926, 11.148582458496094, 10.964988708496094, 10.965849876403809, 11.039555549621582, 11.177163124084473, 11.174426078796387, 11.433714866638184, 11.214362144470215, 10.857284545898438, 10.875025749206543, 10.910564422607422, 10.913041114807129, 11.121216773986816, 11.02056884765625, 11.258443832397461, 10.910962104797363, 11.146634101867676, 11.459746360778809, 11.238499641418457, 11.420052528381348, 10.736989974975586, 10.989458084106445, 11.032843589782715, 12.219621658325195, 12.037677764892578, 10.793627738952637, 10.821863174438477, 11.27301025390625, 11.009603500366211, 10.822281837463379, 10.78106689453125, 11.347261428833008, 11.439054489135742, 11.019874572753906, 10.868906021118164, 11.484602928161621, 11.360865592956543, 10.977842330932617, 11.644601821899414, 13.987875938415527, 11.228166580200195, 10.992253303527832, 11.62928295135498, 10.896384239196777, 10.815622329711914, 10.886168479919434, 10.90539264678955, 10.945603370666504, 11.216754913330078, 11.154537200927734, 10.960309028625488, 11.293124198913574, 10.97059440612793, 11.066285133361816, 11.12533950805664, 11.178598403930664, 10.710755348205566, 10.795727729797363, 10.910801887512207, 11.054425239562988, 10.793128967285156, 11.207067489624023, 11.175911903381348, 11.488862991333008, 10.725976943969727, 10.72347354888916, 12.666888236999512, 11.53774642944336, 11.393659591674805, 10.978205680847168, 10.82606315612793, 10.710453033447266, 12.377145767211914, 11.434429168701172, 11.079845428466797, 11.632279396057129, 11.1736478805542, 11.270124435424805, 11.271882057189941, 10.798913955688477, 11.293513298034668, 11.018409729003906, 10.991114616394043, 10.80313777923584, 11.03164005279541, 11.17917537689209, 11.190534591674805, 11.648802757263184, 10.992070198059082, 11.544876098632812, 10.997413635253906, 10.878336906433105, 10.880428314208984, 11.056571960449219, 11.039371490478516, 11.007730484008789, 11.416568756103516, 11.476208686828613, 11.171696662902832, 11.319143295288086, 11.190831184387207, 11.100830078125, 11.956108093261719, 11.22058391571045, 11.154766082763672, 11.333849906921387, 11.857291221618652, 11.130836486816406, 11.942732810974121, 10.804039001464844, 11.360544204711914, 10.925019264221191, 10.763776779174805, 11.071011543273926, 11.386754989624023, 11.040753364562988, 10.94762134552002, 11.032158851623535, 11.221151351928711, 11.335524559020996, 11.260702133178711, 11.6258544921875, 10.953198432922363, 11.588362693786621, 10.982342720031738, 11.184471130371094, 10.9729642868042, 11.686756134033203, 10.976065635681152, 10.912693977355957, 11.14637279510498, 12.72702407836914, 10.865668296813965, 10.781107902526855, 11.573330879211426, 11.508420944213867, 11.269349098205566, 10.849737167358398, 11.323387145996094, 11.052621841430664, 11.348058700561523, 11.982185363769531, 10.965972900390625, 11.014435768127441, 11.004311561584473, 10.861930847167969, 10.921422004699707, 10.991161346435547, 11.098881721496582, 10.856256484985352, 10.871201515197754, 11.148774147033691, 11.420071601867676, 11.406174659729004, 10.92739486694336, 10.788341522216797, 11.75007438659668, 12.361712455749512, 11.465088844299316, 11.56733226776123, 11.004725456237793, 11.093608856201172, 11.296222686767578, 11.428136825561523, 11.105202674865723, 11.136265754699707, 11.034544944763184, 11.02131462097168, 10.99942398071289, 11.201004028320312, 10.932723045349121, 11.161736488342285, 10.959980964660645, 10.95852279663086, 11.582537651062012, 10.857891082763672, 12.674110412597656, 11.894563674926758, 10.909520149230957, 10.824723243713379, 10.769201278686523, 10.909544944763184, 11.022950172424316, 11.088808059692383, 11.15074634552002, 10.957268714904785, 11.102375984191895, 10.966050148010254, 10.881292343139648, 10.916579246520996, 11.131502151489258, 11.1734037399292, 12.16330337524414, 11.045814514160156, 11.164755821228027, 11.140841484069824, 11.21240520477295, 11.139764785766602, 10.897838592529297, 10.869112014770508, 11.82650375366211, 11.012190818786621, 12.33388614654541, 11.341227531433105, 11.500141143798828, 11.035438537597656, 10.856989860534668, 11.196453094482422, 11.011353492736816, 11.043285369873047, 11.037239074707031, 10.796282768249512, 11.341376304626465, 12.99166202545166, 11.258002281188965, 10.922572135925293, 10.847940444946289, 10.887197494506836, 11.817811965942383, 11.215452194213867, 11.060158729553223, 11.303462028503418, 10.936999320983887, 11.004294395446777, 11.090276718139648, 10.907337188720703, 11.13927936553955, 11.133895874023438, 10.961350440979004, 10.996542930603027, 10.92172622680664, 12.345793724060059, 11.893887519836426, 11.073108673095703, 11.981352806091309, 11.139513969421387, 11.107233047485352, 11.155444145202637, 11.126194953918457, 11.36533260345459, 11.161380767822266, 11.033336639404297, 11.116328239440918, 11.11695384979248, 10.934344291687012, 10.834071159362793, 10.970428466796875, 11.16965389251709, 11.497079849243164, 11.196503639221191, 11.103987693786621, 10.875232696533203, 11.148029327392578, 12.759644508361816, 11.154265403747559, 11.08134651184082, 11.116862297058105, 11.47892951965332, 11.313334465026855, 11.598712921142578, 11.038915634155273, 11.456404685974121, 11.265789985656738, 10.899452209472656, 11.152196884155273, 11.34987735748291, 11.110424041748047, 11.246061325073242, 10.964764595031738, 10.970667839050293, 11.362859725952148, 11.044918060302734, 11.031460762023926, 11.272933006286621, 10.919890403747559, 11.361027717590332, 11.537341117858887, 11.25127124786377, 10.91134262084961, 10.989457130432129, 11.487764358520508, 10.96740436553955, 11.07342529296875, 10.943653106689453, 11.253241539001465, 11.221200942993164, 11.072216033935547, 11.43070125579834, 10.895843505859375, 11.037532806396484, 10.989933013916016, 11.070159912109375, 11.082002639770508, 11.34945011138916, 11.184359550476074, 11.24527359008789, 11.133017539978027, 11.077108383178711, 10.938054084777832, 11.37364673614502, 11.179244041442871, 11.338872909545898, 11.086116790771484, 11.240189552307129, 11.26801586151123, 11.427962303161621, 11.128400802612305, 12.187235832214355, 11.731017112731934, 10.948338508605957, 10.824042320251465, 10.799907684326172, 10.983792304992676, 11.118623733520508, 10.926677703857422, 11.150348663330078, 11.059947967529297, 10.995660781860352, 11.100663185119629, 11.080904960632324, 11.049201011657715, 10.984829902648926, 11.675797462463379, 10.99770450592041, 11.202515602111816, 11.038069725036621, 11.106318473815918, 11.024130821228027, 11.206883430480957, 11.311354637145996, 10.993927001953125, 10.739501953125, 10.951708793640137, 11.151049613952637, 10.905996322631836, 11.227194786071777, 10.999235153198242, 10.947070121765137, 11.490297317504883, 10.962494850158691, 10.851553916931152, 11.035246849060059, 11.522329330444336, 10.894700050354004, 10.752235412597656, 11.09912109375, 11.181412696838379, 13.849104881286621, 11.885563850402832, 10.956777572631836, 10.819953918457031, 10.723708152770996, 10.844167709350586, 11.105010986328125, 10.98482894897461, 11.357426643371582, 11.24789047241211, 11.602005004882812, 10.800999641418457, 10.826330184936523, 11.233174324035645, 11.097955703735352, 10.85023307800293, 11.30567741394043, 11.053887367248535, 10.877817153930664, 11.289966583251953, 11.00965690612793, 11.204092979431152, 10.979269981384277, 10.921544075012207, 11.853157997131348, 11.537955284118652, 12.113576889038086, 11.612607955932617, 11.079973220825195, 11.032917022705078, 10.950860023498535, 10.850234985351562, 10.942010879516602, 11.369160652160645, 11.587897300720215, 11.479866027832031, 11.181366920471191, 11.073219299316406, 11.25430679321289, 11.231186866760254, 11.266402244567871, 11.347189903259277, 10.930118560791016, 11.028443336486816, 10.975704193115234, 10.820074081420898, 11.24338436126709, 11.584776878356934, 11.171088218688965, 11.011445045471191, 11.718497276306152, 11.212905883789062, 10.80209732055664, 10.820206642150879, 11.530611038208008, 11.565476417541504, 11.449392318725586, 11.35953140258789, 11.148369789123535, 11.125082969665527, 11.041688919067383, 10.829977035522461, 11.430140495300293, 11.081761360168457, 11.342482566833496, 12.712767601013184, 11.089218139648438, 11.004142761230469, 10.902602195739746, 10.967503547668457, 11.04336929321289, 10.828926086425781, 10.95518970489502, 10.898961067199707, 11.239603042602539, 11.442212104797363, 11.96804141998291, 11.04503345489502, 10.764591217041016, 11.03674030303955, 10.785491943359375, 10.895984649658203, 10.781145095825195, 10.841628074645996, 11.403185844421387, 11.650946617126465, 10.99625015258789, 11.438671112060547, 11.030142784118652, 10.993766784667969, 11.175877571105957, 11.175138473510742, 11.201658248901367, 10.946754455566406, 11.323101043701172, 11.015835762023926, 11.16823959350586, 11.001227378845215, 11.409761428833008, 11.111457824707031, 11.085704803466797, 12.416971206665039, 12.338248252868652, 10.950695991516113, 10.818401336669922, 11.384041786193848, 11.048345565795898, 10.732203483581543, 11.065252304077148, 10.709358215332031, 11.08713150024414, 11.092658042907715, 11.314388275146484, 10.682048797607422, 11.0767183303833, 10.698040962219238, 10.755419731140137, 11.007914543151855, 10.909416198730469, 10.706478118896484, 10.934966087341309, 11.102203369140625, 10.804887771606445, 10.820527076721191, 10.584866523742676, 10.999866485595703, 10.946682929992676, 11.103172302246094, 11.06746768951416, 11.109468460083008, 10.841556549072266, 11.076742172241211, 11.037163734436035, 10.992974281311035, 11.278334617614746, 11.277900695800781, 11.251639366149902, 11.249288558959961, 11.470149993896484, 11.346100807189941, 11.158085823059082, 11.456550598144531, 12.343623161315918, 11.165306091308594, 11.08330249786377, 10.786211967468262, 10.885931015014648, 11.347513198852539, 10.936936378479004, 11.002676963806152, 11.178850173950195, 10.879660606384277, 10.980708122253418, 10.91838550567627, 10.967819213867188, 12.099621772766113, 10.96080493927002, 10.948495864868164, 11.004436492919922, 10.790403366088867, 10.941636085510254, 11.210660934448242, 11.114431381225586, 11.21569538116455, 13.449613571166992, 11.147676467895508, 10.894639015197754, 10.780112266540527]}\n",
      "Minimum validation loss: 10.336069107055664\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB/7ElEQVR4nO3dd3zU5B8H8M91D7ooFCiUJXtPAVEUAdmCigoiy4miqDjxJ+BAwYWIIojKUJkqS5C9Z6HsUUoLhRZKKd2Lzsvvj/TukrvkLrnLJXft9/169dU29yR57pJLvnmmjmEYBoQQQgghKvHQOgOEEEIIqVoo+CCEEEKIqij4IIQQQoiqKPgghBBCiKoo+CCEEEKIqij4IIQQQoiqKPgghBBCiKoo+CCEEEKIqry0zoA5vV6PlJQUBAUFQafTaZ0dQgghhEjAMAzy8vIQGRkJDw/rZRsuF3ykpKQgKipK62wQQgghxA7JycmoV6+e1TQuF3wEBQUBYDMfHByscW4IIYQQIkVubi6ioqKM93FrXC74MFS1BAcHU/BBCCGEuBkpTSaowSkhhBBCVEXBByGEEEJURcEHIYQQQlRFwQchhBBCVEXBByGEEEJURcEHIYQQQlRFwQchhBBCVEXBByGEEEJURcEHIYQQQlRFwQchhBBCVEXBByGEEEJURcEHIYQQQlRFwYezXD8CxCzWOheEEEKIy3G5WW0rjSUD2N/VGwONH9I0K4QQQogroZIPZ8u8qnUOCCGEEJdCwQchhBBCVEXBByGEEEJURcEHIYQQQlRFwQchhBBCVEXBByGEEEJURcEHIYQQQlRFwQchhBBCVEXBByGEEEJURcEHIYQQQlRFwQchhBBCVEXBByGEEEJURcEHIYQQQlRFwQchhBBCVEXBByGEEEJURcEHIYQQQlRFwYfT6bTOACGEEOJSKPgghBBCiKoo+CCEEEKIqij4IIQQQoiqKPgghBBCiKoo+CCEEEKIqij4IIQQQoiqZAcf+/fvx9ChQxEZGQmdTof169eLpp04cSJ0Oh3mzp3rQBYJIYQQUpnIDj4KCgrQvn17zJ8/32q6devW4ejRo4iMjLQ7c4QQ4rIYBlj9LLBuotY5IcTteMldYeDAgRg4cKDVNDdv3sTrr7+Obdu2YfDgwXZnziVlXgWC6wJevlrnhBCipewkIPZf9u+h39M1gRAZFG/zodfrMWbMGLz77rto3bq1zfTFxcXIzc3l/bisxAPAvI7ALw9rnRNCiNaYcq1z4L6K84DjvwF5t7XOCdGI4sHHl19+CS8vL0yePFlS+lmzZiEkJMT4ExUVpXSWlHNmJfv79nlt80EIIe5s89vA5inAsqFa54RoRNHg48SJE/j++++xdOlS6HTS5jSZOnUqcnJyjD/JyclKZokQQoirubSZ/Z0ep20+iGYUDT4OHDiAtLQ01K9fH15eXvDy8sL169fx9ttvo2HDhoLr+Pr6Ijg4mPdDCCEuj2G0zoH7os+uypPd4NSaMWPGoG/fvrxl/fv3x5gxYzBhwgQld0UIIYS4l4sbgZjFwOOLgGoRWudGU7KDj/z8fCQkJBj/T0xMxOnTp1G9enXUr18f4eHhvPTe3t6oXbs2mjdv7nhuCSHEVXCrlulJXh6J1fKVzpox7O/tH7EBSBUmO/iIiYlB7969jf9PmTIFADBu3DgsXbpUsYwRQohLo4DDflX9sytI1zoHmpMdfDz00ENgZJw4165dk7sL11XVvzCuSq8Hjv4ERHUDorpqnRtSJdG1gRA5FG3zQYgmzv8NbP8f+/fHOdrmhRBCbKJglSaWI+7vziWtc0CqOioVlamKf150vlDwQSoZ+lITTdB5R4gcFHyQyiV2o9Y5IITYVEV7uxhRsErBB6lcspO0zgGpiqjEjchB5ws1OJUkfgeQkWA7HSGEEAno5lvVUfAhxfIR7O/wJvLXraqD6RD75NwE7mYBtdtonRMiC91MiRwani8lBUD+baB6Y+3yAKp2kSc3RescEEGVKMD7rhWwsCdVH7kbKkYncmh5vnzfAZjXEUg9p10eQMGHckoKgfWvmmZrdIb0BOCXPkDcVuftwy1Vwgv/7Qta54AQUhkVpLG/L2t7H6HgQylH5wOnlwOrnrGerqQQyE62bx9rXwRuxgArn7Zv/aps75fAnlla50KGSlSaUyVUwgCYECei4EMpeanS0s1tC8xtw5ZiyFWYIX8dAhTlAnu/APbNBgoztc4NcRWJB4BvWwJxW7TOCalqqJqOgg95FHgaLayYUOjKLse3RSwJfan1ZcJ/k6pt2RAgLwVYOdLxbdHNRB76vKo8Cj7sRU/QLkRGUOguFz3qJeVm3OS8Ii6CzhcKPuTg3hC2/c+xbTnrJlicB+jLnbNtd0A3bUIIcXkUfNgr65rWObCUewuYVQ/4rZ/WOdGOu5Rs2ERBlFupNOedWqr450XnSxUMPi5tBm6csFx+Nxu4ftiBk0KNm4WNvF3axP6+KfD+CMtdSkbcJZ+EEDtQ8FG1go87l9musL8+bPnaooeAJQOBs6ulbctdbg6J+4HfHnHfcSPuZgO/9gOif5aW3tZxoScOQlyAm1w/idNUreAj+7r4a1mJ7O8L66Rty+ImJnZTU/BLZs99c9lQIDkaWOGmY4Mc/gG4cQzY8p609BRcqCfnBnBlt/T0lfnYVOb3RpRH50sVCz48PCUk0gFlxUDCLqD0rhMzo/LJV3BH3f0ppaRA6xxoxA2eDL9rDfzxGHBlj+20ty8A3zQFjv+q3P6v7AFOr1Rue0RFLnbzLcpReYcu9v41UMWCD2/T32I9QnQ64L93gD8fBzZMEt9W2V2KXgkBgOuHbKfZ8BobAG9+W7n9/jEcWD8RSLuk3DbtRtcCt3VgDjC7PnB6hdY5qVKqWPDBmcS3vFQ83cnf2d/n/xFPk3KKncuFOFkVvai7QcGHLIzeedvOowkfiQN2fcL+tvawqTR6cK3KwUexSCIZV/0zGkbKubfkpXfXk91d8+2KUk4DWz7QZoA8aw2BCzLcoKeZAG5+6TwlstD5UsWCD87btVbyYReVu9rOaeHkNimk0ln0IBC9ANg6Veuc8M3ryPY0U2OWzQNzFGwnwoj8TYg70LZ4tWoFH9zrQ3mJcBp36UIL0ERzUjFucpPg5dOJ52GaFt2urbyf4orGfnKCj+J8zqbNtr3+VWDB/UCZ2Xf89kW2iH39ROn7IcQZXKKkTNs8eNlOUolw653LKqpdzq4BMhM5aawckJJ8y2X5d4BjPwPZScrk0VncKajikfAFcdv3ZsYlLkhOovQx2jebu3H+a6eXs7+v7gGa9Tctv6twdRNVu9jP3T4vhqk81xkXUXWDD8Pfa1/kp4nbLG+bf08Arh1wLF9SOfKFdbcvu4GUfNtMY+d7Zxgg/TJQvTHg6W07vcM4+ax0FzqF3096vO005ueF4t8BN/1OVTZlxeyx9fZzcEMi5+ilzcDGycCI34DGDzm4DwM6d6pYtQsn+JA6+Zq1Hi+AcODhrjd6IXez2Tryolytc2I/e4/HmZXA/HvZUXHVoFa1izNFLwIOfW+53JnBlORtO/N7WYm+8+5Erwe+ugf4sgFQXuacfax6BihMB34fptw25VyTru4F1owD8tOU278LqFrBB3fOE0Zi8PH3c8rt354beMopIGaxyMkq84J+YR1wYpm8df4ax9aRb9CqW7ES1S52Fo8f/Yn9Hb9d+joOUekG5qzdlJUAW94FdkwH8lLF04kO6CTnfLYjmFH6oYCqXZR3YT1w6T/p6Uvy2J+yIqDAys354Fxg90wbG3PRY/j7MODieuC/d7XOiaKqVrXL9v+Z/taXy++uKkgHi5NW7EJkuJlZS2Nu0UPs78CacjNm6a/x7O97HgZCo6Stc3Uv+zv2X8f3b4+qVFTu7jcwbkBfWmj2IidYWDwQePWw5fonlgD3vwWENZC5Y61KPtz8eDmCYdiSZEmjRktUmMk+7ADAR2mAl68y29WXAztnsH93GguE1ldmuw6x49zJSVY4D9TbRRv5t9nuqmriDRUu8+RLi5W/Dg9nXdWHElaTwGfkNk+olbjNB/f9WOtts3KU8/Lg1GPvyueVE6waDXzbgt/ryFHFnJJhJYdC4B53VxmewKWvQ+qousFHykknbtwFTyxuexepN7YysYHY3I2dXW3VPox0QZLeDdiuEVOdWO2ipfP/KDtnjhRxm9lqjoQdCm6Ue12S+NlKOgZSHz4qWcDv4qpWtQuXUhcOnU67i5Ccp2PexVriet9KLBla/yqQeg54cbe8XiHlZYDOgz/4mwW5n63Ae3OXkg9nDkGuOaUv7FJKiVTs7aLleWVol9aknx1VVg6y+30LrMc9jnZtV+Q8cJdxfmxy4ndIA1W35GPP587bttgXx9GidEe6DtrzZZY6LsLp5UDqWeDqPunbLisB5rYFfutnPZ2mwYLqRR+cv93wKczasVK6GsmunkEaV7tc3ABsmqJsrwzu51CsRY80JT9TZ53zLhIk8rhKPrRTdYMPLTirK5iB1Qu8Gu0JZHyhbp9jJwS7GeOkvHC5yZOPMy6MFzcAOz9R6aKrZpG2Hecz7zRQ4POQu401Y4GY35SdE8paieb5f4AVI920jZeC5yvvM3KR77/LBEHaoeDDKcR6u8y3f5PlpeLblc1ZwYcTtntiiePb0LLaJekosPNjoLRIQmIn5G3NWODgHHXmTdGs5EPqOtxBBpX4rO08r/JuK7Bvw36ttOX6+zng8hZg/9fK7c9i/wqes3ZVu0hI5y7Vrva4eQKY1wmI3WTHytTbxc0JHECpA5jJsf8rIM+8a7CdX6TK1pPCJjtLPm6fd3zXi/sDB78DjvxgOy1jx9O8VPncG56NzyD2X3ZulDtxMnei5oXdnn25SQmYHNxrjU7kcl7gLnNAcc75pYOl9UwRCybuXGanzmAYyD7uDOOcazh/J/JXEbomrH8VyLwCrB5tZVeuea5T8OEMx39RZz/OmII8OwnY9an1QaLERC9khyGWNCS6/M2Lk9FKXqsvYnqChETObPMhY3urn2Wrxf55Xt621exJIKXNh7U2UopXu6h0XuXcNJuLinuTFPkc3OVhg5vP2+eBU3/aXkcsYJ/flZ06I/Zf8eMeuwlY94rlNpcNBX7s4oSZzzkUO11sHNvCTOD7duzAfy6m6vZ2caazq+WlN0TZsgfscULJx7JHgaxEIHG//O0aut21HQE06mVf3gxKi2R8HnICDhfumeRqTyjFeRITSsi34jdAOz4roYkhhej1wJ+PAYERwBPWHiRULs5nGOC7VuzfHyQBfiHSutA7M2/O3LakMTls7D/lJHBPb05yzuclVlpgmDLj1hmgXhcJedCQX4j116MXsg+Uh74H+n2qTp4kqjrBR/Jx52xXcJh2GRdafTnwQ2e2i+qkYzK7zzrhi59V8VR1w4HPS+7AQ+YzRpYVs3M1+IfZsXOhz88FbupiReI8ajQKdiYVP2dJVVScNCf/ADa+JvyauTuxppF9H1/kOseC+55zU9gbj5RqF6ey85jLHZ9DynbEtmnvw4dTq14U6kps69y0+h6oq606qjfSZr+2nkbybrE3/PTL0p/MTBsx35nUTMncjzNYuWhkJLBzNVi0cRFjo9rFJRqcuWHJh74cuLJHegmIqvmXWUXFCzxgPa+888XK2Ct2l6hJSJuZKFBlIJAXXsmHBpdzOcc86SjbRqEgXdq2JFXfSunJYuf335nj7ij1XXHWjN4qqDolH4E1tM6BMKGTp7yMDUjCm8hfVwpXeZIzct0viGJkf+YKHyN7jnlOMvDHcKDB/cCEzRJW0Ki3i13btpZXzk1cX2al+s+J5+28Duzvp5cDLYeI70/O03laLNvOIfcG0G4k0KCHo7mUZ3F/9ndJvsgxM39/MktHxCbfNA8Sy4rFZ4jlBXt2lHycXQOcWAo8uRSoFiF/fVVRb5fK79YZ4CcZX/R1L7MNnk7bGg/Ani8rlH1CFdyWzO0r+sRs46Km2Wi0Er5qWuSNYWw3rLt+0MZGBBqcWrwXFwt4rX3W3GBDL3FsHlvH7tzf0tNyXeN89kJjekjqPlyx/KfuwJ6Z7M1xyQDr+03YxY5wHL/TRgbtOGdvXxTOq10lH1JKnxj+n7/0Aea2sUxmPlq11GPPtfZF4Pohdmwdq6rAA5cNsoOP/fv3Y+jQoYiMjIROp8P69euNr5WWluL9999H27ZtERgYiMjISIwdOxYpKSlK5tn1mUf1K0cBaRfNElk5+c5XXKgOfW99P0oObWwvpcdLcMa2XKLBqcw2H2r5+zngy4YOdsfUoMGppPp9qxsQf4l7rDKvSswD5+/Mq8CBb4EizoijknsOmSkvEdmfYRn36VzB8+fPx9lqz+VPWE9nz/e/TGzMG2eUfJgtZ/RsTy5J23Og2uVulvS0N2KAn+4ztTMSY893iPves64DhyV0+VeJ7OCjoKAA7du3x/z5lgNmFRYW4uTJk5g2bRpOnjyJtWvXIi4uDo8++qgimXVb9o4waKsls70ULfkQqodWqKGYYlyh5MOF2nxw93NhLVsMfm6Nsts1cNaovmIje0r9DK0OiMa5LC68H7iwTmwjwot/uo/trr5tqvg+SouA5GO2q014wYfAd427vuh7cqFzDxDvxeK0Nh+8FaRvT+9A8GGryob73n4fxk6o+Psw+fuxeV3h7GfRg8D2j+Tvw0lkBx8DBw7EzJkz8dhjj1m8FhISgh07duCpp55C8+bN0b17d/z44484ceIEkpKSFMmwQx76UJv9Wm1IauXG6BtkfbsuUfKhRKOsKlAEKanaxZnDQKtR7WGW5xsxwBd1gEPznLv/08vZovS8VMs8iJLRPkXK0yL3u1hWcXO9fkQ8/Zox7LxGh+Za366t4ENSyYeNz+TgXGBOSyDrmvV0SikrgnCe7Cj5sPUQI3fiT0fbfBjYbIvD2Y/sjgZ2klMaowKnt/nIycmBTqdDaGio4OvFxcXIzc3l/TjNQ+8DE7Y4b/tCSgqkpzW/uNjqZWBxMZI6x4WTqzkM+0iPF396uHXaSfkRyYvpH+fuS5SUY+PmQZj5cdw4mb157pjmjJ2Z/jyxhJ0jaOfH0kvUrBXRx0ucJt7W4RJ7Kj2xFIjfzv59dCE7yaIYbvAh1BWb1+bDzgeBnTPYKha7BqKy45wtF3m/FiUfMvd/M4btUWMtjZzeIfYMtGjcjJN6ysgtSbT6frW93jg1+CgqKsL777+PUaNGITg4WDDNrFmzEBISYvyJiopyZpYATx/nbh8A70aTL2ceB/Mnx2Py0svdD8MAWz6Q0LDV2qZEvmR7Z7GNZsVuPP+9Y5kfNWhV7ZJ3C9g9E8i10n3YJboE28NwvnPy/MdjQEY8J4mMS43shoYVinIg/VwSSXdxPbDlPce2YSQSfORx2sAVpAGf12JHLhXCbQwsWO2i4Hw19ozoadc+JYzLIvT/ub+B1WPYLsiGvHL3//dzbI8a3kObQG8Xa7if8b+Trae1uh0Z1S5SJUezJYnc67VbXSf4nBZ8lJaW4qmnngLDMFiwYIFouqlTpyInJ8f4k5yc7KwssdTuC+/hbf11R2449p54Z1ayvxN2AdELgPUCQwxLzoNQ8MEA+75k/zzyo4Rt2FHXKwd3ez91Y4cclis9Hjizyv68XdrETvBlbQ4Gd597hPvZZF/nP+HKaSyXsEvKziwX6csdb/NxYb30tLbSSJ5tVw+cXCb8miLVLhIp1bNHEoHPxtZ14J/ngdiN7PD/e2dXpBH4TIrMS88527FVHaLY+Bu2Sj7s3E95iWPXa55K2NXWEHhcv34dO3bsEC31AABfX18EBwfzfpxK9hDmju5PxlAqsk98O09gQy+aomz71udlQYkvK2cbRTnA7zIbKMttBX78V3npAbYUZ93L/C6TQuJ3AhtfF69uu3lCfF2lLnz6cstRZp06tgtj9ttBsRsk7FLg4p6V6HiphWC9uMBN8cpuIFektMJIzmcukjbtEn+/FlmTUPIh9bwSDD6EggQrbZOK84DrhyU01nTwXDFOYSEh6JM6aJzY9uzhMiUSrpIPS4oHH4bAIz4+Hjt37kR4eLjSu3CMTuXgQwzDVBQPOvC06+gJrkQgZm9vF7H0h74HCmV2+5Q7yp8jn1tytPXXlz8BnPzddjdpQQpVu/zyMDCrLpB/R8auK/Z3w0pwJHUbglR4ykq/zLb/MLKjzYeUNlrxO9hqpTVjre9LiYAvJwlIqjjneN+TeexvXm8XB9sZCAUfngIlt9ZKa5cMApYMFC/JscbimFg7fnqRdQDLc01i8KEvU66thlolLLa4TBBkSXbwkZ+fj9OnT+P06dMAgMTERJw+fRpJSUkoLS3FiBEjEBMTg+XLl6O8vBypqalITU1FSYmVRlVqUmN0T+4+xE7mzKvArHrAX+M5aRUs+ZCyLSUCMSlf1uI8tueDWJ4Ofmf626LIVAHm++Uen9Iitg41T2LbHKkt4MXq8K1uW6FqF0Nj3vht8tf99WH796vYCKdqdA11YP2rewQ2J7C9AhnBn7XP59K/FfvgfNdOV8z4KqXaRepnL1RaIVhya+WzSz3L/jZU7coi4yHhbrb4axYlHzIa5cZusv66VDavE64bFKhFdvARExODjh07omPHjgCAKVOmoGPHjpg+fTpu3ryJjRs34saNG+jQoQPq1Klj/Dl8+LDimbeLM25u1oid7IYntJRTttOKbtvKTVXKxVlOlZB4JmwnWTwA+LWP+Gy/B75xLAvc933nskAC8zxy0u/5nK1D/aU3JJE6nLXSQ347zMb8N0psW6mnLEmfnYP7ynag67/U72lhBluNeHm7/fsyKCthZ2g1J2WcD0eqXYSuEVK6hNvap5QRTqUMBGdrP+ZdbW0du/UTrb8ulTPnhZHFdYMc2Xefhx56CIyVA27tNZdQvbG6+5N1EirZ5kNm8KHXAx521MJJOd63z7O/z6wC2o+0nlZOg+DyMsDT7BQ+/Scw3HIAPAtZ19mRZA0Bkc36+wpSSz4cHY3Qmd8joV4NipQIyqh2YRgr+5RS8uHgxX3L+5bLTv3Jdte0a98i7/334cJBg1wbXgXO/SWwWwUbKQsGHwKlo5LOU3vyIqPkQ6irseh6ctp8KMTRapfcFCDxANDacjytyqLqze0SVIuduv7tOOftw97SDCV7u9jaVno8sOJJ0/96O7rZAfIuxFICC6k3wcM/ALOjgOTjttMKlRD92ocdhVJWV2iBbYlytORDwn5unQV2fWbZuFQoD9zPldsF1rg7R25cUqr4zD6PTW86sD+JrL0noYGdNkwS387md9jPGpA3mZvkwMPG+SIUeJQV84NhZ7T5sFntYmfJh9D33J5z8Np+ge2YfQ6yGpwqhNGzpexJ0fa9rwX3AeteAg7b03bMPVS94AMAajYHgmqrsy9ZwYfcL4bZSc3tiWGr29ymt/j/iw38YzMLMr5Y1oIP43asXITntGYnpQLYYYJLC4Ht/5OwY4HgQ6g+/vhvtjflzGoXuRepnx9gq6x2z3T+viRt09r5a/Z5nFgqvddRqcBcIFLyv2YMsGac8Gty3v6t08DxX9jPmmEkPm3LZO18Edv2D13Mql0cy4JgqZ7QUAFi+eG2m7oZI97jRXTUUbNl+jJ2vpP9X1tui9FXBIVvC2zGfL8aBB8AW5W7+BHg/D8CL9o4WIZeV5dF2m399660IQNcuCaiagYfanJmtYv5iXX9kOnveR2tj4ZnPrmTPQMMAfIuxJKCDytyb1jWyfqH2V7PMiPCizdPsd1DRPKQyzo75oaws9rF0MjPVn54u1L4InxmNTC3rZXdC3zmm98WbnvBTXtmNfB5bYEuzhI/n4vrpaWTSl8ur7RPqX0KyUmS1v5Cat6E9mOrzQf3PDWM7WMQIyGYB4CCdMttAcDBOex8J7tnWna/1peLd8nnfUdltvmwRWxeGstMABkJ7J9CwUdhBjuejUVQZV71JJLfY4tcap4We1Dw4WzOrHaxdlHJS5ExIyfYp4xUa7M9im1HxvszBB+Giw1/QxVpbJQYlBTy//cJtL1fOZ9rqY2ulpJLPjxkBCpgZ5X943HOAhl5tufpxvy42frcs64DK0byp3g3rcwWEdvDWq8FoGK7DDvA1O6ZwK0z7PLITtL3IVRyYm+wwIgFH46yVvJh5TxiJDQ4lUpqmw+xz8689FSoqsi4Cc5naJy4z0r+s67z/y+7CyQKVLkA/O9o/m3+nDWOHrtlQ6Wls3UsinLYmYPNuyT/2JX/Xq2NC3THiU0HVEDBh7NJGeHTQO4XY8sHbE8S0TlgZFyMykuB/6QO0GRjH7cvCCc1BB+LHhLYjOG927gJml/gJHUXttIrSC45DU5tBSo5N01pdn/GDpIlJOMKsO4V8YtN0mE2jRzW6sWFrJsIXN4CLB0sbz9GCnS13f818HMv9u/AGtI3x23bZGDvqLpio6g6s3jb6tgUAm0+Lm8HNrwmfz/pl03tWgw8vNg2bIsHsLPwAjIamVo75jI/wyu7rWzLDLcU9+QyYCPns5DTXkfIjYo2ZmdWAftl9tITCoJjN/L/z4g3neO2CI3BYo6qXVxU9Xu0zoEZmSdK8lEg6QgQ/bPI5mT0hmH00odXNl/P3P6vhNPGbWZ/5wgMoX/sF/a3rcDAvHrIrqnqHQk+pAaIOvFAJfMq8M+LwHetgOUVN0bzNijcLC8fAZxZwd4AxCzuL5RZ8fRyA12rXVMVbqzKPaZiczHJuagKPiGbrV8ssQu+00o+rLB2wzQU7QNstWRxPhtsnfrDtPzWGSBb4rQVB77hP217eAFLh7LXmd/6sU/m17nDJkjokSKVtRGXE/dJ3475dayAM2ihUuf9upfZBwaxNhnmVaglBewcPuaEHp6kjjytyFAJ2nHv3DuqRjMgU+YTozPZG6WKjspoZXvmxXlMubTgI+82EFjT1C1XqQvxtqlAbSttBgzMSz7yUsWLX8U4UvIhtR2HtZKPeR1Nf1+RMI+JofrsrpUGZkINaLnHxtrAS2qw9zMXzafCT3RfN5GWLuOKcJ4S9wO1Wtk3uBxgo5DASvDBnaDx7+cAnyDLNHcuAXPbSM8LtyFj/m2ghFOymn4ZWPk0J28Su1fH7zT9bd7ezGDpEOl5tMb8OubIzL9/CHR15X6vVzwFfJxjezsbXxde7sgo057e1tvqMQxw1MqwA2oMuGlF1S75UHuSOVuUviHIKSLXl9vubnt1H/BtM3ZiJwO5AZO1m/eyIbarqczzmLiPnTHWKjklHzq2ceMtkUackqtdZLb5sLgQKHBztdoVW+a5Zm9vKAMlg4/cFOW/K1Lf34bXhPe99X22a+V3rezMAGegtpjF/JfEzkUhJWJVsDJwzxtrAS+bWPBP44LlTwLrX2WnHRBjPDcUCihvmHW/L+M0EpV7veKWLBkYxi0yWDaUbcfGWPksBHu8wLFRpq/sFi5FNrA1jIDGVTJVu+Sj+QC2KsA3BHjjNDtd851LQKFQg0gV/NAJ8PK3Y0WRk0jOHCnxO4DU89bTGAIDQ/UJIP8mYN4iXi4lpv22diO8dpAd0EmMUGlG3m12+u0uz3H24WFHbxcOsQtD8nEgqqvUjYi/ZP4+tk0FfAWemg0K0qzsR+knKBvTE8xpaef3hMPeC29hhvg5L3WgOiFZ14Df+rNPs9cO8F8zDJevGpmNnZcNBUKi2HFHuNIvy5+nSQnc0iBzSgSt3Mn+ALbUa8/nQHBd7o6kbcuegR25uOdcUQ7gF2L639H2LU5WtYOPDs8CATWAup2AgOrA+E1skd1nMhqzKa1MalcuhW0VGPHRnFC9sezgY7a89Pbu724WO2cMwwANHzB70crN0vypxtr+j/zEXlyzEoHLW9kf7j7klHxIvRn+1pct5hXswSFjm0Kf40Y7GilKJvKZ2xsEOPw9sXO/+bfZkXGF2NNmyoDbRkNrNySM8mqQclq82tMVGzsqEXwI9ewyL61y6mCEIrZ+yB/dWax6y0VU7eDDwwNoMcj0v04nrQWxq0mPV+eLfifWcpmtWV6VJvV9bn7HdJM4PI//mj0DOhlf5wQU26ayvwNrWqbT6Ry7Gdm6OR4TaGScdslszA/uNqxMM64GOdUuatRF2/v+rQWU9o6V42rEGowLsXaOSz2ORbnqzbkl54HAsR2Z/ry8RTyZeW8XR5z+E7inN9B2BPu/eUmUi6nawUdlcWmT2fTeKlr/irr7Y/S2q4cAIN7aZF7Wgg8bT0aGokxukaZYKYQjxZ4MA5z8g60GFJIp0C33p27i2+NNNQ9l20xc2mw7jSihIKBiYCjujM9KS3fCGAkOBZuVkNRgbNcn7I8a1GporVUg+s/zpuDj6E/a5EEiCj6ERHVT/4neUUpG0K5MXwos7Gk9TXmp9a6TVks+bE0IVXHxKuK0cBfank5mtcslgam8rVWDyO3jn3TE7DUFL8JpIuO68Mgszbi6V/nRSZ2tspR8yHF2lfhrouMPaUi14MMFSh1sVeVp3NuFgg8hz28HPg6xna4qO/c3EBypdS6EGeZFEOVAyUd5Kbv9hffb2J6EQcasslEtIDTnhsUmrLwXRy/CYpOwiRG70IlVf8id8M8V2DzvXMyC+4E67Zy4g0ra5kOKMgd7h6lB4zY5LtbX1IV0Hm/628uP/c3tzVDV/fM8sGSg1rkQYSOiPzRX/DVbF6cbx4AvG/JbmQvdWMuKHbvQ2boweEp4bjg0T/w1Rm9/cLRnFjv9vBwXZZTMHfvZPUsRVo/WOgfy3D4HnF6udS7UdXaNOvvJT1VnP9YEhFt/3XBf0wgFH2IGcHpltBjM9jDoZjapmZTBZYj6bFV3WBsXxJ6AQWhEwvQ44J8XpK0vdfRJgz1fSBvdMMfKqKSMHjgwR95+DezpsSR2TIpEvkOuUGxNKh/z6sfKqDCTnadLi27OMlC1ixhvf+DJZey03/2/YJdxnxRdbmh2YuRIwz+l+sZf3Ss9reDok1ZKPvZ9CXSXWe1hsXm9vHmHnOWP4cLLr8oYTpsQYvJVI2npNO6KS8GHNa2Hsz8G3Ke3l2UO6U3U40iRvasU99uqdpE6F4no9vWuN8IvV1VpQE2IVko1GlOqggtffVwQ94laylTuRBti8yhIcU6lOmGbbAQfjg5KxeglDJ1NiIvxpY4Aiikt1HT3FHzIwR2HX+NuSsQK8+Gp3ZGzh0Z2xdEnCbFFzetuuMTJBt2V6ISk6qDgQ47abYFWwxyvbyfElr/GOXf77tYtlJB+n8qfBfaePvbvr+eb9q/rDqjaxY3odMBTvwMDvhBPM3gOm8aZHJ1Ui5Df+mqdA2IPV26n42w1W8qfBfbhj+zfnz2fdW2zcVPev2b//m2p1QaI6m49TZiVxqdU7VJJNLgf+DAF6Po8WzriTNUinLt9QtxV497O34dS7Q7+lwrUaW89zesn+f93mwhMl1hqNWKx7TTuxCcA8PI1/T/oG+AVG11n63YCWj4qf19P/GYZfERVTF/Q9QWgWi32b8O8Th1GA69GA/0/N6Uf+BXg6QuneWkv8NxW62msVVNR8FFJMOXyGqE+LXOQJv7OHFiXkEqswzPO34e3PxBUR946kZ2EtzNOYFh9Lt9gy1mZrU3DHlzP9HdEa7P1bIyK23Ko9dft0XGMMttp+ShQtzN/mb4MqNXK9roPvM3/v8UQ4LFFwp/HK4eBGdns/CjcKQya9APGbwYmHgIGfg28c5kd5+nNc8Cz/7Al3hEtAL9Q0zr1uvCDJWua9GN/12orLT3AjvVjqw1MSJT4ayUUfLi3WhVjNLR9Ut56LYcC/tWtp3lkJuBTDXhum315k+PZtc7fByG2vHXRsfWlXuwd3cfEQ4C3Ag8bfsHAC7vE19PpgPGbAL+K0hbRp3gde9P0DeIs4lzeI1oBU29Yz+O9AlPFCxksY3C6fp8CY9YDPd+wfM0wYrShFEFMwweAp/9gg7Xguqbl5QJDmE86BtRozl8W2cF0cweAkcuB9k8D/7sFTDxoWt5pHFCrtemG3nwQUKMZ0OFZ4Nm/2WCkdht+8OftDzTpC3hXjBYaVNv0mpeftDYq/0sFhi8Aev8PeGY1u09zDe63XCal8e0wzlg+gWYl5qXU4NS9TdjCRsSdJ/CXv34SgA4Y8p34urZGqew8AfggCajfHZh8ml1WvwegtzIKZ5O+bCTe/wvg3pelvIOKvMisSyXEGULqAh2ftX99NYaM9vIDAsPZm7n507joOlaConpdrKxYcYN56yJbrN+gh3CyHpMsb0Y6D/a60eM19prgbeOzkdIDKqo7W7XsU816upot2aAjoDo7zXu52cB/1WoD/T5jr4+j/7a+Le4N9PFFpr8Nx9pwDB58H6jZHBi1kv2fexPvMMpyu57ebCeC5oPZbZhfq30C2GBm+Hzr+eOqFsF+3i2GADVb8F8Taq8ydiMbwFSrCTz4Hnv+P7+dDVbv6QM8+gPw4S1gwma2mkVI88HCy4cvAELrA22fYv9/6H2gUS/T6xo3OKVBxhzlFww0FIhKw+8BPs5m/970lsjKNr7sOp0pKKjeCHgvkS2G5Y6IOWA2sPUD0//P/sP+btKXHTDr2M9S3gVQ/z5p6QhxtsFzpM8d02wgcHmL6f/aMoqtAfZps+sLQHo88N/b7LDUthiCIw8PIKCGtP0E1mBLO2P/tZ125EpgVcXNsqziBuFbjS3WN9f1BfZG16CnKR1X9Ub8dgjB9YBcgRKQup1N27DGULUsNIrwYz8D6yoeeF49wg+GuHl/5i+2usS3Glv6kSsy3cFHaZZBW1gD9pp3eaupSufZtcC1g0DTR9j/w+8B3o7jV4G0Gg7cexSo19VyP6NWsIGX2OzUcnE/b66h3/Nnqh61Cmj8oGU6/zD2XDGvBqvTgS1hP/cX8OZ50/LGDwJxmy23YzhGw38C7n+TLf3qPAHISADit5vaq2iESj60xH3SGLnC8nXzxkoB1dkJxbglJt1fMf0d3pSfXsr8HwZePtLTVgZK1UUTxw35jr2B9pnB/u/lyz7pj1zBTnFgjlvF2ZBzw5x8mp1p+ZUjQJsRtktBhs0Her3Lfq/qd2OfMg3GrAd8goDHfzUte+YvYPQ/bCmDAXfyrg+tzBkEsE+iBqP/4b/25DIgtAHw4m6g+UC2mL1OByDIxszR1e9hSxYM39/B35peE5pPZ+IBYMJWYHomULeixKXri+x+uZMVik2iabgZmwcf7UaabpbegZY37Q6j2ZKOF/cAzR4BQjhtU/xDTX9z36/Y9av7K8DYDWzJhGH9lkP417Cg2vySHg9PYNDXQLunrL8vZ3huOzBiCdBpDPsA2f1VNtCT2w1YpwOe+JVtaxLKacthXupuYBgryNPbVJ3k4cmWDt33OtB+pH3vRyFU8qEmnyD2QmGo//QNAgrT2b+FWumLzVxqXkUyYQuw/xu2dTUX9wvV8VkgKZq9WJ9Yalf2VdV5AnBiie10hicBufxk9ljo8ZprzIVSGXV5zvJmF1KX/bmwjr+85xtAt1eArOvsU3+bx9nvUcMH2Kd8gH2qHvEbUFoEfG7WniCsEXshfvB9y+nka7djn4yDarPf0w+S2NKNms2AjCvsTdNcvc7AmYoHB58A4N0rbCnKnUvAzRP8kWi9A9h697uZ/OJvwHIqh/Gb2IcTscalY9YBl7ezVSBc3PYOQqUTAdVNVTcv7hJ/4m/aH7gTxw7jzy0N6vWu5bb9QoHHFrLb+SCZ31DTwMMT6DlZ+L14+wNTLrFpqkUAuSlsFUVlqQqu3830d0B1YMAsZbfv5QO8exX4ujF/uSNzXKmAgg81hTVgG04ZPPU7sPZFoM909sI18SAQswSI+c36dgbMBlaOBO6r+DI3uA8YI9Jg9KGpwNnV7FNltQgg+bh7BB/dJkoLPnKsNKKbfJq9eXUYDXxr1oir0YPWgwm/ULbl+3cVreltBSv3vgQcW2Q9DZEvsiP//07jgOA6wAs7TMs6jxdeV6iNQ3gTtsGhEA9P4IWdnP8rbvx12ot3ie08Aci/AzSq6JESWIP9adCDbbB4cQPQ+jHT9iefZNti2Cpp1OmsP43f8zD7Y45745cySq75Prq+ANy+CDTpAzQfwC77mHPu1xcYV6JOe9N2/IJt71NIMKf3ULCN0h5iKTCcbXAMAJ+Esr+dPUqyg6jaRQ1tRrC/zbt81WkHTIoGWlQ0GKrdFnjkM/apqL+V6Lj5QDbS7fep7X0/9AEw+ZRpbBChgXOsDVRjyLstYzdISydVSF3baQDg4Wnir1VvBDwwBQgSaE1vKLI1MC+iZxj+hdRW/eigr62/roRRq4WXtxUpSpYrpL689BO22E4DAAO+lJ8Xg7CGwKtHgeEL2e6R4Q7OJq30IF0enkDvqcLtvoJqAe9dBR6dZ1rmG+TceaG4pQWMlYbpYgZ/Czy3hR/EvLiH/c39jjTitFVwRhddIp95wBrWQLu8SEDBhxoe/wV46wJbRGyLTyAw7l+gx6vW0wWG21dPyb0gGepX+0xnf3O7nRk8MpP/f4fRpr+f4VR3NH6IrYsUqysWItZlr+Wj/C6DYnq9x1Yj+QiktdWmw7y1flAdoLpZsaV3oKnRWrMBtvNjbtJxed0SbWkukIeaLYAnfpG+jVptgb6fWC7v9xlbDC9Hg/uAj+5YLq/XlT82hVAxvBwRLdneCu2ftn8bbZ5gG1sqXeRti6Pv3R5tn2IbkJuPtmmvup3Yh533rpqWjVjMVkUOnSfvO0+cb9y/7IOpPdcsFVG1ixo8PPgNrLRUmGH6+/UTQN4t09Nk7bZA+2dMddgAWxw6IxvIvQnkpwH5t4HTFcXWjXqxN+yaLU3ph3wHxEgcWbHr88DmKZbLuVVTXPW6AjeOm/6/r2L2WqG6YfMSkfo9gCTOaIg+1dgn99h/gSt72C582z4EMg0X2Ir69okH2fEEuMXCxvzcC9w4JpzX9qPYtgI1mwm/R4MRi9m2ACtHAu2eZqvIrKnZgm1PYGDoDTDwK2DLe6blD7wNHPgWFjw82ZbvncYCSUfZXlEeXqYqhvvfAjx9gH0SSyu8fNjGkuf/ZtsgNOnLtreI38FO8FenPdvATUiN5kArO0aflOPxX4H0y0DvD6vOZJByglGpAsPN/q8h3quDaKtRL8s2RS6Igo+qJpDTNdAnwLIYmzvkrqG4XKdjg6eQemzDOwNvP+C1GMui7LZP8aembz8KOLNSfl7r3wckHWYbGYY1ZJ+wfukD3IxhXzc8VQoVpZvXqT+zGri0GVhf0TvI04t9cm/A6WI8bD7wfcXTomFOCG6r8iFzgf/eZQOsRr3YfPzNCT6eXAqcWMa2qG813LT84WlsQDZkLrDiSbYxX8IOduKqNk+waT5IZkt7zIOPlo8CsRtN/798AFjYk72hAqZSn24vA4n7gUub2G6TD09jn0y/Mp/boaKHVUB1oMUgy8+t78fs7/IS4GDFuAftRwEXN4oPSmTeWBJge6+M3cAGaD4BbE8Pn0BgzVj29ajuwPMqDJ7XTubgf4QQVVDwUdXU6wI8+iNQo6nw62VFpr+7T7R8PfwetljPMFqeUKlDzzdMwUe3V4C+M9jgI6IVe9PktsJ+aR+QdY0NCsznGhi/mc0Pt31GzzeANRVVKoaueN1fBfaYVQ+Zd9PzC2HbyhgIDfgT1oCdNyMr0bIKBgC6TGCH7zaUNgRHso3+6t3L/t/6MVPjQq5e77A/AFs1BQBlxfwxDIQa6k0+Bewya9fj5QO8dhw48hNwcA6/a+Ww+Wx1R+vH2IAxoDrbne8KpzpFykBSADvWgMHwBWw31M84gautEXE9PNiqOAPDsOfvXwPSLpnmySCEVEkUfFRFnay0h6jVmh3AxxpbRXq127CT7HkHmIq6P0pjA4LMRODHLqZ64sgO7M9agaGdPTwsG4bW784GPk37mUo+HpjC5mkxpyukYJsRTrG7WMNDDw/rjRq5AYOnN9vl0R5ShgGv3hi8PHP1eJUd74BbleAfahkwjloFZF4BfqpoVCy1wWXXF9iqk+aD2H14erPtfQxVboZpBeTyDxMfpZMQUmVQ8EH4HniHbdVu6IFjL/MW/YabbY0mwEe3LW++QgMiCakWwY5eyB3/wMOT7UtvqKIYMtd2ngLChdNobfAcfhuRWq2BCyKlDFLaMHj5sA02B38L7JnFH6raGp9AdqwJrv6fm4KPqjy1OyHEYRR8ED6fAHaOAWcSeuof/C3w7xvs4E+2iA28NGIJO3SwWANHT2/g7ctsjx9b81xopctzQHaSqZvcfa+z7S+a9ndsu11fALo871ijS/8wtus1U85vO0QIITLpGEZqJbA6cnNzERISgpycHAQH2zlgDXFP+XfYCZYIIYS4HTn3byo7Ja6DAg9CCKkSKPgghBBCiKoo+CCEEEKIqmQHH/v378fQoUMRGRkJnU6H9evX815nGAbTp09HnTp14O/vj759+yI+Pl6p/BJCCCHEzckOPgoKCtC+fXvMnz9f8PWvvvoK8+bNw8KFCxEdHY3AwED0798fRUVFgukJIYQQUrXI7mo7cOBADBw4UPA1hmEwd+5cfPTRRxg2bBgA4Pfff0etWrWwfv16jBw50rHcEkIIIcTtKdrmIzExEampqejbt69xWUhICLp164YjR44IrlNcXIzc3FzeDyGEEEIqL0WDj9TUVABArVq1eMtr1aplfM3crFmzEBISYvyJiooSTEcIIYSQykHz3i5Tp05FTk6O8Sc5OVnrLBFCCCHEiRQNPmrXrg0AuH37Nm/57du3ja+Z8/X1RXBwMO+HEEIIIZWXosFHo0aNULt2bezaZZrCOzc3F9HR0ejRg2ayJIQQQogdvV3y8/ORkJBg/D8xMRGnT59G9erVUb9+fbz55puYOXMmmjZtikaNGmHatGmIjIzE8OHDlcw3IYQQQtyU7OAjJiYGvXv3Nv4/ZQo7/fe4ceOwdOlSvPfeeygoKMBLL72E7Oxs3H///di6dSv8/Fx0FlFCCCGEqIpmtSWEEEKIw2hWW0IIIYS4LAo+CCGEEKIqCj4IIYQQoirZDU4JIYQQNZSXl6O0tFTrbBAOHx8feHg4Xm5BwQchhBCXwjAMUlNTkZ2drXVWiBkPDw80atQIPj4+Dm2Hgg9CCCEuxRB4REREICAgADqdTussEQB6vR4pKSm4desW6tev79BxoeCDEEKIyygvLzcGHuHh4Vpnh5ipWbMmUlJSUFZWBm9vb7u3Qw1OCSGEuAxDG4+AgACNc0KEGKpbysvLHdoOBR+EEEJcDlW1uCaljgsFH4QQQghRFQUfhBBCiAIeeughvPnmm1pnwy1Q8EEIIYQQVVHwQQghhBBVUfBBCCGEKCwrKwtjx45FWFgYAgICMHDgQMTHxxtfv379OoYOHYqwsDAEBgaidevW+O+//4zrjh49GjVr1oS/vz+aNm2KJUuWaPVWnILG+SCEEOLSGIbB3VLHunbaw9/b0+7eHePHj0d8fDw2btyI4OBgvP/++xg0aBAuXrwIb29vTJo0CSUlJdi/fz8CAwNx8eJFVKtWDQAwbdo0XLx4EVu2bEGNGjWQkJCAu3fvKvnWNEfBByGEEJd2t7QcraZvU32/Fz/tjwAf+bdJQ9Bx6NAh3HfffQCA5cuXIyoqCuvXr8eTTz6JpKQkPPHEE2jbti0AoHHjxsb1k5KS0LFjR3Tp0gUA0LBhQ8ffjIuhahdCCCFEQbGxsfDy8kK3bt2My8LDw9G8eXPExsYCACZPnoyZM2eiZ8+emDFjBs6ePWtM+8orr2DVqlXo0KED3nvvPRw+fFj19+BsVPJBCCHEpfl7e+Lip/012a+zvPDCC+jfvz82b96M7du3Y9asWfj222/x+uuvY+DAgbh+/Tr+++8/7NixA3369MGkSZPwzTffOC0/aqOSD0IIIS5Np9MhwMdL9R9723u0bNkSZWVliI6ONi7LyMhAXFwcWrVqZVwWFRWFiRMnYu3atXj77bfxyy+/GF+rWbMmxo0bhz///BNz587FokWL7P8AXRCVfBBCCCEKatq0KYYNG4YXX3wRP//8M4KCgvDBBx+gbt26GDZsGADgzTffxMCBA9GsWTNkZWVhz549aNmyJQBg+vTp6Ny5M1q3bo3i4mJs2rTJ+FplQSUfhBBCiMKWLFmCzp07Y8iQIejRowcYhsF///1nnAm2vLwckyZNQsuWLTFgwAA0a9YMP/30EwB28rapU6eiXbt26NWrFzw9PbFq1Sot347idAzDMFpngis3NxchISHIyclBcHCw1tkhhBCioqKiIiQmJqJRo0bw8/PTOjvEjLXjI+f+TSUfhBBCCFEVBR+EEEIIURUFH4QQQghRFQUfhBBCCFEVBR+EEEIIURUFH4QQQghRFQUfhBBCCFEVBR+EEEIIURUFH4QQQghRFQUfhBBCiAto2LAh5s6dKymtTqfD+vXrnZofZ6LggxBCCCGqouCDEEIIIaqi4IMQQghx0KJFixAZGQm9Xs9bPmzYMDz33HO4cuUKhg0bhlq1aqFatWro2rUrdu7cqdj+z507h4cffhj+/v4IDw/HSy+9hPz8fOPre/fuxb333ovAwECEhoaiZ8+euH79OgDgzJkz6N27N4KCghAcHIzOnTsjJiZGsbwJoeCDEEKIa2MYoKRA/R8Zk74/+eSTyMjIwJ49e4zLMjMzsXXrVowePRr5+fkYNGgQdu3ahVOnTmHAgAEYOnQokpKSHP54CgoK0L9/f4SFheH48eP466+/sHPnTrz22msAgLKyMgwfPhwPPvggzp49iyNHjuCll16CTqcDAIwePRr16tXD8ePHceLECXzwwQfw9vZ2OF/WeDl164QQQoijSguBLyLV3++HKYBPoKSkYWFhGDhwIFasWIE+ffoAAP7++2/UqFEDvXv3hoeHB9q3b29M/9lnn2HdunXYuHGjMUiw14oVK1BUVITff/8dgYFsfn/88UcMHToUX375Jby9vZGTk4MhQ4bgnnvuAQC0bNnSuH5SUhLeffddtGjRAgDQtGlTh/IjBZV8EEIIIQoYPXo0/vnnHxQXFwMAli9fjpEjR8LDwwP5+fl455130LJlS4SGhqJatWqIjY1VpOQjNjYW7du3NwYeANCzZ0/o9XrExcWhevXqGD9+PPr374+hQ4fi+++/x61bt4xpp0yZghdeeAF9+/bF7NmzceXKFYfzZAuVfBBCCHFt3gFsKYQW+5Vh6NChYBgGmzdvRteuXXHgwAF89913AIB33nkHO3bswDfffIMmTZrA398fI0aMQElJiTNybmHJkiWYPHkytm7ditWrV+Ojjz7Cjh070L17d3z88cd45plnsHnzZmzZsgUzZszAqlWr8NhjjzktPxR8EEIIcW06neTqDy35+fnh8ccfx/Lly5GQkIDmzZujU6dOAIBDhw5h/Pjxxht6fn4+rl27psh+W7ZsiaVLl6KgoMBY+nHo0CF4eHigefPmxnQdO3ZEx44dMXXqVPTo0QMrVqxA9+7dAQDNmjVDs2bN8NZbb2HUqFFYsmSJU4MPqnYhhBBCFDJ69Ghs3rwZixcvxujRo43LmzZtirVr1+L06dM4c+YMnnnmGYueMY7s08/PD+PGjcP58+exZ88evP766xgzZgxq1aqFxMRETJ06FUeOHMH169exfft2xMfHo2XLlrh79y5ee+017N27F9evX8ehQ4dw/PhxXpsQZ6CSD0IIIUQhDz/8MKpXr464uDg888wzxuVz5szBc889h/vuuw81atTA+++/j9zcXEX2GRAQgG3btuGNN95A165dERAQgCeeeAJz5swxvn7p0iUsW7YMGRkZqFOnDiZNmoSXX34ZZWVlyMjIwNixY3H79m3UqFEDjz/+OD755BNF8iZGxzAy+hJJUF5ejo8//hh//vknUlNTERkZifHjx+Ojjz4yduuxJjc3FyEhIcjJyUFwcLCSWSOEEOLiioqKkJiYiEaNGsHPz0/r7BAz1o6PnPu34iUfX375JRYsWIBly5ahdevWiImJwYQJExASEoLJkycrvTtCCCGEuBnFg4/Dhw9j2LBhGDx4MAB2opyVK1fi2LFjSu+KEEIIqXSWL1+Ol19+WfC1Bg0a4MKFCyrnSHmKBx/33XcfFi1ahMuXL6NZs2Y4c+YMDh48aKx7MldcXGzsEw1AsTowQgghxB09+uij6Natm+Brzh55VC2KBx8ffPABcnNz0aJFC3h6eqK8vByff/45r9Uv16xZs5zesIUQQghxF0FBQQgKCtI6G06leFfbNWvWYPny5VixYgVOnjyJZcuW4ZtvvsGyZcsE00+dOhU5OTnGn+TkZKWzRAghhBAXonjJx7vvvosPPvgAI0eOBAC0bdsW169fx6xZszBu3DiL9L6+vvD19VU6G4QQQtyYwh0xiUKUOi6Kl3wUFhbCw4O/WU9PT8UGUyGEEFJ5Gdo0FBYWapwTIsQwHLynp6dD21G85GPo0KH4/PPPUb9+fbRu3RqnTp0yDq5CCCGEWOPp6YnQ0FCkpaUBYAfIkjJGFHE+vV6PO3fuICAgAF5ejoUPig8ylpeXh2nTpmHdunVIS0tDZGQkRo0ahenTp8PHx8fm+jTIGCGEVG0MwyA1NRXZ2dlaZ4WY8fDwQKNGjQTv53Lu34oHH46i4IMQQgjAjphdWlqqdTYIh4+Pj0XTCgNNRzglhBBClODp6elw2wLimmhWW0IIIYSoioIPQgghhKiKgg9CCCGEqIqCD0IIIYSoioIPQgghhKiKgg9CCCGEqIqCD0IIIYSoioIPQgghhKiKgg9CCCGEqIqCD0IIIYSoioIPQgghhKiKgg9CCCGEqIqCD0IIIYSoioIPQgghhKiKgg9CCCGEqIqCD0IIIYSoioIPQgghhKiKgg9CCCGEqIqCD0IIIYSoioIPQgghhKiKgg9CCCGEqIqCD0IIIYSoioIPQgghhKiKgg9CCCGEqIqCD0IIIYSoioIPQgghhKiKgg9CCCGEqIqCD0IIIYSoykvrDKjt3I0czN4aizZ1Q3DhZi6+H9kB4dV8tc4WIYQQUmVUuZKPEQsP41BCBn7edxUHE9Lx5dZLWmeJkCrhUmouMvKLtc4GIZo5fCUdPWfvxt64NK2zorkqF3wUl+l5/2cVlmqUE0KqjvjbeRgw9wA6z9ypdVYI0cwzv0TjZvZdjF9yXOusaK7KBR/mGEbrHBBS+R27lql1FgghLqTKBx8ARR+EEEKImqp88EElH4QQQoi6KPjQOgOEEEJIFUPBBxV9EEIIIaqi4EPrDBBCCCFVTJUPPgghhBCirioVfJSW6y2WUa0LIYQQoq4qFXwsO3zNYpleZvTBMAy1EyGEEKKaynjPqVLBx3GRgY42nL6J73fG21y/rFyPQfMO4sXfY5TOGiGVmg46rbNAiFv64+h1dP18F+JS87TOiqKcEnzcvHkTzz77LMLDw+Hv74+2bdsiJkb7G7aXh/DbfWPVaXy38zJOJmVZXf/MjWzE3srFzlgal58QORhq2k2IXaatP4/0/GJ8sPas1llRlOKz2mZlZaFnz57o3bs3tmzZgpo1ayI+Ph5hYWFK70o2L0/Lpy9uaVZGfonV9UvK6AJKCCFEffpKdvtRPPj48ssvERUVhSVLlhiXNWrUSOnd2EWo5IP7RFZu4+gKNVglhNhG1S6EOKiStftQvNpl48aN6NKlC5588klERESgY8eO+OWXX0TTFxcXIzc3l/fjLOkC03nrOfGEoVFPcVk5vt8Zj7M3snlpKfggxD5U7UII4VI8+Lh69SoWLFiApk2bYtu2bXjllVcwefJkLFu2TDD9rFmzEBISYvyJiopSOktG+y7fsVhWwgkoohMzMXXtOXy+ORbf7byMR388xEtbWm66gFbG1seEEEKIGhSvdtHr9ejSpQu++OILAEDHjh1x/vx5LFy4EOPGjbNIP3XqVEyZMsX4f25urlMDEHMnrpsamS4V6IrLxS350DOAQBMSQogAqnYhhHApXvJRp04dtGrViresZcuWSEpKEkzv6+uL4OBg3o8zlNlZZTJ/T4Lxb27wQSUfhBBC1FLZ7jiKBx89e/ZEXFwcb9nly5fRoEEDpXclS4mdwcfX20zvhdsglds2NT2/GH2+3YuF+67YnT9CCCGkqlA8+Hjrrbdw9OhRfPHFF0hISMCKFSuwaNEiTJo0SeldyVJc6nhj0QPx6ca/N51Nwf6KNiTz9yTgyp0CzN5yyeF9CCkqLcdzS48LjtBKCCGEuBvFg4+uXbti3bp1WLlyJdq0aYPPPvsMc+fOxejRo5XelSxFZeUOrX8r5y42nkkx/j9lzRmMXXwMAFBc5txeMGtikrH7UhpmbLzg1P0QQgghalC8wSkADBkyBEOGDHHGpu3mSMmHXs8gJbtI9HVnN//IKypz7g4IIYRUCak5RbieUYBujcM1zUeVmdulTM+geqCP3euKYRueVramQIQQQlyJUg+53WftwtOLjuJYovBcZ2qpMsFHk4hqODmtH34Z20X2uoeupONiSo7ga5VtyFtCCCGVX/TVDE3375RqF1fmYcdwAxOWHBd9rVzPOL3aRUdDJBBCCFGQ1s/NVabkw6BLg+qKbk9P430QQgghslS54CMkwBvnPn4EcTMHKLI9e4OPq3fyMfrXozhyRduiL0IIIa5P6fmRtH5urnLBBwAE+XnD18sTW954wK5qGC49I/0gHrmSgYl/nMDt3CK8uvwkDiVkYNQvRx3LACGEECKT1pM9Vrk2H1wt6wTj4qcD0GLaVru3Ua5nJB9EQ6BRUq5Haq54111CCCHEmajkQ2N+3p7oEBVq9/qFJWVYE3ND1jo3s+5qfuAJURM1mibEtWh9C6rywQcALHy2s93rLtp/VcGcEFI5UbBNCOGi4ANA7RA/BPnaVwO1/cJt3v9/HLlmcx0GjKwnQZqOnBBCqjbFA3iNnwgo+KgQ/b8+dq13M/su7/9pG2j+FULMUbULIa5F68JICj4qBPh4YdVL3bXOBiGVElW7EOJatP5OUvDB0b1xOK7NHoyRXaO0zgohhBDiNFp3taXgQ8DrfZoqsp28olL8fuQa0vKoWy2p2qjahRDCVaXH+RBTPcC+2W+5LqTkYPC8gwCAT/+9iF/HiU9ot/p4Ejw9PDCicz2H90uIK9K6iJcQwqf1d5JKPgT4+3g6tP6Wc7eMgQcAlOkZjLcyOd37/5zDO3+dQVFpuUP7JYQQd1BSpsfeuDQUFJdpnRW3llVQgn5z9uHH3fGy19X6eYCCDyd4ZflJu9YrLtULLqcia+Lu6BwmXN9sj8P4Jccx8c8TWmfFbQiVVCw6cBXxafn4Zvtl9TPkIAo+RPxvUEvV91mmFw4+7MFoXaZGCCEilh+9DgA4EJ+ucU7cW1m5/fcMrW8RFHyIeLFXY/RpEeGUbYsd9HK9MmfD7C2XcO8Xu6ihKyHEJXlQUZhsQncHnQOfI/V2cWE/PdsJHw9thQeb1cSm1+/H1S8GOXV/pQoFHwv3XcGdvGIs2kdDvxNCXBDFHtrTuOSDertY4evlifE9G2F8z0aq7K+0TLlqF0IIIZWbIzGc1hXzVPIh09NdnDcA2YSlbI+YEicFIWdvZCM1h6piCCHaooIPhbjxB0nBh0wvPOC8UpDE9AIcSkhHs4+24NcDjleZcKsDL9/Ow6M/HkL3WbskrUsNVgkhzuJIWwVi4siko1pf4yn4kKlJRDWnbv/tNWcAADM3x2LjmRQwDMM7vXrM2oW1J29I2hb3C346KVtyHubtikfXz3dZTJpHiBK0vugR7VHsoQxHPketv4YUfMik0+kQ++kAjOwahSXju8LfW/6AZPFp+Va2b/p78spTOHIlg/f6rZwiTKkIUABAr2eQW1QqIePS8zdnx2Wk5xfj2+1x0lciRCKtL3pEexR7aE/rryEFH3bw9/HE7CfaoXeLCPz7+v14t39z2dvILhQOGMy7oF3LKLS6nXFLjqHdx9uRmF5g8dqi/VeRkJaHCyk5svMHQPuzkxBSKVG1i3xCJYYONTilkg/31iSiGib1bqLY9sy/k9UDvQXTXbmTj7JyvXGQnr9ikgXT9Z2zH4PnHcSCvVdk54ViD+IMSp1Xl1JzqQG1m6LQQxnuHMNR8OFibmTx21mIDcbT59t9eGP1aeP/nh7Wz0KhkhHietaevIE52+MqdbsIJd7bzey7GDD3gOQG1MS1uNJN82JKLt5cdQpJNkqZXZFDDU5pkLHK4aHmNeGhY3+rZfPZW8a/DcHH55svqrZ/orwpa85g3u4EHL+WpXVWXNrFlFy71su5W4rkTPe7yRDnGfrjQaw/nYIXf4/ROiuq0vr5hgYZU8hv47qiuKwcAT5e0OsZlJTr0WLaVoe3K3XI9bk749GtUTh+OZDo8D4NKvPTt6u7mV0IoLrW2VAM9/lMibPK3nOz/SfbAQCHP3gYkaH+CuSE2Md1ij4M19i423ka50Q+VypBkotKPhTi6aFDgA8by3l46OBnRy8YIWV6RvIJNuqXo5LSDZt/COdv2tkIlagiv6hyTTXODRWUiGkd3cQpGV3PifLc+abpShxrcErVLsSKcj2DlGxlG9WdSc7G+CXHsORQIr7ZJt6dlso9tJNXrF3w4chMmWpx9Lppo4kUcTL6+AkFH070+sOO94LJuVuKpYevOZ4ZM+n5Jfjk34v4cU8CkjMLcSOrELlFpTiTnG1Ms+F0Cu//zWdv4bmlx5FdWKJ4fgifVg8lvx64ihbTtuL4tUxFt8uvdlGk4sWhtenJW1v0+SvEoVlttUXBhxO9/UhzHPtfH9QK9rV7GzM2XlAwR8JSc4tw/5d70O7j7Rg2/xDvNcP/x69lYtKKk9h9KQ1zdlyWvO2sghKMWnQU/5yQNior0dbMzbEo0zN47++zim5X8WoXra+cxCFivTSSMwtxKCFd5dy4Lxrng4iKCPLDhkn3a50Nq2Js9KxITC/AkwuPGP/PLJBe8vH9rngcuZqBt/86YzsxcRmVvVqCBrnSltjH/8BXezD612icuE69vcwJBQsODa9OXW0rv9ohfuhUP9Ri+eQ+TdXPjIAbWda7Hsal8luBy7lwUxWNfbS+N9oaN0Yupd+Oo5dNCj20ZevzP5VEwYcUUsb5OH8zB1kCD4xU8lFFrH21J67NHgxfL9NHLnWCOGdbHp0kK72cCzeVjrsnscHtlOAK1S5U8kGqghPXMzHkh4PoJjAYn9bXZgo+VObFeaLs3CBMw5zYT851W6noOjG9AM8tPY4T15VtCOlKtO76xuXl6do3Z0eLjF373VV+FPwpw9bHuC/uDgCgpMyyB5vWlxsKPlT2asU8MEPa1cFnw9tonBv7OPOysf7UTQyYux/XzIaDf+XPE9h9KQ1PLDgisqb7414MHBk2WQmeziz5UOCZy54LJze4o3ufdXdLyrHz4m3cLSl3yvbp81eGzY/RhT9oCj5U9sqD92D9pJ6Y81QHBPt549S0ftj2Zi+tsyVLwp18TFpxEvFOGBHwzdWncSk1Dx+uO8dbbj7njZI2nU3BpVTL4bq3nr+FdafUqxrTu9DN0cOJLU6VHmRMaokRL7hz3WuyS/hg7Vm88HsM3nFSQ3H6/OUTCtptfY7WX6YGp1WKh4cOHaJC4VPR9iMs0Ach/sIz17qK6MQM3v/nb+Zi89lbGPVLtM11uaf3B/+cxd64NEn7LDAbZMtZF6vDV9Lx2opTGDD3AG+5Xs9g4p8n8dbqM0jLU2fmVNepdHFuyYcSuAGH+QwESRmFWHUsCaVmg6WV84I7135/WttwOgUAsPncLRspiZZsncfW2m5pXe1Cc7u4AG5E++fz3ZCUWYgHmtbAA1/t0TBXJksOXRNcnp5fjD1xabi/SQ14eegEvwjcm8Sq48lYdTwZ12YPlrzvP45eRzVfT+Q5abhxsQnKuKUQuXdLERHk55T9i+1Ta04t+VB6ewwD7jNer6/Z701uUSle6nWPcTmvZEnhPBB51K5WTEjLx9kb2XisY90qFXhae6taX26cXvIxe/Zs6HQ6vPnmm87elduqUY0dhMzTQ4ce94TjmW71EVU9AHXdYOKrCUuO46Gv92LMb8cU3e6ZGzm4mX0X09afx1urnTdGiNgNn/s0LTa336pjSXj65yPIKSxVJC9aXwy4nNrmQ4E3ykg4PtFX+Y2T+dUurnEDOnE9C78euAq9xAkkKwu1P/6+c/Zhypoz2HS2apXkuPJ4PU4NPo4fP46ff/4Z7dq1c+Zu3J63pwcuftof5z/uzxtfYUj7OgCAFrWDtMqaJDez7+JgQrrgBVTokvq3xNFOf9l/1cGc2SZ2H9TzivWFE32w9hyiEzMxf2+CInlxpSdzDzeqkBU7PuZLuTNE2/p8L6TkYOt559+onlhwGDM3x+LfsylO35cr0er85k4X4W7sGWTMWpBdaQcZy8/Px+jRo/HLL78gLMw9u5SqKcDHC/4+/Jlwp/Rrhh9GdcSKF7vjiU71jMs/HdbaYv17agY6PY+25NxlSwD+PZOChh9sxtM/HxEcZIzbiC32Vi6uZxRYpAHYoEaucj0j6ylSLCX3iy70pec+vecrNAmcnvdkrsgm7ebUcT4U2Yb8rchp0Dt43kFM/POkaoNdXUnLV2U/rkKrkqfKVr7kSPWV1iWtTgs+Jk2ahMGDB6Nv375W0xUXFyM3N5f3Q1i+Xp4Y2j4S1QN98EDTGsblY3s0xOOd6hr/n/t0B3z9ZHvj/0Pa1VE1nwYHEtKxK/Y2Xl95CgAQnZiJQwkZgmlHLDiM8zdzMPD7A3jw673Q6xk8ufAwL43cr5Vez2DQ9wcw8PsDkgMQKSUfRaX87oYvLDuO4T+Z8io3n+dv5uCHXfEoLuNv15XG+XAmpQcZEyv5MD8uvOBO4lGLtxEUZOQXK1btVpXY+vSd9VWobF8x2yUf4q9p/VE4pcHpqlWrcPLkSRw/ftxm2lmzZuGTTz5xRjYqlaHtIxGbmot7G1YHAHz1RDu81KsxmtcKMj5FRH/YBzey7uJGVqEmdZuTK4IOKWKuZ+HZ30y9ZeJu5+G42RwzqbnyepmkFxQjrqL7b87dUoQF+thcR+wJmntDe/H3GMR81I9NzzDYGcvvsSP3IW7IDwcBsI06J/U2zXxsz83R3Z1OzkZhcRnua1LDdmIOWyVTgOXFlRuQSj1mQsmmrj2LID9vTOnXDJ1n7gQAXP1ikFMb6VY69FGpwtp1ROtATPGSj+TkZLzxxhtYvnw5/Pxs9xCYOnUqcnJyjD/JyclKZ6lS8PTQYerAlujTshYAwMvTAy1qB/OKL2sF+6FzgzCXaUxnSzbnifGH3fEWr5+9kSNre16chgpnb+ZgwNz92H4h1bhMr2cQcy2TN3CSeMmH6e/0fFPVUblAiYq9gcLFW/xSPlcq+XDqOcR5m8PnH8Izv0bL7s7M/aSk9hKyp02N+ZaTMwux8lgyFu2/ijt5xcblBSXO6Y1VWWl1hdK6nYPSuJ+j0PXDleNhxYOPEydOIC0tDZ06dYKXlxe8vLywb98+zJs3D15eXigv5xc1+/r6Ijg4mPdDHFPkpFEJnem/c6m2E1XYfPYWLqTk4IkFh7H+1E3jTYAbGLz4ewwupebhpT9OAGBLQhp/+B9GLDyCMZwSF7EbvtjyMqHgQ6EveGXu8MD9jIRuAGm5xRbLrLE2zocYJT5f7tgh3MbhRaWWw1fLoeWhL9czOHcjRzCwJvIkpOVhyaFEweHMHWXr6AgdPuvVLtoeb8WrXfr06YNz5/ijU06YMAEtWrTA+++/D09PT5E1iVLaR4VqnQWnmrTipPFvw9TbnRuEYUDr2sbl5l/+XpwxU2I403WLNSYV+iKn5RXB39vy/FXq4cKVRjhVfBZaG412ZW9P9B9x3M9X6p7NPwduQ1zuzdq8XZArYxiGV7L12aaLWHr4Gp7r2QjTh7ZSJQ/ObNCspb5z9gMAisv0mPjgPTZSO477OZqPd2P+uoXKNshYUFAQ2rThz1kSGBiI8PBwi+XEOZrXDsK6V+9D7RA/ZOSXYN6ueOyMvW28oQ5pVwc3su6ibqi/cQTDY//rg3s/t5z50F2cuJ5lDESEGHrimDMfpnvs4mMoKC7DwjGdeen2Xb6DcYuP4dH2kRbb0Ol0KCwpg6+XJ+9puKxcj+0Xb6NLgzBEBNuugpTSjqEyMLw3h96jhAan5njBh5375l7MSzilIHcdDD7UOt5FpeUYNO8A2tUNwdyRHQEASw9fAwAsPpSoWvChVeyh1ud80sq1SEncz1FuwZXWlxga4bSS6lif7d5cJ8Qfi8Z2QW5RKX7cnYBH20eiTd0QAGxjP0PwERHkh471Q3EqKVtwe4E+nihww+ocAJi95ZLgcoZheBej3KIyHIhPBwDcyua3QRi3mB1EbeMZy/EYsgtL0Gr6NrStG4J/X7/fuHzFsSRM33ABoQHeOD39EZv55FclaH1pUBa/2oUl5T0yDINP/r2I5rWDMOre+pxtyC/F0NsRsJjjvo+yctM2Ct3ku7Hv8h1cvVOAq3cKjMGHPbaev4U/jyZhzlPtJQXW5ip7g2otvr1C57TVcT40vsaoEnzs3btXjd0QK4L9vPHhoJa8ZR2iQrFgdCfUCwsAAPz1cg/kFpWh02c7LNZ351vhwn1XLJblFpVi8LwDSM40jSWSVWA5JokUhoDl3E1+A1nDdNbZhaXILizBlvOpGNRWvBs09+boLp/3jaxCLD54DTWCfPBs9wYI9hOep0joOiflSe1QQobxyZwXfEgIJMwvrtzeLkp8vtz2H+7SXkKpG87EP9mqz2+2x+GrEe1tpJZP6/YIjnLGjd2ebbpyiEclH1XcQM7N0MvTA9V8TadElwZhxvYR7nJxlWrN8WRe4AEAh6+YxiQpKZfeYEzs6cKPM2jcpBUncSghAzsv3hbdjpRRVbnWnryBsAAf9G4RITmvUkktFn/sp8PGBr+HEzLw5wvdbK5juIhKeY9i1WW8QM2eNh8SV7L25MgNPtylpErpbNrb0LaSNvkw0uJ0EC75EE+v9RlLwQfh8fY0na0fDWmFjadTkJRZiCt38pGYLjwSqTuauTnWYtmH60wNpYtlXFS5X/AuM3dCpwNefKARr3GqYbC1XZfEZ/WV0yYhObMQU9awI8WKTdR3t6QcOXdLUTtEmUnx7uQVI8Tf2zgjs2GZwcGEdEnbMbw1KW1cxC6e9gQSSpcslXKqXRydm8Vdn/RdfUZuc2pVNThjL0KBsI7X4NRyHVee1daNZnAgauCezIE+npg+tBV+HdcFvl7WT5WFz3bGtdmDseOtXs7OoipKOF3Cm0ZUs5qW25c+Pb8Yd/KK8cV/lyTPYWMg5WIQcy0T/1t3Dgl3+CNvxqXmYfclfqlKr6/3oPusXUjOLBTd3rxd8Rix4LBgbw2GYfDCshi8+HsMrtzJR9fPd6LZR1twIUXe+CuA8Lgc/N4nwm9e7NLJLyUSTmN+seaW3tl7E+Lut4xb7aL1lVwipXPpY3ZdKNczOJ2czSsVEuIuYxHZyxklYYIlG7Ze5zZIdbHSawo+iIWvnmiHt/s1Q9NapgntDCNx9mwSjgPv9eal/2hwSwxow3ZzbVorCI1q8OeZCZcw0qir4XbVFRrbg+u2zDEquBLTC3CyYv4QXjsGkX2OWHgEy6OT8CWnEe3w+YfQf+5+PLc0Buc57U4MpRLWSiTm7LiMmOtZ+CuGP7ifDkBmQQl2xt7Gjou38ceR68bXJi0/CVuOX8sUnZvH8D6lXKBFSz70tgMX8wCDkViyZC0w4b7ErZpzk9jD6fn8dnschs8/hPf/OWs1nT2hB8MweHX5Cby6/ITmjSVtcUr2bIzjIbRLbpBn/n3T+hOk4INYeKprFF7v05S3bEi7OtgwqSd+GdsFUdUDUDPIFwBQN9QfLzzQmJfWfBZed6kP5zI0qAPgtOomD50Ovb/Zi8d/OowbWYW8p2fzT6ywpAz/nTMNmX+FU/JxmjNT5+WK4eW5yvUMPt54AX2+3YsCkUnwpm24gBtZ4iUk3CfZ/GLrPTvO3sjGkwuPoOfs3cZlQg1EZXcN5GyEU+OBTIkNhaW2E+EPc2/+Grfkg5MfR6td3O8rIuinvWzj7rUnb1pNZ0/BR1ZhKf47l4r/zqVKPubmpHzMSw4lYtD3B5Ceb/9DhUqxB3+EU4HCJn7JiNn2ND7pKPggkuh0OrSPCkWAD9tMaOWL3TCsQySWPXevRVrzYKSSXFcVxy0RunKnAOV68SfpVtO34VVOiYOce92Z5GwsPXwNV+4UYMNp8anb3/tb/Gm1lPeUL77znRdv41hiptX8GG7Uci9+/ODB9I/hhmdLucTeLtaCZW4eyvSu1eD0RlYhhs0/JNgd3MBV2pbYE3xwV3FmA/hP/r2Ii7dy8f1OyykfpHLGjd3WOWaz2oVKPkhl0CQiCN+P7IgmAu0hOjcIw7EP+6B/61qoF+aP+2VOGlZVnOKUWAD86h17LjQAsCfuDhp+sBmztpga1P7FaXvCvWGaS83hj23CLYkpLpN2o33h9xjBnkJCjWmlXZ+FRxTl/i1WmmMtD9YDDGvVLqbXSsrFtzdlzWm8zwnmGIZBdqF9T+tSzdhwAWeSs61O8OgCMRIA2+N8COWTN8aKncGHnPcv9bxydD+ObJPX4FRgHQ8r1S5aRx8UfBCniAj2w8JnO2Pfu73h60VD6gs5YxZ8cG+oR65kQK9nMG39eQyff8hiXbGL278VT70/77sq+LqhrcS2C6kWg6/xh3fXgRuncBuk2nrq3MyZUTmroAQMw/DWEWxwKlIkzL3h8LdhWl431N9qfgAgp7AU45ccE90fF/d9mz+hc/dbyg3IOOuk5RVh7cmbWB2TjLyiUuQXl2HWlkvo8OkObDnnvNmms0W6JYvRuthdLilju9jchow7rr0Bjtz9iCkqLee14bKr5IPzt6sNl0BdbYnT6HQ6eOrEu+Otfqk7Vsck42JKLi6lWrZVqEo+XHsOAZxxQY5dy0TjD/9TfD9fbLmEB5tH4OWKCfe4zK9N3FIS7ngOtq5hF1JMs/V2FBiwznAR5G7n2x2XMfvxtijXM/h8cyxuZBdi/as9BfLjWbGuaeUOEuYy+m7nZd7sxNYe+6yWfHDW434+3FKiohLT8u92xGPxoUTj/zM3x/LG1rGdG+nMg4mEtDws2n8Vrz/cFFHVAyz2wzCOj7dha/XbuUWICPK16N0itF9bwRD3M1bjRmqtlNAWB1Y1Grv4GK8K01a8Zau0yKLNR2WbWI4Qc5P7NDFegF/r3QTh1XwQXs0X3RqHo1vjcABAu4+3IbeILeYM8vXCO/2bY8bGC5rlWW1iPUOUVlKmx+M/WZakAEASp0vu7ktpOFXRCwfgBxT5xWU4eyMbW89Ln4mYy3AR/POoqQfN/st3cB+ngSrAjhjLvUddvp2HlceS8VrvJvzeLiJtQbiXVvMGitYbnFq+uOdSGpYcvoZxPRoYl3GrXbj7/W7nZePf3MDDWcr1DBLS8i1uLk8sOIKcu6U4eyMHW9/sZZFPPcPAw4ljYP5x5BqmbbiASb3vwbv9W/BeE+pqa+vmyj0u3DFWnKXMgX0ocWM3bzslFJzxe3AJlXyYTzzHXdfRHDqGgg/idKEBPkicNQg3su6iXpi/4IVn8fiumLLmDN7s2xQD29SBv48nxt3XECeuZ+GJBYcFt7v6pe6oHx6AGRsu4GRStkOt06uSrEJpxfPcdOaf7aM/CgcwUhgugt/vst6gz/xm+uTCI9AzwMmkLAxrX9e4vJx3QxXZp41t814TeGqdsPQ4ACAx3dTLiFvtwm3msu6UeE8PsZIGR24E0zecx/LoJIvlhtFhxUoVnV14MG0D+/Awf88Vy+BDIL2t7HA/I0dKJaRyqNrFGW0+bCwTzK5ItSVAwQepInQ6nbHoV0iXhtWx32z8EIBtvFrN1wv5Zo2/vh/ZwVhqsmhsFwDsTS0psxBDfzhoLEUhrkfqgFxT1pzG5IdNXb4N186rdwpE51URK463eOoTuJTvjUtDQlo+Hu9Uz7hMp+Nvkzumi1i1izVyqjmupRdgdUwynr+/EWpU87V4/XpGAc7eyBEMPKS4nVtk9TupNpvVLpzjYG+phJwbrlrBx92ScsSn5aFt3RAbE8FZX2artMXVql2owSlxedyL0rAOkfhhVEcM61DXIp1Op0OD8ECcnNYPIf7e8PO2PL2Hto90al6JbVIfWq9nFOLHPQmCr3GXl+sZnL+Zg7JyvWiVyWmzxr0MAxxOSEf3L3Zh3Sm2N9D4Jccxc3Msoq+a5vh5a/UZbLtgql7iDj73xX+XONuTGHxwHkXjzcZk0esZXpA9bP4hLNh7Be/8dUZwWw9+vRevW+nZIoSbza+3xcla17QNx29aQvdYW/d67rGVM/eSvRx5n3Ju7KN+OYpHfzxktcQMEK4OtFnyYdZI15UaGVPwQVwe9+vy/ciONgMIL08PHPtfH5yZwZ/G/usR7fD1iHaI/3wgLs8c6IScEink9FSwNjS8wYyNFzDkh4NYHp1kNoQ6WyUxYelx3Mjit6lhwDZyTc0twlurz/B6FaSYdTl+VcKIrvY0gDSf5+elP2LQZsY24zgdhmqTmGtZFuvK4aED1sQk492/zvDaURWWWB8szmDxQX67FSUaewpXuwi31zEu4yyc+McJrDzGlviUlevxwT9nsd7GzVtsu84g5yMyBMarjidbTWe7WkooOOG38eGnl5Q9p6Hgg7i8NpEhACznkbDG18sTvl6e+GtiD/h5e+CzYa3xZJco+Hl7wtvTQ3Rbv43rgt1vP4hGNQLx1RPtFMk/4dMzDKasOS0prZyi70X7r/JmJt53+Q5+5wwLz7X/8h2cuG66qQ/54aDxb3u6wxqyeSvHesNh3nDYnLd2Lb0AO2PZYGTyylOYutY0yWF+cRnum7WLl185PHQ6vPf3Wfx14oboLMHWfLrpIqKvZmDq2nM4GJ+uSFsRRxucpuUVGz+jdaduYtXxZLy5+rTN/ap1w7UnQLM194rtBqdC63C2z5hX02iLgg/i8uaN6ojR3epj0+v3y163a8PqOP9xf4zp0dDitU+HtUbPJuG4t1F147I+LWuhcc1q2PPOQxje0bJqhzhOz9geftseN7Pv4sXfYySltTbpX4wdN3m9nsE/J26gx6zdVtNxb7l3OWOnbL3A7zlkeKo3SMkpwksV762sXC+rusVWACelHcrYxcew8lgSnv0t2q4xNjafvYWvt10y3mDt6WMjdkO/44INzW1NrCfE1udqT1dbXrUMjfNBiDy1Q/zw+WNt7V7fy1M4xh7boyHG9miIpIxCvPv3Gbz8IH9YeG9PaZfIvi0jjE+tXM/f3wi/mRVZE+B7TlfUykLPMPhqi+02FNcyCpGQlo+Lt3Ixz0ZvH3NFpeUoLClDq+nbbKZNyyuymcbA28PD2IYiI78Yk1dZBjbcEW65NzmpDWgnrWCrruqGBuCZbvVF2nzIazBpXG7jpmptHhhntYHgtg2SylYbWj3DICmjEN5eOtQJYQfWszXwmvnrjMhrWqCSD1Ll1Q8PwOqXe+DhFrV4y3U6Hb58oi3eH9ACV78YhDf7mnpeLJ3QFVe/GIQdb/XCL2O7IMiPH8c3qhGIaUNaqZL/zx9ro8p+lLIn7o7WWVBcOcPAy0NisDpnn9Uh0K0RGhxOyL2f75K8TU9Ovr/ZHodDCRlWUgO/HRQePVcKw6i+3Ia3htmXrd1IcwpLeQ1/uWwVMoxdHG38mxtsnErKwoC5B6RkW7bScj1WRCeh/3f7kSJxDB9bgVB+cRl6fb0HPWbtNqa11qbD/PVyvXmDU22jDyr5IMSKp7vWN/79Rp+mGNO9AcI53R6b1mJn8J3/TCe88HsMHmxWE75eHpjSrxkAYOWL3ZFZUIL2USE4lpiJtnVDEBbogy4zdwIA3h/QAl9u5Q9zLqZpRDXEp+Xzlv3x/L14oGlNfPrvRd7TKVGXngFSc6WXNtijoKQcB+LTFdxiRRUIJ2Zaecx6o0cA+GY7v+Tq6p18fPHfJYzoXE9kDZPC0nIUl5XzuiZ3/XwnNk++H6+tMAVk5qUZYxdH48yNHAixVWJy/qZpgDxD1U1GfjEe+0l4/CAllJYz+HAd2yZl1pZL+GFUR5vrnBV5f9xtGtzJL0ZEkJ/NNhx6RvhvQPuSDwo+CJFIp9PxAg+uXs1q4vT0fsZZfw163BNu/LteWADnb3/cyLqL0d3r47GOdeHv44mxi4/h8Y51sfhQIgpLyrH3nYewPPo6alTzRYi/N3rcE44yPYMT17NwLb0AIzrXQ5AfO3Q9t445NMAbU/o1w/QN1keIHdO9Af44Ktwgk8jz+eaLWmdBNkObE0fHOP1mexx2xt7GkSu2A6N/z6QY5x/iem7pcbMxVNg748YzKfDQQTTwAPglBr8euIoXHmiM6KsZiE7MxKTeTXhpyyu6m3auCP5t0esZeEgs0eLiPgjcFelVlJheYPfkdaN/icaOKQ/ylgmWnJiNgOo65R4UfBCiGPPAw5pdbz+IkjI9gvy8EVwRQGyYxM5l8mz3BvDQscHOS73usVi3d/MIoDl/2Yu9Ghsnk2saUc3YnqXhB5uNaWI/HYA9cWlYuO8KZgxtjU71Q3Erpwg7Y2/LfavEDHfuG3dxKCHDYvA+e9zMZkt8CiR23RXCDTwAtoQi526pzeophmF4pSgzN8dieMe6eHrRUQBAeDUfXnq9npHcE+Xy7Tx0/GwHXuvdBB3rh+KL/2LxyaNt0LZeiM11pTQ47f3NXotlmQUlOJWUhTZ1re/DUAJq3oajuKwcH649j94tamJIu0je62zgZTNbqqHggxANGLoCC/G040nr7X7NcSe3GMeuZeKrEe2Ny5/tXh9/HmV7Tvh4eWBQ2zoYxJnYrEXtIF7w8VzPRjbnI3m4RQSC/Lyw4bTlEyxxL21m2G68aouPxIbZcuyMTcMDTWvaTLfv8h3M33OFt4xb0vDDLv4gdeWM9XlhuKUHhoDo8/9ijcue/S3aYvwghmHwyb8XcU9ENeMye7o0A8CIBYdxNb1AcnpuMPHD7gS0qxeCf07ewD8nb6BNZAiv9NN8cD+tZ7ml4IOQSsDHywNznu5gsXzm8Lbw9vRAiL+3YFDz2sNNcO5mDhgAP43uhOirGRbBR6f6oTiZlA0AeLd/c2NR9tv9mmPwDweQJzKUfdeGYXip1z24t1F1tP9ku9X8NwwPQKf6YUjOKsRxBwfVIuq5kXXXKccr9lYunvr5iM1045cct1jG7d1i3g7n3zMpaFs3WHR75iUw5nLuluJQQjoyCkrwaMVgh8cSM7H08DWbeZVCTuAB8BuUbjyTgphrpsnonlvK/2zY3i7WG6iqiYIPQiq5GUNbi77m5+2JZc/da/z/4RYRmDeqI6+4+9unOhiLiEMDvI3L64cH4NiHfdFy+lZT2ifb49zNHHRtWB2D27ElLAzDIMTfW/BpMP7zgbiVXYTIUD94eXrg1wNXLW5mLesEI/YW22hw9UvdjUXqYp7oVA//nBQfx4MoZ4udMxs707D51ic95A6Lb677LNu9hEb/yvaeaVk7CMevZRnPTTE7Y2+j4Qeb0bKOeNBjL/P4gTs6r3kgcyElBxP/NPWWcmTWXiVQ8EEIMdLpdHi0fSTqhvphwpLj+GhwKzSqEYivR7TDvst3LHo0+Hp5wENnaknfu0UEnjBLo9PpEP1hHxy+ko7j17KwYK+pmNzb0wP1w7kNcU1/X/ikv3E02rJyPUrLGfj7eCJx1iA0mvqfYP67N66Ob55sZxF8DGhd22IgL2uoMS6xpd93+2WltxWkONv7/5zj/U/VLoQQl9O5QXWcmfGIcRjsJ7tE4ckuURbpPDx0ODmtH9aduokAH09UD/SxSAOwJSwPt6iFh1vUQteGYViw9wrequiOzNWvVS2M6FwPbSKDEehrujx5eXrA0ERGp9MhcdYg7L18BxMqit1nDm+Dzg3C0CA8ADqdDo93rIu1FXN9PNisJuaOZEtvbuWId4dd8WI3bDiVgr6taqFfq1qoGeSLOTvYbqUbJvW0+URNiJoOJ6TbPTkgIH0mZmfRMa40zR2A3NxchISEICcnB8HByhdTEUIqh6NXMzCyogrm8syBFvP13MgqxL7LdzCoTR2EBfqguKwcqTlFmL8nAS/1aoxF+6/iVFI2/n39fvh5Wzb+zStie1sMbheJB5rWQLcvpA/cZUuIvzeGd4jE013rY9A8y4GuPD10vCfTsT0aiM5TQyqHAB9PyZP9KaFDVCjWV/SwU4qc+zeVfBBC3BJ3CGuhiQLrhQVgdLcGxv99vTzRIDzQ2BuI2ytISJCfN5ZMYNvDpHPmD/nmyfYY3iESLadvteg5MbhtHTSrFYQnu9TDN9vjMLRdJCaYNfx75aF78F7/5oKTqxkc/19ffLj2nLGq6JNHWyMttxhbL6TC21NntccGcU9SR8hVitbVLjS8OiHELTWtVc12IoWEB/rg0faR6NaoOoa0qwMvTw8cndoHT3QytW9pXy8Ec55ujzf6NkVkqD/mPNUBvVtEYFDb2rxtvda7idXAAwCqB/rghQcaGf/X6XRYOKYzdk7phWMf9kXXhmHKvkEH3duwuu1ExKpckV5jzqJ18EHVLoQQt3UxJRehAd6IDPXXZP9FpeV47++z6NMyAsM6WJ8FeU1MMsAAT3Xlt505fi0Tq44lo1VkMOJSczHq3vroWJ8NLnbF3kaD8EA0ieAHWhn5xdh24TY6NwjD5rMpmLebHc+id/OaxrlzPD10GH9fQ97khovHd8Hyo0nYdclyIkRzckpYLn7aH8cSMzF55SnjTfSZbvWx6liS6IRwRFvNalXD9rcetJ1QBjn3bwo+CCHEzf1z4gY2n7uF2Y+3RZCfN5ZHX0e/VrWQV1SGIT8cBAAkzhoEnU6H7MISbDmfiqlrTb0f5j7dAT/sjseVOwXw8tBh0+T7UT3QB2eSc9C7eU0MmncAl2+zo2rOeao9ziRnYxmnDcq12YONf++NS0M1Xy90aVgdK6KTjHOcOOqHUR0Rn5aPHRdv2+w5Mure+lh5LAmD29XB5rO3jMvf6tsMBxPuyB6bhBvUcdUN9cdNiRPHuZp7agZi19sPKbpNCj4IIYQAYAfWqhvmj071+VU1WQUlKCgpQ+1gdowVhmFwLDETLWoHI4QzngvAjtXy0frzqBcWgFceYof8X7T/inHMDG7wwVVUWo53/jqDfq1qoVP9MNzMvosmEdWw5FCixcikYn4a3Qm+Xh7o05Kddbpcz2DernjsuHgbi8d3Ra+v96CkTI8D7/XGy3+cQEm5Hpsn3w9PnQ5enh7YdDYFr604hYbhAdj7bm+8vvKU4Pwy1nzzZHu889cZi+VXvhiEd/46g3UVPavqVw9AUmahrG1rpWWdYGx54wFFt0nBByGEEKcqKi3Hdzsu4+EWEejWONz2CmYS0vLQd45prIztb/XC6uPJCAvwRu8WESgp08NDp0P7qFDJ22QYdu4WL09+c8bUnCKE+HvD38cTablFeH3lKSRnFkKn0xlLLr4f2QH74u7gqa5Rxl5UEx+8B/7enpjcpwmuphcg+momtl1Ixb7Ld9C/dS38PKYLADYgOnwlHfXCAowD8l2bPRhfbr3EG9dGjoggX/z5Qjf0n7vfKXOyULWLGQo+CCGkamj/yXbjyLdipSfOpNcz+OTfC2hXL5Q3OF56fjHulpQjqnqAxTqZBSXYfO4WHm0XaVFCBABX7uQjyNcLEcF+ANggrbhUj3f/PoPHOtbFK8tP8tJHBPlixYvdkZJ9Fy1qByE9vwQf/3sB7/Zvjq4NqyOvqBQPf7sPd/L4Q7/b6po7/r6GVod9b1wzELup2sWEgg9CCKkarqUX4LNNF/Fq73vQuUHV6DHzwrIY3mSOhrY41rSdsQ15ZjMQn/+kP7rM3IFQfx925F/OcOqPto9Eg/AA/LCbP7Hek53roWeTGigt1yPE3xuPtOb3xHIUjfNBCCHE5TWsEYjfxnfVOhuq+ml0JzT7aIvxf1uBBwA81CLCop1KNV8vxHzUDzqwIwgzDIPfDiaCAVtdlJZbhMUHEzG0fST6tqyFY9cy8f6AFnbNmu0MVPJBCCGEqKi4rBzz91xB7+Y1jd2qrckpLGW7agP4/L9YANKqqcrK9RbtX5yJSj4IIYQQF+Xr5YkpAnMbiQkJ8MaLvRpDr2cQ5OeFTg2kDTKnZuAhFwUfhBBCiBvw8NBh5L31tc6GIlw3LCKEEEJIpUTBByGEEEJURcEHIYQQQlSlePAxa9YsdO3aFUFBQYiIiMDw4cMRFxen9G4IIYQQ4qYUDz727duHSZMm4ejRo9ixYwdKS0vxyCOPoKCgwPbKhBBCCKn0nD7Ox507dxAREYF9+/ahV69eNtPTOB+EEEKI+3GpcT5ycnIAANWrCw+dW1xcjOJi05j1ubnWp0omhBBCiHtzaoNTvV6PN998Ez179kSbNm0E08yaNQshISHGn6ioKGdmiRBCCCEac2q1yyuvvIItW7bg4MGDqFevnmAaoZKPqKgoqnYhhBBC3IhLVLu89tpr2LRpE/bv3y8aeACAr68vfH19nZUNQgghhLgYxYMPhmHw+uuvY926ddi7dy8aNWqk9C4IIYQQ4sYUDz4mTZqEFStWYMOGDQgKCkJqaioAICQkBP7+/krvjhBCCCFuRvE2HzqdTnD5kiVLMH78eJvrU1dbQgghxP1o2ubD0VjGsD51uSWEEELch+G+LSUOcPo4H3Ll5eUBAHW5JYQQQtxQXl4eQkJCrKZx+gincun1eqSkpCAoKEi0Csdehm68ycnJVKXjAuh4uBY6Hq6HjolroeNhHcMwyMvLQ2RkJDw8rA8j5nIlHx4eHla75iohODiYThwXQsfDtdDxcD10TFwLHQ9xtko8DJw6wikhhBBCiDkKPgghhBCiqioVfPj6+mLGjBk0oqqLoOPhWuh4uB46Jq6FjodyXK7BKSGEEEIqtypV8kEIIYQQ7VHwQQghhBBVUfBBCCGEEFVR8EEIIYQQVVWZ4GP+/Plo2LAh/Pz80K1bNxw7dkzrLFVKH3/8MXQ6He+nRYsWxteLioowadIkhIeHo1q1anjiiSdw+/Zt3jaSkpIwePBgBAQEICIiAu+++y7KysrUfituaf/+/Rg6dCgiIyOh0+mwfv163usMw2D69OmoU6cO/P390bdvX8THx/PSZGZmYvTo0QgODkZoaCief/555Ofn89KcPXsWDzzwAPz8/BAVFYWvvvrK2W/Nbdk6JuPHj7f4zgwYMICXho6JMmbNmoWuXbsiKCgIERERGD58OOLi4nhplLpG7d27F506dYKvry+aNGmCpUuXOvvtuZUqEXysXr0aU6ZMwYwZM3Dy5Em0b98e/fv3R1pamtZZq5Rat26NW7duGX8OHjxofO2tt97Cv//+i7/++gv79u1DSkoKHn/8cePr5eXlGDx4MEpKSnD48GEsW7YMS5cuxfTp07V4K26noKAA7du3x/z58wVf/+qrrzBv3jwsXLgQ0dHRCAwMRP/+/VFUVGRMM3r0aFy4cAE7duzApk2bsH//frz00kvG13Nzc/HII4+gQYMGOHHiBL7++mt8/PHHWLRokdPfnzuydUwAYMCAAbzvzMqVK3mv0zFRxr59+zBp0iQcPXoUO3bsQGlpKR555BEUFBQY0yhxjUpMTMTgwYPRu3dvnD59Gm+++SZeeOEFbNu2TdX369KYKuDee+9lJk2aZPy/vLyciYyMZGbNmqVhriqnGTNmMO3btxd8LTs7m/H29mb++usv47LY2FgGAHPkyBGGYRjmv//+Yzw8PJjU1FRjmgULFjDBwcFMcXGxU/Ne2QBg1q1bZ/xfr9cztWvXZr7++mvjsuzsbMbX15dZuXIlwzAMc/HiRQYAc/z4cWOaLVu2MDqdjrl58ybDMAzz008/MWFhYbzj8f777zPNmzd38jtyf+bHhGEYZty4ccywYcNE16Fj4jxpaWkMAGbfvn0Mwyh3jXrvvfeY1q1b8/b19NNPM/3793f2W3Iblb7ko6SkBCdOnEDfvn2Nyzw8PNC3b18cOXJEw5xVXvHx8YiMjETjxo0xevRoJCUlAQBOnDiB0tJS3rFo0aIF6tevbzwWR44cQdu2bVGrVi1jmv79+yM3NxcXLlxQ941UMomJiUhNTeV9/iEhIejWrRvv8w8NDUWXLl2Mafr27QsPDw9ER0cb0/Tq1Qs+Pj7GNP3790dcXByysrJUejeVy969exEREYHmzZvjlVdeQUZGhvE1OibOk5OTAwCoXr06AOWuUUeOHOFtw5CG7jkmlT74SE9PR3l5Oe9EAYBatWohNTVVo1xVXt26dcPSpUuxdetWLFiwAImJiXjggQeQl5eH1NRU+Pj4IDQ0lLcO91ikpqYKHivDa8R+hs/P2nchNTUVERERvNe9vLxQvXp1OkZOMmDAAPz+++/YtWsXvvzyS+zbtw8DBw5EeXk5ADomzqLX6/Hmm2+iZ8+eaNOmDQAodo0SS5Obm4u7d+864+24HZeb1Za4t4EDBxr/bteuHbp164YGDRpgzZo18Pf31zBnhLimkSNHGv9u27Yt2rVrh3vuuQd79+5Fnz59NMxZ5TZp0iScP3+e1yaNqKfSl3zUqFEDnp6eFq2Vb9++jdq1a2uUq6ojNDQUzZo1Q0JCAmrXro2SkhJkZ2fz0nCPRe3atQWPleE1Yj/D52ftu1C7dm2LhthlZWXIzMykY6SSxo0bo0aNGkhISABAx8QZXnvtNWzatAl79uxBvXr1jMuVukaJpQkODqaHsAqVPvjw8fFB586dsWvXLuMyvV6PXbt2oUePHhrmrGrIz8/HlStXUKdOHXTu3Bne3t68YxEXF4ekpCTjsejRowfOnTvHu9ju2LEDwcHBaNWqler5r0waNWqE2rVr8z7/3NxcREdH8z7/7OxsnDhxwphm9+7d0Ov16NatmzHN/v37UVpaakyzY8cONG/eHGFhYSq9m8rrxo0byMjIQJ06dQDQMVESwzB47bXXsG7dOuzevRuNGjXiva7UNapHjx68bRjS0D2HQ+sWr2pYtWoV4+vryyxdupS5ePEi89JLLzGhoaG81spEGW+//Tazd+9eJjExkTl06BDTt29fpkaNGkxaWhrDMAwzceJEpn79+szu3buZmJgYpkePHkyPHj2M65eVlTFt2rRhHnnkEeb06dPM1q1bmZo1azJTp07V6i25lby8PObUqVPMqVOnGADMnDlzmFOnTjHXr19nGIZhZs+ezYSGhjIbNmxgzp49ywwbNoxp1KgRc/fuXeM2BgwYwHTs2JGJjo5mDh48yDRt2pQZNWqU8fXs7GymVq1azJgxY5jz588zq1atYgICApiff/5Z9ffrDqwdk7y8POadd95hjhw5wiQmJjI7d+5kOnXqxDRt2pQpKioyboOOiTJeeeUVJiQkhNm7dy9z69Yt409hYaExjRLXqKtXrzIBAQHMu+++y8TGxjLz589nPD09ma1bt6r6fl1ZlQg+GIZhfvjhB6Z+/fqMj48Pc++99zJHjx7VOkuV0tNPP83UqVOH8fHxYerWrcs8/fTTTEJCgvH1u3fvMq+++ioTFhbGBAQEMI899hhz69Yt3jauXbvGDBw4kPH392dq1KjBvP3220xpaanab8Ut7dmzhwFg8TNu3DiGYdjuttOmTWNq1arF+Pr6Mn369GHi4uJ428jIyGBGjRrFVKtWjQkODmYmTJjA5OXl8dKcOXOGuf/++xlfX1+mbt26zOzZs9V6i27H2jEpLCxkHnnkEaZmzZqMt7c306BBA+bFF1+0eDCiY6IMoeMAgFmyZIkxjVLXqD179jAdOnRgfHx8mMaNG/P2QRhGxzAMo3ZpCyGEEEKqrkrf5oMQQgghroWCD0IIIYSoioIPQgghhKiKgg9CCCGEqIqCD0IIIYSoioIPQgghhKiKgg9CCCGEqIqCD0IIIYSoioIPQgghhKiKgg9CCCGEqIqCD0IIIYSoioIPQgghhKjq/zPwkw5a3AxeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(history)\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot()\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))\n",
    "\n",
    "# plt.plot(history.history['accuracy'], label='accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.ylim([0.5, 1])\n",
    "# plt.legend(loc='lower right')\n",
    "\n",
    "# test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_acc)\n",
    "\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: out\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: out\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('out')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
